{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: BILATERAL EQUITY & DEBT INVESTMENT POSITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: INITIALIZATION\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1) ### To display long strings\n",
    "import math\n",
    "import requests\n",
    "import json ### To correct JSON structure before unpacking\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version:  0.25.3\n",
      "numpy version:  1.17.2\n",
      "python version:  3.7.4\n"
     ]
    }
   ],
   "source": [
    "### RUN EVERY TIME: VERSION CONTROL\n",
    "\n",
    "from platform import python_version\n",
    "print('pandas version: ', pd.__version__)\n",
    "print('numpy version: ', np.__version__)\n",
    "print('python version: ', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: MAIN CONSTANTS\n",
    "\n",
    "### MultiIndex level slice constant:\n",
    "All = slice(None)\n",
    "### Universe path:\n",
    "str_path_universe = 'Data_Files/Source_Files/acadian_universe.xlsx'\n",
    "### Detailed IMF CPIS dataset:\n",
    "str_path_imf_cpis_detailed_raw = 'Data_Files/Source_Files/cpis_detailed_raw.h5'\n",
    "str_key_imf_cpis_assets = 'cpis_detailed_assets'\n",
    "str_key_imf_cpis_liabilities = 'cpis_detailed_liabilities'\n",
    "str_path_imf_cpis_total_augmented = 'Data_Files/Source_Files/cpis_total_augmented.h5'\n",
    "str_key_imf_cpis_total_augmented = 'cpis_total_augmented'\n",
    "str_path_total_imf_cpis_options = 'Data_Files/Source_Files/cpis_total_options.h5'\n",
    "str_key_total_imf_cpis_options = 'cpis_total_options'\n",
    "### Filtered IMF CPIS dataset:\n",
    "str_path_imf_cpis_filtered = 'Data_Files/Source_Files/cpis_filtered.h5'\n",
    "str_key_imf_cpis_filtered_asset = 'cpis_filtered_asset'\n",
    "str_key_imf_cpis_filtered_liability = 'cpis_filtered_liability'\n",
    "str_path_imf_cpis_filtered_augmented = 'Data_Files/Source_Files/cpis_filtered_augmented.h5'\n",
    "str_key_imf_cpis_filtered_augmented = 'cpis_filtered_augmented'\n",
    "str_path_filtered_imf_cpis_options = 'Data_Files/Source_Files/cpis_filtered_options.h5'\n",
    "str_key_filtered_imf_cpis_options = 'cpis_filtered_options'\n",
    "### Direct Investment Options:\n",
    "str_path_total_direct_options = 'Data_Files/Source_Files/direct_total_options.h5'\n",
    "str_key_total_direct_options = 'direct_total_options'\n",
    "str_path_equity_direct_options = 'Data_Files/Source_Files/direct_equity_options.h5'\n",
    "str_key_equity_direct_options = 'direct_equity_options'\n",
    "### Full Investment Options:\n",
    "str_path_total_investment_options = 'Data_Files/Source_Files/investment_total_options.h5'\n",
    "str_key_total_investment_options = 'investment_total_options'\n",
    "str_path_filtered_investment_options = 'Data_Files/Source_Files/investment_filtered_options.h5'\n",
    "str_key_filtered_investment_options = 'investment_filtered_options'\n",
    "### Technical Constants:\n",
    "str_date_end = '2022-10-31'\n",
    "date_start = pd.Timestamp('1989-12-29')\n",
    "date_end = pd.Timestamp(str_date_end)\n",
    "date_ison = pd.Timestamp('1994-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING COUNTRY CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    ### In case if URL is unavailable:\n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    ### Online extraction:\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']].sort_index()    \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "    ### Results output:\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM MS EXCEL SOURCE (TO BE IGNORED IN PRODUCT CODE)\n",
    "\n",
    "def ison_membership_converting(str_path_universe, date_end, bool_daily = False, int_backfill_months = 0):\n",
    "    ### Defining business-month-end reindexation on country level:\n",
    "    def country_modify(ser_raw_country, date_end):\n",
    "        ser_res_country = ser_raw_country.droplevel(0).resample('MS').last().resample('BM').last()\n",
    "        range_country = pd.date_range(ser_res_country.index[0], date_end, freq = 'BM')\n",
    "        return ser_res_country.reindex(range_country).ffill()\n",
    "    ### Markets encoding table:\n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM', 0: np.NaN}     \n",
    "    ### Loading source file:\n",
    "    df_raw_universe = pd.read_excel(engine = 'openpyxl', io = str_path_universe, sheet_name = 'Switchers', header = 0, parse_dates = True, index_col = [0, 1],\n",
    "                                 na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    ### Converting source file:\n",
    "    df_raw_universe.index.names = ['Country', 'Date']\n",
    "    ser_raw_universe = df_raw_universe['Region']\n",
    "    ser_raw_universe.fillna(0, inplace = True)\n",
    "    ser_raw_universe.name = 'Market'\n",
    "    ### By country reindexation and translation:\n",
    "    ser_res_universe = ser_raw_universe.groupby('Country').apply(country_modify, date_end)\n",
    "    ser_res_universe.index.names = ['Country', 'Date']\n",
    "    ser_res_universe = ser_res_universe.replace(dict_markets).reorder_levels([1, 0]).sort_index() \n",
    "    ### Expanding membership for primary regions members by backfilling:\n",
    "    if int_backfill_months:\n",
    "        ### List of regions:\n",
    "        list_region = list(ser_res_universe.dropna().unique())\n",
    "        ### Initialising of collection of series with backfilled data for each region:\n",
    "        list_ison_backfill = []\n",
    "        ### Regions looping:\n",
    "        for iter_region in list_region:\n",
    "            ### Defining start of region date:\n",
    "            date_first_valid = ser_res_universe.loc[ser_res_universe == iter_region].first_valid_index()[0]\n",
    "            ### Creating dates index to backfilling:\n",
    "            idx_date_backfill = pd.date_range(end = date_first_valid, periods = int_backfill_months + 1, freq = 'BM')[: -1]\n",
    "            ### Creating primary countries index to backfilling:            \n",
    "            idx_region_backfill = ser_res_universe.loc[ser_res_universe == iter_region].loc[date_first_valid, All].index.get_level_values('Country')\n",
    "            ### Creating full index:\n",
    "            idx_ison_backfill = pd.MultiIndex.from_product([idx_date_backfill, idx_region_backfill])\n",
    "            ### Series with backfilled data:\n",
    "            list_ison_backfill.append(pd.Series(iter_region, index = idx_ison_backfill))\n",
    "        ### Combination of backfilled series and original ISON data:    \n",
    "        ser_res_universe = ser_res_universe.combine_first(pd.concat(list_ison_backfill, axis = 0)).sort_index()  \n",
    "        ser_res_universe.index.names = ['Date', 'Country']\n",
    "    ### Converting to daily frequency:\n",
    "    if bool_daily:\n",
    "        ser_res_universe = ser_res_universe.reset_index('Country').groupby('Country').resample('B').ffill()['Market'].swaplevel().sort_index()    \n",
    "    ### Results output:\n",
    "    ser_res_universe.name = 'Market'\n",
    "    return ser_res_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: COMMON DATA EXTRACTION STEPS\n",
    "\n",
    "### World Country Codes:\n",
    "df_country_codes = get_country_codes()\n",
    "### ISON membership history:\n",
    "ser_ison_membership = ison_membership_converting(str_path_universe, pd.to_datetime(str_date_end))\n",
    "### ISON LONG IDs list:\n",
    "list_ison_long = list(df_country_codes.loc[df_country_codes['ISO SHORT'].isin(ser_ison_membership.index.get_level_values('Country').unique()), 'ISO LONG'].values)\n",
    "### ISON current status:\n",
    "ser_ison_status = ser_ison_membership.loc[str_date_end].droplevel('Date')\n",
    "### ISON stats:\n",
    "int_ison_number = len(list_ison_long)\n",
    "list_regions = ['DM', 'EM', 'FM']\n",
    "dict_ison_len = {}\n",
    "dict_ison_len['Full Universe'] = int_ison_number\n",
    "for iter_region in list_regions:\n",
    "    dict_ison_len[iter_region] = len(ser_ison_status[ser_ison_status == iter_region])\n",
    "ser_market_len = pd.Series(dict_ison_len)\n",
    "ser_market_len.index.names = ['Market']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "dict_request_headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "str_imf_base_url = 'http://dataservices.imf.org/REST/SDMX_JSON.svc/'\n",
    "str_imf_dataflow_add = 'DataFlow'\n",
    "str_imf_datastructure_add = 'DataStructure/'\n",
    "str_imf_codelist_add = 'CodeList/'\n",
    "str_imf_dataset_add = 'CompactData/'\n",
    "int_seconds_to_sleep = 1\n",
    "int_imf_country_limit = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: REQUESTS SESSION INITIALIZING\n",
    "\n",
    "request_session = requests.Session()\n",
    "### For avoiding data request errors from IMF Data Service:\n",
    "request_session.headers.update(dict_request_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPIS\n"
     ]
    }
   ],
   "source": [
    "### IMF CPIS: DATAFLOW SEARCHING\n",
    "\n",
    "obj_imf_dataflow_list = request_session.get(str_imf_base_url + str_imf_dataflow_add).json()\n",
    "df_imf_dataflow = pd.DataFrame(obj_imf_dataflow_list['Structure']['Dataflows']['Dataflow'])\n",
    "df_imf_dataflow = df_imf_dataflow.assign(Description = df_imf_dataflow['Name'].apply(pd.Series)['#text'].values)[['@id', 'Description']]\n",
    "ser_imf_dataflow = df_imf_dataflow.set_index('@id', drop = True).squeeze()\n",
    "### Searching DataFlow code for further requests:\n",
    "str_imf_cpis_id = ser_imf_dataflow[ser_imf_dataflow.str.contains('CPIS')].index[0].replace('DS-', '')\n",
    "print(str_imf_cpis_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          @conceptRef          @codelist @isFrequencyDimension\n",
      "0  FREQ                CL_FREQ            true                \n",
      "1  REF_AREA            CL_AREA_CPIS       NaN                 \n",
      "2  INDICATOR           CL_INDICATOR_CPIS  NaN                 \n",
      "3  REF_SECTOR          CL_SECTOR_CPIS     NaN                 \n",
      "4  COUNTERPART_SECTOR  CL_SECTOR_CPIS     NaN                 \n",
      "5  COUNTERPART_AREA    CL_AREA_CPIS       NaN                 \n"
     ]
    }
   ],
   "source": [
    "### IMF CPIS: DATASTRUCTURE SEARCHING\n",
    "\n",
    "obj_imf_cpis_structure = request_session.get(str_imf_base_url + str_imf_datastructure_add + str_imf_cpis_id).json()\n",
    "df_imf_cpis_params = pd.DataFrame(obj_imf_cpis_structure['Structure']['KeyFamilies']['KeyFamily']['Components']['Dimension'])\\\n",
    "                                [['@conceptRef', '@codelist', '@isFrequencyDimension']]\n",
    "### Receiving DataFlow parameters and code lists for each of them:\n",
    "print(df_imf_cpis_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: CODES DESCRIPTIONS LOADING\n",
    "\n",
    "for int_counter, str_param_code in enumerate(df_imf_cpis_params['@codelist']):\n",
    "    if (int_counter == 2):\n",
    "        time.sleep(int_seconds_to_sleep)    \n",
    "        obj_imf_cpis_param = request_session.get(str_imf_base_url + str_imf_codelist_add + str_param_code).json()\n",
    "        df_imf_cpis_param =  pd.DataFrame(obj_imf_cpis_param['Structure']['CodeLists']['CodeList']['Code'])\n",
    "        ### Receiving values for each code list:\n",
    "        df_imf_cpis_param = df_imf_cpis_param.assign(Text = df_imf_cpis_param['Description'].apply(pd.Series)['#text'].values)[['@value', 'Text']]\n",
    "#        print(int_counter, ':', df_imf_cpis_params.iloc[int_counter, All]['@conceptRef'], ':', str_param_code, ':\\n', df_imf_cpis_param.head(20))\n",
    "        dict_indicator = dict(zip(df_imf_cpis_param[: 10]['@value'], df_imf_cpis_param[: 10]['Text']))\n",
    "    elif (int_counter == 3):\n",
    "        time.sleep(int_seconds_to_sleep)    \n",
    "        obj_imf_cpis_param = request_session.get(str_imf_base_url + str_imf_codelist_add + str_param_code).json()\n",
    "        df_imf_cpis_param =  pd.DataFrame(obj_imf_cpis_param['Structure']['CodeLists']['CodeList']['Code'])\n",
    "        ### Receiving values for each code list:\n",
    "        df_imf_cpis_param = df_imf_cpis_param.assign(Text = df_imf_cpis_param['Description'].apply(pd.Series)['#text'].values)[['@value', 'Text']]\n",
    "#        print(int_counter, ':', df_imf_cpis_params.iloc[int_counter, All]['@conceptRef'], ':', str_param_code, ':\\n', df_imf_cpis_param.head(20))        \n",
    "        dict_sector = dict(zip(df_imf_cpis_param['@value'], df_imf_cpis_param['Text']))\n",
    "        list_sector_filtered = ['T', 'CB', 'GG', 'HH', 'NP']\n",
    "\n",
    "list_ison_countries = sorted(list(map(str, ser_ison_membership.index.get_level_values(1).unique())))\n",
    "str_cpis_freq = 'A' # 'B' # \n",
    "#str_cpis_asset_indicator = 'I_A_T_T_T_BP6_USD' \n",
    "#str_cpis_liability_indicator = 'I_L_T_T_T_BP6_USD'\n",
    "#str_cpis_ref_sector = 'T'\n",
    "#str_cpis_cp_sector = 'T'\n",
    "# 0: FREQ == 'B' # Semi-annual frequency - they don't have Quaterly or Monthly frequency data\n",
    "# 1: REF_AREA == '??' # Country\n",
    "# 2: INDICATOR  == 'I_A_T_T_T_BP6_USD' # Assets, Total Investment, BPM6, US Dollars & I_L_T_T_T_BP6_USD    Liabilities, Total Investment, BPM6, US Dollars\n",
    "# 3: REF_SECTOR == 'T' # Total Holdings (all sectors)\n",
    "# 4: COUNTERPART_SECTOR  == 'T' # Total Holdings (all sectors)\n",
    "# 5: COUNTERPART_AREA == '??' # Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS : REPORTED PORTFOLIO INVESTMENT ASSETS DATASET RETRIEVING\n",
    "\n",
    "gc.collect()\n",
    "### List of bilateral dataframes for future concatenation:\n",
    "list_cpis_bilateral = [] \n",
    "### Beggining of request URL:\n",
    "str_cpis_const_url = str_imf_base_url + str_imf_dataset_add + str_imf_cpis_id + '/' \n",
    "### Looping over reporter:\n",
    "for iter_investor in list_ison_countries:\n",
    "#for iter_reporter in ['US', 'BD']:  \n",
    "    ### Looping over indicator:\n",
    "    for iter_indicator in dict_indicator:        \n",
    "        if (iter_indicator[2] == 'A'):\n",
    "            str_reporter_sector = '+'.join(list_sector_filtered)        \n",
    "            str_partner_sector = '+'.join(list_sector_filtered)\n",
    "            str_cpis_full_url = str_cpis_const_url + '.'.join([str_cpis_freq, iter_investor, iter_indicator, str_reporter_sector, str_partner_sector])\n",
    "            obj_cpis_set = request_session.get(str_cpis_full_url)\n",
    "            ### Data reading as JSON:\n",
    "            dict_cpis_set = json.loads(obj_cpis_set.text.replace('@OBS_STATUS', '@OBS_VALUE'))\n",
    "            ### Converting each bilateral dataset to dataframe and it's mungling:\n",
    "            if ('Series' in dict_cpis_set['CompactData']['DataSet']):\n",
    "                if isinstance(dict_cpis_set['CompactData']['DataSet']['Series'], list):\n",
    "                    list_series = dict_cpis_set['CompactData']['DataSet']['Series']\n",
    "                else:\n",
    "                    list_series = [dict_cpis_set['CompactData']['DataSet']['Series']]\n",
    "                for dict_cpis_pair in list_series:\n",
    "                    if isinstance(dict_cpis_pair['Obs'], list):\n",
    "                        dict_bilateral = dict_cpis_pair['Obs']\n",
    "                    else:\n",
    "                        dict_bilateral = [dict_cpis_pair['Obs']]\n",
    "                    df_cpis_bilateral = pd.DataFrame(dict_bilateral)\n",
    "                    df_cpis_bilateral = df_cpis_bilateral[['@TIME_PERIOD', '@OBS_VALUE']]\n",
    "                    df_cpis_bilateral.columns = ['Date', 'Value']\n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Indicator = dict_cpis_pair['@INDICATOR'])\n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Reporter_Sector = dict_cpis_pair['@REF_SECTOR'])\n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Partner_Sector = dict_cpis_pair['@COUNTERPART_SECTOR'])                    \n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Reporter_ID = dict_cpis_pair['@REF_AREA'])\n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Partner_ID = dict_cpis_pair['@COUNTERPART_AREA'])\n",
    "                    list_cpis_bilateral.append(df_cpis_bilateral)  \n",
    "            else:\n",
    "                print('No data in response of the next request:\\n', str_cpis_full_url)\n",
    "            time.sleep(int_seconds_to_sleep)                    \n",
    "#        break\n",
    "    print(iter_investor, ': loading completed')\n",
    "#    break\n",
    "### Bilateral datasets aggregating:\n",
    "df_cpis_raw = pd.concat(list_cpis_bilateral, axis = 0, ignore_index = True)\n",
    "df_cpis_raw['Date'] = pd.to_datetime(df_cpis_raw['Date']) + pd.offsets.BYearEnd()\n",
    "df_cpis_raw.loc[df_cpis_raw['Value'] == 'C', 'Value'] = np.NaN\n",
    "df_cpis_raw.loc[df_cpis_raw['Value'] == '-', 'Value'] = np.NaN\n",
    "df_cpis_raw = df_cpis_raw[df_cpis_raw['Reporter_ID'] != df_cpis_raw['Partner_ID']]\n",
    "df_cpis_raw = df_cpis_raw[df_cpis_raw['Partner_ID'].isin(df_country_codes['ISO SHORT'].values)]\n",
    "print('Unique partners number:', len(df_cpis_raw['Partner_ID'].unique()))\n",
    "df_cpis_raw.rename({'Reporter_ID': 'Reporter', 'Partner_ID': 'Partner'}, axis = 1, inplace = True)\n",
    "df_cpis_raw = df_cpis_raw.astype({'Indicator': 'str', 'Reporter_Sector': 'str', 'Partner_Sector': 'str', 'Reporter': 'str', 'Partner': 'str', \n",
    "                                  'Value': 'float32'})    \n",
    "### Data saving:\n",
    "ser_cpis_asset = df_cpis_raw.set_index(['Date', 'Indicator', 'Reporter_Sector', 'Partner_Sector', 'Reporter', 'Partner'])['Value'].sort_index().astype('float32')\n",
    "del df_cpis_raw\n",
    "gc.collect()\n",
    "ser_cpis_asset.to_hdf(path_or_buf = str_path_imf_cpis_detailed_raw, key = str_key_imf_cpis_assets, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS : REPORTED PORTFOLIO INVESTMENT LIABILITIES DATASET RETRIEVING\n",
    "\n",
    "gc.collect()\n",
    "### List of bilateral dataframes for future concatenation:\n",
    "list_cpis_bilateral = [] \n",
    "### Beggining of request URL:\n",
    "str_cpis_const_url = str_imf_base_url + str_imf_dataset_add + str_imf_cpis_id + '/' \n",
    "### Looping over reporter:\n",
    "for iter_investor in list_ison_countries:\n",
    "#for iter_investor in ['US', 'BD']:  \n",
    "    ### Looping over indicator:\n",
    "    for iter_indicator in dict_indicator:        \n",
    "        if (iter_indicator[2] == 'L'):\n",
    "            str_reporter_sector = '+'.join(list_sector_filtered)        \n",
    "            str_partner_sector = '+'.join(list_sector_filtered)\n",
    "            str_cpis_full_url = str_cpis_const_url + '.'.join([str_cpis_freq, '', iter_indicator, str_reporter_sector, str_partner_sector, iter_investor])\n",
    "            obj_cpis_set = request_session.get(str_cpis_full_url)\n",
    "            ### Data reading as JSON:\n",
    "            dict_cpis_set = json.loads(obj_cpis_set.text.replace('@OBS_STATUS', '@OBS_VALUE'))\n",
    "            ### Converting each bilateral dataset to dataframe and it's mungling:\n",
    "            if ('Series' in dict_cpis_set['CompactData']['DataSet']):\n",
    "                if isinstance(dict_cpis_set['CompactData']['DataSet']['Series'], list):\n",
    "                    list_series = dict_cpis_set['CompactData']['DataSet']['Series']\n",
    "                else:\n",
    "                    list_series = [dict_cpis_set['CompactData']['DataSet']['Series']]\n",
    "                for dict_cpis_pair in list_series:\n",
    "                    if isinstance(dict_cpis_pair['Obs'], list):\n",
    "                        dict_bilateral = dict_cpis_pair['Obs']\n",
    "                    else:\n",
    "                        dict_bilateral = [dict_cpis_pair['Obs']]\n",
    "                    df_cpis_bilateral = pd.DataFrame(dict_bilateral)\n",
    "                    df_cpis_bilateral = df_cpis_bilateral[['@TIME_PERIOD', '@OBS_VALUE']]\n",
    "                    df_cpis_bilateral.columns = ['Date', 'Value']\n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Indicator = dict_cpis_pair['@INDICATOR'])\n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Reporter_S = dict_cpis_pair['@REF_SECTOR'])\n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Partner_S = dict_cpis_pair['@COUNTERPART_SECTOR'])                    \n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Reporter_ID = dict_cpis_pair['@REF_AREA'])\n",
    "                    df_cpis_bilateral = df_cpis_bilateral.assign(Partner_ID = dict_cpis_pair['@COUNTERPART_AREA'])\n",
    "                    list_cpis_bilateral.append(df_cpis_bilateral)  \n",
    "            else:\n",
    "                print('No data in response of the next request:\\n', str_cpis_full_url)\n",
    "            time.sleep(int_seconds_to_sleep)                    \n",
    "#        break\n",
    "    print(iter_investor, ': loading completed')\n",
    "#    break\n",
    "### Bilateral datasets aggregating:\n",
    "df_cpis_raw = pd.concat(list_cpis_bilateral, axis = 0, ignore_index = True)\n",
    "df_cpis_raw['Date'] = pd.to_datetime(df_cpis_raw['Date']) + pd.offsets.BYearEnd()\n",
    "df_cpis_raw.loc[df_cpis_raw['Value'] == 'C', 'Value'] = np.NaN\n",
    "df_cpis_raw.loc[df_cpis_raw['Value'] == '-', 'Value'] = np.NaN\n",
    "df_cpis_raw = df_cpis_raw[df_cpis_raw['Reporter_ID'] != df_cpis_raw['Partner_ID']]\n",
    "df_cpis_raw = df_cpis_raw[df_cpis_raw['Reporter_ID'].isin(df_country_codes['ISO SHORT'].values)]\n",
    "print('Unique reporters number:', len(df_cpis_raw['Reporter_ID'].unique()))\n",
    "df_cpis_raw.rename({'Reporter_ID': 'Partner', 'Partner_ID': 'Reporter', 'Reporter_S': 'Partner_Sector', 'Partner_S': 'Reporter_Sector'}, axis = 1, inplace = True)\n",
    "df_cpis_raw = df_cpis_raw.astype({'Indicator': 'str', 'Reporter_Sector': 'str', 'Partner_Sector': 'str', 'Reporter': 'str', 'Partner': 'str', \n",
    "                                  'Value': 'float32'})    \n",
    "### Data saving:\n",
    "ser_cpis_liability_inv = df_cpis_raw.set_index(['Date', 'Indicator', 'Reporter_Sector', 'Partner_Sector', 'Reporter', 'Partner'])['Value'].sort_index()\\\n",
    "                                    .astype('float32')\n",
    "del df_cpis_raw\n",
    "gc.collect()\n",
    "ser_cpis_liability_inv.to_hdf(path_or_buf = str_path_imf_cpis_detailed_raw, key = str_key_imf_cpis_liabilities, mode = 'a', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: COUNTERPART SECTOR TEST\n",
    "\n",
    "gc.collect()\n",
    "ser_cpis_asset = pd.read_hdf(path_or_buf = str_path_imf_cpis_detailed_raw, key = str_key_imf_cpis_assets)\n",
    "ser_cpis_asset_total = ser_cpis_asset.loc[:, 'I_A_T_T_T_BP6_USD', 'T', :, :, :]\n",
    "ser_reporter_sum = ser_cpis_asset_total.groupby(['Date', 'Partner_Sector', 'Reporter']).sum()\n",
    "df_reporter_detailed = ser_reporter_sum.unstack('Partner_Sector').dropna(subset = ['CB', 'GG'], how = 'all')\n",
    "df_reporter_detailed['CB_Share'] = df_reporter_detailed['CB'] / df_reporter_detailed['T'] * 100\n",
    "df_reporter_detailed['GG_Share'] = df_reporter_detailed['GG'] / df_reporter_detailed['T'] * 100\n",
    "display(df_reporter_detailed[['CB_Share', 'GG_Share']].groupby('Reporter').median())\n",
    "#display(df_reporter_detailed.loc[(All, 'US'), ['CB_Share', 'GG_Share']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: TOTAL DATA AGGREGATION: DATASETS LOADING\n",
    "\n",
    "gc.collect()\n",
    "ser_cpis_asset = pd.read_hdf(path_or_buf = str_path_imf_cpis_detailed_raw, key = str_key_imf_cpis_assets)\n",
    "ser_cpis_asset_total = ser_cpis_asset.loc[:, 'I_A_T_T_T_BP6_USD', 'T', 'T', :, :]\n",
    "ser_cpis_asset_total.name = 'Asset'\n",
    "ser_cpis_liability_inv = pd.read_hdf(path_or_buf = str_path_imf_cpis_detailed_raw, key = str_key_imf_cpis_liabilities)\n",
    "ser_cpis_liability_inv_total = ser_cpis_liability_inv.loc[:, 'I_L_T_T_T_BP6_USD', 'T', 'T', :, :]\n",
    "ser_cpis_liability_inv_total.name = 'Liability_Inverted'\n",
    "df_cpis_total = pd.concat([ser_cpis_asset_total, ser_cpis_liability_inv_total], axis = 1, names = 'Data Source').astype('float32').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: TOTAL DATA AGGREGATION: DATA QUALITY RATIOS\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "### Defining similarity for investors by date\n",
    "def get_investor_ratio(df_group):\n",
    "#    df_group['Asset'].fillna(0.0, inplace = True)\n",
    "    df_group.fillna(0.0, inplace = True)    \n",
    "    df_both = df_group.dropna()    \n",
    "    if (df_both['Asset'].sum() > 0.0):\n",
    "        flo_result = (df_both['Asset'] - df_both['Liability_Inverted']).abs().clip(upper = df_group['Asset'].max()).sum() / df_group['Asset'].sum() / len(df_group)    \n",
    "    else:\n",
    "        flo_result = np.NaN    \n",
    "    return flo_result\n",
    "### Defining similarity for borrowers by date\n",
    "def get_borrower_ratio(df_group):\n",
    "#    df_group['Liability_Inverted'].fillna(0.0, inplace = True)\n",
    "    df_group.fillna(0.0, inplace = True)     \n",
    "    df_both = df_group.dropna()\n",
    "    if (df_both['Liability_Inverted'].sum() > 0.0):\n",
    "        flo_result = (df_both['Asset'] - df_both['Liability_Inverted']).abs().clip(upper = df_group['Liability_Inverted'].max()).sum() \\\n",
    "                                                                        / df_group['Liability_Inverted'].sum() / len(df_group)\n",
    "    else:\n",
    "        flo_result = np.NaN    \n",
    "    return flo_result\n",
    "### Similarity values calculation:\n",
    "ser_investor_ratio = df_cpis_total.groupby(['Date', 'Reporter']).apply(get_investor_ratio)\n",
    "ser_investor_ratio.name = 'Investor_Ratio'\n",
    "ser_borrower_ratio = df_cpis_total.groupby(['Date', 'Partner']).apply(get_borrower_ratio)\n",
    "ser_borrower_ratio.name = 'Borrower_Ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002 / (Timestamp('2018-12-31 00:00:00'), 'RO')\n",
      "0.8929 / (Timestamp('1997-12-31 00:00:00'), 'ES')\n"
     ]
    }
   ],
   "source": [
    "### IMF CPIS: TOTAL DATA AGGREGATION: SIMILARITY TEST\n",
    "\n",
    "print(round(ser_borrower_ratio.min(), 4), '/', ser_borrower_ratio.idxmin())\n",
    "print(round(ser_borrower_ratio.max(), 4), '/', ser_borrower_ratio.idxmax())\n",
    "\n",
    "#display(df_cpis_total.loc[('2018-12-31', All, 'RO'), :])\n",
    "#display(df_cpis_total.loc[('1997-12-31', All, 'ES'), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023 / (Timestamp('2010-12-31 00:00:00'), 'NZ')\n",
      "0.25 / (Timestamp('2002-12-31 00:00:00'), 'UA')\n"
     ]
    }
   ],
   "source": [
    "### IMF CPIS: TOTAL DATA AGGREGATION: SIMILARITY TEST\n",
    "\n",
    "print(round(ser_investor_ratio.min(), 4), '/', ser_investor_ratio.idxmin())\n",
    "print(round(ser_investor_ratio.max(), 4), '/', ser_investor_ratio.idxmax())\n",
    "\n",
    "#display(df_cpis_total.loc[('2010-12-31', 'NZ', All), :].dropna(subset = ['Liability_Inverted']))\n",
    "#display(df_cpis_total.loc[('2002-12-31', 'UA', All), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: TOTAL DATA AGGREGATION: ADDING RATIOS\n",
    "\n",
    "#df_cpis_to_augment = df_cpis_total.join(ser_investor_rank).join(ser_borrower_rank)\n",
    "df_cpis_to_augment = df_cpis_total.join(ser_investor_ratio).join(ser_borrower_ratio)\n",
    "df_cpis_to_augment['Asset_Augmented'] = np.NaN # -999 # \n",
    "#df_cpis_augmented['Verified'] = False\n",
    "df_cpis_to_augment = df_cpis_to_augment.reorder_levels(['Date', 'Reporter', 'Partner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: TOTAL DATA AGGREGATION: CONDITIONAL REPLACING\n",
    "\n",
    "gc.collect()\n",
    "def augment_by_date(df_date, int_option = 0):\n",
    "    '''\n",
    "       -1 : Replace NaN Asset values unconditionally\n",
    "        0 : Replace NaN Asset values when Investor's Ratio > Borrower's Ratio\n",
    "        1 : Replace NaN or zero Asset values when Investor's Ratio > Borrower's Ratio\n",
    "        2 : Replace any Asset values when Investor's Ratio > Borrower's Ratio\n",
    "    '''\n",
    "    if (int_option == -1):\n",
    "        ### Replacing zero Asset & Liability values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN        \n",
    "        df_date['Asset_Augmented'] = df_date['Asset'].combine_first(df_date['Liability_Inverted'])\n",
    "    elif (int_option == 0):\n",
    "        ### Fill resulting column with not NaN Asset values:\n",
    "        df_date.loc[df_date['Asset'].notna(), 'Asset_Augmented'] = df_date[df_date['Asset'].notna()]['Asset'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is NaN (and doesn't matter if Borrower Ratio is NaN):\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna(), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna()]['Liability_Inverted'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is bigger than Borrower Ratio:\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio']), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio'])]['Liability_Inverted'].values\n",
    "    elif (int_option == 1):\n",
    "        ### Replacing zero Asset values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN\n",
    "        ### Fill resulting column with not NaN Asset values:\n",
    "        df_date.loc[df_date['Asset'].notna(), 'Asset_Augmented'] = df_date.loc[df_date['Asset'].notna(), 'Asset'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is NaN (and doesn't matter if Borrower Ratio is NaN):\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna(), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna()]['Liability_Inverted'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is bigger than Borrower Ratio:\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio']), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio'])]['Liability_Inverted'].values\n",
    "    else:\n",
    "        ### Replacing zero Asset & Liability values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN        \n",
    "        df_date.loc[df_date['Liability_Inverted'] == 0.0, 'Liability_Inverted'] = np.NaN\n",
    "        ### Ratios preparation:\n",
    "        df_date.loc[df_date['Investor_Ratio'].isna(), 'Investor_Ratio'] = 999.0\n",
    "        df_date.loc[df_date['Borrower_Ratio'].isna(), 'Borrower_Ratio'] = 1000.0\n",
    "        ### Ratios comparision:\n",
    "        df_date.loc[df_date['Investor_Ratio'] <= df_date['Borrower_Ratio'], 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Investor_Ratio'] <= df_date['Borrower_Ratio']]['Asset'].values\n",
    "        df_date.loc[df_date['Investor_Ratio'] > df_date['Borrower_Ratio'], 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Investor_Ratio'] > df_date['Borrower_Ratio']]['Liability_Inverted'].values                                       \n",
    "    return df_date\n",
    "\n",
    "dict_cpis_augmented = {}\n",
    "dict_cpis_augmented[-1] = df_cpis_to_augment.groupby('Date').apply(augment_by_date, -1)\n",
    "dict_cpis_augmented[0] = df_cpis_to_augment.groupby('Date').apply(augment_by_date, 0)\n",
    "dict_cpis_augmented[1] = df_cpis_to_augment.groupby('Date').apply(augment_by_date, 1)\n",
    "dict_cpis_augmented[2] = df_cpis_to_augment.groupby('Date').apply(augment_by_date, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: TOTAL DATA AGGREGATION: RESULTS TESTING\n",
    "\n",
    "ser_quantity = df_cpis_to_augment['Asset'].replace({0.0: np.NaN}).groupby(['Date','Reporter']).count()\n",
    "ser_quantity = ser_quantity[ser_quantity > 0].groupby('Date').count()\n",
    "ser_quantity.name = 'raw'\n",
    "ser_quantity.to_excel('Data_Files/Test_Files/Augmentation_Test_' + ser_quantity.name + '.xlsx', merge_cells = False)\n",
    "\n",
    "for iter_option in dict_cpis_augmented:\n",
    "    dt_option = dict_cpis_augmented[iter_option]\n",
    "    ser_quantity = dt_option['Asset_Augmented'].replace({0.0: np.NaN}).groupby(['Date','Reporter']).count()\n",
    "    ser_quantity = ser_quantity[ser_quantity > 0].groupby('Date').count()\n",
    "    ser_quantity.name = str(iter_option)\n",
    "    ser_quantity.to_excel('Data_Files/Test_Files/Augmentation_Test_' + str(iter_option) + '.xlsx', merge_cells = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: TOTAL DATA AGGREGATION: RESULTS SAVING (SERIES)\n",
    "\n",
    "ser_total_augmented = dict_cpis_augmented[2]['Asset_Augmented']\n",
    "ser_total_augmented.name = 'Total'\n",
    "ser_total_augmented.replace({0.0: np.NaN})\\\n",
    "    .to_hdf(path_or_buf = str_path_imf_cpis_total_augmented, key = str_key_imf_cpis_total_augmented, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: TOTAL DATA AGGREGATION: RESULTS CONSOLIDATION TO DATAFRAME AND SAVING\n",
    "\n",
    "df_augmentation_way = pd.concat([df_cpis_to_augment['Asset'].replace({0.0: np.NaN}), \n",
    "                                 dict_cpis_augmented[-1]['Asset_Augmented'], \n",
    "                                 dict_cpis_augmented[2]['Asset_Augmented']], \n",
    "                                axis = 1, keys = ['Assets_Only', 'Unconditional', 'Option_2'], names = 'Augmentation_Way')\n",
    "df_augmentation_way.to_hdf(path_or_buf = str_path_total_imf_cpis_options, key = str_key_total_imf_cpis_options, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: RAW ASSET DATA LOADING\n",
    "\n",
    "gc.collect()\n",
    "ser_cpis_asset = pd.read_hdf(path_or_buf = str_path_imf_cpis_detailed_raw, key = str_key_imf_cpis_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: ASSSET FILTERING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "list_valid_indicators = ['I_A_T_T_T_BP6_USD', 'I_A_D_S_T_BP6_USD']\n",
    "list_valid_reporter_sectors = ['T', 'CB', 'GG']\n",
    "list_valid_partner_sectors = ['T']\n",
    "list_valid_partners = df_country_codes['ISO SHORT'].values\n",
    "\n",
    "ser_asset_filtered = ser_cpis_asset.loc[:, list_valid_indicators, list_valid_reporter_sectors, list_valid_partner_sectors, :, list_valid_partners]\\\n",
    "                     .droplevel('Partner_Sector').reorder_levels([0, 1, 3, 4, 2]).sort_index().astype('float32')\n",
    "del ser_cpis_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: ASSET REPORTER SECTOR CLEARING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "def reindex_reporter_sectors(ser_group):\n",
    "    ser_group = ser_group.droplevel(['Date', 'Indicator', 'Reporter', 'Partner'])\n",
    "    if (len(ser_group.index) < 3):\n",
    "        ser_group = ser_group.reindex(list_valid_reporter_sectors).fillna(0.0)\n",
    "    ser_sectors_cleared = ser_group['T'] - (ser_group['CB'] + ser_group['GG'])\n",
    "    return ser_sectors_cleared\n",
    "\n",
    "def get_commerce(ser_raw):\n",
    "    return ser_raw.groupby(['Date', 'Indicator', 'Reporter', 'Partner']).apply(reindex_reporter_sectors)\n",
    "\n",
    "#list_test_date = ['1997-12-31', '2021-12-31'] # ['2021-12-31'] # \n",
    "#list_test_indicator = ['I_A_D_S_T_BP6_USD']\n",
    "#list_test_reporter = ['PT', 'AT']\n",
    "#list_test_partner = ['US', 'IT'] # ['IT'] # \n",
    "\n",
    "#ser_test_raw = ser_asset_filtered.loc[:, :, list_test_reporter, :, :]\n",
    "#display(ser_test_raw.loc[list_test_date, list_test_indicator, list_test_reporter, list_test_partner, :])\n",
    "#ser_test_res = ser_test_raw.groupby(['Date', 'Indicator', 'Reporter', 'Partner']).apply(reindex_reporter_sectors)\n",
    "#ser_test_res = get_commerce(ser_test_raw)\n",
    "#display(ser_test_res.loc[list_test_date, list_test_indicator, list_test_reporter, list_test_partner])\n",
    "\n",
    "#%timeit get_commerce(ser_test_raw)\n",
    "\n",
    "#%lprun -f reindex_reporter_sectors get_commerce(ser_test_raw)\n",
    "\n",
    "ser_asset_commerce = ser_asset_filtered.groupby(['Date', 'Indicator', 'Reporter', 'Partner']).apply(reindex_reporter_sectors)\n",
    "ser_asset_commerce = ser_asset_commerce.reorder_levels([0, 2, 3, 1]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Reporter  Partner  Indicator        \n",
       "1997-12-31  PT        IT       I_A_D_S_T_BP6_USD    0.000000    \n",
       "                               I_A_T_T_T_BP6_USD    507.593262  \n",
       "                      US       I_A_D_S_T_BP6_USD    91.923386   \n",
       "                               I_A_T_T_T_BP6_USD    3332.449951 \n",
       "2021-12-31  PT        IT       I_A_D_S_T_BP6_USD    3289.410400 \n",
       "                               I_A_T_T_T_BP6_USD    18311.003906\n",
       "                      US       I_A_D_S_T_BP6_USD    3.329844    \n",
       "                               I_A_T_T_T_BP6_USD    13202.219727\n",
       "Name: Value, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### IMF CPIS: ASSET CLEARING TEST\n",
    "\n",
    "list_test_date = ['1997-12-31', '2021-12-31'] # ['2021-12-31'] # \n",
    "list_test_indicator = ['I_A_D_S_T_BP6_USD']\n",
    "list_test_reporter = ['PT']\n",
    "list_test_partner = ['US', 'IT'] # ['IT'] # \n",
    "\n",
    "#display(ser_asset_filtered.loc[list_test_date, list_test_reporter, list_test_partner, list_test_indicator])\n",
    "display(ser_asset_commerce.loc[list_test_date, list_test_reporter, list_test_partner, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: SHORT-TERM DEBTS EXCLUDING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "def reindex_indicators(ser_group):\n",
    "    ser_group = ser_group.droplevel(['Date', 'Reporter', 'Partner'])\n",
    "    if (len(ser_group.index) < 3):\n",
    "        ser_group = ser_group.reindex(list_valid_indicators).fillna(0.0)\n",
    "    ser_indicators_cleared = ser_group['I_A_T_T_T_BP6_USD'] - ser_group['I_A_D_S_T_BP6_USD']\n",
    "    return ser_indicators_cleared\n",
    "\n",
    "#list_test_date = ['1997-12-31', '2021-12-31'] # ['2021-12-31'] # \n",
    "#list_test_reporter = ['PT']\n",
    "#list_test_partner = ['US', 'IT'] # ['IT'] # \n",
    "\n",
    "#ser_test_raw = ser_asset_commerce.loc[:, list_test_reporter, :, :]\n",
    "#display(ser_test_raw.loc[list_test_date, list_test_reporter, list_test_partner, :])\n",
    "#ser_test_res = ser_test_raw.groupby(['Date', 'Reporter', 'Partner']).apply(reindex_indicators)\n",
    "#display(ser_test_res.loc[list_test_date, list_test_reporter, list_test_partner])\n",
    "\n",
    "ser_asset_minus_short_term = ser_asset_commerce.groupby(['Date', 'Reporter', 'Partner']).apply(reindex_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Reporter  Partner  Indicator        \n",
       "1997-12-31  PT        IT       I_A_D_S_T_BP6_USD    0.000000    \n",
       "                               I_A_T_T_T_BP6_USD    507.593262  \n",
       "                      US       I_A_D_S_T_BP6_USD    91.923386   \n",
       "                               I_A_T_T_T_BP6_USD    3332.449951 \n",
       "2021-12-31  PT        IT       I_A_D_S_T_BP6_USD    3289.410400 \n",
       "                               I_A_T_T_T_BP6_USD    18311.003906\n",
       "                      US       I_A_D_S_T_BP6_USD    3.329844    \n",
       "                               I_A_T_T_T_BP6_USD    13202.219727\n",
       "Name: Value, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Date        Reporter  Partner\n",
       "1997-12-31  PT        IT         507.593262  \n",
       "                      US         3240.526566 \n",
       "2021-12-31  PT        IT         15021.593506\n",
       "                      US         13198.889883\n",
       "Name: Value, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### IMF CPIS: ASSET CLEARING TEST\n",
    "\n",
    "list_test_date = ['1997-12-31', '2021-12-31'] # ['2021-12-31'] # \n",
    "list_test_reporter = ['PT']\n",
    "list_test_partner = ['US', 'IT'] # ['IT'] # \n",
    "\n",
    "display(ser_asset_commerce.loc[list_test_date, list_test_reporter, list_test_partner])\n",
    "display(ser_asset_minus_short_term.loc[list_test_date, list_test_reporter, list_test_partner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: FILTERED ASSET DATASET SAVING\n",
    "\n",
    "ser_asset_minus_short_term.replace({0.0: np.NaN})\\\n",
    "    .to_hdf(path_or_buf = str_path_imf_cpis_filtered, key = str_key_imf_cpis_filtered_asset, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: RAW LIABILITY DATA LOADING\n",
    "\n",
    "gc.collect()\n",
    "ser_cpis_liability_inv = pd.read_hdf(path_or_buf = str_path_imf_cpis_detailed_raw, key = str_key_imf_cpis_liabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: LIABILITY FILTERING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "list_valid_indicators = ['I_L_T_T_T_BP6_USD', 'I_L_D_S_T_BP6_USD']\n",
    "list_valid_reporter_sectors = ['T', 'CB', 'GG']\n",
    "list_valid_partner_sectors = ['T']\n",
    "list_valid_partners = df_country_codes['ISO SHORT'].values\n",
    "\n",
    "ser_liability_filtered = ser_cpis_liability_inv.loc[:, list_valid_indicators, list_valid_reporter_sectors, list_valid_partner_sectors, :, list_valid_partners]\\\n",
    "                     .droplevel('Partner_Sector').reorder_levels([0, 1, 3, 4, 2]).sort_index().astype('float32')\n",
    "del ser_cpis_liability_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: LIABILITY REPORTER SECTOR CLEARING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "def reindex_reporter_sectors(ser_group):\n",
    "    ser_group = ser_group.droplevel(['Date', 'Indicator', 'Reporter', 'Partner'])\n",
    "    if (len(ser_group.index) < 3):\n",
    "        ser_group = ser_group.reindex(list_valid_reporter_sectors).fillna(0.0)\n",
    "    ser_sectors_cleared = ser_group['T'] - (ser_group['CB'] + ser_group['GG'])\n",
    "    return ser_sectors_cleared\n",
    "\n",
    "def get_commerce(ser_raw):\n",
    "    return ser_raw.groupby(['Date', 'Indicator', 'Reporter', 'Partner']).apply(reindex_reporter_sectors)\n",
    "\n",
    "ser_liability_commerce = ser_liability_filtered.groupby(['Date', 'Indicator', 'Reporter', 'Partner']).apply(reindex_reporter_sectors)\n",
    "ser_liability_commerce = ser_liability_commerce.reorder_levels([0, 2, 3, 1]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Reporter  Partner  Indicator        \n",
       "1997-12-31  AU        IL       I_L_D_S_T_BP6_USD    0.000000    \n",
       "                               I_L_T_T_T_BP6_USD    3.612000    \n",
       "                      JP       I_L_D_S_T_BP6_USD    143.131973  \n",
       "                               I_L_T_T_T_BP6_USD    9109.657227 \n",
       "2021-12-31  AU        IL       I_L_T_T_T_BP6_USD    132.000000  \n",
       "                      JP       I_L_D_S_T_BP6_USD    17969.404297\n",
       "                               I_L_T_T_T_BP6_USD    59019.222656\n",
       "Name: Value, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### IMF CPIS: LIABILITY CLEARING TEST\n",
    "\n",
    "list_test_date = ['1997-12-31', '2021-12-31'] # ['2021-12-31'] # \n",
    "list_test_indicator = ['I_L_D_S_T_BP6_USD']\n",
    "list_test_reporter = ['AU']\n",
    "list_test_partner = ['JP', 'IL'] # ['IT'] # \n",
    "\n",
    "#display(ser_liability_commerce.loc[list_test_date, list_test_reporter, list_test_partner, list_test_indicator])\n",
    "display(ser_liability_commerce.loc[list_test_date, list_test_reporter, list_test_partner, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: SHORT-TERM DEBTS EXCLUDING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "def reindex_indicators(ser_group):\n",
    "    ser_group = ser_group.droplevel(['Date', 'Reporter', 'Partner'])\n",
    "    if (len(ser_group.index) < 3):\n",
    "        ser_group = ser_group.reindex(list_valid_indicators).fillna(0.0)\n",
    "    ser_indicators_cleared = ser_group['I_L_T_T_T_BP6_USD'] - ser_group['I_L_D_S_T_BP6_USD']\n",
    "    return ser_indicators_cleared\n",
    "\n",
    "ser_liability_minus_short_term = ser_liability_commerce.groupby(['Date', 'Reporter', 'Partner']).apply(reindex_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Reporter  Partner  Indicator        \n",
       "1997-12-31  AU        IL       I_L_D_S_T_BP6_USD    0.000000    \n",
       "                               I_L_T_T_T_BP6_USD    3.612000    \n",
       "                      JP       I_L_D_S_T_BP6_USD    143.131973  \n",
       "                               I_L_T_T_T_BP6_USD    9109.657227 \n",
       "2021-12-31  AU        IL       I_L_T_T_T_BP6_USD    132.000000  \n",
       "                      JP       I_L_D_S_T_BP6_USD    17969.404297\n",
       "                               I_L_T_T_T_BP6_USD    59019.222656\n",
       "Name: Value, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Date        Reporter  Partner\n",
       "1997-12-31  AU        IL         3.612000    \n",
       "                      JP         8966.525253 \n",
       "2021-12-31  AU        IL         132.000000  \n",
       "                      JP         41049.818359\n",
       "Name: Value, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### IMF CPIS: LIABILITY CLEARING TEST\n",
    "\n",
    "list_test_date = ['1997-12-31', '2021-12-31'] # ['2021-12-31'] # \n",
    "list_test_reporter = ['AU']\n",
    "list_test_partner = ['JP', 'IL'] # ['IT'] # \n",
    "\n",
    "display(ser_liability_commerce.loc[list_test_date, list_test_reporter, list_test_partner])\n",
    "display(ser_liability_minus_short_term.loc[list_test_date, list_test_reporter, list_test_partner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: LIABILITY ASSET DATASET SAVING\n",
    "\n",
    "ser_liability_minus_short_term.replace({0.0: np.NaN})\\\n",
    "    .to_hdf(path_or_buf = str_path_imf_cpis_filtered, key = str_key_imf_cpis_filtered_liability, mode = 'a', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: FILTERED DATA AGGREGATION: DATASETS LOADING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "ser_cpis_asset_filtered = pd.read_hdf(path_or_buf = str_path_imf_cpis_filtered, key = str_key_imf_cpis_filtered_asset)\n",
    "ser_cpis_asset_filtered.name = 'Asset'\n",
    "ser_cpis_liability_filtered = pd.read_hdf(path_or_buf = str_path_imf_cpis_filtered, key = str_key_imf_cpis_filtered_liability)\n",
    "ser_cpis_liability_filtered.name = 'Liability_Inverted'\n",
    "df_cpis_total = pd.concat([ser_cpis_asset_filtered, ser_cpis_liability_filtered], axis = 1, names = 'Data Source').astype('float32').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: FILTERED DATA AGGREGATION: DATA QUALITY RATIOS\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "### Defining similarity for investors by date\n",
    "def get_investor_ratio(df_group):\n",
    "#    df_group['Asset'].fillna(0.0, inplace = True)\n",
    "    df_group.fillna(0.0, inplace = True)    \n",
    "    df_both = df_group.dropna()    \n",
    "    if (df_both['Asset'].sum() > 0.0):\n",
    "        flo_result = (df_both['Asset'] - df_both['Liability_Inverted']).abs().clip(upper = df_group['Asset'].max()).sum() / df_group['Asset'].sum() / len(df_group)    \n",
    "    else:\n",
    "        flo_result = np.NaN    \n",
    "    return flo_result\n",
    "### Defining similarity for borrowers by date\n",
    "def get_borrower_ratio(df_group):\n",
    "#    df_group['Liability_Inverted'].fillna(0.0, inplace = True)\n",
    "    df_group.fillna(0.0, inplace = True)     \n",
    "    df_both = df_group.dropna()\n",
    "    if (df_both['Liability_Inverted'].sum() > 0.0):\n",
    "        flo_result = (df_both['Asset'] - df_both['Liability_Inverted']).abs().clip(upper = df_group['Liability_Inverted'].max()).sum() \\\n",
    "                                                                        / df_group['Liability_Inverted'].sum() / len(df_group)\n",
    "    else:\n",
    "        flo_result = np.NaN    \n",
    "    return flo_result\n",
    "### Similarity values calculation:\n",
    "ser_investor_ratio = df_cpis_total.groupby(['Date', 'Reporter']).apply(get_investor_ratio)\n",
    "ser_investor_ratio.name = 'Investor_Ratio'\n",
    "ser_borrower_ratio = df_cpis_total.groupby(['Date', 'Partner']).apply(get_borrower_ratio)\n",
    "ser_borrower_ratio.name = 'Borrower_Ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0022 / (Timestamp('2018-12-31 00:00:00'), 'RO')\n",
      "0.8929 / (Timestamp('1997-12-31 00:00:00'), 'ES')\n"
     ]
    }
   ],
   "source": [
    "### IMF CPIS: FILTERED DATA AGGREGATION: SIMILARITY TEST\n",
    "\n",
    "print(round(ser_borrower_ratio.min(), 4), '/', ser_borrower_ratio.idxmin())\n",
    "print(round(ser_borrower_ratio.max(), 4), '/', ser_borrower_ratio.idxmax())\n",
    "\n",
    "#display(df_cpis_total.loc[('2018-12-31', All, 'RO'), :])\n",
    "#display(df_cpis_total.loc[('1997-12-31', All, 'ES'), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0024 / (Timestamp('2010-12-31 00:00:00'), 'NZ')\n",
      "0.25 / (Timestamp('2002-12-31 00:00:00'), 'UA')\n"
     ]
    }
   ],
   "source": [
    "### IMF CPIS: FILTERED DATA AGGREGATION: SIMILARITY TEST\n",
    "\n",
    "print(round(ser_investor_ratio.min(), 4), '/', ser_investor_ratio.idxmin())\n",
    "print(round(ser_investor_ratio.max(), 4), '/', ser_investor_ratio.idxmax())\n",
    "\n",
    "#display(df_cpis_total.loc[('2010-12-31', 'NZ', All), :].dropna(subset = ['Liability_Inverted']))\n",
    "#display(df_cpis_total.loc[('2002-12-31', 'UA', All), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: FILTERED DATA AGGREGATION: ADDING RATIOS\n",
    "\n",
    "df_cpis_to_augment = df_cpis_total.join(ser_investor_ratio).join(ser_borrower_ratio)\n",
    "df_cpis_to_augment['Asset_Augmented'] = np.NaN # -999 # \n",
    "df_cpis_to_augment = df_cpis_to_augment.reorder_levels(['Date', 'Reporter', 'Partner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: FILTERED DATA AGGREGATION: CONDITIONAL REPLACING\n",
    "\n",
    "gc.collect()\n",
    "def augment_by_date(df_date, int_option = 0):\n",
    "    '''\n",
    "       -1 : Replace NaN Asset values unconditionally\n",
    "        0 : Replace NaN Asset values when Investor's Ratio > Borrower's Ratio\n",
    "        1 : Replace NaN or zero Asset values when Investor's Ratio > Borrower's Ratio\n",
    "        2 : Replace any Asset values when Investor's Ratio > Borrower's Ratio\n",
    "    '''\n",
    "    if (int_option == -1):\n",
    "        ### Replacing zero Asset & Liability values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN        \n",
    "        df_date['Asset_Augmented'] = df_date['Asset'].combine_first(df_date['Liability_Inverted'])\n",
    "    elif (int_option == 0):\n",
    "        ### Fill resulting column with not NaN Asset values:\n",
    "        df_date.loc[df_date['Asset'].notna(), 'Asset_Augmented'] = df_date[df_date['Asset'].notna()]['Asset'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is NaN (and doesn't matter if Borrower Ratio is NaN):\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna(), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna()]['Liability_Inverted'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is bigger than Borrower Ratio:\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio']), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio'])]['Liability_Inverted'].values\n",
    "    elif (int_option == 1):\n",
    "        ### Replacing zero Asset values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN\n",
    "        ### Fill resulting column with not NaN Asset values:\n",
    "        df_date.loc[df_date['Asset'].notna(), 'Asset_Augmented'] = df_date.loc[df_date['Asset'].notna(), 'Asset'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is NaN (and doesn't matter if Borrower Ratio is NaN):\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna(), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna()]['Liability_Inverted'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is bigger than Borrower Ratio:\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio']), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio'])]['Liability_Inverted'].values\n",
    "    else:\n",
    "        ### Replacing zero Asset & Liability values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN        \n",
    "        df_date.loc[df_date['Liability_Inverted'] == 0.0, 'Liability_Inverted'] = np.NaN\n",
    "        ### Ratios preparation:\n",
    "        df_date.loc[df_date['Investor_Ratio'].isna(), 'Investor_Ratio'] = 999.0\n",
    "        df_date.loc[df_date['Borrower_Ratio'].isna(), 'Borrower_Ratio'] = 1000.0\n",
    "        ### Ratios comparision:\n",
    "        df_date.loc[df_date['Investor_Ratio'] <= df_date['Borrower_Ratio'], 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Investor_Ratio'] <= df_date['Borrower_Ratio']]['Asset'].values\n",
    "        df_date.loc[df_date['Investor_Ratio'] > df_date['Borrower_Ratio'], 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Investor_Ratio'] > df_date['Borrower_Ratio']]['Liability_Inverted'].values                                       \n",
    "    return df_date\n",
    "\n",
    "dict_cpis_augmented = {}\n",
    "dict_cpis_augmented[-1] = df_cpis_to_augment.groupby('Date').apply(augment_by_date, -1)\n",
    "dict_cpis_augmented[0] = df_cpis_to_augment.groupby('Date').apply(augment_by_date, 0)\n",
    "dict_cpis_augmented[1] = df_cpis_to_augment.groupby('Date').apply(augment_by_date, 1)\n",
    "dict_cpis_augmented[2] = df_cpis_to_augment.groupby('Date').apply(augment_by_date, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: FILTERED DATA AGGREGATION: RESULTS TESTING\n",
    "\n",
    "ser_quantity = df_cpis_to_augment['Asset'].replace({0.0: np.NaN}).groupby(['Date','Reporter']).count()\n",
    "ser_quantity = ser_quantity[ser_quantity > 0].groupby('Date').count()\n",
    "ser_quantity.name = 'raw'\n",
    "ser_quantity.to_excel('Data_Files/Test_Files/Augmentation_Test_' + ser_quantity.name + '.xlsx', merge_cells = False)\n",
    "\n",
    "for iter_option in dict_cpis_augmented:\n",
    "    dt_option = dict_cpis_augmented[iter_option]\n",
    "    ser_quantity = dt_option['Asset_Augmented'].replace({0.0: np.NaN}).groupby(['Date','Reporter']).count()\n",
    "    ser_quantity = ser_quantity[ser_quantity > 0].groupby('Date').count()\n",
    "    ser_quantity.name = str(iter_option)\n",
    "    ser_quantity.to_excel('Data_Files/Test_Files/Augmentation_Test_' + str(iter_option) + '.xlsx', merge_cells = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: FILTERED DATA AGGREGATION: RESULTS SAVING (SERIES)\n",
    "\n",
    "ser_filtered_augmented = dict_cpis_augmented[2]['Asset_Augmented']\n",
    "ser_filtered_augmented.name = 'Filtered'\n",
    "ser_filtered_augmented.replace({0.0: np.NaN})\\\n",
    "    .to_hdf(path_or_buf = str_path_imf_cpis_filtered_augmented, key = str_key_imf_cpis_filtered_augmented, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: FILTERED DATA AGGREGATION: RESULTS CONSOLIDATION TO DATAFRAME AND SAVING\n",
    "\n",
    "df_augmentation_way = pd.concat([df_cpis_to_augment['Asset'].replace({0.0: np.NaN}), \n",
    "                                 dict_cpis_augmented[-1]['Asset_Augmented'], \n",
    "                                 dict_cpis_augmented[2]['Asset_Augmented']], \n",
    "                                axis = 1, keys = ['Assets_Only', 'Unconditional', 'Option_2'], names = 'Augmentation_Way')\n",
    "df_augmentation_way.to_hdf(path_or_buf = str_path_filtered_imf_cpis_options, key = str_key_filtered_imf_cpis_options, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: INVESTMENT POSITIONS AGGREGATING AND SAVING\n",
    "\n",
    "df_total_direct_options = pd.read_hdf(path_or_buf = str_path_total_direct_options, key = str_key_total_direct_options)\n",
    "df_equity_direct_options = pd.read_hdf(path_or_buf = str_path_equity_direct_options, key = str_key_equity_direct_options)\n",
    "df_total_portfolio_options = pd.read_hdf(path_or_buf = str_path_total_imf_cpis_options, key = str_key_total_imf_cpis_options)\n",
    "df_filtered_portfolio_options = pd.read_hdf(path_or_buf = str_path_filtered_imf_cpis_options, key = str_key_filtered_imf_cpis_options)\n",
    "df_total_investment_options = (df_total_direct_options.fillna(0.0) + df_total_portfolio_options.fillna(0.0)).replace({0.0: np.NaN})\n",
    "df_total_investment_options.to_hdf(path_or_buf = str_path_total_investment_options, key = str_key_total_investment_options, mode = 'w', format = 'fixed')\n",
    "df_filtered_investment_options = (df_equity_direct_options.fillna(0.0) + df_filtered_portfolio_options.fillna(0.0)).replace({0.0: np.NaN})\n",
    "df_filtered_investment_options.to_hdf(path_or_buf = str_path_filtered_investment_options, key = str_key_filtered_investment_options, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "display(df_filtered_portfolio_options['Unconditional'].groupby('Date').count() / df_total_portfolio_options['Unconditional'].groupby('Date').count())\n",
    "display(df_filtered_portfolio_options['Unconditional'].groupby('Date').sum() / df_total_portfolio_options['Unconditional'].groupby('Date').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
