{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GFD: 3-MONTH TREASURY BILL RATE FOR LOCAL INTEREST RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GFD: DEFINING GFD LOGIN FUNCTION\n",
    "\n",
    "def gfd_auth(username = None, password = None):\n",
    "    \"\"\"\n",
    "    Pulls a GFD API token and stores it as an environmental variable.\n",
    "    Parameters\n",
    "        username: GFD-approved email address.\n",
    "        password: Password for GFD-approved email address.\n",
    "    \"\"\"\n",
    "    if username is None:\n",
    "        username = getpass.getpass('Please enter your GFD Finaeon username: ')\n",
    "\n",
    "    if password is None:\n",
    "        password = getpass.getpass('Please enter your GFD Finaeon password: ')\n",
    "\n",
    "    url = 'https://api.globalfinancialdata.com/login/'\n",
    "    parameters = {'username': username, 'password': password}\n",
    "    resp = requests.post(url, data = parameters)\n",
    "    #check for unsuccessful API returns\n",
    "    if resp.status_code != 200:\n",
    "        raise ValueError('GFD API request failed with HTTP status code %s' % resp.status_code)\n",
    "\n",
    "    json_content = resp.json()\n",
    "    os.environ['GFD_API_TOKEN'] = json_content['token'].strip('\"')\n",
    "    print(\"GFD API token recieved at %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GFD: RUNNING AUTHORIZATION FUNCTION\n",
    "\n",
    "gfd_auth('kaminski.ihar@tut.by', '1990757229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE: INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COUNTRY ISO CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    import pandas as pd\n",
    "    \n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']]      \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def get_market_membership_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Declaring local constants & variables: \n",
    "    path_msci = 'Data_Files/Source_Files/sample_universe.xlsx' ### Path for membership source    \n",
    "    tab_monthly = 'universe_joined'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    no_slice = slice(None)\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci, sheet_name = tab_monthly, skiprows = [0, 2], header = 0, parse_dates = True, \n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    df_universe = df_universe.loc[no_slice, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Country']\n",
    "    df_universe.set_index(['Date', 'Country'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    ### Results output:\n",
    "    return ser_market_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE: COUNTRIES DATA EXTRACTION AND MODIFICATION\n",
    "\n",
    "def get_un_comtrade_country_id(df_country_codes):\n",
    "    ### Getting UN Comtrade country info from post request:\n",
    "    str_UNC_countries_set = 'http://comtrade.un.org/data/cache/partnerAreas.json'\n",
    "    obj_UNC_countries_set = requests.post(str_UNC_countries_set)\n",
    "    ### Object to dataframe transformation:\n",
    "    list_UNC_countries = obj_UNC_countries_set.json()['results']\n",
    "    df_UNC_countries = pd.DataFrame(list_UNC_countries)\n",
    "    df_UNC_countries.columns = ['UNC ID', 'COUNTRY']\n",
    "    df_UNC_countries['COUNTRY'] = df_UNC_countries['COUNTRY'].str.upper()\n",
    "    df_UNC_countries.replace(dict_map_to_replace, inplace = True)\n",
    "    df_UNC_countries.set_index('COUNTRY', append = False, drop = True, inplace = True)\n",
    "    df_UNC_country_id = df_UNC_countries.join(df_country_codes, on = 'COUNTRY', how = 'left').dropna(how = 'any').reset_index(drop = True)\n",
    "    df_UNC_country_id.drop('ISO LONG', axis = 1, inplace = True)\n",
    "    df_UNC_country_id.columns = ['Comtrade_ID', 'Country']\n",
    "    ser_UNC_country_id = df_UNC_country_id.set_index('Country').squeeze().sort_index()\n",
    "    ### Results output:\n",
    "    return ser_UNC_country_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE: DATA REQUEST EXECUTION\n",
    "\n",
    "def get_un_comtrade_data(str_rep_country_id, str_par_country_id, int_max_rec = 50000, str_type = 'C', str_freq = 'M', str_classification_system = 'HS', \n",
    "                         str_period = 'all', str_trade_flow = 'All', str_classification_code = 'TOTAL'):\n",
    "    ### Trade flows codification:\n",
    "    dict_trade_flow = {'All': 'all', 'Import': '1', 'Export': '2', 're-Export': '3', 're-Import': '4'}\n",
    "    ### URL prefix:\n",
    "    str_url_base = 'http://comtrade.un.org/api/get?'\n",
    "    ### Request URL preparation:\n",
    "    str_url_request = str_url_base\n",
    "    list_parameters = []\n",
    "    list_parameters.append('max=' + str(int_max_rec)) # Usage limit\n",
    "    list_parameters.append('type=' + str_type) # C = Commodities (merchandise trade data) / S = Services (trade in services data)\n",
    "    list_parameters.append('freq=' + str_freq) # A = Annual, M = Mpnthly\n",
    "    list_parameters.append('px=' + str_classification_system) # Trade data classification scheme. See list of valid classifications\n",
    "    list_parameters.append('ps=' + str_period) # Time period\n",
    "    list_parameters.append('r=' + str_rep_country_id) # Reporter country\n",
    "    list_parameters.append('p=' + str_par_country_id) # Partner country\n",
    "    list_parameters.append('rg=' + dict_trade_flow[str_trade_flow]) # Trade direction\n",
    "    list_parameters.append('cc=' + str_classification_code) # Commodity code\n",
    "    list_parameters.append('fmt=json')        \n",
    "    str_url_request += '&'.join(list_parameters)\n",
    "    ### Getting UN Comtrade data from post request:    \n",
    "    obj_unc_dataset = requests.post(str_url_request)\n",
    "    ### Object to dataframe transformation:    \n",
    "    list_unc_dataset = obj_unc_dataset.json()['dataset']\n",
    "    if (len(list_unc_dataset) > 0):\n",
    "        df_unc_dataset = pd.DataFrame(list_unc_dataset)[['period', 'rtCode', 'ptCode', 'TradeValue']]\n",
    "        df_unc_dataset.columns = ['Period', 'Reporter_ID', 'Partner_ID', 'Value']    \n",
    "        df_unc_dataset['Date'] = pd.to_datetime(df_unc_dataset['Period'], format = '%Y%m') + pd.offsets.BMonthEnd()    \n",
    "        df_unc_dataset = df_unc_dataset[['Date', 'Reporter_ID', 'Partner_ID', 'Value']]\n",
    "    else:\n",
    "        df_unc_dataset = pd.DataFrame(columns = ['Date', 'Reporter_ID', 'Partner_ID', 'Value'])\n",
    "    \n",
    "    return df_unc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE: GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "int_seconds_to_sleep = 35\n",
    "int_unc_limit = 5\n",
    "All = slice(None)\n",
    "str_path_unc_dataset = 'Data_Files/Source_Files/unc_dataset.h5'\n",
    "str_unc_exp_total_dataset = 'export_total_dataset'\n",
    "str_unc_imp_total_dataset = 'import_total_dataset'\n",
    "### UN Comtrade country names to rename:\n",
    "dict_map_to_replace = {'BOLIVIA (PLURINATIONAL STATE OF)': 'BOLIVIA',\n",
    "                       'BOSNIA HERZEGOVINA': 'BOSNIA AND HERZEGOVINA',\n",
    "                       'BR. INDIAN OCEAN TERR.': 'BRITISH INDIAN OCEAN TERRITORY',\n",
    "                       'BR. VIRGIN ISDS': 'BRITISH VIRGIN ISLANDS',\n",
    "                       'BRUNEI DARUSSALAM': 'BRUNEI',\n",
    "                       'CABO VERDE': 'CAPE VERDE',\n",
    "                       'CAYMAN ISDS': 'CAYMAN ISLANDS',\n",
    "                       'CENTRAL AFRICAN REP.': 'CENTRAL AFRICAN REPUBLIC',\n",
    "                       'CHRISTMAS ISDS': 'CHRISTMAS ISLAND',\n",
    "                       'COCOS ISDS': 'COCOS ISLANDS',\n",
    "                       'COOK ISDS': 'COOK ISLANDS',                    \n",
    "                       'CURAÇAO': 'CURACAO',                          \n",
    "                       'CZECHIA': 'CZECH REPUBLIC',                    \n",
    "                       'DEM. REP. OF THE CONGO': 'DEMOCRATIC REPUBLIC OF THE CONGO',                          \n",
    "                       'DOMINICAN REP.': 'DOMINICAN REPUBLIC',                    \n",
    "                       'TIMOR-LESTE': 'EAST TIMOR',                          \n",
    "                       'FALKLAND ISDS (MALVINAS)': 'FALKLAND ISLANDS',                    \n",
    "                       'FAEROE ISDS': 'FAROE ISLANDS',                                           \n",
    "                       'CHINA, HONG KONG SAR': 'HONG KONG',                          \n",
    "                       'CÔTE D\\'IVOIRE': 'IVORY COAST',                                           \n",
    "                       'LAO PEOPLE\\'S DEM. REP.': 'LAOS',                                         \n",
    "                       'CHINA, MACAO SAR': 'MACAU',                          \n",
    "                       'TFYR OF MACEDONIA': 'MACEDONIA',                    \n",
    "                       'MARSHALL ISDS': 'MARSHALL ISLANDS',                          \n",
    "                       'FS MICRONESIA': 'MICRONESIA',                    \n",
    "                       'REP. OF MOLDOVA': 'MOLDOVA',                          \n",
    "                       'NETH. ANTILLES': 'NETHERLANDS ANTILLES',                          \n",
    "                       'DEM. PEOPLE\\'S REP. OF KOREA': 'NORTH KOREA',                          \n",
    "                       'N. MARIANA ISDS': 'NORTHERN MARIANA ISLANDS',                    \n",
    "                       'STATE OF PALESTINE': 'PALESTINE',                          \n",
    "                       'CONGO': 'REPUBLIC OF THE CONGO',                          \n",
    "                       'RÉUNION': 'REUNION',                    \n",
    "                       'RUSSIAN FEDERATION': 'RUSSIA',                          \n",
    "                       'SOLOMON ISDS': 'SOLOMON ISLANDS',                    \n",
    "                       'REP. OF KOREA': 'SOUTH KOREA',                                       \n",
    "                       'UNITED REP. OF TANZANIA': 'TANZANIA',     \n",
    "                       'OTHER ASIA, NES': 'TAIWAN',\n",
    "                       'TURKS AND CAICOS ISDS': 'TURKS AND CAICOS ISLANDS',                    \n",
    "                       'US VIRGIN ISDS': 'U.S. VIRGIN ISLANDS',                          \n",
    "                       'USA': 'UNITED STATES',                          \n",
    "                       'HOLY SEE (VATICAN CITY STATE)': 'VATICAN',                    \n",
    "                       'VIET NAM': 'VIETNAM',                          \n",
    "                       'WALLIS AND FUTUNA ISDS': 'WALLIS AND FUTUNA'\n",
    "                      }\n",
    "### ISO country codes loading:\n",
    "df_country_codes = get_country_codes()\n",
    "### ISON membership loading:\n",
    "ser_market_membership = get_market_membership_from_excel()\n",
    "### Getting UN Comtrade country IDs:\n",
    "ser_UNC_country_id = get_un_comtrade_country_id(df_country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE: EXPORT DATA EXTRACTION SCRIPT\n",
    "\n",
    "### Filtering ISON countries only:\n",
    "ser_UNC_country_id = ser_UNC_country_id.reindex(ser_market_membership.index.get_level_values(1).unique().to_list())\n",
    "### Concatenation aggregator initializing:\n",
    "list_dataset = []\n",
    "### Reporter country looping (5 country groups):\n",
    "for iter_reporter_group in range((len(ser_UNC_country_id.index) - 1) // int_unc_limit + 1):\n",
    "    ### Partner country looping (5 country groups):\n",
    "    for iter_partner_group in range((len(ser_UNC_country_id.index) - 1) // int_unc_limit + 1):\n",
    "        print(iter_reporter_group * int_unc_limit, '-', (iter_reporter_group + 1) * int_unc_limit - 1, '/', \n",
    "              iter_partner_group * int_unc_limit, '-', (iter_partner_group + 1) * int_unc_limit - 1)\n",
    "#        if (iter_partner_group > 1):\n",
    "#            break        \n",
    "        ### Country groups preparing:\n",
    "        str_reporter_group = ','.join(ser_UNC_country_id.iloc[iter_reporter_group * int_unc_limit : (iter_reporter_group + 1) * int_unc_limit].to_list())\n",
    "        str_partner_group = ','.join(ser_UNC_country_id.iloc[iter_partner_group * int_unc_limit : (iter_partner_group + 1) * int_unc_limit].to_list())    \n",
    "        ### Request performing:\n",
    "        df_iter_dataset = get_un_comtrade_data(str_reporter_group, str_partner_group, str_trade_flow = 'Export')\n",
    "        list_dataset += [df_iter_dataset]\n",
    "        ### Pause for API limitations:\n",
    "        time.sleep(int_seconds_to_sleep)            \n",
    "#    break\n",
    "### Results concatenating:\n",
    "df_loop_dataset = pd.concat(list_dataset, axis = 0, sort = False, ignore_index = True)[['Date', 'Reporter_ID', 'Partner_ID', 'Value']]\n",
    "df_loop_dataset = df_loop_dataset.astype({'Reporter_ID': 'int16', 'Partner_ID': 'int16', 'Value': 'int64'})\n",
    "### UN Comtrade country codes replacing to ISON country codes:\n",
    "df_loop_dataset.loc[All, ['Reporter_ID', 'Partner_ID']] = df_loop_dataset.loc[All, ['Reporter_ID', 'Partner_ID']]\\\n",
    "                                                                         .replace(list(map(int, ser_UNC_country_id.values)), ser_UNC_country_id.index.to_list())\n",
    "### Series indexing:\n",
    "ser_unc_dataset = df_loop_dataset.set_index(['Date', 'Reporter_ID', 'Partner_ID'], drop = True).squeeze()\n",
    "### Data saving:\n",
    "ser_unc_dataset.to_hdf(path_or_buf = str_path_unc_dataset, key = str_unc_exp_total_dataset, mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE: IMPORT DATA EXTRACTION SCRIPT\n",
    "\n",
    "### Filtering ISON countries only:\n",
    "ser_UNC_country_id = ser_UNC_country_id.reindex(ser_market_membership.index.get_level_values(1).unique().to_list())\n",
    "### Concatenation aggregator initializing:\n",
    "list_dataset = []\n",
    "### Reporter country looping (5 country groups):\n",
    "for iter_reporter_group in range((len(ser_UNC_country_id.index) - 1) // int_unc_limit + 1):\n",
    "    ### Partner country looping (5 country groups):    \n",
    "    for iter_partner_group in range((len(ser_UNC_country_id.index) - 1) // int_unc_limit + 1):\n",
    "        print(iter_reporter_group * int_unc_limit, '-', (iter_reporter_group + 1) * int_unc_limit - 1, '/', \n",
    "              iter_partner_group * int_unc_limit, '-', (iter_partner_group + 1) * int_unc_limit - 1)\n",
    "#        if (iter_partner_group > 1):\n",
    "#            break        \n",
    "        ### Country groups preparing:\n",
    "        str_reporter_group = ','.join(ser_UNC_country_id.iloc[iter_reporter_group * int_unc_limit : (iter_reporter_group + 1) * int_unc_limit].to_list())\n",
    "        str_partner_group = ','.join(ser_UNC_country_id.iloc[iter_partner_group * int_unc_limit : (iter_partner_group + 1) * int_unc_limit].to_list())    \n",
    "        ### Request performing:        \n",
    "        df_iter_dataset = get_un_comtrade_data(str_reporter_group, str_partner_group, str_trade_flow = 'Import')\n",
    "        list_dataset += [df_iter_dataset]\n",
    "        ### Pause for API limitations:        \n",
    "        time.sleep(int_seconds_to_sleep)            \n",
    "#    break\n",
    "### Results concatenating:\n",
    "df_loop_dataset = pd.concat(list_dataset, axis = 0, sort = False, ignore_index = True)[['Date', 'Reporter_ID', 'Partner_ID', 'Value']]\n",
    "df_loop_dataset = df_loop_dataset.astype({'Reporter_ID': 'int16', 'Partner_ID': 'int16', 'Value': 'int64'})\n",
    "### UN Comtrade country codes replacing to ISON country codes:\n",
    "df_loop_dataset.loc[All, ['Reporter_ID', 'Partner_ID']] = df_loop_dataset.loc[All, ['Reporter_ID', 'Partner_ID']]\\\n",
    "                                                                         .replace(list(map(int, ser_UNC_country_id.values)), ser_UNC_country_id.index.to_list())\n",
    "### Series indexing:\n",
    "ser_unc_dataset = df_loop_dataset.set_index(['Date', 'Reporter_ID', 'Partner_ID'], drop = True).squeeze()\n",
    "### Data saving:\n",
    "ser_unc_dataset.to_hdf(path_or_buf = str_path_unc_dataset, key = str_unc_imp_total_dataset, mode = 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT -> BE Export 152803671\n",
      "AT <- BE Import 266718776\n",
      "BE -> AT Export 304453035\n",
      "BE <- AT Import 151602472\n"
     ]
    }
   ],
   "source": [
    "### UN COMTRADE: TEST: COMPARING WITH ONLINE DATA\n",
    "\n",
    "ser_unc_total_export = pd.read_hdf(path_or_buf = str_path_unc_dataset, key = str_unc_exp_total_dataset)\n",
    "ser_unc_total_import = pd.read_hdf(path_or_buf = str_path_unc_dataset, key = str_unc_imp_total_dataset)\n",
    "print('AT -> BE Export', ser_unc_total_export.loc['2017-04-28', 'AT', 'BE'])\n",
    "print('AT <- BE Import',ser_unc_total_import.loc['2017-04-28', 'AT', 'BE'])\n",
    "print('BE -> AT Export', ser_unc_total_export.loc['2017-04-28', 'BE', 'AT'])\n",
    "print('BE <- AT Import',ser_unc_total_import.loc['2017-04-28', 'BE', 'AT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIS: BILATERAL BANK LENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIS: INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIS: DEFINING EXTRACTION UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def get_market_membership_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Declaring local constants & variables: \n",
    "    path_msci = 'Data_Files/Source_Files/sample_universe.xlsx' ### Path for membership source    \n",
    "    tab_monthly = 'universe_joined'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    no_slice = slice(None)\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci, sheet_name = tab_monthly, skiprows = [0, 2], header = 0, parse_dates = True, \n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    df_universe = df_universe.loc[no_slice, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Country']\n",
    "    df_universe.set_index(['Date', 'Country'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    ### Results output:\n",
    "    return ser_market_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIS: GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "str_path_bis_csv = 'Data_Files/Source_Files/bis_bank_loans.csv'\n",
    "str_url_bis_zip = 'https://www.bis.org/statistics/full_bis_lbs_diss_csv.zip'\n",
    "str_csv_file_name = 'WEBSTATS_LBS_D_PUB_DATAFLOW_csv_col.csv'\n",
    "str_path_bis_dataset = 'Data_Files/Source_Files/bis_dataset.h5'\n",
    "str_bis_claim_dataset = 'claim_dataset'\n",
    "str_bis_liability_dataset = 'claim_dataset'\n",
    "### ISON membership loading:\n",
    "ser_market_membership = get_market_membership_from_excel()\n",
    "### BIS dataset filter:\n",
    "list_ison_countries = list(map(str, ser_market_membership.index.get_level_values(1).unique()))\n",
    "str_measure = 'S' # 'Amounts outstanding'\n",
    "str_claim_position = 'C'\n",
    "str_liability_position = 'L'\n",
    "str_instruments = 'A' # All\n",
    "str_currency_denomination = 'TO1' # All currencies\n",
    "str_currency_type = 'A' # All currencies\n",
    "str_parent_country = '5J' # All countries\n",
    "str_institution = 'A' ### All institutions\n",
    "str_sector = 'A' ### All sectors\n",
    "str_position_type = 'N' ### Cross-border\n",
    "#tup_bis_claim_filter = ('S', 'C', 'A', 'TO1', 'A', '5J', 'A', list_ison_countries, 'A', list_ison_countries, 'N')\n",
    "#tup_bis_liability_filter = ('S', 'L', 'A', 'TO1', 'A', '5J', 'A', list_ison_countries, 'A', list_ison_countries, 'N')\n",
    "tup_bis_claim_filter = (str_measure, str_claim_position, str_instruments, str_currency_denomination, str_currency_type, str_parent_country, str_institution,\n",
    "                        list_ison_countries, str_sector, list_ison_countries, str_position_type)\n",
    "tup_bis_liability_filter = (str_measure, str_liability_position, str_instruments, str_currency_denomination, str_currency_type, str_parent_country, str_institution,\n",
    "                            list_ison_countries, str_sector, list_ison_countries, str_position_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIS: CSV LOADING\n",
    "\n",
    "### File downloading:\n",
    "obj_bis_zip = requests.get(str_url_bis_zip)\n",
    "file_bis_zip = zipfile.ZipFile(io.BytesIO(obj_bis_zip.content))\n",
    "### Offline alternative:\n",
    "#df_bis_full_data = pd.read_csv(str_path_bis_csv, index_col = [*range(2, 23, 2)])\n",
    "### DataFrame creating:\n",
    "df_bis_full_data = pd.read_csv(file_bis_zip.open(str_csv_file_name), index_col = [*range(2, 23, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIS: DATASET MUNGLING\n",
    "\n",
    "### Text columns replacing and date columns stacking:\n",
    "df_bis_full_data.drop(df_bis_full_data.columns[ : 14], axis = 1, inplace = True)\n",
    "ser_bis_full_data = df_bis_full_data.stack()\n",
    "### Quarterly date managing:\n",
    "ser_bis_full_data.index.names = ser_bis_full_data.index.names[ : -1] + ['Date_Q']\n",
    "ser_bis_full_data.name = 'Value'\n",
    "### Claims dataset filtering:\n",
    "ser_bis_claim = ser_bis_full_data.loc[tup_bis_claim_filter].reset_index(level = [0, 1, 2, 3, 4, 5, 6, 8, 10], drop = True)\n",
    "### Claims resampling to monthly:\n",
    "df_bis_claim = ser_bis_claim.reset_index('Date_Q')\n",
    "df_bis_claim.index.names = ['Reporter_ID', 'Partner_ID']\n",
    "df_bis_claim['Date_Q'] = df_bis_claim['Date_Q'].str.replace('-', '')\n",
    "df_bis_claim['Date'] = pd.to_datetime(df_bis_claim['Date_Q']) + pd.offsets.BQuarterEnd()\n",
    "df_bis_claim.drop('Date_Q', axis = 1, inplace = True)\n",
    "ser_bis_claim = df_bis_claim.set_index('Date', append = True).squeeze().reorder_levels([2, 0, 1])\n",
    "ser_bis_claim = ser_bis_claim.groupby(['Reporter_ID', 'Partner_ID'])\\\n",
    "                             .apply(lambda iter_group: iter_group.droplevel(['Reporter_ID', 'Partner_ID']).resample('BM').bfill())\n",
    "### Liabilities dataset filtering:\n",
    "ser_bis_liability = ser_bis_full_data.loc[tup_bis_liability_filter].reset_index(level = [0, 1, 2, 3, 4, 5, 6, 8, 10], drop = True)\n",
    "### Liabilities resampling to monthly:\n",
    "df_bis_liability = ser_bis_liability.reset_index('Date_Q')\n",
    "df_bis_liability.index.names = ['Reporter_ID', 'Partner_ID']\n",
    "df_bis_liability['Date_Q'] = df_bis_liability['Date_Q'].str.replace('-', '')\n",
    "df_bis_liability['Date'] = pd.to_datetime(df_bis_liability['Date_Q']) + pd.offsets.BQuarterEnd()\n",
    "df_bis_liability.drop('Date_Q', axis = 1, inplace = True)\n",
    "ser_bis_liability = df_bis_liability.set_index('Date', append = True).squeeze().reorder_levels([2, 0, 1])\n",
    "ser_bis_liability = ser_bis_liability.groupby(['Reporter_ID', 'Partner_ID'])\\\n",
    "                                     .apply(lambda iter_group: iter_group.droplevel(['Reporter_ID', 'Partner_ID']).resample('BM').bfill())\n",
    "### Datasets saving\n",
    "ser_bis_claim.reorder_levels([2, 0, 1]).to_hdf(path_or_buf = str_path_bis_dataset, key = str_bis_claim_dataset, mode = 'w')\n",
    "ser_bis_liability.reorder_levels([2, 0, 1]).to_hdf(path_or_buf = str_path_bis_dataset, key = str_bis_liability_dataset, mode = 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Reporter_ID  Partner_ID\n",
       "2019-11-29  ZA           ZM            177.0\n",
       "2019-12-31  ZA           ZM            177.0\n",
       "2020-01-31  ZA           ZM            137.0\n",
       "2020-02-28  ZA           ZM            137.0\n",
       "2020-03-31  ZA           ZM            137.0\n",
       "Name: Value, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BIS: TEST: RESULTS LOADING\n",
    "\n",
    "pd.read_hdf(path_or_buf = str_path_bis_dataset, key = str_bis_claim_dataset).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIS: TEST: COLUMNS LEARNING\n",
    "\n",
    "list_ison = ser_market_membership.index.get_level_values(1).unique().to_list()\n",
    "print(len([iter_country for iter_country in df_bis_full_data['L_PARENT_CTY'].unique() if (iter_country in list_ison)]))\n",
    "print(len([iter_country for iter_country in df_bis_full_data['L_REP_CTY'].unique() if (iter_country in list_ison)]))\n",
    "print(len([iter_country for iter_country in df_bis_full_data['L_CP_COUNTRY'].unique() if (iter_country in list_ison)]))\n",
    "print(df_bis_full_data[(df_bis_full_data['L_REP_CTY'] != '5A') & (df_bis_full_data['L_PARENT_CTY'] != '5J') \\\n",
    "                 & (df_bis_full_data['L_REP_CTY'] != df_bis_full_data['L_PARENT_CTY'])][df_bis_full_data.columns[10 : 20]])\n",
    "#df_bis_full_data[(df_bis_full_data['L_REP_CTY'] == 'US') & (df_bis_full_data['L_CP_COUNTRY'] == 'CA')][df_bis_full_data.columns[ : 23]].head()\n",
    "print(df_bis_full_data['L_DENOM'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: BILATERAL EQUITY & DEBT INVESTMENT POSITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: DEFINING EXTRACTION UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def get_market_membership_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Declaring local constants & variables: \n",
    "    path_msci = 'Data_Files/Source_Files/sample_universe.xlsx' ### Path for membership source    \n",
    "    tab_monthly = 'universe_joined'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    no_slice = slice(None)\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci, sheet_name = tab_monthly, skiprows = [0, 2], header = 0, parse_dates = True, \n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    df_universe = df_universe.loc[no_slice, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Country']\n",
    "    df_universe.set_index(['Date', 'Country'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    ### Results output:\n",
    "    return ser_market_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "dict_request_headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "str_imf_base_url = 'http://dataservices.imf.org/REST/SDMX_JSON.svc/'\n",
    "str_imf_dataflow_add = 'DataFlow'\n",
    "str_imf_datastructure_add = 'DataStructure/'\n",
    "str_imf_codelist_add = 'CodeList/'\n",
    "str_imf_dataset_add = 'CompactData/'\n",
    "int_seconds_to_sleep = 3\n",
    "int_imf_country_limit = 35\n",
    "str_path_imf_dataset = 'Data_Files/Source_Files/cpis_dataset.h5'\n",
    "str_asset_imf_dataset = 'cpis_asset_dataset'\n",
    "str_liability_imf_dataset = 'cpis_liability_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: REQUESTS SESSION INITIALIZING\n",
    "\n",
    "request_session = requests.Session()\n",
    "### For avoiding data request errors from IMF Data Service:\n",
    "request_session.headers.update({'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPIS\n"
     ]
    }
   ],
   "source": [
    "### IMF CPIS: DATAFLOW SEARCHING\n",
    "\n",
    "obj_imf_dataflow_list = request_session.get(str_imf_base_url + str_imf_dataflow_add).json()\n",
    "df_imf_dataflow = pd.DataFrame(obj_imf_dataflow_list['Structure']['Dataflows']['Dataflow'])\n",
    "df_imf_dataflow = df_imf_dataflow.assign(Description = df_imf_dataflow['Name'].apply(pd.Series)['#text'].values)[['@id', 'Description']]\n",
    "ser_imf_dataflow = df_imf_dataflow.set_index('@id', drop = True).squeeze()\n",
    "### Searching DataFlow code for further requests:\n",
    "str_imf_cpis_id = ser_imf_dataflow[ser_imf_dataflow.str.contains('CPIS')].index[0].replace('DS-', '')\n",
    "print(str_imf_cpis_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          @conceptRef          @codelist @isFrequencyDimension\n",
      "0                FREQ            CL_FREQ                  true\n",
      "1            REF_AREA       CL_AREA_CPIS                   NaN\n",
      "2           INDICATOR  CL_INDICATOR_CPIS                   NaN\n",
      "3          REF_SECTOR     CL_SECTOR_CPIS                   NaN\n",
      "4  COUNTERPART_SECTOR     CL_SECTOR_CPIS                   NaN\n",
      "5    COUNTERPART_AREA       CL_AREA_CPIS                   NaN\n"
     ]
    }
   ],
   "source": [
    "### IMF CPIS: DATASTRUCTURE SEARCHING\n",
    "\n",
    "obj_imf_cpis_structure = request_session.get(str_imf_base_url + str_imf_datastructure_add + str_imf_cpis_id).json()\n",
    "df_imf_cpis_params = pd.DataFrame(obj_imf_cpis_structure['Structure']['KeyFamilies']['KeyFamily']['Components']['Dimension'])\\\n",
    "                                [['@conceptRef', '@codelist', '@isFrequencyDimension']]\n",
    "### Receiving DataFlow parameters and code lists for each of them:\n",
    "print(df_imf_cpis_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS: CODES DESCRIPTION SEARCHING\n",
    "\n",
    "for int_counter, str_param_code in enumerate(df_imf_cpis_params['@codelist']):\n",
    "    if (int_counter >= 0):\n",
    "        time.sleep(int_seconds_to_sleep)    \n",
    "        obj_imf_cpis_param = request_session.get(str_imf_base_url + str_imf_codelist_add + str_param_code).json()\n",
    "        df_imf_cpis_param =  pd.DataFrame(obj_imf_cpis_param['Structure']['CodeLists']['CodeList']['Code'])\n",
    "        ### Receiving values for each code list:\n",
    "        df_imf_cpis_param = df_imf_cpis_param.assign(Text = df_imf_cpis_param['Description'].apply(pd.Series)['#text'].values)[['@value', 'Text']]\n",
    "#        print(int_counter, ':', df_imf_cpis_params.iloc[int_counter, All]['@conceptRef'], ':', str_param_code, ':\\n', \n",
    "#              df_imf_cpis_param.head(10))\n",
    "    \n",
    "str_cpis_freq = 'B'\n",
    "str_cpis_asset_indicator = 'I_A_T_T_T_BP6_USD' \n",
    "str_cpis_liability_indicator = 'I_L_T_T_T_BP6_USD'\n",
    "str_cpis_ref_sector = 'T'\n",
    "str_cpis_cp_sector = 'T'\n",
    "list_ison_countries = list(map(str, get_market_membership_from_excel().index.get_level_values(1).unique()))\n",
    "# 0: FREQ == 'B' # Semi-annual frequency - they don't have Quaterly or Monthly frequency data\n",
    "# 1: REF_AREA == '??' # Country\n",
    "# 2: INDICATOR  == 'I_A_T_T_T_BP6_USD' # Assets, Total Investment, BPM6, US Dollars & I_L_T_T_T_BP6_USD    Liabilities, Total Investment, BPM6, US Dollars\n",
    "# 3: REF_SECTOR == 'T' # Total Holdings (all sectors)\n",
    "# 4: COUNTERPART_SECTOR  == 'T' # Total Holdings (all sectors)\n",
    "# 5: COUNTERPART_AREA == '??' # Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS ASSETS: REPORTED TOTAL PORTFOLIO INVESTMENT ASSET DATASET RETRIEVING\n",
    "\n",
    "list_cpis_bilateral = [] # List of bilateral dataframes for future concatenation\n",
    "str_cpis_const_url = str_imf_base_url + str_imf_dataset_add + str_imf_cpis_id + '/' # Beggining of request URL\n",
    "### Looping for reporter country groups:\n",
    "for int_ison_reporter_part in range(0, - (len(list_ison_countries) // ( - int_imf_country_limit))):\n",
    "    str_cpis_reporters = '+'.join(list_ison_countries[int_ison_reporter_part * int_imf_country_limit : (int_ison_reporter_part + 1) * int_imf_country_limit])\n",
    "    ### Looping for partner country groups:\n",
    "    for int_ison_partner_part in range(0, - (len(list_ison_countries) // ( - int_imf_country_limit))):\n",
    "        str_cpis_partners = '+'.join(list_ison_countries[int_ison_partner_part * int_imf_country_limit : (int_ison_partner_part + 1) * int_imf_country_limit])    \n",
    "        ### Generating complete request URL:\n",
    "        str_cpis_full_url = str_cpis_const_url + \\\n",
    "                            '.'.join([str_cpis_freq, str_cpis_reporters, str_cpis_asset_indicator, str_cpis_ref_sector, str_cpis_ref_sector, str_cpis_partners])\n",
    "        ### Receiving CPIS dataset from IMF API:\n",
    "        obj_cpis_set = request_session.get(str_cpis_full_url).json()\n",
    "        ### Converting each bilateral dataset to dataframe and it's mungling:\n",
    "        for dict_cpis_pair in obj_cpis_set['CompactData']['DataSet']['Series']:\n",
    "            if isinstance(dict_cpis_pair['Obs'], list):\n",
    "                df_cpis_bilateral = pd.DataFrame(dict_cpis_pair['Obs'])\n",
    "            else:\n",
    "                df_cpis_bilateral = pd.DataFrame([dict_cpis_pair['Obs']])\n",
    "            df_cpis_bilateral = df_cpis_bilateral[['@TIME_PERIOD', '@OBS_VALUE']]\n",
    "            df_cpis_bilateral.columns = ['Date_B', 'Value']\n",
    "            df_cpis_bilateral = df_cpis_bilateral.assign(Reporter_ID = dict_cpis_pair['@REF_AREA'])\n",
    "            df_cpis_bilateral = df_cpis_bilateral.assign(Partner_ID = dict_cpis_pair['@COUNTERPART_AREA'])\n",
    "            list_cpis_bilateral.append(df_cpis_bilateral)   \n",
    "### Bilateral dataset aggregating:\n",
    "df_cpis = pd.concat(list_cpis_bilateral, axis = 0, ignore_index = True)\n",
    "df_cpis = df_cpis[df_cpis['Reporter_ID'] != df_cpis['Partner_ID']]\n",
    "df_cpis = df_cpis.astype({'Reporter_ID': 'str', 'Partner_ID': 'str', 'Value': 'float32'})\n",
    "### Dataframe converting to stadartized format series:\n",
    "df_cpis = pd.concat(list_cpis_bilateral, axis = 0, ignore_index = True)\n",
    "df_cpis = df_cpis[df_cpis['Reporter_ID'] != df_cpis['Partner_ID']]\n",
    "df_cpis = df_cpis.astype({'Reporter_ID': 'str', 'Partner_ID': 'str', 'Value': 'float32'})\n",
    "df_cpis.loc[All, 'Date_B'] = df_cpis['Date_B'].str.replace('-B1', 'Q2').str.replace('-B2', 'Q4')\n",
    "df_cpis['Date'] = pd.to_datetime(df_cpis['Date_B']) + pd.offsets.BQuarterEnd()\n",
    "ser_asset_cpis_data = df_cpis.drop('Date_B', axis = 1).set_index(['Date', 'Reporter_ID', 'Partner_ID']).squeeze().sort_index(level = [1, 2, 0])\n",
    "ser_asset_cpis_data = ser_asset_cpis_data.groupby(['Reporter_ID', 'Partner_ID']).\\\n",
    "                                          apply(lambda iter_group: iter_group.droplevel(['Reporter_ID', 'Partner_ID']).resample('BM').bfill()).reorder_levels([2, 0, 1])\n",
    "### Series saving:\n",
    "ser_asset_cpis_data.to_hdf(path_or_buf = str_path_imf_dataset, key = str_asset_imf_dataset, mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Reporter_ID  Partner_ID\n",
       "2019-02-28  ZA           ZM            32.391674\n",
       "2019-03-29  ZA           ZM            32.391674\n",
       "2019-04-30  ZA           ZM            32.391674\n",
       "2019-05-31  ZA           ZM            32.391674\n",
       "2019-06-28  ZA           ZM            32.391674\n",
       "Name: Value, dtype: float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### IMF CPIS ASSETS: TEST\n",
    "\n",
    "pd.read_hdf(path_or_buf = str_path_imf_dataset, key = str_asset_imf_dataset).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF CPIS LIABILITIES: REPORTED TOTAL PORTFOLIO INVESTMENT LIABILITY DATASET RETRIEVING\n",
    "\n",
    "list_cpis_bilateral = [] # List of bilateral dataframes for future concatenation\n",
    "str_cpis_const_url = str_imf_base_url + str_imf_dataset_add + str_imf_cpis_id + '/' # Beggining of request URL\n",
    "### Looping for reporter country groups:\n",
    "for int_ison_reporter_part in range(0, - (len(list_ison_countries) // ( - int_imf_country_limit))):\n",
    "    str_cpis_reporters = '+'.join(list_ison_countries[int_ison_reporter_part * int_imf_country_limit : (int_ison_reporter_part + 1) * int_imf_country_limit])\n",
    "    ### Looping for partner country groups:\n",
    "    for int_ison_partner_part in range(0, - (len(list_ison_countries) // ( - int_imf_country_limit))):\n",
    "        str_cpis_partners = '+'.join(list_ison_countries[int_ison_partner_part * int_imf_country_limit : (int_ison_partner_part + 1) * int_imf_country_limit])    \n",
    "        ### Generating complete request URL:\n",
    "        str_cpis_full_url = str_cpis_const_url + \\\n",
    "                            '.'.join([str_cpis_freq, str_cpis_reporters, str_cpis_liability_indicator, str_cpis_ref_sector, str_cpis_ref_sector, str_cpis_partners])\n",
    "        ### Receiving CPIS dataset from IMF API:\n",
    "        obj_cpis_set = request_session.get(str_cpis_full_url).json()\n",
    "        ### Converting each bilateral dataset to dataframe and it's mungling:\n",
    "        for dict_cpis_pair in obj_cpis_set['CompactData']['DataSet']['Series']:\n",
    "            if isinstance(dict_cpis_pair['Obs'], list):\n",
    "                df_cpis_bilateral = pd.DataFrame(dict_cpis_pair['Obs'])\n",
    "            else:\n",
    "                df_cpis_bilateral = pd.DataFrame([dict_cpis_pair['Obs']])\n",
    "            df_cpis_bilateral = df_cpis_bilateral[['@TIME_PERIOD', '@OBS_VALUE']]\n",
    "            df_cpis_bilateral.columns = ['Date_B', 'Value']\n",
    "            df_cpis_bilateral = df_cpis_bilateral.assign(Reporter_ID = dict_cpis_pair['@REF_AREA'])\n",
    "            df_cpis_bilateral = df_cpis_bilateral.assign(Partner_ID = dict_cpis_pair['@COUNTERPART_AREA'])\n",
    "            list_cpis_bilateral.append(df_cpis_bilateral)   \n",
    "### Bilateral dataset aggregating:\n",
    "df_cpis = pd.concat(list_cpis_bilateral, axis = 0, ignore_index = True)\n",
    "df_cpis = df_cpis[df_cpis['Reporter_ID'] != df_cpis['Partner_ID']]\n",
    "df_cpis = df_cpis.astype({'Reporter_ID': 'str', 'Partner_ID': 'str', 'Value': 'float32'})\n",
    "### Dataframe converting to stadartized format series:\n",
    "df_cpis = pd.concat(list_cpis_bilateral, axis = 0, ignore_index = True)\n",
    "df_cpis = df_cpis[df_cpis['Reporter_ID'] != df_cpis['Partner_ID']]\n",
    "df_cpis = df_cpis.astype({'Reporter_ID': 'str', 'Partner_ID': 'str', 'Value': 'float32'})\n",
    "df_cpis.loc[All, 'Date_B'] = df_cpis['Date_B'].str.replace('-B1', 'Q2').str.replace('-B2', 'Q4')\n",
    "df_cpis['Date'] = pd.to_datetime(df_cpis['Date_B']) + pd.offsets.BQuarterEnd()\n",
    "ser_liability_cpis_data = df_cpis.drop('Date_B', axis = 1).set_index(['Date', 'Reporter_ID', 'Partner_ID']).squeeze().sort_index(level = [1, 2, 0])\n",
    "ser_liability_cpis_data = ser_liability_cpis_data.groupby(['Reporter_ID', 'Partner_ID']).\\\n",
    "                                          apply(lambda iter_group: iter_group.droplevel(['Reporter_ID', 'Partner_ID']).resample('BM').bfill()).reorder_levels([2, 0, 1])\n",
    "### Series saving:\n",
    "ser_liability_cpis_data.to_hdf(path_or_buf = str_path_imf_dataset, key = str_liability_imf_dataset, mode = 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Reporter_ID  Partner_ID\n",
       "2010-08-31  TH           ZM            0.0\n",
       "2010-09-30  TH           ZM            0.0\n",
       "2010-10-29  TH           ZM            0.0\n",
       "2010-11-30  TH           ZM            0.0\n",
       "2010-12-31  TH           ZM            0.0\n",
       "Name: Value, dtype: float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### IMF CPIS LIABILITIES: TEST\n",
    "\n",
    "pd.read_hdf(path_or_buf = str_path_imf_dataset, key = str_liability_imf_dataset).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FOREIGN DIRECT INVESTMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import xml.etree.ElementTree as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COUNTRY ISO CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    import pandas as pd\n",
    "    \n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']]      \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def get_market_membership_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Declaring local constants & variables: \n",
    "    path_msci = 'Data_Files/Source_Files/sample_universe.xlsx' ### Path for membership source    \n",
    "    tab_monthly = 'universe_joined'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    no_slice = slice(None)\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci, sheet_name = tab_monthly, skiprows = [0, 2], header = 0, parse_dates = True, \n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    df_universe = df_universe.loc[no_slice, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Country']\n",
    "    df_universe.set_index(['Date', 'Country'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    ### Results output:\n",
    "    return ser_market_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "str_oecd_base_url = 'https://stats.oecd.org/sdmx-json/data/'\n",
    "str_oecd_structure_url = 'https://stats.oecd.org/restsdmx/sdmx.ashx/GetDataStructure/'\n",
    "str_fdi_flow_dataset_add = 'FDI_FLOW_CTRY'\n",
    "str_fdi_pos_dataset_add = 'FDI_POS_CTRY'\n",
    "### General data:\n",
    "df_countries = get_country_codes()\n",
    "ser_ison_membership = get_market_membership_from_excel()\n",
    "### Results saving:\n",
    "str_path_fdi_dataset = 'Data_Files/Source_Files/oecd_dataset.h5'\n",
    "str_fdi_flow_oecd_dataset = 'fdi_flow_dataset'\n",
    "str_fdi_pos_oecd_dataset = 'fdi_pos_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: REQUESTS SESSION INITIALIZING\n",
    "\n",
    "request_session = requests.Session()\n",
    "### For avoiding data request errors:\n",
    "request_session.headers.update({'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI FLOW STRUCTURE REQUEST\n",
    "\n",
    "obj_oecd_structure = request_session.get(str_oecd_structure_url + str_fdi_flow_dataset_add)\n",
    "xml_tree_root = et.fromstring(obj_oecd_structure.content)\n",
    "dict_concepts = {}\n",
    "dict_dimensions = {}\n",
    "dict_codelists = {}\n",
    "for xml_tree_child in xml_tree_root:\n",
    "    if xml_tree_child.tag.endswith('Concepts'):\n",
    "        for xml_tree_grand in xml_tree_child:\n",
    "            str_concept_id = xml_tree_grand.attrib['id']\n",
    "            str_concept_name = xml_tree_grand[0].text\n",
    "            dict_concepts[str_concept_id] = str_concept_name\n",
    "    if xml_tree_child.tag.endswith('KeyFamilies'):\n",
    "        for xml_tree_family in xml_tree_child:\n",
    "            for xml_tree_component in xml_tree_family:\n",
    "                if xml_tree_component.tag.endswith('Components'):\n",
    "                    for xml_tree_measure in xml_tree_component:\n",
    "                        if xml_tree_measure.tag.endswith('Dimension'):\n",
    "                            str_concept_id = xml_tree_measure.attrib['conceptRef']\n",
    "                            str_concept_cl_id = xml_tree_measure.attrib['codelist']\n",
    "                            dict_dimensions[str_concept_id] = str_concept_cl_id\n",
    "    if xml_tree_child.tag.endswith('CodeLists'):       \n",
    "        for num_tree_grand, xml_tree_grand in enumerate(xml_tree_child):\n",
    "            str_codelist_id = xml_tree_grand.attrib['id']\n",
    "            dict_codelist = {}\n",
    "            for xml_tree_codelist in xml_tree_grand:                \n",
    "                if xml_tree_codelist.tag.endswith('Code'):\n",
    "                    str_code_id = xml_tree_codelist.attrib['value']\n",
    "                    str_code_value = xml_tree_codelist[0].text\n",
    "                    dict_codelist[str_code_id] = str_code_value\n",
    "            dict_codelists[str_codelist_id] = dict_codelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COU': 'Reporting country',\n",
       " 'MEASURE': 'Currency',\n",
       " 'MEASURE_PRINCIPLE': 'Measurement principle',\n",
       " 'FDI_TYPE': 'Type of FDI',\n",
       " 'TYPE_ENTITY': 'Type of entity',\n",
       " 'ACCOUNTING_ENTRY': 'Accounting entry',\n",
       " 'LEVEL_COUNTERPART': 'Level of counterpart',\n",
       " 'COUNTERPART_AREA': 'Partner country/territory',\n",
       " 'TIME': 'Year',\n",
       " 'OBS_VALUE': 'Observation Value',\n",
       " 'TIME_FORMAT': 'Time Format',\n",
       " 'OBS_STATUS': 'Observation Status',\n",
       " 'UNIT': 'Unit',\n",
       " 'POWERCODE': 'Unit multiplier',\n",
       " 'REFERENCEPERIOD': 'Reference period'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OECD FDI: FDI FLOW CONCEPTS DESCRIPTION:\n",
    "\n",
    "dict_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COU': 'CL_FDI_FLOW_CTRY_COU',\n",
       " 'MEASURE': 'CL_FDI_FLOW_CTRY_MEASURE',\n",
       " 'MEASURE_PRINCIPLE': 'CL_FDI_FLOW_CTRY_MEASURE_PRINCIPLE',\n",
       " 'FDI_TYPE': 'CL_FDI_FLOW_CTRY_FDI_TYPE',\n",
       " 'TYPE_ENTITY': 'CL_FDI_FLOW_CTRY_TYPE_ENTITY',\n",
       " 'ACCOUNTING_ENTRY': 'CL_FDI_FLOW_CTRY_ACCOUNTING_ENTRY',\n",
       " 'LEVEL_COUNTERPART': 'CL_FDI_FLOW_CTRY_LEVEL_COUNTERPART',\n",
       " 'COUNTERPART_AREA': 'CL_FDI_FLOW_CTRY_COUNTERPART_AREA',\n",
       " 'TIME': 'CL_FDI_FLOW_CTRY_TIME'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OECD FDI: FDI FLOW CONCEPTS SOURCES: \n",
    "\n",
    "dict_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>COU</td>\n",
       "      <td>Reporting country</td>\n",
       "      <td>CL_FDI_FLOW_CTRY_COU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MEASURE</td>\n",
       "      <td>Currency</td>\n",
       "      <td>CL_FDI_FLOW_CTRY_MEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MEASURE_PRINCIPLE</td>\n",
       "      <td>Measurement principle</td>\n",
       "      <td>CL_FDI_FLOW_CTRY_MEASURE_PRINCIPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FDI_TYPE</td>\n",
       "      <td>Type of FDI</td>\n",
       "      <td>CL_FDI_FLOW_CTRY_FDI_TYPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TYPE_ENTITY</td>\n",
       "      <td>Type of entity</td>\n",
       "      <td>CL_FDI_FLOW_CTRY_TYPE_ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ACCOUNTING_ENTRY</td>\n",
       "      <td>Accounting entry</td>\n",
       "      <td>CL_FDI_FLOW_CTRY_ACCOUNTING_ENTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LEVEL_COUNTERPART</td>\n",
       "      <td>Level of counterpart</td>\n",
       "      <td>CL_FDI_FLOW_CTRY_LEVEL_COUNTERPART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>COUNTERPART_AREA</td>\n",
       "      <td>Partner country/territory</td>\n",
       "      <td>CL_FDI_FLOW_CTRY_COUNTERPART_AREA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TIME</td>\n",
       "      <td>Year</td>\n",
       "      <td>CL_FDI_FLOW_CTRY_TIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0  \\\n",
       "COU                        Reporting country   \n",
       "MEASURE                             Currency   \n",
       "MEASURE_PRINCIPLE      Measurement principle   \n",
       "FDI_TYPE                         Type of FDI   \n",
       "TYPE_ENTITY                   Type of entity   \n",
       "ACCOUNTING_ENTRY            Accounting entry   \n",
       "LEVEL_COUNTERPART       Level of counterpart   \n",
       "COUNTERPART_AREA   Partner country/territory   \n",
       "TIME                                    Year   \n",
       "\n",
       "                                                    1  \n",
       "COU                              CL_FDI_FLOW_CTRY_COU  \n",
       "MEASURE                      CL_FDI_FLOW_CTRY_MEASURE  \n",
       "MEASURE_PRINCIPLE  CL_FDI_FLOW_CTRY_MEASURE_PRINCIPLE  \n",
       "FDI_TYPE                    CL_FDI_FLOW_CTRY_FDI_TYPE  \n",
       "TYPE_ENTITY              CL_FDI_FLOW_CTRY_TYPE_ENTITY  \n",
       "ACCOUNTING_ENTRY    CL_FDI_FLOW_CTRY_ACCOUNTING_ENTRY  \n",
       "LEVEL_COUNTERPART  CL_FDI_FLOW_CTRY_LEVEL_COUNTERPART  \n",
       "COUNTERPART_AREA    CL_FDI_FLOW_CTRY_COUNTERPART_AREA  \n",
       "TIME                            CL_FDI_FLOW_CTRY_TIME  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "pd.concat([pd.Series(dict_concepts), pd.Series(dict_dimensions)], axis = 1, sort = False).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IMC': 'Immediate counterpart (Immediate investor or immediate host)'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OECD FDI: FDI FLOW CONCEPT SOURCE CODELISTS:\n",
    "\n",
    "dict_codelists['CL_FDI_FLOW_CTRY_LEVEL_COUNTERPART']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISON countries with no OECD partner match: {'ROU'}\n"
     ]
    }
   ],
   "source": [
    "### OECD FDI: FDI FLOW PARAMETERS PREPARATION: Reporters and partners control and preparation\n",
    "\n",
    "### ISON Countries collecting:\n",
    "df_ison_countries = df_countries.set_index('ISO SHORT', append = True).reset_index('COUNTRY', drop = True)\n",
    "df_ison_countries = df_ison_countries.reindex(ser_ison_membership.index.get_level_values(1).unique().to_list())\n",
    "ser_ison_countries = df_ison_countries.reset_index().set_index('ISO LONG').squeeze()\n",
    "### OECD reporters vs ISON members:\n",
    "ser_oecd_reporters = pd.Series(dict_codelists['CL_FDI_FLOW_CTRY_COU'])\n",
    "ser_oecd_reporters = ser_oecd_reporters.to_frame().join(ser_ison_countries).drop(0, axis = 1).squeeze()\n",
    "for iter_iso_long in (ser_oecd_reporters[ser_oecd_reporters.isna()].index.get_level_values(0)):\n",
    "    if iter_iso_long in ser_ison_countries.index:\n",
    "        print('OECD Reporter country with no ISON match:', iter_iso_long)\n",
    "### OECD partners vs ISON members:\n",
    "ser_oecd_partners = pd.Series(dict_codelists['CL_FDI_FLOW_CTRY_COUNTERPART_AREA'])\n",
    "ser_oecd_partners = ser_oecd_partners.to_frame().join(ser_ison_countries).drop(0, axis = 1).squeeze()\n",
    "for iter_iso_long in (ser_oecd_partners[ser_oecd_partners.isna()].index.get_level_values(0)):\n",
    "    if iter_iso_long in ser_ison_countries.index:\n",
    "        print('OECD Partner country with no ISON match:', iter_iso_long)\n",
    "### ISON countries with no OECD partner match:\n",
    "print('ISON countries with no OECD partner match:', set(ser_ison_countries.dropna().index) - set(ser_oecd_partners.index))\n",
    "### Lists preparation:\n",
    "str_reporters_all = '+'.join(ser_oecd_reporters.dropna().index.to_list())\n",
    "str_partners_all = '+'.join(ser_oecd_partners.dropna().index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI FLOW PARAMETERS PREPARATION: Non-country parameters:\n",
    "\n",
    "### Currency:\n",
    "str_measure = 'USD'\n",
    "### Direction:\n",
    "str_direction = '+'.join(['DI', 'DO'])\n",
    "### Investment type:\n",
    "str_fdi_type = 'T_FA_F'\n",
    "### Residence defining:\n",
    "str_residence = 'ALL'\n",
    "### Accounting way:\n",
    "str_accounting = '+'.join(['NET', 'A', 'L'])\n",
    "### Level counterpart(???):\n",
    "str_counterpart = 'IMC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI FLOW REQUEST CONSTRUCTING\n",
    "\n",
    "str_fdi_flow_request_params = '.'.join([str_reporters_all, str_measure, str_direction, str_fdi_type, str_residence, str_accounting, str_counterpart, str_partners_all])\n",
    "str_fdi_flow_request = str_oecd_base_url + str_fdi_flow_dataset_add + '/' + str_fdi_flow_request_params + '/all?detail=DataOnly'\n",
    "obj_fdi_flow_dataset = request_session.get(str_fdi_flow_request).json()\n",
    "#str_fdi_flow_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI FLOW INDEX DATA COLLECTING:\n",
    "\n",
    "### Dates:\n",
    "list_idx_dates = []\n",
    "for tup_date in obj_fdi_flow_dataset['structure']['dimensions']['observation'][0]['values']:\n",
    "    list_idx_dates.append(pd.to_datetime(tup_date['id']) + pd.offsets.BYearEnd())\n",
    "### Parameters:    \n",
    "list_idx_library = []\n",
    "for iter_position in obj_fdi_flow_dataset['structure']['dimensions']['series']:\n",
    "    list_param_values = []\n",
    "    for tup_parameter in iter_position['values']:\n",
    "        list_param_values.append(tup_parameter['id'])            \n",
    "    list_idx_library.append(list_param_values)\n",
    "### Result:\n",
    "list_idx_library.append(list_idx_dates)\n",
    "### Converting to dictionary for future replacing:\n",
    "list_idx_dict = []\n",
    "for iter_list in list_idx_library:\n",
    "    list_idx_dict.append(dict(zip(map(str, range(len(iter_list))), iter_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI FLOW DATASET RESAMPLING\n",
    "\n",
    "dict_datasets_res = {}\n",
    "dict_datasets_source = obj_fdi_flow_dataset['dataSets'][0]['series']\n",
    "### Parameters and date indexes integration:\n",
    "for iter_dataset in dict_datasets_source:\n",
    "    dict_observations = dict_datasets_source[iter_dataset]['observations']\n",
    "    for iter_observation in dict_observations:\n",
    "        str_iter_idx = iter_dataset + ':' + iter_observation\n",
    "        flo_iter_value = dict_observations[iter_observation][0]\n",
    "        dict_datasets_res[str_iter_idx] = flo_iter_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI FLOW DATASET REINDEXATION\n",
    "\n",
    "df_fdi_flow_data = pd.Series(dict_datasets_res)\n",
    "df_fdi_flow_data.index = pd.MultiIndex.from_arrays(zip(*df_fdi_flow_data.index.str.split(':')))\n",
    "int_levels_number = df_fdi_flow_data.index.nlevels\n",
    "df_fdi_flow_data = df_fdi_flow_data.reset_index()\n",
    "### Replacing numbers with parameter values:\n",
    "for iter_level in range(int_levels_number):\n",
    "    df_fdi_flow_data['level_' + str(iter_level)].replace(list_idx_dict[iter_level], inplace = True)\n",
    "    ### Replacing long ISO names with short ISO names:\n",
    "    if (iter_level == 0):\n",
    "        df_fdi_flow_data['level_' + str(iter_level)].replace(dict(zip(ser_oecd_reporters.index, ser_oecd_reporters)), inplace = True)\n",
    "    elif (iter_level == 7):\n",
    "        df_fdi_flow_data['level_' + str(iter_level)].replace(dict(zip(ser_oecd_partners.index, ser_oecd_partners)), inplace = True)      \n",
    "    ### Directions renaming:\n",
    "    elif (iter_level == 2):\n",
    "        df_fdi_flow_data['level_' + str(iter_level)].replace({'DI': 'Inward', 'DO': 'Outward'}, inplace = True)\n",
    "    ### Flow types renaming:\n",
    "    elif (iter_level == 5):\n",
    "        df_fdi_flow_data['level_' + str(iter_level)].replace({'NET': 'Net', 'A': 'Asset', 'L': 'Liability'}, inplace = True)      \n",
    "\n",
    "### Indexes defining:\n",
    "ser_fdi_flow_data = df_fdi_flow_data.drop(['level_3', 'level_4', 'level_6'], axis = 1)\\\n",
    "                    .set_index(['level_8', 'level_0', 'level_7', 'level_1', 'level_2', 'level_5']).squeeze()\n",
    "ser_fdi_flow_data.index.names = ['Date', 'Reporter_ID', 'Partner_ID', 'Currency', 'Direction', 'Accounting']\n",
    "ser_fdi_flow_data.sort_index(inplace = True)  \n",
    "ser_fdi_flow_data.name = 'FDI Flows'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION STRUCTURE REQUEST\n",
    "\n",
    "obj_oecd_structure = request_session.get(str_oecd_structure_url + str_fdi_pos_dataset_add)\n",
    "xml_tree_root = et.fromstring(obj_oecd_structure.content)\n",
    "dict_concepts = {}\n",
    "dict_dimensions = {}\n",
    "dict_codelists = {}\n",
    "for xml_tree_child in xml_tree_root:\n",
    "    if xml_tree_child.tag.endswith('Concepts'):\n",
    "        for xml_tree_grand in xml_tree_child:\n",
    "            str_concept_id = xml_tree_grand.attrib['id']\n",
    "            str_concept_name = xml_tree_grand[0].text\n",
    "            dict_concepts[str_concept_id] = str_concept_name\n",
    "    if xml_tree_child.tag.endswith('KeyFamilies'):\n",
    "        for xml_tree_family in xml_tree_child:\n",
    "            for xml_tree_component in xml_tree_family:\n",
    "                if xml_tree_component.tag.endswith('Components'):\n",
    "                    for xml_tree_measure in xml_tree_component:\n",
    "                        if xml_tree_measure.tag.endswith('Dimension'):\n",
    "                            str_concept_id = xml_tree_measure.attrib['conceptRef']\n",
    "                            str_concept_cl_id = xml_tree_measure.attrib['codelist']\n",
    "                            dict_dimensions[str_concept_id] = str_concept_cl_id\n",
    "    if xml_tree_child.tag.endswith('CodeLists'):       \n",
    "        for num_tree_grand, xml_tree_grand in enumerate(xml_tree_child):\n",
    "            str_codelist_id = xml_tree_grand.attrib['id']\n",
    "            dict_codelist = {}\n",
    "            for xml_tree_codelist in xml_tree_grand:                \n",
    "                if xml_tree_codelist.tag.endswith('Code'):\n",
    "                    str_code_id = xml_tree_codelist.attrib['value']\n",
    "                    str_code_value = xml_tree_codelist[0].text\n",
    "                    dict_codelist[str_code_id] = str_code_value\n",
    "            dict_codelists[str_codelist_id] = dict_codelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COU': 'CL_FDI_POS_CTRY_COU',\n",
       " 'MEASURE': 'CL_FDI_POS_CTRY_MEASURE',\n",
       " 'MEASURE_PRINCIPLE': 'CL_FDI_POS_CTRY_MEASURE_PRINCIPLE',\n",
       " 'FDI_TYPE': 'CL_FDI_POS_CTRY_FDI_TYPE',\n",
       " 'TYPE_ENTITY': 'CL_FDI_POS_CTRY_TYPE_ENTITY',\n",
       " 'ACCOUNTING_ENTRY': 'CL_FDI_POS_CTRY_ACCOUNTING_ENTRY',\n",
       " 'LEVEL_COUNTERPART': 'CL_FDI_POS_CTRY_LEVEL_COUNTERPART',\n",
       " 'COUNTERPART_AREA': 'CL_FDI_POS_CTRY_COUNTERPART_AREA',\n",
       " 'TIME': 'CL_FDI_POS_CTRY_TIME'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OECD FDI: FDI POSITION CONCEPTS SOURCES: \n",
    "\n",
    "dict_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>COU</td>\n",
       "      <td>Reporting country</td>\n",
       "      <td>CL_FDI_POS_CTRY_COU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MEASURE</td>\n",
       "      <td>Currency</td>\n",
       "      <td>CL_FDI_POS_CTRY_MEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MEASURE_PRINCIPLE</td>\n",
       "      <td>Measurement principle</td>\n",
       "      <td>CL_FDI_POS_CTRY_MEASURE_PRINCIPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FDI_TYPE</td>\n",
       "      <td>Type of FDI</td>\n",
       "      <td>CL_FDI_POS_CTRY_FDI_TYPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TYPE_ENTITY</td>\n",
       "      <td>Type of entity</td>\n",
       "      <td>CL_FDI_POS_CTRY_TYPE_ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ACCOUNTING_ENTRY</td>\n",
       "      <td>Accounting entry</td>\n",
       "      <td>CL_FDI_POS_CTRY_ACCOUNTING_ENTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LEVEL_COUNTERPART</td>\n",
       "      <td>Level of counterpart</td>\n",
       "      <td>CL_FDI_POS_CTRY_LEVEL_COUNTERPART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>COUNTERPART_AREA</td>\n",
       "      <td>Partner country/territory</td>\n",
       "      <td>CL_FDI_POS_CTRY_COUNTERPART_AREA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TIME</td>\n",
       "      <td>Year</td>\n",
       "      <td>CL_FDI_POS_CTRY_TIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0  \\\n",
       "COU                        Reporting country   \n",
       "MEASURE                             Currency   \n",
       "MEASURE_PRINCIPLE      Measurement principle   \n",
       "FDI_TYPE                         Type of FDI   \n",
       "TYPE_ENTITY                   Type of entity   \n",
       "ACCOUNTING_ENTRY            Accounting entry   \n",
       "LEVEL_COUNTERPART       Level of counterpart   \n",
       "COUNTERPART_AREA   Partner country/territory   \n",
       "TIME                                    Year   \n",
       "\n",
       "                                                   1  \n",
       "COU                              CL_FDI_POS_CTRY_COU  \n",
       "MEASURE                      CL_FDI_POS_CTRY_MEASURE  \n",
       "MEASURE_PRINCIPLE  CL_FDI_POS_CTRY_MEASURE_PRINCIPLE  \n",
       "FDI_TYPE                    CL_FDI_POS_CTRY_FDI_TYPE  \n",
       "TYPE_ENTITY              CL_FDI_POS_CTRY_TYPE_ENTITY  \n",
       "ACCOUNTING_ENTRY    CL_FDI_POS_CTRY_ACCOUNTING_ENTRY  \n",
       "LEVEL_COUNTERPART  CL_FDI_POS_CTRY_LEVEL_COUNTERPART  \n",
       "COUNTERPART_AREA    CL_FDI_POS_CTRY_COUNTERPART_AREA  \n",
       "TIME                            CL_FDI_POS_CTRY_TIME  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "pd.concat([pd.Series(dict_concepts), pd.Series(dict_dimensions)], axis = 1, sort = False).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LE_FA_F': 'FDI positions -Total',\n",
       " 'LE_FA_F5': 'FDI positions - Equity (including reinvestment of earnings)',\n",
       " 'LE_FA_FL': 'FDI positions - Debt'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OECD FDI: FDI POSITION CONCEPT SOURCE CODELISTS:\n",
    "\n",
    "dict_codelists['CL_FDI_POS_CTRY_FDI_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION PARAMETERS PREPARATION: Non-country parameters:\n",
    "\n",
    "### Currency:\n",
    "str_measure = 'USD'\n",
    "### Direction:\n",
    "str_direction = '+'.join(['DI', 'DO'])\n",
    "### Investment type:\n",
    "str_fdi_type = 'LE_FA_F'\n",
    "### Residence defining:\n",
    "str_residence = 'ALL'\n",
    "### Accounting way:\n",
    "str_accounting = '+'.join(['NET', 'A', 'L'])\n",
    "### Level counterpart(???):\n",
    "str_counterpart = 'IMC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISON countries with no OECD partner match: {'ROU'}\n"
     ]
    }
   ],
   "source": [
    "### OECD FDI: FDI POSITION PARAMETERS PREPARATION: Reporters and partners control and preparation\n",
    "\n",
    "### ISON Countries collecting:\n",
    "df_ison_countries = df_countries.set_index('ISO SHORT', append = True).reset_index('COUNTRY', drop = True)\n",
    "df_ison_countries = df_ison_countries.reindex(ser_ison_membership.index.get_level_values(1).unique().to_list())\n",
    "ser_ison_countries = df_ison_countries.reset_index().set_index('ISO LONG').squeeze()\n",
    "### OECD reporters vs ISON members:\n",
    "ser_oecd_reporters = pd.Series(dict_codelists['CL_FDI_POS_CTRY_COU'])\n",
    "ser_oecd_reporters = ser_oecd_reporters.to_frame().join(ser_ison_countries).drop(0, axis = 1).squeeze()\n",
    "for iter_iso_long in (ser_oecd_reporters[ser_oecd_reporters.isna()].index.get_level_values(0)):\n",
    "    if iter_iso_long in ser_ison_countries.index:\n",
    "        print('OECD Reporter country with no ISON match:', iter_iso_long)\n",
    "### OECD partners vs ISON members:\n",
    "ser_oecd_partners = pd.Series(dict_codelists['CL_FDI_POS_CTRY_COUNTERPART_AREA'])\n",
    "ser_oecd_partners = ser_oecd_partners.to_frame().join(ser_ison_countries).drop(0, axis = 1).squeeze()\n",
    "for iter_iso_long in (ser_oecd_partners[ser_oecd_partners.isna()].index.get_level_values(0)):\n",
    "    if iter_iso_long in ser_ison_countries.index:\n",
    "        print('OECD Partner country with no ISON match:', iter_iso_long)\n",
    "### ISON countries with no OECD partner match:\n",
    "print('ISON countries with no OECD partner match:', set(ser_ison_countries.dropna().index) - set(ser_oecd_partners.index))\n",
    "### Lists preparation:\n",
    "str_reporters_all = '+'.join(ser_oecd_reporters.dropna().index.to_list())\n",
    "str_partners_all = '+'.join(ser_oecd_partners.dropna().index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION REQUEST CONSTRUCTING\n",
    "\n",
    "str_fdi_pos_request_params = '.'.join([str_reporters_all, str_measure, str_direction, str_fdi_type, str_residence, str_accounting, str_counterpart, str_partners_all])\n",
    "str_fdi_pos_request = str_oecd_base_url + str_fdi_pos_dataset_add + '/' + str_fdi_pos_request_params + '/all?detail=DataOnly'\n",
    "obj_fdi_pos_dataset = request_session.get(str_fdi_pos_request).json()\n",
    "#str_fdi_pos_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION INDEX DATA COLLECTING:\n",
    "\n",
    "### Dates:\n",
    "list_idx_dates = []\n",
    "for tup_date in obj_fdi_pos_dataset['structure']['dimensions']['observation'][0]['values']:\n",
    "    list_idx_dates.append(pd.to_datetime(tup_date['id']) + pd.offsets.BYearEnd())\n",
    "### Parameters:    \n",
    "list_idx_library = []\n",
    "for iter_position in obj_fdi_pos_dataset['structure']['dimensions']['series']:\n",
    "    list_param_values = []\n",
    "    for tup_parameter in iter_position['values']:\n",
    "        list_param_values.append(tup_parameter['id'])            \n",
    "    list_idx_library.append(list_param_values)\n",
    "### Result:\n",
    "list_idx_library.append(list_idx_dates)\n",
    "### Converting to dictionary for future replacing:\n",
    "list_idx_dict = []\n",
    "for iter_list in list_idx_library:\n",
    "    list_idx_dict.append(dict(zip(map(str, range(len(iter_list))), iter_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION DATASET RESAMPLING\n",
    "\n",
    "dict_datasets_res = {}\n",
    "dict_datasets_source = obj_fdi_pos_dataset['dataSets'][0]['series']\n",
    "### Parameters and date indexes integration:\n",
    "for iter_dataset in dict_datasets_source:\n",
    "    dict_observations = dict_datasets_source[iter_dataset]['observations']\n",
    "    for iter_observation in dict_observations:\n",
    "        str_iter_idx = iter_dataset + ':' + iter_observation\n",
    "        flo_iter_value = dict_observations[iter_observation][0]\n",
    "        dict_datasets_res[str_iter_idx] = flo_iter_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION DATASET REINDEXATION\n",
    "\n",
    "df_fdi_pos_data = pd.Series(dict_datasets_res)\n",
    "df_fdi_pos_data.index = pd.MultiIndex.from_arrays(zip(*df_fdi_pos_data.index.str.split(':')))\n",
    "int_levels_number = df_fdi_pos_data.index.nlevels\n",
    "df_fdi_pos_data = df_fdi_pos_data.reset_index()\n",
    "### Replacing numbers with parameter values:\n",
    "for iter_level in range(int_levels_number):\n",
    "    df_fdi_pos_data['level_' + str(iter_level)].replace(list_idx_dict[iter_level], inplace = True)\n",
    "    ### Replacing long ISO names with short ISO names:\n",
    "    if (iter_level == 0):\n",
    "        df_fdi_pos_data['level_' + str(iter_level)].replace(dict(zip(ser_oecd_reporters.index, ser_oecd_reporters)), inplace = True)\n",
    "    elif (iter_level == 7):\n",
    "        df_fdi_pos_data['level_' + str(iter_level)].replace(dict(zip(ser_oecd_partners.index, ser_oecd_partners)), inplace = True)      \n",
    "    ### Directions renaming:\n",
    "    elif (iter_level == 2):\n",
    "        df_fdi_pos_data['level_' + str(iter_level)].replace({'DI': 'Inward', 'DO': 'Outward'}, inplace = True)\n",
    "    ### Flow types renaming:\n",
    "    elif (iter_level == 5):\n",
    "        df_fdi_pos_data['level_' + str(iter_level)].replace({'NET': 'Net', 'A': 'Asset', 'L': 'Liability'}, inplace = True)      \n",
    "\n",
    "### Indexes defining:\n",
    "ser_fdi_pos_data = df_fdi_pos_data.drop(['level_3', 'level_4', 'level_6'], axis = 1)\\\n",
    "                    .set_index(['level_8', 'level_0', 'level_7', 'level_1', 'level_2', 'level_5']).squeeze()\n",
    "ser_fdi_pos_data.index.names = ['Date', 'Reporter_ID', 'Partner_ID', 'Currency', 'Direction', 'Accounting']\n",
    "ser_fdi_pos_data.sort_index(inplace = True)\n",
    "ser_fdi_pos_data.name = 'FDI Positions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI RESULTS SAVING\n",
    "\n",
    "ser_fdi_flow_data.to_hdf(path_or_buf = str_path_fdi_dataset, key = str_fdi_flow_oecd_dataset, mode = 'w')\n",
    "ser_fdi_pos_data.to_hdf(path_or_buf = str_path_fdi_dataset, key = str_fdi_pos_oecd_dataset, mode = 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI RESULTS READING\n",
    "\n",
    "pd.read_hdf(path_or_buf = str_path_fdi_dataset, key = str_fdi_pos_oecd_dataset).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CEPII DISTANCES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CEPII DISTANCES: INITIALIZATION\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COUNTRY ISO CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    import pandas as pd\n",
    "    \n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']]      \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def get_market_membership_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Declaring local constants & variables: \n",
    "    path_msci = 'Data_Files/Source_Files/sample_universe.xlsx' ### Path for membership source    \n",
    "    tab_monthly = 'universe_joined'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    no_slice = slice(None)\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci, sheet_name = tab_monthly, skiprows = [0, 2], header = 0, parse_dates = True, \n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    df_universe = df_universe.loc[no_slice, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Country']\n",
    "    df_universe.set_index(['Date', 'Country'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    ### Results output:\n",
    "    return ser_market_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CEPII DISTANCES: GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "str_path_cepii_source = 'Data_Files/Source_Files/CEPII Distance Data/dist_cepii.xls'\n",
    "### General data:\n",
    "df_countries = get_country_codes()\n",
    "ser_ison_membership = get_market_membership_from_excel()\n",
    "### Results saving:\n",
    "str_path_cepii_dataset = 'Data_Files/Source_Files/cepii_dataset.h5'\n",
    "str_distance_dataset = 'distance_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CEPII DISTANCES: DATA EXPORT AND REPACKING\n",
    "\n",
    "#### Source data export:\n",
    "df_distance_source = pd.read_excel('Data_Files/Source_Files/CEPII Distance Data/dist_cepii.xls', index_col = [0, 1])\n",
    "### Long to Short Country ID's converting:\n",
    "df_distance_data = df_distance_source.join(df_countries.set_index('ISO LONG').squeeze(), on = 'iso_o')\n",
    "df_distance_data.rename({'ISO SHORT': 'From_ID'}, axis = 1, inplace = True)\n",
    "df_distance_data = df_distance_data.join(df_countries.set_index('ISO LONG').squeeze(), on = 'iso_d')\n",
    "df_distance_data.rename({'ISO SHORT': 'To_ID'}, axis = 1, inplace = True)\n",
    "### ISON countries filtering:\n",
    "list_ison_countries = ser_ison_membership.index.get_level_values(1).unique()\n",
    "df_distance_data = df_distance_data.dropna().set_index(['From_ID', 'To_ID']).loc[(list_ison_countries, list_ison_countries), ['dist', 'distcap', 'distw', 'distwces']]\n",
    "df_distance_data = df_distance_data.astype('float16')\n",
    "### Result saving:\n",
    "df_distance_data.to_hdf(path_or_buf = str_path_cepii_dataset, key = str_distance_dataset, mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CEPII DISTANCES: DATA READING:\n",
    "\n",
    "pd.read_hdf(path_or_buf = str_path_cepii_dataset, key = str_distance_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BLOOMBERG DATA READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BLOOMBERG DATA: INITIALIZATION\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BLOOMBERG XCRA GDP: GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "### Bloomberg data repository::\n",
    "str_path_bb_hdf = 'Data_Files/Source_Files/Bloomberg_prepared.h5'\n",
    "str_key_ret = 'bb_ret'\n",
    "str_key_mmr = 'bb_mmr'\n",
    "str_key_fx = 'bb_fx'\n",
    "str_key_mcap = 'bb_mcap'\n",
    "str_key_reer = 'bb_reer'\n",
    "str_key_neer = 'bb_neer'\n",
    "str_key_xcra = 'bb_xcra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1992-01-31', '1992-02-28', '1992-03-31', '1992-04-30',\n",
       "               '1992-05-29', '1992-06-30', '1992-07-31', '1992-08-31',\n",
       "               '1992-09-30', '1992-10-30',\n",
       "               ...\n",
       "               '2019-07-31', '2019-08-30', '2019-09-30', '2019-10-31',\n",
       "               '2019-11-29', '2019-12-31', '2020-01-31', '2020-02-28',\n",
       "               '2020-03-31', '2020-04-30'],\n",
       "              dtype='datetime64[ns]', name='Date', length=340, freq=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(path_or_buf = str_path_bb_hdf, key = str_key_ret).index.get_level_values(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
