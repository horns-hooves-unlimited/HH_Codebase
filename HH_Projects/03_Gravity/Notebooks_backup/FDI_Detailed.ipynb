{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FOREIGN DIRECT INVESTMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: INITIALIZATION\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1) ### To display long strings\n",
    "import math\n",
    "import requests\n",
    "import json ### To correct JSON structure before unpacking\n",
    "import xml.etree.ElementTree as et\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "#%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: VERSION CONTROL\n",
    "\n",
    "from platform import python_version\n",
    "print('pandas version: ', pd.__version__)\n",
    "print('python version: ', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: MAIN CONSTANTS\n",
    "\n",
    "### MultiIndex level slice constant:\n",
    "All = slice(None)\n",
    "### Universe path:\n",
    "str_path_universe = 'Data_Files/Source_Files/acadian_universe.xlsx'\n",
    "### OECD FDI datasets:\n",
    "str_path_oecd_fdi_dataset = 'Data_Files/Source_Files/oecd_dataset.h5'\n",
    "str_key_do_total_oecd_fdi_dataset = 'fdi_total_outward_dataset'\n",
    "str_key_di_total_oecd_fdi_dataset = 'fdi_total_inward_dataset'\n",
    "str_key_do_equity_oecd_fdi_dataset = 'fdi_equity_outward_dataset'\n",
    "str_key_di_equity_oecd_fdi_dataset = 'fdi_equity_inward_dataset'\n",
    "str_path_oecd_fdi_augmented = 'Data_Files/Source_Files/oecd_augmented.h5'\n",
    "str_key_do_total_oecd_fdi_augmented = 'fdi_total_outward_augmented'\n",
    "str_key_do_equity_oecd_fdi_augmented = 'fdi_equity_outward_augmented'\n",
    "str_path_oecd_fdi_options = 'Data_Files/Source_Files/oecd_options.h5'\n",
    "str_key_total_oecd_fdi_options = 'fdi_total_outward_options'\n",
    "str_key_equity_oecd_fdi_options = 'fdi_equity_outward_options'\n",
    "### Technical Constants:\n",
    "str_date_end = '2022-10-31'\n",
    "date_start = pd.Timestamp('1989-12-29')\n",
    "date_end = pd.Timestamp(str_date_end)\n",
    "date_ison = pd.Timestamp('1994-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING COUNTRY CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    ### In case if URL is unavailable:\n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    ### Online extraction:\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']].sort_index()    \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "    ### Results output:\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM MS EXCEL SOURCE (TO BE IGNORED IN PRODUCT CODE)\n",
    "\n",
    "def ison_membership_converting(str_path_universe, date_end, bool_daily = False, int_backfill_months = 0):\n",
    "    ### Defining business-month-end reindexation on country level:\n",
    "    def country_modify(ser_raw_country, date_end):\n",
    "        ser_res_country = ser_raw_country.droplevel(0).resample('MS').last().resample('BM').last()\n",
    "        range_country = pd.date_range(ser_res_country.index[0], date_end, freq = 'BM')\n",
    "        return ser_res_country.reindex(range_country).ffill()\n",
    "    ### Markets encoding table:\n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM', 0: np.NaN}     \n",
    "    ### Loading source file:\n",
    "    df_raw_universe = pd.read_excel(engine = 'openpyxl', io = str_path_universe, sheet_name = 'Switchers', header = 0, parse_dates = True, index_col = [0, 1],\n",
    "                                 na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    ### Converting source file:\n",
    "    df_raw_universe.index.names = ['Country', 'Date']\n",
    "    ser_raw_universe = df_raw_universe['Region']\n",
    "    ser_raw_universe.fillna(0, inplace = True)\n",
    "    ser_raw_universe.name = 'Market'\n",
    "    ### By country reindexation and translation:\n",
    "    ser_res_universe = ser_raw_universe.groupby('Country').apply(country_modify, date_end)\n",
    "    ser_res_universe.index.names = ['Country', 'Date']\n",
    "    ser_res_universe = ser_res_universe.replace(dict_markets).reorder_levels([1, 0]).sort_index() \n",
    "    ### Expanding membership for primary regions members by backfilling:\n",
    "    if int_backfill_months:\n",
    "        ### List of regions:\n",
    "        list_region = list(ser_res_universe.dropna().unique())\n",
    "        ### Initialising of collection of series with backfilled data for each region:\n",
    "        list_ison_backfill = []\n",
    "        ### Regions looping:\n",
    "        for iter_region in list_region:\n",
    "            ### Defining start of region date:\n",
    "            date_first_valid = ser_res_universe.loc[ser_res_universe == iter_region].first_valid_index()[0]\n",
    "            ### Creating dates index to backfilling:\n",
    "            idx_date_backfill = pd.date_range(end = date_first_valid, periods = int_backfill_months + 1, freq = 'BM')[: -1]\n",
    "            ### Creating primary countries index to backfilling:            \n",
    "            idx_region_backfill = ser_res_universe.loc[ser_res_universe == iter_region].loc[date_first_valid, All].index.get_level_values('Country')\n",
    "            ### Creating full index:\n",
    "            idx_ison_backfill = pd.MultiIndex.from_product([idx_date_backfill, idx_region_backfill])\n",
    "            ### Series with backfilled data:\n",
    "            list_ison_backfill.append(pd.Series(iter_region, index = idx_ison_backfill))\n",
    "        ### Combination of backfilled series and original ISON data:    \n",
    "        ser_res_universe = ser_res_universe.combine_first(pd.concat(list_ison_backfill, axis = 0)).sort_index()  \n",
    "        ser_res_universe.index.names = ['Date', 'Country']\n",
    "    ### Converting to daily frequency:\n",
    "    if bool_daily:\n",
    "        ser_res_universe = ser_res_universe.reset_index('Country').groupby('Country').resample('B').ffill()['Market'].swaplevel().sort_index()    \n",
    "    ### Results output:\n",
    "    ser_res_universe.name = 'Market'\n",
    "    return ser_res_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: COMMON DATA EXTRACTION STEPS\n",
    "\n",
    "### World Country Codes:\n",
    "df_country_codes = get_country_codes()\n",
    "### ISON membership history:\n",
    "ser_ison_membership = ison_membership_converting(str_path_universe, pd.to_datetime(str_date_end))\n",
    "### ISON LONG IDs list:\n",
    "list_ison_long = list(df_country_codes.loc[df_country_codes['ISO SHORT'].isin(ser_ison_membership.index.get_level_values('Country').unique()), 'ISO LONG'].values)\n",
    "### ISON current status:\n",
    "ser_ison_status = ser_ison_membership.loc[str_date_end].droplevel('Date')\n",
    "### ISON stats:\n",
    "int_ison_number = len(list_ison_long)\n",
    "list_regions = ['DM', 'EM', 'FM']\n",
    "dict_ison_len = {}\n",
    "dict_ison_len['Full Universe'] = int_ison_number\n",
    "for iter_region in list_regions:\n",
    "    dict_ison_len[iter_region] = len(ser_ison_status[ser_ison_status == iter_region])\n",
    "ser_market_len = pd.Series(dict_ison_len)\n",
    "ser_market_len.index.names = ['Market']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "str_oecd_base_url = 'https://stats.oecd.org/sdmx-json/data/'\n",
    "str_oecd_structure_url = 'https://stats.oecd.org/restsdmx/sdmx.ashx/GetDataStructure/'\n",
    "str_fdi_pos_dataset_add = 'FDI_POS_CTRY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: REQUESTS SESSION INITIALIZING\n",
    "\n",
    "request_session = requests.Session()\n",
    "### For avoiding data request errors:\n",
    "dict_header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "request_session.headers.update(dict_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION STRUCTURE REQUEST\n",
    "\n",
    "obj_oecd_structure = request_session.get(str_oecd_structure_url + str_fdi_pos_dataset_add)\n",
    "xml_tree_root = et.fromstring(obj_oecd_structure.content)\n",
    "dict_concepts = {}\n",
    "dict_dimensions = {}\n",
    "dict_codelists = {}\n",
    "for xml_tree_child in xml_tree_root:\n",
    "    if xml_tree_child.tag.endswith('Concepts'):\n",
    "        for xml_tree_grand in xml_tree_child:\n",
    "            str_concept_id = xml_tree_grand.attrib['id']\n",
    "            str_concept_name = xml_tree_grand[0].text\n",
    "            dict_concepts[str_concept_id] = str_concept_name\n",
    "    if xml_tree_child.tag.endswith('KeyFamilies'):\n",
    "        for xml_tree_family in xml_tree_child:\n",
    "            for xml_tree_component in xml_tree_family:\n",
    "                if xml_tree_component.tag.endswith('Components'):\n",
    "                    for xml_tree_measure in xml_tree_component:\n",
    "                        if xml_tree_measure.tag.endswith('Dimension'):\n",
    "                            str_concept_id = xml_tree_measure.attrib['conceptRef']\n",
    "                            str_concept_cl_id = xml_tree_measure.attrib['codelist']\n",
    "                            dict_dimensions[str_concept_id] = str_concept_cl_id\n",
    "    if xml_tree_child.tag.endswith('CodeLists'):       \n",
    "        for num_tree_grand, xml_tree_grand in enumerate(xml_tree_child):\n",
    "            str_codelist_id = xml_tree_grand.attrib['id']\n",
    "            dict_codelist = {}\n",
    "            for xml_tree_codelist in xml_tree_grand:                \n",
    "                if xml_tree_codelist.tag.endswith('Code'):\n",
    "                    str_code_id = xml_tree_codelist.attrib['value']\n",
    "                    str_code_value = xml_tree_codelist[0].text\n",
    "                    dict_codelist[str_code_id] = str_code_value\n",
    "            dict_codelists[str_codelist_id] = dict_codelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COU</th>\n",
       "      <td>Reporting country</td>\n",
       "      <td>CL_FDI_POS_CTRY_COU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEASURE</th>\n",
       "      <td>Currency</td>\n",
       "      <td>CL_FDI_POS_CTRY_MEASURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEASURE_PRINCIPLE</th>\n",
       "      <td>Measurement principle</td>\n",
       "      <td>CL_FDI_POS_CTRY_MEASURE_PRINCIPLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDI_TYPE</th>\n",
       "      <td>Type of FDI</td>\n",
       "      <td>CL_FDI_POS_CTRY_FDI_TYPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYPE_ENTITY</th>\n",
       "      <td>Type of entity</td>\n",
       "      <td>CL_FDI_POS_CTRY_TYPE_ENTITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCOUNTING_ENTRY</th>\n",
       "      <td>Accounting entry</td>\n",
       "      <td>CL_FDI_POS_CTRY_ACCOUNTING_ENTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEVEL_COUNTERPART</th>\n",
       "      <td>Level of counterpart</td>\n",
       "      <td>CL_FDI_POS_CTRY_LEVEL_COUNTERPART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COUNTERPART_AREA</th>\n",
       "      <td>Partner country/territory</td>\n",
       "      <td>CL_FDI_POS_CTRY_COUNTERPART_AREA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIME</th>\n",
       "      <td>Year</td>\n",
       "      <td>CL_FDI_POS_CTRY_TIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0  \\\n",
       "COU                Reporting country           \n",
       "MEASURE            Currency                    \n",
       "MEASURE_PRINCIPLE  Measurement principle       \n",
       "FDI_TYPE           Type of FDI                 \n",
       "TYPE_ENTITY        Type of entity              \n",
       "ACCOUNTING_ENTRY   Accounting entry            \n",
       "LEVEL_COUNTERPART  Level of counterpart        \n",
       "COUNTERPART_AREA   Partner country/territory   \n",
       "TIME               Year                        \n",
       "\n",
       "                                                   1  \n",
       "COU                CL_FDI_POS_CTRY_COU                \n",
       "MEASURE            CL_FDI_POS_CTRY_MEASURE            \n",
       "MEASURE_PRINCIPLE  CL_FDI_POS_CTRY_MEASURE_PRINCIPLE  \n",
       "FDI_TYPE           CL_FDI_POS_CTRY_FDI_TYPE           \n",
       "TYPE_ENTITY        CL_FDI_POS_CTRY_TYPE_ENTITY        \n",
       "ACCOUNTING_ENTRY   CL_FDI_POS_CTRY_ACCOUNTING_ENTRY   \n",
       "LEVEL_COUNTERPART  CL_FDI_POS_CTRY_LEVEL_COUNTERPART  \n",
       "COUNTERPART_AREA   CL_FDI_POS_CTRY_COUNTERPART_AREA   \n",
       "TIME               CL_FDI_POS_CTRY_TIME               "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OECD FDI: DIMENSIONS\n",
    "\n",
    "pd.concat([pd.Series(dict_concepts), pd.Series(dict_dimensions)], axis = 1, sort = False).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LE_FA_F': 'FDI positions -Total',\n",
       " 'LE_FA_F5': 'FDI positions - Equity (including reinvestment of earnings)',\n",
       " 'LE_FA_FL': 'FDI positions - Debt'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OECD FDI: FDI POSITION CONCEPT SOURCE CODELISTS:\n",
    "\n",
    "dict_codelists['CL_FDI_POS_CTRY_FDI_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI TOTAL POSITION PARAMETERS PREPARATION:\n",
    "\n",
    "### Currency:\n",
    "str_measure = 'USD'\n",
    "### Direction:\n",
    "str_direction = '+'.join(['DI', 'DO'])\n",
    "### Investment type:\n",
    "str_fdi_type = '+'.join(['LE_FA_F', 'LE_FA_F5'])\n",
    "### Residence defining:\n",
    "str_residence = 'ALL'\n",
    "### Accounting way:\n",
    "str_accounting = 'NET' # '+'.join(['NET', 'A', 'L']) # \n",
    "### Level counterpart(???):\n",
    "str_counterpart = 'IMC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISON countries with no OECD reporter match: {'NGA', 'BRA', 'ZAF', 'MAR', 'KWT', 'PER', 'VNM', 'THA', 'SAU', 'GHA', 'ARG', 'ECU', 'BGD', 'ROU', 'CIV', 'UGA', 'UKR', 'TWN', 'MLT', 'CYP', 'SRB', 'ZMB', 'JOR', 'IDN', 'KAZ', 'KEN', 'BWA', 'PAK', 'HKG', 'QAT', 'MUS', 'LBN', 'PAN', 'ARE', 'NAM', 'TUN', 'RUS', 'LKA', 'PHL', 'IND', 'MYS', 'OMN', 'BGR', 'CHN', 'HRV', 'SGP', 'EGY', 'BHR'} ( 48 )\n",
      "ISON countries with no OECD partner match: {'ROU'} ( 1 )\n"
     ]
    }
   ],
   "source": [
    "### OECD FDI: FDI POSITION PARAMETERS PREPARATION:\n",
    "\n",
    "### ISON Countries collecting:\n",
    "df_ison_countries = df_country_codes.set_index('ISO SHORT', append = True).reset_index('COUNTRY', drop = True)\n",
    "df_ison_countries = df_ison_countries.reindex(ser_ison_membership.index.get_level_values(1).unique().to_list())\n",
    "ser_ison_countries = df_ison_countries.reset_index().set_index('ISO LONG').squeeze()\n",
    "### OECD reporters vs ISON members:\n",
    "ser_oecd_reporters = pd.Series(dict_codelists['CL_FDI_POS_CTRY_COU'])\n",
    "ser_oecd_reporters = ser_oecd_reporters.to_frame().join(ser_ison_countries).drop(0, axis = 1).squeeze()\n",
    "for iter_iso_long in (ser_oecd_reporters[ser_oecd_reporters.isna()].index.get_level_values(0)):\n",
    "    if iter_iso_long in ser_ison_countries.index:\n",
    "        print('OECD Reporter country with no ISON match:', iter_iso_long)\n",
    "### ISON countries with no OECD reporter match:\n",
    "set_no_reporters = set(ser_ison_countries.dropna().index) - set(ser_oecd_reporters.index)\n",
    "print('ISON countries with no OECD reporter match:', set_no_reporters, '(', len(set_no_reporters), ')')           \n",
    "### OECD partners vs ISON members:\n",
    "ser_oecd_partners = pd.Series(dict_codelists['CL_FDI_POS_CTRY_COUNTERPART_AREA'])\n",
    "ser_oecd_partners = ser_oecd_partners.to_frame().join(ser_ison_countries).drop(0, axis = 1).squeeze()\n",
    "for iter_iso_long in (ser_oecd_partners[ser_oecd_partners.isna()].index.get_level_values(0)):\n",
    "    if iter_iso_long in ser_ison_countries.index:\n",
    "        print('OECD Partner country with no ISON match:', iter_iso_long)\n",
    "### ISON countries with no OECD partner match:\n",
    "set_no_partners = set(ser_ison_countries.dropna().index) - set(ser_oecd_partners.index)\n",
    "print('ISON countries with no OECD partner match:', set_no_partners, '(', len(set_no_partners), ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION REQUEST CONSTRUCTING\n",
    "\n",
    "str_fdi_pos_request_params = '.'.join(['', str_measure, str_direction, str_fdi_type, str_residence, str_accounting, str_counterpart, ''])\n",
    "str_fdi_pos_request = str_oecd_base_url + str_fdi_pos_dataset_add + '/' + str_fdi_pos_request_params + '/all?startTime=' + str(date_start.year) + \\\n",
    "                      '&endTime=' + str(date_end.year) + '&detail=DataOnly'\n",
    "obj_fdi_pos_dataset = request_session.get(str_fdi_pos_request).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION INDEX DATA COLLECTING:\n",
    "\n",
    "### Dates:\n",
    "list_idx_dates = []\n",
    "for tup_date in obj_fdi_pos_dataset['structure']['dimensions']['observation'][0]['values']:\n",
    "    list_idx_dates.append(pd.to_datetime(tup_date['id']) + pd.offsets.BYearEnd())\n",
    "### Parameters:    \n",
    "list_idx_library = []\n",
    "for iter_position in obj_fdi_pos_dataset['structure']['dimensions']['series']:\n",
    "    list_param_values = []\n",
    "    for tup_parameter in iter_position['values']:\n",
    "        list_param_values.append(tup_parameter['id'])            \n",
    "    list_idx_library.append(list_param_values)\n",
    "### Result:\n",
    "list_idx_library.append(list_idx_dates)\n",
    "### Converting to dictionary for future replacing:\n",
    "list_idx_dict = []\n",
    "for iter_list in list_idx_library:\n",
    "    list_idx_dict.append(dict(zip(map(str, range(len(iter_list))), iter_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION DATASET RESAMPLING\n",
    "\n",
    "dict_datasets_res = {}\n",
    "dict_datasets_source = obj_fdi_pos_dataset['dataSets'][0]['series']\n",
    "### Parameters and date indexes integration:\n",
    "for iter_dataset in dict_datasets_source:\n",
    "    dict_observations = dict_datasets_source[iter_dataset]['observations']\n",
    "    for iter_observation in dict_observations:\n",
    "        str_iter_idx = iter_dataset + ':' + iter_observation\n",
    "        flo_iter_value = dict_observations[iter_observation][0]\n",
    "        dict_datasets_res[str_iter_idx] = flo_iter_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION DATASET REINDEXATION\n",
    "\n",
    "gc.collect()\n",
    "df_fdi_pos_data = pd.Series(dict_datasets_res)\n",
    "df_fdi_pos_data.index = pd.MultiIndex.from_arrays(zip(*df_fdi_pos_data.index.str.split(':')))\n",
    "int_levels_number = df_fdi_pos_data.index.nlevels\n",
    "df_fdi_pos_data = df_fdi_pos_data.reset_index()\n",
    "### Replacing numbers with parameter values:\n",
    "for iter_level in range(int_levels_number):\n",
    "    df_fdi_pos_data['level_' + str(iter_level)].replace(list_idx_dict[iter_level], inplace = True)\n",
    "    ### Replacing long ISO names with short ISO names:\n",
    "    if (iter_level == 0):\n",
    "        df_fdi_pos_data['level_' + str(iter_level)].replace(dict(zip(df_country_codes['ISO LONG'].values, df_country_codes['ISO SHORT'].values)), inplace = True)\n",
    "    elif (iter_level == 7):\n",
    "        df_fdi_pos_data['level_' + str(iter_level)].replace(dict(zip(df_country_codes['ISO LONG'].values, df_country_codes['ISO SHORT'].values)), inplace = True)\n",
    "    ### Directions renaming:\n",
    "    elif (iter_level == 2):\n",
    "        df_fdi_pos_data['level_' + str(iter_level)].replace({'DI': 'Inward', 'DO': 'Outward'}, inplace = True)\n",
    "    ### Investment types renaming:\n",
    "    elif (iter_level == 3):\n",
    "        df_fdi_pos_data['level_' + str(iter_level)].replace({'LE_FA_F': 'Total', 'LE_FA_F5': 'Equity'}, inplace = True)         \n",
    "#    ### Flow types renaming:\n",
    "#    elif (iter_level == 5):\n",
    "#        df_fdi_pos_data['level_' + str(iter_level)].replace({'NET': 'Net', 'A': 'Asset', 'L': 'Liability'}, inplace = True)      \n",
    "\n",
    "### Intergated observations dropping:\n",
    "df_fdi_pos_data = df_fdi_pos_data.loc[\n",
    "                                      df_fdi_pos_data['level_0'].isin(df_country_codes['ISO SHORT'].values) & \n",
    "                                      df_fdi_pos_data['level_7'].isin(df_country_codes['ISO SHORT'].values)\n",
    "                                     ]\n",
    "### Indexes defining:\n",
    "ser_fdi_pos_data = df_fdi_pos_data.drop(['level_1', 'level_4', 'level_5', 'level_6'], axis = 1)\\\n",
    "                    .set_index(['level_3', 'level_2', 'level_8', 'level_0', 'level_7']).squeeze()\n",
    "ser_fdi_pos_data.index.names = ['Type', 'Direction', 'Date', 'Reporter', 'Partner']\n",
    "ser_fdi_pos_data.sort_index(inplace = True)\n",
    "ser_fdi_pos_data = ser_fdi_pos_data[ser_fdi_pos_data.index.get_level_values('Reporter') != ser_fdi_pos_data.index.get_level_values('Partner')]\n",
    "ser_fdi_pos_data[ser_fdi_pos_data < 0.0] = 0.0\n",
    "ser_fdi_pos_data.name = 'FDI Positions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: FDI POSITION DATASETS SAVING\n",
    "\n",
    "ser_fdi_pos_data.loc['Total', 'Outward', :, ser_ison_status.index, :].droplevel(['Type', 'Direction'])\\\n",
    "    .to_hdf(path_or_buf = str_path_oecd_fdi_dataset, key = str_key_do_total_oecd_fdi_dataset, mode = 'w', format = 'fixed')\n",
    "ser_fdi_pos_data.loc['Equity', 'Outward', :, ser_ison_status.index, :].droplevel(['Type', 'Direction'])\\\n",
    "    .to_hdf(path_or_buf = str_path_oecd_fdi_dataset, key = str_key_do_equity_oecd_fdi_dataset, mode = 'a', format = 'fixed')\n",
    "ser_total_di = ser_fdi_pos_data.loc['Total', 'Inward', :, :, ser_ison_status.index].droplevel(['Type', 'Direction'])\n",
    "ser_total_di.index.names = ['Date', 'Partner', 'Reporter']\n",
    "ser_total_di.reorder_levels(['Date', 'Reporter', 'Partner']).sort_index()\\\n",
    "    .to_hdf(path_or_buf = str_path_oecd_fdi_dataset, key = str_key_di_total_oecd_fdi_dataset, mode = 'a', format = 'fixed')\n",
    "ser_equity_di = ser_fdi_pos_data.loc['Equity', 'Inward', :, :, ser_ison_status.index].droplevel(['Type', 'Direction'])\n",
    "ser_equity_di.index.names = ['Date', 'Partner', 'Reporter']\n",
    "ser_equity_di.reorder_levels(['Date', 'Reporter', 'Partner']).sort_index()\\\n",
    "    .to_hdf(path_or_buf = str_path_oecd_fdi_dataset, key = str_key_di_equity_oecd_fdi_dataset, mode = 'a', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: TOTAL DATA AGGREGATION: DATASETS LOADING\n",
    "\n",
    "gc.collect()\n",
    "ser_oecd_asset = pd.read_hdf(path_or_buf = str_path_oecd_fdi_dataset, key = str_key_do_total_oecd_fdi_dataset)\n",
    "ser_oecd_asset.name = 'Asset'\n",
    "ser_oecd_liability_inv = pd.read_hdf(path_or_buf = str_path_oecd_fdi_dataset, key = str_key_di_total_oecd_fdi_dataset)\n",
    "ser_oecd_liability_inv.name = 'Liability_Inverted'\n",
    "df_oecd_total = pd.concat([ser_oecd_asset, ser_oecd_liability_inv], axis = 1, names = 'Data Source').astype('float32').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: TOTAL DATA AGGREGATION: DATA QUALITY RATIOS\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "### Defining similarity for investors by date\n",
    "def get_investor_ratio(df_group):\n",
    "#    df_group['Asset'].fillna(0.0, inplace = True)\n",
    "    df_group.fillna(0.0, inplace = True)    \n",
    "    df_both = df_group.dropna()    \n",
    "    if (df_both['Asset'].sum() > 0.0):\n",
    "        flo_result = (df_both['Asset'] - df_both['Liability_Inverted']).abs().clip(upper = df_group['Asset'].max()).sum() / df_group['Asset'].sum() / len(df_group)    \n",
    "    else:\n",
    "        flo_result = np.NaN    \n",
    "    return flo_result\n",
    "### Defining similarity for borrowers by date\n",
    "def get_borrower_ratio(df_group):\n",
    "#    df_group['Liability_Inverted'].fillna(0.0, inplace = True)\n",
    "    df_group.fillna(0.0, inplace = True)     \n",
    "    df_both = df_group.dropna()\n",
    "    if (df_both['Liability_Inverted'].sum() > 0.0):\n",
    "        flo_result = (df_both['Asset'] - df_both['Liability_Inverted']).abs().clip(upper = df_group['Liability_Inverted'].max()).sum() \\\n",
    "                                                                        / df_group['Liability_Inverted'].sum() / len(df_group)\n",
    "    else:\n",
    "        flo_result = np.NaN    \n",
    "    return flo_result\n",
    "### Similarity values calculation:\n",
    "ser_investor_ratio = df_oecd_total.groupby(['Date', 'Reporter']).apply(get_investor_ratio)\n",
    "ser_investor_ratio.name = 'Investor_Ratio'\n",
    "ser_borrower_ratio = df_oecd_total.groupby(['Date', 'Partner']).apply(get_borrower_ratio)\n",
    "ser_borrower_ratio.name = 'Borrower_Ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025 / (Timestamp('2019-12-31 00:00:00'), 'ES')\n",
      "0.0406 / (Timestamp('2017-12-29 00:00:00'), 'IL')\n"
     ]
    }
   ],
   "source": [
    "### OECD FDI: TOTAL DATA AGGREGATION: SIMILARITY TEST\n",
    "\n",
    "print(round(ser_borrower_ratio.min(), 4), '/', ser_borrower_ratio.idxmin())\n",
    "print(round(ser_borrower_ratio.max(), 4), '/', ser_borrower_ratio.idxmax())\n",
    "\n",
    "#display(df_oecd_total.loc[('2019-12-31', All, 'ES'), :])\n",
    "#display(df_oecd_total.loc[('2017-12-29', All, 'IL'), :].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013 / (Timestamp('2015-12-31 00:00:00'), 'FR')\n",
      "0.0171 / (Timestamp('2014-12-31 00:00:00'), 'NZ')\n"
     ]
    }
   ],
   "source": [
    "### OECD FDI: TOTAL DATA AGGREGATION: SIMILARITY TEST\n",
    "\n",
    "print(round(ser_investor_ratio.min(), 4), '/', ser_investor_ratio.idxmin())\n",
    "print(round(ser_investor_ratio.max(), 4), '/', ser_investor_ratio.idxmax())\n",
    "\n",
    "#display(df_oecd_total.loc[('2015-12-31', 'FR', All), :])\n",
    "#display(df_oecd_total.loc[('2014-12-31', 'NZ', All), :].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: TOTAL DATA AGGREGATION: ADDING RATIOS\n",
    "\n",
    "df_oecd_to_augment = df_oecd_total.join(ser_investor_ratio).join(ser_borrower_ratio)\n",
    "df_oecd_to_augment['Asset_Augmented'] = np.NaN # -999 # \n",
    "#df_cpis_augmented['Verified'] = False\n",
    "df_oecd_to_augment = df_oecd_to_augment.reorder_levels(['Date', 'Reporter', 'Partner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: TOTAL DATA AGGREGATION: CONDITIONAL REPLACING\n",
    "\n",
    "gc.collect()\n",
    "def augment_by_date(df_date, int_option = -1):\n",
    "    '''\n",
    "       -1 : Replace NaN Asset values unconditionally\n",
    "        0 : Replace NaN Asset values when Investor's Ratio > Borrower's Ratio\n",
    "        1 : Replace NaN or zero Asset values when Investor's Ratio > Borrower's Ratio\n",
    "        2 : Replace any Asset values when Investor's Ratio > Borrower's Ratio\n",
    "    '''\n",
    "    if (int_option == -1):\n",
    "        ### Replacing zero Asset & Liability values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN        \n",
    "        df_date['Asset_Augmented'] = df_date['Asset'].combine_first(df_date['Liability_Inverted'])\n",
    "    elif (int_option == 0):\n",
    "        ### Fill resulting column with not NaN Asset values:\n",
    "        df_date.loc[df_date['Asset'].notna(), 'Asset_Augmented'] = df_date[df_date['Asset'].notna()]['Asset'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is NaN (and doesn't matter if Borrower Ratio is NaN):\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna(), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna()]['Liability_Inverted'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is bigger than Borrower Ratio:\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio']), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio'])]['Liability_Inverted'].values\n",
    "    elif (int_option == 1):\n",
    "        ### Replacing zero Asset values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN\n",
    "        ### Fill resulting column with not NaN Asset values:\n",
    "        df_date.loc[df_date['Asset'].notna(), 'Asset_Augmented'] = df_date.loc[df_date['Asset'].notna(), 'Asset'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is NaN (and doesn't matter if Borrower Ratio is NaN):\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna(), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna()]['Liability_Inverted'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is bigger than Borrower Ratio:\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio']), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio'])]['Liability_Inverted'].values\n",
    "    else:\n",
    "        ### Replacing zero Asset & Liability values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN        \n",
    "        df_date.loc[df_date['Liability_Inverted'] == 0.0, 'Liability_Inverted'] = np.NaN\n",
    "        ### Ratios preparation:\n",
    "        df_date.loc[df_date['Investor_Ratio'].isna(), 'Investor_Ratio'] = 999.0\n",
    "        df_date.loc[df_date['Borrower_Ratio'].isna(), 'Borrower_Ratio'] = 1000.0\n",
    "        ### Ratios comparision:\n",
    "        df_date.loc[df_date['Investor_Ratio'] <= df_date['Borrower_Ratio'], 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Investor_Ratio'] <= df_date['Borrower_Ratio']]['Asset'].values\n",
    "        df_date.loc[df_date['Investor_Ratio'] > df_date['Borrower_Ratio'], 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Investor_Ratio'] > df_date['Borrower_Ratio']]['Liability_Inverted'].values                                       \n",
    "    return df_date\n",
    "\n",
    "dict_oecd_augmented = {}\n",
    "dict_oecd_augmented[-1] = df_oecd_to_augment.groupby('Date').apply(augment_by_date, -1)\n",
    "dict_oecd_augmented[0] = df_oecd_to_augment.groupby('Date').apply(augment_by_date, 0)\n",
    "dict_oecd_augmented[1] = df_oecd_to_augment.groupby('Date').apply(augment_by_date, 1)\n",
    "dict_oecd_augmented[2] = df_oecd_to_augment.groupby('Date').apply(augment_by_date, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: TOTAL DATA AGGREGATION: RESULTS TESTING\n",
    "\n",
    "ser_quantity = df_oecd_to_augment['Asset'].replace({0.0: np.NaN}).groupby(['Date','Reporter']).count()\n",
    "ser_quantity = ser_quantity[ser_quantity > 0].groupby('Date').count()\n",
    "ser_quantity.name = 'raw'\n",
    "ser_quantity.to_excel('Data_Files/Test_Files/Augmentation_Test_' + ser_quantity.name + '.xlsx', merge_cells = False)\n",
    "\n",
    "for iter_option in dict_oecd_augmented:\n",
    "    dt_option = dict_oecd_augmented[iter_option]\n",
    "    ser_quantity = dt_option['Asset_Augmented'].replace({0.0: np.NaN}).groupby(['Date','Reporter']).count()\n",
    "    ser_quantity = ser_quantity[ser_quantity > 0].groupby('Date').count()\n",
    "    ser_quantity.name = str(iter_option)\n",
    "    ser_quantity.to_excel('Data_Files/Test_Files/Augmentation_Test_' + str(iter_option) + '.xlsx', merge_cells = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: TOTAL DATA AGGREGATION: RESULTS SAVING TO SERIES\n",
    "\n",
    "ser_total_augmented = dict_oecd_augmented[2]['Asset_Augmented']\n",
    "ser_total_augmented.name = 'Total'\n",
    "ser_total_augmented.replace({0.0: np.NaN})\\\n",
    "    .to_hdf(path_or_buf = str_path_oecd_fdi_augmented, key = str_key_do_total_oecd_fdi_augmented, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: TOTAL DATA AGGREGATION: RESULTS CONSOLIDATION TO DATAFRAME AND SAVING\n",
    "\n",
    "df_augmentation_way = pd.concat([df_oecd_to_augment['Asset'].replace({0.0: np.NaN}), \n",
    "                                 dict_oecd_augmented[-1]['Asset_Augmented'], \n",
    "                                 dict_oecd_augmented[2]['Asset_Augmented']], \n",
    "                                axis = 1, keys = ['Assets_Only', 'Unconditional', 'Option_2'], names = 'Augmentation_Way')\n",
    "df_augmentation_way.to_hdf(path_or_buf = str_path_oecd_fdi_options, key = str_key_total_oecd_fdi_options, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: EQUITY DATA AGGREGATION: DATASETS LOADING\n",
    "\n",
    "gc.collect()\n",
    "ser_oecd_asset = pd.read_hdf(path_or_buf = str_path_oecd_fdi_dataset, key = str_key_do_equity_oecd_fdi_dataset)\n",
    "ser_oecd_asset.name = 'Asset'\n",
    "ser_oecd_liability_inv = pd.read_hdf(path_or_buf = str_path_oecd_fdi_dataset, key = str_key_di_equity_oecd_fdi_dataset)\n",
    "ser_oecd_liability_inv.name = 'Liability_Inverted'\n",
    "df_oecd_equity = pd.concat([ser_oecd_asset, ser_oecd_liability_inv], axis = 1, names = 'Data Source').astype('float32').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: EQUITY DATA AGGREGATION: DATA QUALITY RATIOS\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "### Defining similarity for investors by date\n",
    "def get_investor_ratio(df_group):\n",
    "#    df_group['Asset'].fillna(0.0, inplace = True)\n",
    "    df_group.fillna(0.0, inplace = True)    \n",
    "    df_both = df_group.dropna()    \n",
    "    if (df_both['Asset'].sum() > 0.0):\n",
    "        flo_result = (df_both['Asset'] - df_both['Liability_Inverted']).abs().clip(upper = df_group['Asset'].max()).sum() / df_group['Asset'].sum() / len(df_group)    \n",
    "    else:\n",
    "        flo_result = np.NaN    \n",
    "    return flo_result\n",
    "### Defining similarity for borrowers by date\n",
    "def get_borrower_ratio(df_group):\n",
    "#    df_group['Liability_Inverted'].fillna(0.0, inplace = True)\n",
    "    df_group.fillna(0.0, inplace = True)     \n",
    "    df_both = df_group.dropna()\n",
    "    if (df_both['Liability_Inverted'].sum() > 0.0):\n",
    "        flo_result = (df_both['Asset'] - df_both['Liability_Inverted']).abs().clip(upper = df_group['Liability_Inverted'].max()).sum() \\\n",
    "                                                                        / df_group['Liability_Inverted'].sum() / len(df_group)\n",
    "    else:\n",
    "        flo_result = np.NaN    \n",
    "    return flo_result\n",
    "### Similarity values calculation:\n",
    "ser_investor_ratio = df_oecd_equity.groupby(['Date', 'Reporter']).apply(get_investor_ratio)\n",
    "ser_investor_ratio.name = 'Investor_Ratio'\n",
    "ser_borrower_ratio = df_oecd_equity.groupby(['Date', 'Partner']).apply(get_borrower_ratio)\n",
    "ser_borrower_ratio.name = 'Borrower_Ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026 / (Timestamp('2020-12-31 00:00:00'), 'IT')\n",
      "0.0526 / (Timestamp('2017-12-29 00:00:00'), 'IL')\n"
     ]
    }
   ],
   "source": [
    "### OECD FDI: EQUITY DATA AGGREGATION: SIMILARITY TEST\n",
    "\n",
    "print(round(ser_borrower_ratio.min(), 4), '/', ser_borrower_ratio.idxmin())\n",
    "print(round(ser_borrower_ratio.max(), 4), '/', ser_borrower_ratio.idxmax())\n",
    "\n",
    "#display(df_oecd_equity.loc[('2020-12-31', All, 'IT'), :].dropna())\n",
    "#display(df_oecd_equity.loc[('2017-12-29', All, 'IL'), :].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012 / (Timestamp('2019-12-31 00:00:00'), 'BE')\n",
      "0.0192 / (Timestamp('2016-12-30 00:00:00'), 'NZ')\n"
     ]
    }
   ],
   "source": [
    "### OECD FDI: EQUITY DATA AGGREGATION: SIMILARITY TEST\n",
    "\n",
    "print(round(ser_investor_ratio.min(), 4), '/', ser_investor_ratio.idxmin())\n",
    "print(round(ser_investor_ratio.max(), 4), '/', ser_investor_ratio.idxmax())\n",
    "\n",
    "#display(df_oecd_equity.loc[('2019-12-31', 'BE', All), :].dropna())\n",
    "#display(df_oecd_equity.loc[('2016-12-30', 'NZ', All), :].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: EQUITY DATA AGGREGATION: ADDING RATIOS\n",
    "\n",
    "df_oecd_to_augment = df_oecd_equity.join(ser_investor_ratio).join(ser_borrower_ratio)\n",
    "df_oecd_to_augment['Asset_Augmented'] = np.NaN # -999 # \n",
    "#df_cpis_augmented['Verified'] = False\n",
    "df_oecd_to_augment = df_oecd_to_augment.reorder_levels(['Date', 'Reporter', 'Partner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: EQUITY DATA AGGREGATION: CONDITIONAL REPLACING\n",
    "\n",
    "gc.collect()\n",
    "def augment_by_date(df_date, int_option = -1):\n",
    "    '''\n",
    "       -1 : Replace NaN Asset values unconditionally\n",
    "        0 : Replace NaN Asset values when Investor's Ratio > Borrower's Ratio\n",
    "        1 : Replace NaN or zero Asset values when Investor's Ratio > Borrower's Ratio\n",
    "        2 : Replace any Asset values when Investor's Ratio > Borrower's Ratio\n",
    "    '''\n",
    "    if (int_option == -1):\n",
    "        ### Replacing zero Asset & Liability values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN        \n",
    "        df_date['Asset_Augmented'] = df_date['Asset'].combine_first(df_date['Liability_Inverted'])\n",
    "    elif (int_option == 0):\n",
    "        ### Fill resulting column with not NaN Asset values:\n",
    "        df_date.loc[df_date['Asset'].notna(), 'Asset_Augmented'] = df_date[df_date['Asset'].notna()]['Asset'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is NaN (and doesn't matter if Borrower Ratio is NaN):\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna(), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna()]['Liability_Inverted'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is bigger than Borrower Ratio:\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio']), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio'])]['Liability_Inverted'].values\n",
    "    elif (int_option == 1):\n",
    "        ### Replacing zero Asset values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN\n",
    "        ### Fill resulting column with not NaN Asset values:\n",
    "        df_date.loc[df_date['Asset'].notna(), 'Asset_Augmented'] = df_date.loc[df_date['Asset'].notna(), 'Asset'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is NaN (and doesn't matter if Borrower Ratio is NaN):\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna(), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].isna()]['Liability_Inverted'].values\n",
    "        ### Fill resulting column with Liability value if Asset value is NaN & Investor Ratio is bigger than Borrower Ratio:\n",
    "        df_date.loc[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio']), 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Asset'].isna() & df_date['Investor_Ratio'].notna() & df_date['Borrower_Ratio'].notna() & \\\n",
    "                    (df_date['Investor_Ratio'] > df_date['Borrower_Ratio'])]['Liability_Inverted'].values\n",
    "    else:\n",
    "        ### Replacing zero Asset & Liability values with NaN:\n",
    "        df_date.loc[df_date['Asset'] == 0.0, 'Asset'] = np.NaN        \n",
    "        df_date.loc[df_date['Liability_Inverted'] == 0.0, 'Liability_Inverted'] = np.NaN\n",
    "        ### Ratios preparation:\n",
    "        df_date.loc[df_date['Investor_Ratio'].isna(), 'Investor_Ratio'] = 999.0\n",
    "        df_date.loc[df_date['Borrower_Ratio'].isna(), 'Borrower_Ratio'] = 1000.0\n",
    "        ### Ratios comparision:\n",
    "        df_date.loc[df_date['Investor_Ratio'] <= df_date['Borrower_Ratio'], 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Investor_Ratio'] <= df_date['Borrower_Ratio']]['Asset'].values\n",
    "        df_date.loc[df_date['Investor_Ratio'] > df_date['Borrower_Ratio'], 'Asset_Augmented'] = \\\n",
    "            df_date[df_date['Investor_Ratio'] > df_date['Borrower_Ratio']]['Liability_Inverted'].values                                       \n",
    "    return df_date\n",
    "\n",
    "dict_oecd_augmented = {}\n",
    "dict_oecd_augmented[-1] = df_oecd_to_augment.groupby('Date').apply(augment_by_date, -1)\n",
    "dict_oecd_augmented[0] = df_oecd_to_augment.groupby('Date').apply(augment_by_date, 0)\n",
    "dict_oecd_augmented[1] = df_oecd_to_augment.groupby('Date').apply(augment_by_date, 1)\n",
    "dict_oecd_augmented[2] = df_oecd_to_augment.groupby('Date').apply(augment_by_date, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: EQUITY DATA AGGREGATION: RESULTS TESTING\n",
    "\n",
    "ser_quantity = df_oecd_to_augment['Asset'].replace({0.0: np.NaN}).groupby(['Date','Reporter']).count()\n",
    "ser_quantity = ser_quantity[ser_quantity > 0].groupby('Date').count()\n",
    "ser_quantity.name = 'raw'\n",
    "ser_quantity.to_excel('Data_Files/Test_Files/Augmentation_Test_' + ser_quantity.name + '.xlsx', merge_cells = False)\n",
    "\n",
    "for iter_option in dict_oecd_augmented:\n",
    "    dt_option = dict_oecd_augmented[iter_option]\n",
    "    ser_quantity = dt_option['Asset_Augmented'].replace({0.0: np.NaN}).groupby(['Date','Reporter']).count()\n",
    "    ser_quantity = ser_quantity[ser_quantity > 0].groupby('Date').count()\n",
    "    ser_quantity.name = str(iter_option)\n",
    "    ser_quantity.to_excel('Data_Files/Test_Files/Augmentation_Test_' + str(iter_option) + '.xlsx', merge_cells = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: EQUITY DATA AGGREGATION: RESULTS SAVING (SERIES)\n",
    "\n",
    "ser_equity_augmented = dict_oecd_augmented[2]['Asset_Augmented']\n",
    "ser_equity_augmented.name = 'Total'\n",
    "ser_equity_augmented.replace({0.0: np.NaN})\\\n",
    "    .to_hdf(path_or_buf = str_path_oecd_fdi_augmented, key = str_key_do_equity_oecd_fdi_augmented, mode = 'a', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OECD FDI: EQUITY DATA AGGREGATION: RESULTS CONSOLIDATION TO DATAFRAME AND SAVING\n",
    "\n",
    "df_augmentation_way = pd.concat([df_oecd_to_augment['Asset'].replace({0.0: np.NaN}), \n",
    "                                 dict_oecd_augmented[-1]['Asset_Augmented'], \n",
    "                                 dict_oecd_augmented[2]['Asset_Augmented']], \n",
    "                                axis = 1, keys = ['Assets_Only', 'Unconditional', 'Option_2'], names = 'Augmentation_Way')\n",
    "df_augmentation_way.to_hdf(path_or_buf = str_path_oecd_fdi_options, key = str_key_equity_oecd_fdi_options, mode = 'a', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
