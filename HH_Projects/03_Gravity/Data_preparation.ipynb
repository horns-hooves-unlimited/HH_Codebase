{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GFD: 3-MONTH TREASURY BILL RATE FOR LOCAL INTEREST RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING GFD LOGIN FUNCTION\n",
    "\n",
    "def gfd_auth(username = None, password = None):\n",
    "    \"\"\"\n",
    "    Pulls a GFD API token and stores it as an environmental variable.\n",
    "    Parameters\n",
    "        username: GFD-approved email address.\n",
    "        password: Password for GFD-approved email address.\n",
    "    \"\"\"\n",
    "    if username is None:\n",
    "        username = getpass.getpass('Please enter your GFD Finaeon username: ')\n",
    "\n",
    "    if password is None:\n",
    "        password = getpass.getpass('Please enter your GFD Finaeon password: ')\n",
    "\n",
    "    url = 'https://api.globalfinancialdata.com/login/'\n",
    "    parameters = {'username': username, 'password': password}\n",
    "    resp = requests.post(url, data = parameters)\n",
    "    #check for unsuccessful API returns\n",
    "    if resp.status_code != 200:\n",
    "        raise ValueError('GFD API request failed with HTTP status code %s' % resp.status_code)\n",
    "\n",
    "    json_content = resp.json()\n",
    "    os.environ['GFD_API_TOKEN'] = json_content['token'].strip('\"')\n",
    "    print(\"GFD API token recieved at %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUNNING AUTHORIZATION FUNCTION\n",
    "\n",
    "gfd_auth('kaminski.ihar@tut.by', '1990757229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COUNTRY ISO CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    import pandas as pd\n",
    "    \n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']]      \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def get_market_membership_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Declaring local constants & variables: \n",
    "    path_msci = 'Data_Files/Source_Files/sample_universe.xlsx' ### Path for membership source    \n",
    "    tab_monthly = 'universe_joined'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    no_slice = slice(None)\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci, sheet_name = tab_monthly, skiprows = [0, 2], header = 0, parse_dates = True, \n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    df_universe = df_universe.loc[no_slice, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Country']\n",
    "    df_universe.set_index(['Date', 'Country'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    ### Results output:\n",
    "    return ser_market_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE COUNTRIES DATA EXTRACTION AND MODIFICATION\n",
    "\n",
    "def get_un_comtrade_country_id(df_country_codes):\n",
    "    ### Getting UN Comtrade country info from post request:\n",
    "    str_UNC_countries_set = 'http://comtrade.un.org/data/cache/partnerAreas.json'\n",
    "    obj_UNC_countries_set = requests.post(str_UNC_countries_set)\n",
    "    ### Object to dataframe transformation:\n",
    "    list_UNC_countries = obj_UNC_countries_set.json()['results']\n",
    "    df_UNC_countries = pd.DataFrame(list_UNC_countries)\n",
    "    df_UNC_countries.columns = ['UNC ID', 'COUNTRY']\n",
    "    df_UNC_countries['COUNTRY'] = df_UNC_countries['COUNTRY'].str.upper()\n",
    "    df_UNC_countries.replace(dict_map_to_replace, inplace = True)\n",
    "    df_UNC_countries.set_index('COUNTRY', append = False, drop = True, inplace = True)\n",
    "    df_UNC_country_id = df_UNC_countries.join(df_country_codes, on = 'COUNTRY', how = 'left').dropna(how = 'any').reset_index(drop = True)\n",
    "    df_UNC_country_id.drop('ISO LONG', axis = 1, inplace = True)\n",
    "    df_UNC_country_id.columns = ['Comtrade_ID', 'Country']\n",
    "    ser_UNC_country_id = df_UNC_country_id.set_index('Country').squeeze().sort_index()\n",
    "    ### Results output:\n",
    "    return ser_UNC_country_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UN COMTRADE DATA REQUEST EXECUTION\n",
    "\n",
    "def get_un_comtrade_data(str_rep_country_id, str_par_country_id, int_max_rec = 50000, str_type = 'C', str_freq = 'M', str_classification_system = 'HS', \n",
    "                         str_period = 'all', str_trade_flow = 'All', str_classification_code = 'TOTAL'):\n",
    "    ### Trade flows codification:\n",
    "    dict_trade_flow = {'All': 'all', 'Import': '1', 'Export': '2', 're-Export': '3', 're-Import': '4'}\n",
    "    ### URL prefix:\n",
    "    str_url_base = 'http://comtrade.un.org/api/get?'\n",
    "    ### Request URL preparation:\n",
    "    str_url_request = str_url_base\n",
    "    list_parameters = []\n",
    "    list_parameters.append('max=' + str(int_max_rec))\n",
    "    list_parameters.append('type=' + str_type)\n",
    "    list_parameters.append('freq=' + str_freq)\n",
    "    list_parameters.append('px=' + str_classification_system)\n",
    "    list_parameters.append('ps=' + str_period)\n",
    "    list_parameters.append('r=' + str_rep_country_id)\n",
    "    list_parameters.append('p=' + str_par_country_id)\n",
    "    list_parameters.append('rg=' + dict_trade_flow[str_trade_flow])\n",
    "    list_parameters.append('cc=' + str_classification_code)    \n",
    "    list_parameters.append('fmt=json')        \n",
    "    str_url_request += '&'.join(list_parameters)\n",
    "    ### Getting UN Comtrade data from post request:    \n",
    "    obj_unc_dataset = requests.post(str_url_request)\n",
    "    ### Object to dataframe transformation:    \n",
    "    list_unc_dataset = obj_unc_dataset.json()['dataset']\n",
    "    if (len(list_unc_dataset) > 0):\n",
    "        df_unc_dataset = pd.DataFrame(list_unc_dataset)[['period', 'rtCode', 'ptCode', 'TradeValue']]\n",
    "        df_unc_dataset.columns = ['Period', 'Reporter_ID', 'Partner_ID', 'Value']    \n",
    "        df_unc_dataset['Date'] = pd.to_datetime(df_unc_dataset['Period'], format = '%Y%m') + pd.offsets.BMonthEnd()    \n",
    "        df_unc_dataset = df_unc_dataset[['Date', 'Reporter_ID', 'Partner_ID', 'Value']]\n",
    "    else:\n",
    "        df_unc_dataset = pd.DataFrame(columns = ['Date', 'Reporter_ID', 'Partner_ID', 'Value'])\n",
    "    \n",
    "    return df_unc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "int_seconds_to_sleep = 35\n",
    "int_unc_limit = 5\n",
    "All = slice(None)\n",
    "str_path_unc_dataset = 'Data_Files/Source_Files/unc_dataset.h5'\n",
    "str_unc_exp_total_dataset = 'export_total_dataset'\n",
    "str_unc_imp_total_dataset = 'import_total_dataset'\n",
    "### UN Comtrade country names to rename:\n",
    "dict_map_to_replace = {'BOLIVIA (PLURINATIONAL STATE OF)': 'BOLIVIA',\n",
    "                       'BOSNIA HERZEGOVINA': 'BOSNIA AND HERZEGOVINA',\n",
    "                       'BR. INDIAN OCEAN TERR.': 'BRITISH INDIAN OCEAN TERRITORY',\n",
    "                       'BR. VIRGIN ISDS': 'BRITISH VIRGIN ISLANDS',\n",
    "                       'BRUNEI DARUSSALAM': 'BRUNEI',\n",
    "                       'CABO VERDE': 'CAPE VERDE',\n",
    "                       'CAYMAN ISDS': 'CAYMAN ISLANDS',\n",
    "                       'CENTRAL AFRICAN REP.': 'CENTRAL AFRICAN REPUBLIC',\n",
    "                       'CHRISTMAS ISDS': 'CHRISTMAS ISLAND',\n",
    "                       'COCOS ISDS': 'COCOS ISLANDS',\n",
    "                       'COOK ISDS': 'COOK ISLANDS',                    \n",
    "                       'CURAÇAO': 'CURACAO',                          \n",
    "                       'CZECHIA': 'CZECH REPUBLIC',                    \n",
    "                       'DEM. REP. OF THE CONGO': 'DEMOCRATIC REPUBLIC OF THE CONGO',                          \n",
    "                       'DOMINICAN REP.': 'DOMINICAN REPUBLIC',                    \n",
    "                       'TIMOR-LESTE': 'EAST TIMOR',                          \n",
    "                       'FALKLAND ISDS (MALVINAS)': 'FALKLAND ISLANDS',                    \n",
    "                       'FAEROE ISDS': 'FAROE ISLANDS',                                           \n",
    "                       'CHINA, HONG KONG SAR': 'HONG KONG',                          \n",
    "                       'CÔTE D\\'IVOIRE': 'IVORY COAST',                                           \n",
    "                       'LAO PEOPLE\\'S DEM. REP.': 'LAOS',                                         \n",
    "                       'CHINA, MACAO SAR': 'MACAU',                          \n",
    "                       'TFYR OF MACEDONIA': 'MACEDONIA',                    \n",
    "                       'MARSHALL ISDS': 'MARSHALL ISLANDS',                          \n",
    "                       'FS MICRONESIA': 'MICRONESIA',                    \n",
    "                       'REP. OF MOLDOVA': 'MOLDOVA',                          \n",
    "                       'NETH. ANTILLES': 'NETHERLANDS ANTILLES',                          \n",
    "                       'DEM. PEOPLE\\'S REP. OF KOREA': 'NORTH KOREA',                          \n",
    "                       'N. MARIANA ISDS': 'NORTHERN MARIANA ISLANDS',                    \n",
    "                       'STATE OF PALESTINE': 'PALESTINE',                          \n",
    "                       'CONGO': 'REPUBLIC OF THE CONGO',                          \n",
    "                       'RÉUNION': 'REUNION',                    \n",
    "                       'RUSSIAN FEDERATION': 'RUSSIA',                          \n",
    "                       'SOLOMON ISDS': 'SOLOMON ISLANDS',                    \n",
    "                       'REP. OF KOREA': 'SOUTH KOREA',                                       \n",
    "                       'UNITED REP. OF TANZANIA': 'TANZANIA',     \n",
    "                       'OTHER ASIA, NES': 'TAIWAN',\n",
    "                       'TURKS AND CAICOS ISDS': 'TURKS AND CAICOS ISLANDS',                    \n",
    "                       'US VIRGIN ISDS': 'U.S. VIRGIN ISLANDS',                          \n",
    "                       'USA': 'UNITED STATES',                          \n",
    "                       'HOLY SEE (VATICAN CITY STATE)': 'VATICAN',                    \n",
    "                       'VIET NAM': 'VIETNAM',                          \n",
    "                       'WALLIS AND FUTUNA ISDS': 'WALLIS AND FUTUNA'\n",
    "                      }\n",
    "### ISO country codes loading:\n",
    "df_country_codes = get_country_codes()\n",
    "### ISON membership loading:\n",
    "ser_market_membership = get_market_membership_from_excel()\n",
    "### Getting UN Comtrade country IDs:\n",
    "ser_UNC_country_id = get_un_comtrade_country_id(df_country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT DATA EXRACTION SCRIPT\n",
    "\n",
    "### Filtering ISON countries only:\n",
    "ser_UNC_country_id = ser_UNC_country_id.reindex(ser_market_membership.index.get_level_values(1).unique().to_list())\n",
    "### Concatenation aggregator initializing:\n",
    "list_dataset = []\n",
    "### Reporter country looping (5 country groups):\n",
    "for iter_reporter_group in range((len(ser_UNC_country_id.index) - 1) // int_unc_limit + 1):\n",
    "    ### Partner country looping (5 country groups):\n",
    "    for iter_partner_group in range((len(ser_UNC_country_id.index) - 1) // int_unc_limit + 1):\n",
    "        print(iter_reporter_group * int_unc_limit, '-', (iter_reporter_group + 1) * int_unc_limit - 1, '/', \n",
    "              iter_partner_group * int_unc_limit, '-', (iter_partner_group + 1) * int_unc_limit - 1)\n",
    "#        if (iter_partner_group > 1):\n",
    "#            break        \n",
    "        ### Country groups preparing:\n",
    "        str_reporter_group = ','.join(ser_UNC_country_id.iloc[iter_reporter_group * int_unc_limit : (iter_reporter_group + 1) * int_unc_limit].to_list())\n",
    "        str_partner_group = ','.join(ser_UNC_country_id.iloc[iter_partner_group * int_unc_limit : (iter_partner_group + 1) * int_unc_limit].to_list())    \n",
    "        ### Request performing:\n",
    "        df_iter_dataset = get_un_comtrade_data(str_reporter_group, str_partner_group, str_trade_flow = 'Export')\n",
    "        list_dataset += [df_iter_dataset]\n",
    "        ### Pause for API limitations:\n",
    "        time.sleep(int_seconds_to_sleep)            \n",
    "#    break\n",
    "### Results concatenating:\n",
    "df_loop_dataset = pd.concat(list_dataset, axis = 0, sort = False, ignore_index = True)[['Date', 'Reporter_ID', 'Partner_ID', 'Value']]\n",
    "df_loop_dataset = df_loop_dataset.astype({'Reporter_ID': 'int16', 'Partner_ID': 'int16', 'Value': 'int64'})\n",
    "### UN Comtrade country codes replacing to ISON country codes:\n",
    "df_loop_dataset.loc[All, ['Reporter_ID', 'Partner_ID']] = df_loop_dataset.loc[All, ['Reporter_ID', 'Partner_ID']]\\\n",
    "                                                                         .replace(list(map(int, ser_UNC_country_id.values)), ser_UNC_country_id.index.to_list())\n",
    "### Series indexing:\n",
    "ser_unc_dataset = df_loop_dataset.set_index(['Date', 'Reporter_ID', 'Partner_ID'], drop = True).squeeze()\n",
    "### Data saving:\n",
    "ser_unc_dataset.to_hdf(path_or_buf = str_path_unc_dataset, key = str_unc_exp_total_dataset, mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT DATA EXRACTION SCRIPT\n",
    "\n",
    "### Filtering ISON countries only:\n",
    "ser_UNC_country_id = ser_UNC_country_id.reindex(ser_market_membership.index.get_level_values(1).unique().to_list())\n",
    "### Concatenation aggregator initializing:\n",
    "list_dataset = []\n",
    "### Reporter country looping (5 country groups):\n",
    "for iter_reporter_group in range((len(ser_UNC_country_id.index) - 1) // int_unc_limit + 1):\n",
    "    ### Partner country looping (5 country groups):    \n",
    "    for iter_partner_group in range((len(ser_UNC_country_id.index) - 1) // int_unc_limit + 1):\n",
    "        print(iter_reporter_group * int_unc_limit, '-', (iter_reporter_group + 1) * int_unc_limit - 1, '/', \n",
    "              iter_partner_group * int_unc_limit, '-', (iter_partner_group + 1) * int_unc_limit - 1)\n",
    "#        if (iter_partner_group > 1):\n",
    "#            break        \n",
    "        ### Country groups preparing:\n",
    "        str_reporter_group = ','.join(ser_UNC_country_id.iloc[iter_reporter_group * int_unc_limit : (iter_reporter_group + 1) * int_unc_limit].to_list())\n",
    "        str_partner_group = ','.join(ser_UNC_country_id.iloc[iter_partner_group * int_unc_limit : (iter_partner_group + 1) * int_unc_limit].to_list())    \n",
    "        ### Request performing:        \n",
    "        df_iter_dataset = get_un_comtrade_data(str_reporter_group, str_partner_group, str_trade_flow = 'Import')\n",
    "        list_dataset += [df_iter_dataset]\n",
    "        ### Pause for API limitations:        \n",
    "        time.sleep(int_seconds_to_sleep)            \n",
    "#    break\n",
    "### Results concatenating:\n",
    "df_loop_dataset = pd.concat(list_dataset, axis = 0, sort = False, ignore_index = True)[['Date', 'Reporter_ID', 'Partner_ID', 'Value']]\n",
    "df_loop_dataset = df_loop_dataset.astype({'Reporter_ID': 'int16', 'Partner_ID': 'int16', 'Value': 'int64'})\n",
    "### UN Comtrade country codes replacing to ISON country codes:\n",
    "df_loop_dataset.loc[All, ['Reporter_ID', 'Partner_ID']] = df_loop_dataset.loc[All, ['Reporter_ID', 'Partner_ID']]\\\n",
    "                                                                         .replace(list(map(int, ser_UNC_country_id.values)), ser_UNC_country_id.index.to_list())\n",
    "### Series indexing:\n",
    "ser_unc_dataset = df_loop_dataset.set_index(['Date', 'Reporter_ID', 'Partner_ID'], drop = True).squeeze()\n",
    "### Data saving:\n",
    "ser_unc_dataset.to_hdf(path_or_buf = str_path_unc_dataset, key = str_unc_imp_total_dataset, mode = 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST: COMPARING WITH ONLINE DATA\n",
    "\n",
    "ser_unc_total_export = pd.read_hdf(path_or_buf = str_path_unc_dataset, key = str_unc_exp_total_dataset)\n",
    "ser_unc_total_import = pd.read_hdf(path_or_buf = str_path_unc_dataset, key = str_unc_imp_total_dataset)\n",
    "print(ser_unc_total_export.loc[All, 'AT', 'BE'].tail())\n",
    "print(ser_unc_total_import.loc[All, 'AT', 'BE'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIS: BILATERAL BANK LENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def get_market_membership_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Declaring local constants & variables: \n",
    "    path_msci = 'Data_Files/Source_Files/sample_universe.xlsx' ### Path for membership source    \n",
    "    tab_monthly = 'universe_joined'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    no_slice = slice(None)\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci, sheet_name = tab_monthly, skiprows = [0, 2], header = 0, parse_dates = True, \n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    df_universe = df_universe.loc[no_slice, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Country']\n",
    "    df_universe.set_index(['Date', 'Country'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    ### Results output:\n",
    "    return ser_market_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "str_path_bis_csv = 'Data_Files/Source_Files/bis_bank_loans.csv'\n",
    "str_url_bis_zip = 'https://www.bis.org/statistics/full_bis_lbs_diss_csv.zip'\n",
    "str_csv_file_name = 'WEBSTATS_LBS_D_PUB_DATAFLOW_csv_col.csv'\n",
    "str_path_bis_dataset = 'Data_Files/Source_Files/bis_dataset.h5'\n",
    "str_claim_bis_dataset = 'claim_dataset'\n",
    "### ISON membership loading:\n",
    "ser_market_membership = get_market_membership_from_excel()\n",
    "### BIS dataset filter:\n",
    "list_ison_countries = list(map(str, ser_market_membership.index.get_level_values(1).unique()))\n",
    "tup_bis_filter = (All, 'C', 'A', 'TO1', 'A', '5J', 'A', list_ison_countries, 'A', list_ison_countries, 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSV LOADING\n",
    "\n",
    "### File downloading:\n",
    "obj_bis_zip = requests.get(str_url_bis_zip)\n",
    "file_bis_zip = zipfile.ZipFile(io.BytesIO(obj_bis_zip.content))\n",
    "### Offline alternative:\n",
    "#df_bis_full_data = pd.read_csv(str_path_bis_csv, index_col = [*range(2, 23, 2)])\n",
    "### DataFrame creating:\n",
    "df_bis_full_data = pd.read_csv(file_bis_zip.open(str_csv_file_name), index_col = [*range(2, 23, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BIS DATASET MUNGLING\n",
    "\n",
    "### Text columns replacing and date columns stacking:\n",
    "ser_bis_full_data = df_bis_full_data.drop(df_bis_full_data.columns[ : 14], axis = 1).stack()\n",
    "### Quarterly date managing:\n",
    "ser_bis_full_data.index.names = ser_bis_full_data.index.names[ : -1] + ['Date_Q']\n",
    "ser_bis_full_data.name = 'Value'\n",
    "### Dataset filtering:\n",
    "ser_bis_filtered = ser_bis_full_data.loc[tup_bis_filter].reset_index(level = [1, 2, 3, 4, 5, 6, 8, 10], drop = True)\n",
    "ser_bis_filtered = ser_bis_filtered.groupby(ser_bis_filtered.index.names[1 : ], group_keys = False).sum()\n",
    "#### Date resampling to monthly:\n",
    "df_bis_filtered = ser_bis_filtered.reset_index('Date_Q')\n",
    "df_bis_filtered.index.names = ['Reporter_ID', 'Partner_ID']\n",
    "df_bis_filtered['Date_Q'] = df_bis_filtered['Date_Q'].str.replace('-', '')\n",
    "df_bis_filtered['Date'] = pd.to_datetime(df_bis_filtered['Date_Q']) + pd.offsets.BQuarterEnd()\n",
    "df_bis_filtered.drop('Date_Q', axis = 1, inplace = True)\n",
    "ser_bis_monthly = df_bis_filtered.set_index('Date', append = True).squeeze().reorder_levels([2, 0, 1])\n",
    "ser_bis_monthly = ser_bis_monthly.groupby(['Reporter_ID', 'Partner_ID']).\\\n",
    "                                  apply(lambda iter_group: iter_group.droplevel(['Reporter_ID', 'Partner_ID']).resample('BM').bfill())\n",
    "ser_bis_monthly.reorder_levels([2, 0, 1]).to_hdf(path_or_buf = str_path_bis_dataset, key = str_claim_bis_dataset, mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST: RESULTS LOADING\n",
    "\n",
    "pd.read_hdf(path_or_buf = str_path_bis_dataset, key = str_claim_bis_dataset).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST: COLUMNS LEARNING\n",
    "\n",
    "list_ison = ser_market_membership.index.get_level_values(1).unique().to_list()\n",
    "print(len([iter_country for iter_country in df_bis_full_data['L_PARENT_CTY'].unique() if (iter_country in list_ison)]))\n",
    "print(len([iter_country for iter_country in df_bis_full_data['L_REP_CTY'].unique() if (iter_country in list_ison)]))\n",
    "print(len([iter_country for iter_country in df_bis_full_data['L_CP_COUNTRY'].unique() if (iter_country in list_ison)]))\n",
    "print(df_bis_full_data[(df_bis_full_data['L_REP_CTY'] != '5A') & (df_bis_full_data['L_PARENT_CTY'] != '5J') \\\n",
    "                 & (df_bis_full_data['L_REP_CTY'] != df_bis_full_data['L_PARENT_CTY'])][df_bis_full_data.columns[10 : 20]])\n",
    "#df_bis_full_data[(df_bis_full_data['L_REP_CTY'] == 'US') & (df_bis_full_data['L_CP_COUNTRY'] == 'CA')][df_bis_full_data.columns[ : 23]].head()\n",
    "print(df_bis_full_data['L_DENOM'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
