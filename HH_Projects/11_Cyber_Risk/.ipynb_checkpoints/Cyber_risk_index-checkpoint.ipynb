{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715afa9b-aa87-481d-83b9-b974777043ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CYBER RISK INDEX CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6a4b11-aa81-41f7-a956-d4b32bdc2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import boxplot_stats ### To Annotate Fliers\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import zipfile\n",
    "import io\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7742c1fd-4a09-4743-ba44-28987d4f8eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.11.5\n",
      "numpy version:  1.26.3\n",
      "pandas version:  2.1.4\n"
     ]
    }
   ],
   "source": [
    "### VERSION CONTROL\n",
    "\n",
    "from platform import python_version\n",
    "print('python version: ', python_version())\n",
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769c6c33-1831-4a41-b4ae-2c42f8f269d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "### MultiIndex level Slice Constant:\n",
    "no_filter = slice(None)\n",
    "### NA for MS Excel Files:\n",
    "list_na_excel_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Requesting Data...', '#N/A Invalid Security', '#N/A Field Not Applicable']\n",
    "### Request Header:\n",
    "dict_header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "### Path to Selenium:\n",
    "str_chromedriver_path = 'D:/Distribs/Python toolboxes/Selenium/chromedriver.exe'\n",
    "### Data Loading: HACK ETF Holdings:\n",
    "str_htf_link = 'https://amplifyetfs.com/hack-holdings/'\n",
    "### Data Loading: Convertation from SIC Classificator to Fama-French Industries:\n",
    "str_ff_converter_link = 'https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/Siccodes12.zip'\n",
    "str_ff_txt_path = 'Data_Files/Source_Files/Siccodes12.txt'\n",
    "### Data Loading: MITTRE ATT&CK Tactics:\n",
    "str_mitre_tactics_link = 'https://attack.mitre.org/tactics/enterprise/'\n",
    "str_mitre_tech_link = 'https://attack.mitre.org/tactics/'\n",
    "### Data Loading:\n",
    "str_sec_10_k_index_link = 'https://www.sec.gov/Archives/edgar/full-index/company.zip'\n",
    "str_10_k_index_txt_path = 'Data_Files/Source_Files/company.idx'\n",
    "str_sec_archive_prefix = 'https://sec.gov/Archives/'\n",
    "### Data saving:\n",
    "str_dataset_key = 'dataset'\n",
    "str_htf_holdings_path = 'Data_Files/Source_Files/HTF_Holdings.h5'\n",
    "str_sic_to_ff_path = 'Data_Files/Source_Files/CIS_FF_Converter.h5'\n",
    "str_mitre_sub_path = 'Data_Files/Source_Files/MITRE_Sub_Techniques.h5'\n",
    "str_10_k_index_path = 'Data_Files/Source_Files/SEC_10_k_Index.h5'\n",
    "str_10_k_par_path = 'Data_Files/Source_Files/SEC_10_k_Paragraphs.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c803c92-e286-4805-a61d-197122235e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HTF HOLDING LIST PARSING\n",
    "\n",
    "### Web-Driver Preparation:\n",
    "obj_service = Service(str_chromedriver_path)\n",
    "driver = webdriver.Chrome(executable_path=str_chromedriver_path)\n",
    "driver.maximize_window()\n",
    "### Get Response from website:\n",
    "driver.get(str_htf_link)\n",
    "obj_htf_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "driver.close()\n",
    "### Parse Holdings Table Header:\n",
    "list_htf_header = []\n",
    "for tag_i in obj_htf_soup.find('thead').find('tr').find_all('th'):\n",
    "    list_htf_header.append(tag_i.text)\n",
    "### Parse Holdings Table Body:\n",
    "list_htf_body = []\n",
    "for tag_i in obj_htf_soup.find('tbody').find_all('tr'):\n",
    "    list_htf_body.append([tag_j.text for tag_j in tag_i.find_all('td')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced21c5-1bf6-49b8-a19d-9274f4871004",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HTF HOLDING LIST PREPROCESSING\n",
    "\n",
    "### Data Processing:\n",
    "df_htf_holdings = pd.DataFrame(list_htf_body, columns=(list_htf_header[: -1] + ['%'])).set_index('Name')\n",
    "df_htf_holdings['Shares'] = df_htf_holdings['Shares'].str.replace(',', '').astype(int)\n",
    "df_htf_holdings['Market_Value'] = df_htf_holdings['Market Value'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "df_htf_holdings.drop('Market Value', axis=1, inplace=True)\n",
    "df_htf_holdings['%'] = df_htf_holdings['%'].str.replace('%', '').astype('float32') / 100\n",
    "### Control Output:\n",
    "print('HDF Holding DataFrame Head:\\n{}\\n'.format(df_htf_holdings.head()))\n",
    "print('HDF Holding DataFrame Types:\\n{}\\n'.format(df_htf_holdings.dtypes))\n",
    "print('HDF Holding DataFrame Check Sum:\\n{:.2f}\\n'.format(df_htf_holdings['%'].sum()))\n",
    "### Results Saving:\n",
    "df_htf_holdings.to_hdf(str_htf_holdings_path, key=str_dataset_key, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0075d7-1b8f-4763-9733-9ff4ed2363d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CIS TO FAMA-FRENCH CONVERTER LOADING\n",
    "\n",
    "### Function to Expand Range to List:\n",
    "def expand_range(str_range):\n",
    "    int_start = int(str_range.split('-')[0])\n",
    "    int_end = int(str_range.split('-')[1])\n",
    "    list_expanded = list(map(lambda int_i: str(int_i).zfill(4), range(int_start, int_end + 1)))\n",
    "    return list_expanded\n",
    "### Archive Loading & UnPacking:\n",
    "obj_response = requests.get(str_ff_converter_link, stream=True)\n",
    "file_zipped = zipfile.ZipFile(io.BytesIO(obj_response.content))\n",
    "file_zipped.extractall(str_ff_txt_path.rpartition('/')[0])\n",
    "### File Reading:\n",
    "with open(str_ff_txt_path) as file_ff_txt:\n",
    "    list_ff_lines = [line.rstrip().lstrip() for line in file_ff_txt if (len(line.rstrip().lstrip()) > 0)]\n",
    "### Line Data Convertation:\n",
    "dict_names = {}\n",
    "dict_codes_ranged = {}\n",
    "for str_line_i in list_ff_lines:\n",
    "    list_splitted = str_line_i.split(' ')\n",
    "    if (len(list_splitted) > 1):\n",
    "        str_ind_num = list_splitted[0]\n",
    "        str_ind_name = list_splitted[1]\n",
    "        dict_names[str_ind_num] = str_ind_name       \n",
    "        dict_codes_ranged[str_ind_num] = []\n",
    "    else:\n",
    "        dict_codes_ranged[str_ind_num].append(str_line_i)\n",
    "### SIC Ranges to SIC lists:\n",
    "dict_series_expanded = {}\n",
    "for str_code_i in dict_codes_ranged:\n",
    "    list_collection = []\n",
    "    for str_range_i in dict_codes_ranged[str_code_i]:\n",
    "        list_collection.extend(expand_range(str_range_i))\n",
    "    dict_series_expanded[str_code_i] = pd.Series(list_collection, name='SIC_Code')\n",
    "### Data Aggregation:\n",
    "df_sic_ff_converter = pd.concat(dict_series_expanded, axis=0, names=['FF_Code']).droplevel(1).to_frame().join(pd.Series(dict_names, name='FF_Name')).sort_index()\n",
    "df_sic_ff_converter = df_sic_ff_converter.reset_index().set_index('SIC_Code').sort_index()\n",
    "### Results Saving:\n",
    "df_sic_ff_converter.to_hdf(str_sic_to_ff_path, key=str_dataset_key, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fcc48e-fadf-48b9-a201-45c4e139b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MITRE TACTICS PARSING\n",
    "\n",
    "### Tactics Table Loading:\n",
    "obj_mitre_soup_tactics = BeautifulSoup(requests.get(str_mitre_tactics_link).text, 'html.parser')\n",
    "### Head Extrtacting:\n",
    "list_tactics_head = []\n",
    "for tag_i in obj_mitre_soup_tactics.find('table').find('thead').find_all('th'):\n",
    "    list_tactics_head.append(tag_i.text)\n",
    "### Body Extrtacting:   \n",
    "list_tactics_body = []\n",
    "for tag_i in obj_mitre_soup_tactics.find('table').find('tbody').find_all('tr'):\n",
    "#    print(tag_i)\n",
    "    list_i_tactics = []\n",
    "    for tag_j in tag_i.find_all('td'):\n",
    "        list_i_tactics.append(tag_j.text.strip(' ').strip('\\n').strip(' '))\n",
    "#        print(tag_j)        \n",
    "    list_tactics_body.append(list_i_tactics)\n",
    "### Tactics table aggregation:\n",
    "df_mitre_tactics = pd.DataFrame(list_tactics_body, columns=list_tactics_head).set_index('ID').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93e22621-c733-4932-8a6a-ac068edb26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MITRE SUB-TECHNIQUES PARSING\n",
    "\n",
    "### Function to Drop Technique Description (if Technique has more than 1 sub):\n",
    "def check_main_only(df_group):\n",
    "    df_group = df_group.droplevel('Tech_ID')\n",
    "    if (len(df_group) > 1):\n",
    "        return df_group.drop('000', axis=0)\n",
    "    else:\n",
    "        return df_group\n",
    "### Head Preparation:\n",
    "list_tech_head = ['Tech_ID', 'Sub_ID', 'Tech_Name', 'Sub_Name', 'Description']\n",
    "### Body Preparation:   \n",
    "list_tech_body = []\n",
    "### Techniques Tables Loading:\n",
    "for id_i in df_mitre_tactics.index:\n",
    "    obj_mitre_soup_tech = BeautifulSoup(requests.get(str_mitre_tech_link + id_i + '/').text, 'html.parser')\n",
    "    ### Sun-Technique Tables Extraction:\n",
    "    for tag_i in obj_mitre_soup_tech.find('table').find('tbody').find_all('tr'):\n",
    "#        print(tag_i)\n",
    "        list_i_tech = []\n",
    "        for tag_j in tag_i.find_all('td'):\n",
    "#            print(tag_j)\n",
    "            list_i_tech.append(tag_j.text.strip(' ').strip('\\n').strip(' '))\n",
    "        ### Table Modification to Unificate Structure:\n",
    "        if (len(list_i_tech) == 3):\n",
    "            str_tech_id = list_i_tech[0]\n",
    "            str_tech_name = list_i_tech[1]\n",
    "            list_i_tech.insert(1, '000')\n",
    "            list_i_tech.insert(3, 'Root')\n",
    "        else:\n",
    "            list_i_tech[0] = str_tech_id\n",
    "            list_i_tech[1] = list_i_tech[1][1 :]\n",
    "            list_i_tech.insert(2, str_tech_name)\n",
    "        ### Row Collecting:\n",
    "        list_tech_body.append(list_i_tech)    \n",
    "#    break\n",
    "### Data Aggregation:\n",
    "df_mitre_subs = pd.DataFrame(list_tech_body, columns=list_tech_head).set_index(['Tech_ID', 'Sub_ID']).sort_index()\n",
    "### Killing Technique Description (if Technique has more than 1 sub)\n",
    "df_mitre_subs = df_mitre_subs.groupby(['Tech_ID'], observed=True).apply(check_main_only)\n",
    "### Results Saving:\n",
    "df_mitre_subs.to_hdf(str_mitre_sub_path, key=str_dataset_key, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b8b79a6-372d-4cb3-835f-643a0e896e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name            object\n",
      "CIK             object\n",
      "Date    datetime64[ns]\n",
      "URL             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "### SEC 10-K LIST LOADING\n",
    "\n",
    "### Archive Loading & UnPacking:\n",
    "obj_response = requests.get(str_sec_10_k_index_link, headers=dict_header, stream=True)\n",
    "file_zipped = zipfile.ZipFile(io.BytesIO(obj_response.content))\n",
    "file_zipped.extractall(str_10_k_index_txt_path.rpartition('/')[0])\n",
    "### File Reading:\n",
    "list_10_k_lines = []\n",
    "str_head_pattern = r'\\-{10,}'\n",
    "str_body_pattern = r'(?P<Name>.+?)\\s{2,}(?P<Form>.+?)\\s{2,}(?P<CIK>.+?)\\s{2,}(?P<Date>.+?)\\s{2,}(?P<URL>.+?)\\s{2,}'\n",
    "with open(str_10_k_index_txt_path) as file_10_k_txt:\n",
    "    bool_body_started = False\n",
    "    for str_line_i in file_10_k_txt:\n",
    "        if bool_body_started:\n",
    "            re_match = re.match(str_body_pattern, str_line_i)\n",
    "            if (re_match.group('Form') == '10-K'):\n",
    "                list_10_k_lines.append([re_match.group('Name'), re_match.group('CIK'), re_match.group('Date'), re_match.group('URL')])    \n",
    "            else:\n",
    "                continue\n",
    "#                break\n",
    "        elif (re.match(str_head_pattern, str_line_i) is None):\n",
    "            continue\n",
    "        else:\n",
    "            bool_body_started = True\n",
    "### Results saving:\n",
    "df_10_k_index = pd.DataFrame(list_10_k_lines, columns = ['Name', 'CIK', 'Date', 'URL'])\n",
    "df_10_k_index['Date'] = pd.to_datetime(df_10_k_index['Date'])\n",
    "print(df_10_k_index.dtypes)\n",
    "df_10_k_index = df_10_k_index#.set_index(['CIK', 'Date']).sort_index()\n",
    "df_10_k_index.to_hdf(str_10_k_index_path, key=str_dataset_key, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe9aa0-f409-4b21-8190-21810190eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SEC FORM 10-K PARSING\n",
    "\n",
    "### Definition of Security Rsik Pragraph extractor:\n",
    "def sec_par_extract(str_10_k_url):\n",
    "    gc.collect()\n",
    "    ### Loading 10-K Form:\n",
    "    print(str_sec_archive_prefix  + str_10_k_url)\n",
    "    try:\n",
    "        obj_form_i = BeautifulSoup(requests.get(str_sec_archive_prefix  + str_10_k_url, headers=dict_header).text, 'html.parser')\n",
    "    except:\n",
    "        print('URL parse error')\n",
    "        return None\n",
    "    else:\n",
    "    ### Getting attributes:\n",
    "        list_10_k_head = obj_form_i.find('acceptance-datetime').text.replace('\\t', '').split('\\n')\n",
    "        str_comp_name = [str_i.replace('COMPANY CONFORMED NAME:', '') for str_i in list_10_k_head if str_i.startswith('COMPANY CONFORMED NAME:')][0]\n",
    "        str_comp_cik = [str_i.replace('CENTRAL INDEX KEY:', '') for str_i in list_10_k_head if str_i.startswith('CENTRAL INDEX KEY:')][0]\n",
    "        str_comp_date = [str_i.replace('CONFORMED PERIOD OF REPORT:', '') for str_i in list_10_k_head if str_i.startswith('CONFORMED PERIOD OF REPORT:')][0]\n",
    "#        print('Mark 10')\n",
    "        ### Cyber Risk Paragraphs parsing:\n",
    "        list_pars = []\n",
    "#        tag_item_1c = obj_form_i.find(name=['span', 'p'], string=re.compile(r'.*1c\\.\\s*cybersecurity.*', re.IGNORECASE))\n",
    "        tag_item_1c = obj_form_i.find(name='a', string=re.compile(r'.*ybersecurity.*', re.IGNORECASE)).next\\\n",
    "                                .find_next(string=re.compile(r'.*1c\\.\\s*cybersecurity.*', re.IGNORECASE))  \n",
    "        tag_item_1c_par = tag_item_1c.parent\n",
    "#        print(tag_item_1c_par)\n",
    "#        print('Mark 20')        \n",
    "        while not (tag_item_1c_par.name in ['p', 'div']):\n",
    "            tag_item_1c_par = tag_item_1c_par.parent\n",
    "#        tag_item_2 = obj_form_i.find(name=['span', 'p'], string=re.compile(r'.*item\\s*2\\.\\s*Propert.*', re.IGNORECASE))\n",
    "        tag_item_2 = obj_form_i.find(name='a', string=re.compile(r'.*Propert*', re.IGNORECASE)).next\\\n",
    "                               .find_next(string=re.compile(r'.*item\\s*2\\.\\s*Propert.*', re.IGNORECASE))        \n",
    "        tag_item_2_par = tag_item_2.parent\n",
    "#        print(tag_item_2_par)\n",
    "#        print('Mark 30')              \n",
    "        while not (tag_item_2_par.name in ['p', 'div']):\n",
    "            tag_item_2_par = tag_item_2_par.parent\n",
    "        tag_next = tag_item_1c_par\n",
    "#        print('Mark 40')            \n",
    "        while (tag_next.next != tag_item_2_par):\n",
    "            tag_next = tag_next.next\n",
    "            if (len(tag_next.text.split()) > 10):\n",
    "                if (tag_next.text.find(' means ') == -1):\n",
    "#                    print(tag_next.text)\n",
    "                    list_pars.append(tag_next.text)\n",
    "#        print('Mark 50')                    \n",
    "        ### Paragraphs aggregation:\n",
    "        ser_i_pars = pd.Series(list_pars, index=[[str_comp_name] * len(list_pars), [str_comp_cik] * len(list_pars), [str_comp_date] * len(list_pars)])\n",
    "        ser_i_pars.name = 'Text'\n",
    "        ser_i_pars.index.names = ['Name', 'CIK', 'Date']\n",
    "        ser_i_pars = ser_i_pars.drop_duplicates()\n",
    "        ### Results output:         \n",
    "        print('URL parsed successfully')\n",
    "        return ser_i_pars\n",
    "### SEC 10-K Forms Loading:\n",
    "df_10_k_index = pd.read_hdf(str_10_k_index_path)\n",
    "### Paragraphs Extraction:\n",
    "ser_10_k_pars = pd.concat(map(sec_par_extract, df_10_k_index['URL'][: 11]), axis=0)\n",
    "### Data saving:\n",
    "ser_10_k_pars.index.set_levels(pd.to_datetime(ser_10_k_pars.index.levels[2]), level=2)\n",
    "ser_10_k_pars.to_hdf(str_10_k_par_path, key=str_dataset_key, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e9bf2e-1679-4178-9ed7-be4003ff6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPARE TRAINING SET & MODEL TRAINING\n",
    "\n",
    "### Model creation:\n",
    "model_vect = TfidfVectorizer(stop_words=list(ENGLISH_STOP_WORDS.union(['cybersecurity'])), lowercase=True,  ngram_range=(1, 4), min_df=0.05, max_df=0.50, max_features=40)\n",
    "### Train data loading:\n",
    "df_mitre_subs = pd.read_hdf(str_mitre_sub_path)\n",
    "### Model fitting:\n",
    "model_vect.fit(df_mitre_subs['Description'])\n",
    "matrix_mitre_subs = model_vect.transform(df_mitre_subs['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce1e5ed-73f1-47f1-b1aa-79617b0ebf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRANSFORM TESTING SET\n",
    "\n",
    "ser_10_k_pars = pd.read_hdf(str_10_k_par_path)\n",
    "matrix_10_k_pars = model_vect.transform(ser_10_k_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b6c56c9-7dec-46a1-b2d0-000254831253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                              CIK         Date      \n",
       "99 Acquisition Group Inc.                         0001950429  2023-12-31    0.000000\n",
       "4Front Ventures Corp.                             0001783875  2023-12-31    0.274309\n",
       "1606 CORP.                                        0001877461  2023-12-31    0.619548\n",
       "60 DEGREES PHARMACEUTICALS, INC.                  0001946563  2023-12-31    0.695081\n",
       "ADIAL PHARMACEUTICALS, INC.                       0001513525  2023-12-31    0.762586\n",
       "1847 Holdings LLC                                 0001599407  2023-12-31    0.810525\n",
       "AB Commercial Real Estate Private Debt Fund, LLC  0001876255  2023-12-31    0.888397\n",
       "8X8 INC /DE/                                      0001023731  2024-03-31    0.913674\n",
       "ABERCROMBIE & FITCH CO /DE/                       0001018840  2024-02-03    0.933996\n",
       "23andMe Holding Co.                               0001804591  2024-03-31    0.935648\n",
       "Name: Cosine, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RESULTS ANALYZING\n",
    "\n",
    "df_10_k_cosines = pd.DataFrame(cosine_similarity(matrix_10_k_pars, matrix_mitre_subs))\n",
    "\n",
    "ser_10_k_cosines = df_10_k_cosines.apply(lambda ser_par: ser_par.max(), axis=1)\n",
    "ser_10_k_cosines.name = 'Cosine'\n",
    "ser_10_k_cosines.index = ser_10_k_pars.index\n",
    "\n",
    "ser_10_k_cosines.groupby(['Name', 'CIK', 'Date'], observed=True).apply(lambda ser_ticker: ser_ticker.nlargest(5).mean()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7320389b-192d-46f6-833d-0e09f2ee13f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1606 CORP.</td>\n",
       "      <td>1877461</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>edgar/data/1877461/0001477932-24-002182.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1847 Holdings LLC</td>\n",
       "      <td>1599407</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>edgar/data/1599407/0001213900-24-036197.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st FRANKLIN FINANCIAL CORP</td>\n",
       "      <td>38723</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>edgar/data/38723/0000038723-24-000047.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23andMe Holding Co.</td>\n",
       "      <td>1804591</td>\n",
       "      <td>2024-05-30</td>\n",
       "      <td>edgar/data/1804591/0001804591-24-000038.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4Front Ventures Corp.</td>\n",
       "      <td>1783875</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>edgar/data/1783875/0001628280-24-016208.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60 DEGREES PHARMACEUTICALS, INC.</td>\n",
       "      <td>1946563</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>edgar/data/1946563/0001213900-24-028577.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8X8 INC /DE/</td>\n",
       "      <td>1023731</td>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>edgar/data/1023731/0001023731-24-000042.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99 Acquisition Group Inc.</td>\n",
       "      <td>1950429</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>edgar/data/1950429/0001213900-24-030594.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AB Commercial Real Estate Private Debt Fund, LLC</td>\n",
       "      <td>1876255</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>edgar/data/1876255/0001193125-24-083290.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABERCROMBIE &amp; FITCH CO /DE/</td>\n",
       "      <td>1018840</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>edgar/data/1018840/0001018840-24-000019.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ADIAL PHARMACEUTICALS, INC.</td>\n",
       "      <td>1513525</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>edgar/data/1513525/0001213900-24-028701.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name      CIK       Date  \\\n",
       "0                                         1606 CORP.  1877461 2024-04-17   \n",
       "1                                  1847 Holdings LLC  1599407 2024-04-25   \n",
       "2                        1st FRANKLIN FINANCIAL CORP    38723 2024-04-01   \n",
       "3                                23andMe Holding Co.  1804591 2024-05-30   \n",
       "4                              4Front Ventures Corp.  1783875 2024-04-15   \n",
       "5                   60 DEGREES PHARMACEUTICALS, INC.  1946563 2024-04-01   \n",
       "6                                       8X8 INC /DE/  1023731 2024-05-21   \n",
       "7                          99 Acquisition Group Inc.  1950429 2024-04-05   \n",
       "8   AB Commercial Real Estate Private Debt Fund, LLC  1876255 2024-04-01   \n",
       "9                        ABERCROMBIE & FITCH CO /DE/  1018840 2024-04-01   \n",
       "10                       ADIAL PHARMACEUTICALS, INC.  1513525 2024-04-01   \n",
       "\n",
       "                                            URL  \n",
       "0   edgar/data/1877461/0001477932-24-002182.txt  \n",
       "1   edgar/data/1599407/0001213900-24-036197.txt  \n",
       "2     edgar/data/38723/0000038723-24-000047.txt  \n",
       "3   edgar/data/1804591/0001804591-24-000038.txt  \n",
       "4   edgar/data/1783875/0001628280-24-016208.txt  \n",
       "5   edgar/data/1946563/0001213900-24-028577.txt  \n",
       "6   edgar/data/1023731/0001023731-24-000042.txt  \n",
       "7   edgar/data/1950429/0001213900-24-030594.txt  \n",
       "8   edgar/data/1876255/0001193125-24-083290.txt  \n",
       "9   edgar/data/1018840/0001018840-24-000019.txt  \n",
       "10  edgar/data/1513525/0001213900-24-028701.txt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://sec.gov/Archives/edgar/data/1877461/0001477932-24-002182.txt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### VISUAL CONTROL\n",
    "\n",
    "df_10_k_index = pd.read_hdf(str_10_k_index_path)\n",
    "display(df_10_k_index[ : 11])\n",
    "\n",
    "str_sec_archive_prefix + df_10_k_index.loc[0]['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e039e-bae5-4c30-a85a-3928157f5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
