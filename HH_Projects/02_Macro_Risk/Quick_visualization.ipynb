{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "### Importing standard modules and date-special modules:\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "### Constants declaring:\n",
    "All = slice(None) ### Internal constant for slicing\n",
    "arr_tup_index = [(All, All, All), (All, All, ['DM', 'EM', 'FM']), (All, All, 'DM'), (All, All, 'EM'), (All, All, 'FM')] ### Regions' dataset filters\n",
    "arr_tup_market = ['All', 'ISON', 'DM', 'EM', 'FM'] ### Regions' external names\n",
    "num_rating_round_level = 2 ### Rating rounding order\n",
    "num_quantile_bins = 10 ### Bins number for data distribution\n",
    "arr_roll_max = [12] ### Length of look-back variants in months #[12, 36, 60]\n",
    "path_source = 'Data_Files/Test_Files/Quick_Visualization_Test_Source.xlsx' ### Path for MS Excel source file\n",
    "path_result = 'Data_Files/Test_Files/Quick_Visualization_Test_Table.xlsx' ### Path for MS Excel result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING CONSTANT RATING PERIODS LENGTH CALCULATOR\n",
    "\n",
    "def rolling_count(iter_delta):\n",
    "    if (iter_delta == 0):\n",
    "        rolling_count.iter_counter = rolling_count.iter_counter + 1\n",
    "        rolling_count.iter_result = 0\n",
    "    else:\n",
    "        rolling_count.iter_result = rolling_count.iter_counter\n",
    "        rolling_count.iter_counter = 1\n",
    "    return rolling_count.iter_result\n",
    "rolling_count.iter_counter = 1 \n",
    "rolling_count.iter_result = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN SCRIPT\n",
    "\n",
    "### Source data extraction:\n",
    "df_source_raw = pd.read_excel(path_source, index_col = [0, 1, 2], parse_dates = True, \n",
    "                              na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                           '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "\n",
    "### Resulting table initialazition:\n",
    "arr_parameters = ['Average x-sectional median', \n",
    "                  'Average x-sectional range (90 â€“ 10 ptile)', \n",
    "                  'Proportion of revised observations (decile bins)', \n",
    "                  'Average revisions per country', \n",
    "                  'Average age of ratings (months)', \n",
    "                  'Mean revision abs step (decile bins)', \n",
    "                  'Mean % of x-section revised in past 12 mo (decile bins)']\n",
    "idx_table_res = pd.MultiIndex.from_product([arr_parameters, arr_tup_market], names = ['Parameter', 'Region'])\n",
    "df_table_res = pd.DataFrame(index = idx_table_res, columns = df_source_raw.columns)\n",
    "\n",
    "### Main loop performing:\n",
    "for iter_pillar_num, iter_pillar in enumerate(df_source_raw.columns): ### Agencies iterating\n",
    "    for iter_market_num, iter_tup_market in enumerate(arr_tup_index):  ### Universe filters iterating\n",
    "        ### Grades series defining:\n",
    "        iter_ser_grades = df_source_raw.loc[iter_tup_market, iter_pillar].dropna().sort_index(level = ['Country', 'Date'], ascending = [True, True])        \n",
    "        ### Counter for country rankings:\n",
    "        iter_ser_counter = iter_ser_grades.groupby('Country').count()\n",
    "        ### Quantile bins distribution:\n",
    "        iter_ser_deciles = df_source_raw.loc[All, iter_pillar].groupby('Date').transform(lambda iter_group: pd.qcut(iter_group, q = num_quantile_bins, \n",
    "                                                                                                                     labels = False, duplicates = 'drop')) \n",
    "        ### Bin changing fixation:\n",
    "        iter_ser_deltas = iter_ser_deciles.dropna().groupby('Country').diff().sort_index(level = ['Country', 'Date'], ascending = [True, True])\n",
    "        ### Rolling revisions number for every date calculation:\n",
    "        arr_df_roll_flag_date = {} ### Cross-sectional changes quantity for each look-back period\n",
    "        arr_df_roll_flag_market = {} ### Cros-sectional changes proportion for each look-back period\n",
    "        arr_df_crosstab = {}        \n",
    "        for iter_roll_max in arr_roll_max:\n",
    "            num_roll_max = iter_roll_max\n",
    "            num_roll_min = 2 # num_roll_max // 2\n",
    "            ### Bin changing signed flag:\n",
    "            iter_ser_flag = iter_ser_deltas.copy()\n",
    "            iter_ser_flag[iter_ser_flag != 0] = iter_ser_flag / iter_ser_flag.abs()\n",
    "            iter_ser_flag_plus = iter_ser_flag.copy()\n",
    "            iter_ser_flag_plus[iter_ser_flag_plus != 1] = 0\n",
    "            iter_ser_flag_minus = iter_ser_flag.copy()\n",
    "            iter_ser_flag_minus[iter_ser_flag_minus != -1] = 0\n",
    "            ### Positive changes quantity for country for look-back period:\n",
    "            iter_ser_roll_flag_plus = iter_ser_flag_plus.groupby('Country').rolling(window = num_roll_max, min_periods = num_roll_min).sum()\n",
    "            iter_ser_roll_flag_plus = iter_ser_roll_flag_plus.reset_index(level = 0, drop = True)\n",
    "            ### Negative changes quantity for country for look-back period:            \n",
    "            iter_ser_roll_flag_minus = iter_ser_flag_minus.abs().groupby('Country').rolling(window = num_roll_max, min_periods = num_roll_min).sum()\n",
    "            iter_ser_roll_flag_minus = iter_ser_roll_flag_minus.reset_index(level = 0, drop = True)\n",
    "            ### Any changes quantity for country for look-back period:\n",
    "            iter_ser_roll_flag = iter_ser_roll_flag_plus + iter_ser_roll_flag_minus\n",
    "            ### Changes quantity info concatenation:\n",
    "            iter_df_roll_flag = pd.concat([iter_ser_roll_flag, iter_ser_roll_flag_plus, iter_ser_roll_flag_minus], axis = 1)\n",
    "            iter_df_roll_flag.sort_index(level = ['Country', 'Date'], ascending = [True, True], inplace = True)  \n",
    "            iter_df_roll_flag = iter_df_roll_flag.loc[iter_tup_market, All]\n",
    "            iter_df_roll_flag.columns = ['Any', 'Plus', 'Minus']\n",
    "            ### Changes quantity for cross-section for look-back period:\n",
    "            iter_df_roll_flag_date = iter_df_roll_flag.groupby('Date').sum()          \n",
    "            arr_df_roll_flag_date[num_roll_max] = iter_df_roll_flag_date\n",
    "            ### Changes proportion for cross-section for look-back period:\n",
    "            iter_df_roll_flag_market_all = iter_df_roll_flag.groupby('Date')\n",
    "            iter_df_roll_flag_market_revised = iter_df_roll_flag[iter_df_roll_flag['Any'] > 0].groupby('Date')\n",
    "            iter_df_roll_flag_market = iter_df_roll_flag_market_revised.count().div(iter_df_roll_flag_market_all.count())['Any']\n",
    "            iter_df_roll_flag_market.fillna(0, inplace = True)\n",
    "            arr_df_roll_flag_market[num_roll_max] = iter_df_roll_flag_market            \n",
    "        ### Constant periods lengths series calculation:\n",
    "        iter_ser_deltas = iter_ser_deltas.shift(-1)    \n",
    "        iter_ser_distances = iter_ser_deltas.apply(rolling_count)\n",
    "        iter_ser_distances = iter_ser_distances.loc[iter_tup_market]\n",
    "        iter_ser_deltas = iter_ser_deltas.shift()  \n",
    "        iter_ser_deltas = iter_ser_deltas.loc[iter_tup_market]\n",
    "        ### Deltas number for countries calculation:        \n",
    "        iter_ser_deltas_countries = iter_ser_deltas.dropna()[iter_ser_deltas != 0].groupby('Country').count()\n",
    "        iter_ser_deltas_countries = iter_ser_deltas_countries / iter_ser_deltas.dropna().groupby('Country').count()\n",
    "        iter_ser_deltas_countries.fillna(0, inplace = True)\n",
    "        iter_ser_deltas_countries = iter_ser_deltas_countries * iter_ser_deltas.dropna().groupby('Country').count()       \n",
    "        iter_ser_deltas_countries.name = 'Country revisions number'\n",
    "        ### Mean deltas for universe filter:\n",
    "        iter_ser_deltas_mean = pd.Series(iter_ser_deltas_countries.mean(), index = iter_ser_deltas_countries.index)        \n",
    "        iter_ser_deltas_mean.name = iter_pillar + ' / ' + arr_tup_market[iter_market_num] + ' mean'\n",
    "        ### Timeline for filtered market time-series and cross-sections aggregating:\n",
    "        grouper_market_by_country = iter_ser_grades.groupby('Country')\n",
    "        grouper_market_by_date = iter_ser_grades.groupby('Date')        \n",
    "        ### Plots drawing:\n",
    "        if ((iter_pillar_num == 0) & (iter_market_num == 0)):\n",
    "            ### Filtered universe grades distribution drawing:            \n",
    "            (iter_ser_grades.groupby(pd.cut(iter_ser_grades, 20)).count() / iter_ser_grades.count()).plot(figsize = (15, 5), kind = 'bar', color = '#1f77b4',\n",
    "                                                                                    title = iter_pillar + ' / ' + arr_tup_market[iter_market_num] + ' - distribution')\n",
    "            plt.show()        \n",
    "            ### Timeline for filtered countries plotting:\n",
    "            dict_color = {'boxes': 'DarkBlue', 'medians': 'Green', 'whiskers': 'Blue', 'caps': 'Black'}\n",
    "            iter_ser_grades.unstack('Country').reindex(iter_ser_grades.unstack('Country').median().sort_values().index, axis = 1).plot.box(figsize = (20, 5), \n",
    "                                                                               title = iter_pillar + ' / ' + arr_tup_market[iter_market_num] + ' - by country box plot',\n",
    "                                                                               color = dict_color, sym = 'r+', whis = [10, 90])        \n",
    "            plt.show()\n",
    "            ### Revisions number for filtered countries plotting:        \n",
    "            iter_ser_deltas_countries.plot.bar(figsize = (20, 5), title = iter_pillar + ' / ' + arr_tup_market[iter_market_num] + ' - by country revisions number',\n",
    "                                               legend = True, width = 0.5)\n",
    "            iter_ser_deltas_mean.plot(color = 'Orange', legend = True)\n",
    "            plt.show()\n",
    "        ### Resulting table filling:\n",
    "        df_table_res.loc[('Proportion of revised observations (decile bins)', arr_tup_market[iter_market_num]), iter_pillar] = \\\n",
    "                                                '{:.0%}'.format(len(iter_ser_deltas.dropna()[iter_ser_deltas != 0].index) / iter_ser_grades.count())        \n",
    "        df_table_res.loc[('Average revisions per country', arr_tup_market[iter_market_num]), iter_pillar] = \\\n",
    "                                                round(iter_ser_deltas_countries.mean(), 0)\n",
    "        df_table_res.loc[('Average age of ratings (months)', arr_tup_market[iter_market_num]), iter_pillar] = \\\n",
    "                                                round(iter_ser_distances[iter_ser_distances > 0].mean(), 1)\n",
    "        df_table_res.loc[('Mean revision abs step (decile bins)', arr_tup_market[iter_market_num]), iter_pillar] = \\\n",
    "                                                round(iter_ser_deltas.abs()[iter_ser_deltas != 0].mean(), 1)       \n",
    "        df_table_res.loc[('Average x-sectional range (90 â€“ 10 ptile)', arr_tup_market[iter_market_num]), iter_pillar] = \\\n",
    "                                                round((grouper_market_by_date.quantile(0.90) - grouper_market_by_date.quantile(0.10)).mean(), 1)\n",
    "        df_table_res.loc[('Average x-sectional median', arr_tup_market[iter_market_num]), iter_pillar] = \\\n",
    "                                                round(grouper_market_by_date.median().mean(), 1)        \n",
    "        for iter_roll_max in arr_roll_max:\n",
    "            if (iter_roll_max == 12):\n",
    "                num_roll_max = iter_roll_max\n",
    "                iter_df_roll_flag_date = arr_df_roll_flag_date[num_roll_max]\n",
    "                iter_df_roll_flag_market = arr_df_roll_flag_market[num_roll_max]\n",
    "                df_table_res.loc[('Mean % of x-section revised in past 12 mo (decile bins)', arr_tup_market[iter_market_num]), iter_pillar] = \\\n",
    "                                                        '{:.0%}'.format(round(iter_df_roll_flag_market.mean(), 2))\n",
    "#        break        \n",
    "#    break\n",
    "#df_table_res.to_excel(path_result, engine = 'openpyxl')\n",
    "df_table_res.to_excel(path_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
