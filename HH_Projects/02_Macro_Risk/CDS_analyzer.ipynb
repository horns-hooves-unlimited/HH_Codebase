{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "def get_market_membership_from_excel(path_msci, convert_to_daily = False):\n",
    "    ### Importing standard modules and date-special modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Reindexing function declaring:\n",
    "    def reindex_month_ends(iter_group):\n",
    "        iter_range = pd.date_range(iter_group.first_valid_index(), iter_group.last_valid_index(), freq = 'BM')\n",
    "        iter_result = iter_group.reindex(iter_range)\n",
    "        return iter_result    \n",
    "    ### Declaring local constants & variables: \n",
    "    tab_monthly = 'universe_joined'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    no_slice = slice(None)\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci, sheet_name = tab_monthly, skiprows = [0, 2], header = 0, parse_dates = True, \n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    df_universe = df_universe.loc[no_slice, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Country']\n",
    "    df_universe.set_index(['Date', 'Country'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    ### Reindexing to show absent monthes for future daily resampling: \n",
    "    if (convert_to_daily):\n",
    "        ser_market_membership = ser_market_membership.groupby('Country').apply(lambda iter_group: reindex_month_ends(iter_group.droplevel(1)))\n",
    "        ser_market_membership.index.names = ['Country', 'Date']\n",
    "        ser_market_membership = ser_market_membership.swaplevel()\n",
    "        ser_market_membership = ser_market_membership.reset_index('Country').groupby('Country').resample('B').ffill().drop('Country', axis = 1).squeeze()\n",
    "        ser_market_membership = ser_market_membership.swaplevel().sort_index(level = ['Country', 'Date'])\n",
    "        \n",
    "    return ser_market_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cds_from_excel(path_cds, path_msci):\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd \n",
    "    ### Declaring global constants & variables: \n",
    "    arr_cds_source = ['CBIN', 'CMAN']\n",
    "    dict_cds = {}\n",
    "    ### Collecting sheets:\n",
    "    with pd.ExcelFile(path_cds) as file_excel:\n",
    "        for str_sheet_name in file_excel.sheet_names:\n",
    "            ### Sheet checking and reading:\n",
    "            if (str_sheet_name.upper() in arr_cds_source):\n",
    "                df_source = pd.read_excel(io = file_excel, sheet_name = str_sheet_name, skiprows = list(range(9)), header = 0, index_col = [0], parse_dates = True, \n",
    "                                          na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                                       '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False) \n",
    "                ### Table mungling:\n",
    "                ser_cds = df_source.stack(dropna = False).squeeze()\n",
    "                ser_cds.name = str_sheet_name\n",
    "                dict_cds[str_sheet_name.upper()] = ser_cds.sort_index()\n",
    "    ### Aggregating tables:                \n",
    "    df_cds = pd.concat(dict_cds, axis = 1).sort_index()\n",
    "    df_cds.index.names = ['Date', 'Country']\n",
    "    ### Receiving MSCI membership data:    \n",
    "    ser_market_membership = get_market_membership_from_excel(path_msci, convert_to_daily = True)\n",
    "    ### Adding membership column to result dataframe:    \n",
    "    df_cds = df_cds.join(ser_market_membership, on = ['Date', 'Country'], how = 'left')\n",
    "    df_cds = df_cds.set_index('Market', drop = True, append = True) \n",
    " \n",
    "    return df_cds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALL RATINGS IMPORTING\n",
    "### Importing standard modules and date-special modules:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "### Declaring global constants & variables: \n",
    "path_msci = 'Data_Files/Source_Files/sample_universe.xlsx' ### Path to membership source\n",
    "path_cds = 'Data_Files/Source_Files/CDS_Spreadsheet.xlsx' ### Path to CDS data file\n",
    "path_market_cap = 'Data_Files/Source_Files/Market_Cap.h5'\n",
    "key_market_cap = 'mcap'\n",
    "All = slice(None)\n",
    "### Market caps extracting:\n",
    "ser_mcap = pd.read_hdf(path_market_cap, key_market_cap)\n",
    "ser_mcap_daily = ser_mcap.groupby('Country').apply(lambda iter_group: iter_group.droplevel([1, 2]).resample('B').bfill())\n",
    "### Receiving aggregated ratings table:\n",
    "df_cds = get_cds_from_excel(path_cds, path_msci)\n",
    "### Joining market caps:\n",
    "df_cds_mcap = df_cds.reset_index('Market').join(ser_mcap_daily.swaplevel()).set_index('Market', append = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT RESULTS SAVING\n",
    "\n",
    "### Declaring constants:\n",
    "path_cds_hdf = 'Data_Files/Source_Files/CDS_Data.h5'\n",
    "key_cds_mcap = 'cds_mcap'\n",
    "### Saving to hdf:\n",
    "df_cds_mcap.to_hdf(path_cds_hdf, key_cds_mcap, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPLORING CDS DATA\n",
    "import matplotlib.pyplot as plt\n",
    "### Declaring global constants & variables: \n",
    "arr_cds_source = ['CBIN', 'CMAN']\n",
    "arr_market = [All, ['DM', 'EM', 'FM'], ['DM'], ['EM'], ['FM']]\n",
    "arr_market_str = ['ANY REGION', 'DM + EM + FM', 'DM only', 'EM only', 'FM only']\n",
    "arr_period = [999, 24, 12]\n",
    "arr_period_str = ['ALL DATES', 'LAST TWO YEARS', 'LAST YEAR']\n",
    "### Testing values:\n",
    "#arr_cds_source = ['CBIN']\n",
    "#arr_market = [['DM']]\n",
    "#arr_market_str = ['DM only']\n",
    "#arr_period = [12]\n",
    "#arr_period_str = ['LAST YEAR']\n",
    "### Defining function for internal missing observations counting:\n",
    "def get_missing_observations(iter_group, iter_last_date):\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd  \n",
    "    ### Internal gaps calculation:\n",
    "    iter_group = iter_group.droplevel([1, 2])\n",
    "    if (len(iter_group.dropna()) > 0):\n",
    "        iter_start_date = iter_group.first_valid_index()        \n",
    "        iter_date_range = pd.date_range(start = iter_start_date, end = iter_last_date, freq = 'B')\n",
    "        iter_result = iter_group.count() / len(iter_date_range)\n",
    "    else:\n",
    "        iter_result = np.NaN\n",
    "    return iter_result\n",
    "### Defining function for market cap weighting:\n",
    "def set_mcap_weights(iter_group):\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd \n",
    "    ### Normalizing by mcap:\n",
    "#   iter_group.loc[iter_group[iter_source].isna(), 'Market Cap'] = 0\n",
    "    iter_result = iter_group[iter_source].mul(iter_group['Market Cap'].pow(0.5))\n",
    "    iter_result = iter_result / (iter_group['Market Cap'].pow(0.5)).sum()  \n",
    "    return iter_result\n",
    "### Main loop\n",
    "for iter_source in arr_cds_source:\n",
    "    ### Preparing market cap weighted CDS quantity counter:\n",
    "    df_cds_weighted = df_cds_mcap[[iter_source, 'Market Cap']].copy()\n",
    "    df_cds_weighted.loc[df_cds_weighted[iter_source].notna(), iter_source] = 1\n",
    "    ### Looping periods:\n",
    "    for iter_period_num, iter_period in enumerate(arr_period):\n",
    "        ### Looping markets:\n",
    "        for iter_market_num, iter_market in enumerate(arr_market):\n",
    "            ### Defining index:\n",
    "            iter_prefix = iter_source + ' : ' + arr_period_str[iter_period_num] + ' : ' + arr_market_str[iter_market_num]\n",
    "            ### Selecting appropriate data set:\n",
    "            ser_iter_cds = df_cds_mcap[iter_source].copy()\n",
    "            iter_last_date = ser_iter_cds.index.get_level_values(0).max()\n",
    "            ser_iter_cds = ser_iter_cds.loc[iter_last_date - pd.offsets.BMonthEnd(iter_period) + pd.offsets.BDay(): iter_last_date, All, iter_market]\n",
    "            ### Calculating marketcap weighted counter:\n",
    "            df_iter_cds_weighted = df_cds_weighted.loc[ser_iter_cds.index, All]\n",
    "            ser_iter_weighted = df_iter_cds_weighted.groupby('Date').apply(lambda iter_group: set_mcap_weights(iter_group)).droplevel(0)                    \n",
    "            ### Calculating nominal counters:\n",
    "            ser_iter_country_count = ser_iter_cds.groupby('Country').count()\n",
    "            ser_iter_date_proportion = ser_iter_cds.groupby('Date').apply(lambda iter_group: iter_group.count() / len(iter_group.index))\n",
    "            ser_iter_country_missed = ser_iter_cds.groupby('Country').apply(lambda iter_group: get_missing_observations(iter_group, iter_last_date))\n",
    "            ser_iter_country_missed = ser_iter_country_missed.dropna()    \n",
    "            ### Results output:\n",
    "            print(iter_prefix, ': Data set date range:', ser_iter_cds.dropna().index.get_level_values(0).min().date(), '-',\n",
    "                  ser_iter_cds.dropna().index.get_level_values(0).max().date(), '(', len(ser_iter_cds.dropna().index.get_level_values(0).unique()), 'dates )')\n",
    "            print(iter_prefix, ': Data set coverage:', '{:.2%}'.format(ser_iter_cds.count() / len(ser_iter_cds.index)), '(', ser_iter_cds.count(), ')')\n",
    "            print(iter_prefix, ': Average country\\'s number per date:', round(ser_iter_cds.groupby('Date').count().mean(), 2))\n",
    "            print(iter_prefix, ': Number of countries with at least one effective observation:', \n",
    "                  ser_iter_cds.groupby('Country').count()[ser_iter_cds.groupby('Country').count() > 0].count())        \n",
    "            print(iter_prefix, ': Average number of valid observations for country:', int(ser_iter_country_count.mean()), \n",
    "                  '(', '{:.2%}'.format(ser_iter_country_count.mean() / len(ser_iter_cds.dropna().index.get_level_values(0).unique())), 'of dates number)')\n",
    "            print(iter_prefix, ': Average number of valid observations for country with at least one valid observation:', \n",
    "                  int(ser_iter_country_count[ser_iter_country_count > 0].mean()), \n",
    "                  '(', '{:.2%}'.format(ser_iter_country_count[ser_iter_country_count > 0].mean() / len(ser_iter_cds.dropna().index.get_level_values(0).unique())), ')')  \n",
    "            print(iter_prefix, ': Average proportion of coverage after first valid observation to the last available data set date:', \n",
    "                  '{:.2%}'.format(ser_iter_country_missed.mean()))\n",
    "            print(iter_prefix, ': Average proportion of coverage per date:', '{:.2%}'.format(ser_iter_date_proportion.mean()), 'of countries number') \n",
    "            print(iter_prefix, ': Average proportion of coverage per date weighted by market cap square rooted:', \n",
    "                  '{:.2%}'.format(ser_iter_weighted.groupby('Date').sum().mean()), 'of weighted countries number')       \n",
    "            \n",
    "            ser_coverage_to_show = pd.concat([ser_iter_date_proportion.resample('BM').mean(), ser_iter_weighted.groupby('Date').sum().resample('BM').mean()], axis = 1)\n",
    "            ser_coverage_to_show.columns = ['Simple coverage', 'Weighted coverage']\n",
    "            ser_coverage_to_show.plot(figsize = (20, 5), title = iter_prefix + ': Coverage evolution (month average)')\n",
    "            plt.show()             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CDS DTA SOURCES COMPARING\n",
    "import matplotlib.pyplot as plt\n",
    "### Declaring global constants & variables: \n",
    "arr_market = [All, ['DM', 'EM', 'FM'], ['DM'], ['EM'], ['FM']]\n",
    "arr_market_str = ['ANY REGION', 'DM + EM + FM', 'DM only', 'EM only', 'FM only']\n",
    "arr_period = [999, 24, 12]\n",
    "arr_period_str = ['ALL DATES', 'LAST TWO YEARS', 'LAST YEAR']\n",
    "### Testing values:\n",
    "arr_market = [['DM']]\n",
    "arr_market_str = ['DM']\n",
    "arr_period = [999]\n",
    "arr_period_str = ['ALL DATES']\n",
    "### Looping periods:\n",
    "for iter_period_num, iter_period in enumerate(arr_period):\n",
    "    ### Looping markets:\n",
    "    for iter_market_num, iter_market in enumerate(arr_market):\n",
    "        ### Defining index:\n",
    "        iter_prefix = arr_period_str[iter_period_num] + ' : ' + arr_market_str[iter_market_num]\n",
    "        ### Selecting appropriate data set:\n",
    "        iter_last_date = df_cds_mcap.index.get_level_values(0).max()\n",
    "        iter_range = pd.date_range(iter_last_date - pd.offsets.BMonthEnd(iter_period) + pd.offsets.BDay(), iter_last_date, freq = 'B')\n",
    "        df_iter_cds = df_cds_mcap.loc[(iter_range, All, iter_market), :]\n",
    "        ### Reasults output:\n",
    "        ser_iter_cbin = df_iter_cds.loc[df_iter_cds['CBIN'].notna()]\n",
    "        print(iter_prefix, ': CBIN covered observations :', '{:.2%}'.format(len(ser_iter_cbin.index) / len(df_iter_cds.index)),\n",
    "              '(', len(ser_iter_cbin.index), 'observations from', len(df_iter_cds.index), ')')  \n",
    "        print(iter_prefix, ': CBIN covered :', 'Proportion of dates presence :', \n",
    "              '{:.2%}'.format(len(ser_iter_cbin.index.get_level_values(0).unique()) / len(df_iter_cds.index.get_level_values(0).unique())),\n",
    "              '(', len(ser_iter_cbin.index.get_level_values(0).unique()), 'dates from', len(df_iter_cds.index.get_level_values(0).unique()), ')')\n",
    "        print(iter_prefix, ': CBIN covered :', 'Proportion of countries presence :', \n",
    "              '{:.2%}'.format(len(ser_iter_cbin.index.get_level_values(1).unique()) / len(df_iter_cds.index.get_level_values(1).unique())),\n",
    "              '(', len(ser_iter_cbin.index.get_level_values(1).unique()), 'countries from', len(df_iter_cds.index.get_level_values(1).unique()), ')')         \n",
    "        ser_iter_cman = df_iter_cds.loc[df_iter_cds['CMAN'].notna()]        \n",
    "        print(iter_prefix, ': CMAN covered observations :', '{:.2%}'.format(len(ser_iter_cman.index) / len(df_iter_cds.index)),\n",
    "              '(', len(ser_iter_cman.index), 'observations from', len(df_iter_cds.index), ')')\n",
    "        print(iter_prefix, ': CMAN covered :', 'Proportion of dates presence :', \n",
    "              '{:.2%}'.format(len(ser_iter_cman.index.get_level_values(0).unique()) / len(df_iter_cds.index.get_level_values(0).unique())),\n",
    "              '(', len(ser_iter_cman.index.get_level_values(0).unique()), 'dates from', len(df_iter_cds.index.get_level_values(0).unique()), ')')\n",
    "        print(iter_prefix, ': CMAN covered :', 'Proportion of countries presence :', \n",
    "              '{:.2%}'.format(len(ser_iter_cman.index.get_level_values(1).unique()) / len(df_iter_cds.index.get_level_values(1).unique())),\n",
    "              '(', len(ser_iter_cman.index.get_level_values(1).unique()), 'countries from', len(df_iter_cds.index.get_level_values(1).unique()), ')')                 \n",
    "        print(iter_prefix, ': Both CMAN absent and CBIN absent :', \n",
    "              '{:.2%}'.format(len(df_iter_cds.loc[df_iter_cds['CMAN'].isna() & df_iter_cds['CBIN'].isna()].index) / len(df_iter_cds.index)),\n",
    "              '(', len(df_iter_cds.loc[df_iter_cds['CMAN'].isna() & df_iter_cds['CBIN'].isna()].index), 'observations from', len(df_iter_cds.index), ')')\n",
    "        print(iter_prefix, ': CMAN :', 'Empty countries number :', \n",
    "              df_iter_cds['CMAN'].groupby('Country').apply(lambda iter_group: 1 if iter_group.count() == 0 else 0).sum())        \n",
    "        print(iter_prefix, ': CMAN :', 'Empty dates number :', \n",
    "              df_iter_cds['CMAN'].groupby('Date').apply(lambda iter_group: 1 if iter_group.count() == 0 else 0).sum())  \n",
    "        print(iter_prefix, ': CBIN :', 'Empty countries number :', \n",
    "              df_iter_cds['CBIN'].groupby('Country').apply(lambda iter_group: 1 if iter_group.count() == 0 else 0).sum())        \n",
    "        print(iter_prefix, ': CBIN :', 'Empty dates number :', \n",
    "              df_iter_cds['CBIN'].groupby('Date').apply(lambda iter_group: 1 if iter_group.count() == 0 else 0).sum())  \n",
    "        ser_iter_cbin_only = df_iter_cds.loc[df_iter_cds['CMAN'].isna() & df_iter_cds['CBIN'].notna()]['CBIN']        \n",
    "        print(iter_prefix, ': CMAN absent and CBIN covered :', \n",
    "              '{:.2%}'.format(len(ser_iter_cbin_only.index) / len(df_iter_cds.index)),\n",
    "              '(', len(ser_iter_cbin_only.index), 'observations from', len(df_iter_cds.index), ')')   \n",
    "        print(iter_prefix, ': CBIN only covered :', 'Proportion of dates presence :', \n",
    "              '{:.2%}'.format(len(ser_iter_cbin_only.index.get_level_values(0).unique()) / len(df_iter_cds.index.get_level_values(0).unique())),\n",
    "              '(', len(ser_iter_cbin_only.index.get_level_values(0).unique()), 'dates from', len(df_iter_cds.index.get_level_values(0).unique()), ')')\n",
    "        print(iter_prefix, ': CBIN only covered :', 'Proportion of countries presence :', \n",
    "              '{:.2%}'.format(len(ser_iter_cbin_only.index.get_level_values(1).unique()) / len(df_iter_cds.index.get_level_values(1).unique())),\n",
    "              '(', len(ser_iter_cbin_only.index.get_level_values(1).unique()), 'countries from', len(df_iter_cds.index.get_level_values(1).unique()), ')')          \n",
    "        ser_iter_cman_only = df_iter_cds.loc[df_iter_cds['CMAN'].notna() & df_iter_cds['CBIN'].isna()]['CMAN']\n",
    "        print(iter_prefix, ': CMAN covered and CBIN absent :', \n",
    "              '{:.2%}'.format(len(ser_iter_cman_only.index) / len(df_iter_cds.index)),\n",
    "              '(', len(ser_iter_cman_only.index), 'observations from', len(df_iter_cds.index), ')')\n",
    "        print(iter_prefix, ': CMAN only covered :', 'Proportion of dates presence :', \n",
    "              '{:.2%}'.format(len(ser_iter_cman_only.index.get_level_values(0).unique()) / len(df_iter_cds.index.get_level_values(0).unique())),\n",
    "              '(', len(ser_iter_cman_only.index.get_level_values(0).unique()), 'dates from', len(df_iter_cds.index.get_level_values(0).unique()), ')')\n",
    "        print(iter_prefix, ': CMAN only covered :', 'Proportion of countries presence :', \n",
    "              '{:.2%}'.format(len(ser_iter_cman_only.index.get_level_values(1).unique()) / len(df_iter_cds.index.get_level_values(1).unique())),\n",
    "              '(', len(ser_iter_cman_only.index.get_level_values(1).unique()), 'countries from', len(df_iter_cds.index.get_level_values(1).unique()), ')')         \n",
    "        print(iter_prefix, ': Both CMAN covered and CBIN covered :', \n",
    "              '{:.2%}'.format(len(df_iter_cds.loc[df_iter_cds['CMAN'].notna() & df_iter_cds['CBIN'].notna()].index) / len(df_iter_cds.index)),\n",
    "              '(', len(df_iter_cds.loc[df_iter_cds['CMAN'].notna() & df_iter_cds['CBIN'].notna()].index), 'observations from', len(df_iter_cds.index), ')')\n",
    "        df_iter_both = df_iter_cds.loc[df_iter_cds['CMAN'].notna() & df_iter_cds['CBIN'].notna()]\n",
    "        print(iter_prefix, ': Both covered :', 'Proportion of dates presence :', \n",
    "              '{:.2%}'.format(len(df_iter_both.index.get_level_values(0).unique()) / len(df_iter_cds.index.get_level_values(0).unique())),\n",
    "              '(', len(df_iter_both.index.get_level_values(0).unique()), 'dates from', len(df_iter_cds.index.get_level_values(0).unique()), ')')\n",
    "        print(iter_prefix, ': Both covered :', 'Proportion of countries presence :', \n",
    "              '{:.2%}'.format(len(df_iter_both.index.get_level_values(1).unique()) / len(df_iter_cds.index.get_level_values(1).unique())),\n",
    "              '(', len(df_iter_both.index.get_level_values(1).unique()), 'countries from', len(df_iter_cds.index.get_level_values(1).unique()), ')')   \n",
    "        df_iter_both = df_iter_both.assign(Variation = (df_iter_both['CMAN'] - df_iter_both['CBIN']).abs().div(df_iter_both[['CMAN', 'CBIN']].mean(axis = 1)))\n",
    "        print(iter_prefix, ': Both covered :', 'One observation countries number :', \n",
    "              '{:.2%}'.format(df_iter_both['CMAN'].groupby('Country').\\\n",
    "                              apply(lambda iter_group: 1 if iter_group.count() == 1 else 0).sum() / len(df_iter_both.index.get_level_values(1).unique())), \n",
    "              '(', df_iter_both['CMAN'].groupby('Country').apply(lambda iter_group: 1 if iter_group.count() == 1 else 0).sum(), 'countries from', \n",
    "              len(df_iter_both.index.get_level_values(1).unique()), ')')    \n",
    "        print(iter_prefix, ': Both covered :', 'One observation dates number :', \n",
    "              '{:.2%}'.format(df_iter_both['CMAN'].groupby('Date').\\\n",
    "                              apply(lambda iter_group: 1 if iter_group.count() == 1 else 0).sum() / len(df_iter_both.index.get_level_values(0).unique())), \n",
    "              '(', df_iter_both['CMAN'].groupby('Date').apply(lambda iter_group: 1 if iter_group.count() == 1 else 0).sum(), 'dates from', \n",
    "              len(df_iter_both.index.get_level_values(0).unique()), ')')                \n",
    "        print(iter_prefix, ': Both covered :', 'Equal values number :', \n",
    "              '{:.2%}'.format(len(df_iter_both[df_iter_both['Variation'] == 0].index) / len(df_iter_both.index)),\n",
    "              '(', len(df_iter_both[df_iter_both['Variation'] == 0].index), 'observations from', len(df_iter_both.index), ')')\n",
    "        print(iter_prefix, ': Both covered :', '0% < Variation coefficient <= 1%:', \n",
    "              '{:.2%}'.format(len(df_iter_both[(df_iter_both['Variation'] > 0) & (df_iter_both['Variation'] <= 0.01)].index) / len(df_iter_both.index)),\n",
    "              '(', len(df_iter_both[(df_iter_both['Variation'] > 0) & (df_iter_both['Variation'] <= 0.01)].index), 'observations from', len(df_iter_both.index), ')')\n",
    "        print(iter_prefix, ': Both covered :', '1% < Variation coefficient <= 5%:', \n",
    "              '{:.2%}'.format(len(df_iter_both[(df_iter_both['Variation'] > 0.01) & (df_iter_both['Variation'] <= 0.05)].index) / len(df_iter_both.index)),\n",
    "              '(', len(df_iter_both[(df_iter_both['Variation'] > 0.01) & (df_iter_both['Variation'] <= 0.05)].index), 'observations from', len(df_iter_both.index), ')')\n",
    "        print(iter_prefix, ': Both covered :', '5% < Variation coefficient <= 10%:', \n",
    "              '{:.2%}'.format(len(df_iter_both[(df_iter_both['Variation'] > 0.05) & (df_iter_both['Variation'] <= 0.10)].index) / len(df_iter_both.index)),\n",
    "              '(', len(df_iter_both[(df_iter_both['Variation'] > 0.05) & (df_iter_both['Variation'] <= 0.10)].index), 'observations from', len(df_iter_both.index), ')')\n",
    "        print(iter_prefix, ': Both covered :', '10% < Variation coefficient:', \n",
    "              '{:.2%}'.format(len(df_iter_both[df_iter_both['Variation'] > 0.10].index) / len(df_iter_both.index)),\n",
    "              '(', len(df_iter_both[df_iter_both['Variation'] > 0.10].index), 'observations from', len(df_iter_both.index), ')')  \n",
    "        df_iter_both_country_filled = df_iter_both.groupby('Country').apply(lambda iter_group: iter_group.droplevel([1, 2]).resample('B').ffill())\n",
    "        ser_iter_country_corr = df_iter_both_country_filled.groupby('Country').apply(lambda iter_group: iter_group['CBIN'].corr(iter_group['CMAN'], min_periods = 5))     \n",
    "        print(iter_prefix, ': Both covered :', 'Average by country correlation :', \n",
    "              '{:.2%}'.format(ser_iter_country_corr.mean()))\n",
    "        plt_iter_country = ser_iter_country_corr.plot(figsize = (20, 5), title = iter_prefix + ': By country CMAN / CBIN correlation')\n",
    "        plt_iter_country.set_xticks(range(len(ser_iter_country_corr.index)))\n",
    "        plt_iter_country.set_xticklabels(ser_iter_country_corr.index.values)\n",
    "        plt.show()           \n",
    "        ser_iter_date_corr = df_iter_both.groupby('Date').apply(lambda iter_group: iter_group['CBIN'].corr(iter_group['CMAN'], min_periods = 5))        \n",
    "        print(iter_prefix, ': Both covered :', 'Average by date correlation :', \n",
    "              '{:.2%}'.format(ser_iter_date_corr.mean()))\n",
    "        plt_iter_date = ser_iter_date_corr.plot(figsize = (20, 5), title = iter_prefix + ': By date CMAN / CBIN correlation')\n",
    "        plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cds_to_export = df_cds_mcap.reset_index('Market', drop = True)[['CMAN', 'CBIN']].sort_index(level = ['Country', 'Date']).\\\n",
    "                                        unstack('Country').swaplevel(axis = 1).sort_index(axis = 1)\n",
    "df_cds_to_export.to_excel('Data_Files/Test_Files/CDS_Table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
