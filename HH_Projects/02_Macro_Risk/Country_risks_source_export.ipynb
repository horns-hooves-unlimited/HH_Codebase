{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COUNTRY RISKS SOURCE DATA EXPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODULES IMPORT\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from datetime import date, datetime\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL PARAMETERS\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "### Universe path:\n",
    "str_path_universe = 'Data_Files/Source_Files/Country_Risks/acadian_universe.xlsx'\n",
    "### PRS datasources paths:\n",
    "str_path_prs_full = 'Data_Files/Source_Files/Country_Risks/PRS_full.xlsx'\n",
    "str_path_prs_pillars_only = 'Data_Files/Source_Files/Country_Risks/PRS_pillars_only.xlsx'\n",
    "str_path_prs_political_risk_pillar = 'Data_Files/Source_Files/Country_Risks/PRS_political_risk_pillar.xlsx'\n",
    "### PRS results saving:\n",
    "str_path_prs_hdf = 'Data_Files/Source_Files/Country_Risks/PRS_loaded.h5'\n",
    "str_key_prs_full_converted = 'prs_full_converted'\n",
    "str_key_prs_pillars_only_converted = 'prs_pillars_only_converted'\n",
    "str_key_prs_political_risk_pillar_converted = 'prs_political_risk_pillar_converted'\n",
    "### Continuum datasources paths:\n",
    "str_path_continuum_composite = 'Data_Files/Source_Files/Country_Risks/Continuum_Composite_Indicators.xlsx'\n",
    "str_path_continuum_gp_pillar = 'Data_Files/Source_Files/Country_Risks/Continuum_Growth_Potential_pillar.xlsx'\n",
    "str_path_continuum_si_pillar = 'Data_Files/Source_Files/Country_Risks/Continuum_Social_Inclusion_pillar.xlsx'\n",
    "str_path_continuum_politics = 'Data_Files/Source_Files/Country_Risks/Continuum_Politics.xlsx'\n",
    "### Continuum results saving:\n",
    "str_path_continuum_hdf = 'Data_Files/Source_Files/Country_Risks/Continuum_loaded.h5'\n",
    "str_key_continuum_composite_converted = 'continuum_composite_indicators_converted'\n",
    "str_key_continuum_gp_pillar_converted = 'continuum_gp_pillar_converted'\n",
    "str_key_continuum_si_pillar_converted = 'continuum_si_pillar_converted'\n",
    "str_key_continuum_politics_converted = 'continuum_politics_converted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM MS EXCEL SOURCE\n",
    "\n",
    "def ison_membership_converting(str_path_universe, date_end = datetime.today(), bool_daily = False, int_backfill_months = 0):\n",
    "    ### Defining business-month-end reindexation on country level:\n",
    "    def country_modify(ser_raw_country, date_end):\n",
    "        ser_res_country = ser_raw_country.droplevel(0).resample('MS').last().resample('BM').last()\n",
    "        range_country = pd.date_range(ser_res_country.index[0], date_end, freq = 'BM')\n",
    "        return ser_res_country.reindex(range_country).ffill()\n",
    "    ### Markets encoding table:\n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM', 0: np.NaN}     \n",
    "    ### Loading source file:\n",
    "    df_raw_universe = pd.read_excel(io = str_path_universe, sheet_name = 0, header = 0, parse_dates = True, index_col = [0, 1],\n",
    "                                 na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    ### Converting source file:\n",
    "    df_raw_universe.index.names = ['Country', 'Date']\n",
    "    ser_raw_universe = df_raw_universe['Region']\n",
    "    ser_raw_universe.fillna(0, inplace = True)\n",
    "    ser_raw_universe.name = 'Market'\n",
    "    ### By country reindexation and translation:\n",
    "    ser_res_universe = ser_raw_universe.groupby('Country').apply(country_modify, date_end)\n",
    "    ser_res_universe.index.names = ['Country', 'Date']\n",
    "    ser_res_universe = ser_res_universe.replace(dict_markets).reorder_levels([1, 0]).sort_index() \n",
    "    ### Expanding membership for primary regions members by backfilling:\n",
    "    if int_backfill_months:\n",
    "        ### List of regions:\n",
    "        list_region = list(ser_res_universe.dropna().unique())\n",
    "        ### Initialising of collection of series with backfilled data for each region:\n",
    "        list_ison_backfill = []\n",
    "        ### Regions looping:\n",
    "        for iter_region in list_region:\n",
    "            ### Defining start of region date:\n",
    "            date_first_valid = ser_res_universe.loc[ser_res_universe == iter_region].first_valid_index()[0]\n",
    "            ### Creating dates index to backfilling:\n",
    "            idx_date_backfill = pd.date_range(end = date_first_valid, periods = int_backfill_months + 1, freq = 'BM')[: -1]\n",
    "            ### Creating primary countries index to backfilling:            \n",
    "            idx_region_backfill = ser_res_universe.loc[ser_res_universe == iter_region].loc[date_first_valid, All].index.get_level_values('Country')\n",
    "            ### Creating full index:\n",
    "            idx_ison_backfill = pd.MultiIndex.from_product([idx_date_backfill, idx_region_backfill])\n",
    "            ### Series with backfilled data:\n",
    "            list_ison_backfill.append(pd.Series(iter_region, index = idx_ison_backfill))\n",
    "        ### Combination of backfilled series and original ISON data:    \n",
    "        ser_res_universe = ser_res_universe.combine_first(pd.concat(list_ison_backfill, axis = 0)).sort_index()  \n",
    "        ser_res_universe.index.names = ['Date', 'Country']\n",
    "    ### Converting to daily frequency:\n",
    "    if bool_daily:\n",
    "        ser_res_universe = ser_res_universe.reset_index('Country').groupby('Country').resample('B').ffill()['Market'].swaplevel().sort_index()    \n",
    "    ### Results output:\n",
    "    ser_res_universe.name = 'Market'\n",
    "    return ser_res_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING DATE/COUNTRY DATA VECTOR DESCRIBER FUNCTION\n",
    "\n",
    "def date_country_vector_describer(ser_data, ser_ison):\n",
    "    ### ISON countries set:\n",
    "    set_ison_countries = set(ser_ison.index.get_level_values(1).unique())\n",
    "    ### Vector countries set:    \n",
    "    set_vector_countries = set(ser_data.dropna().index.get_level_values(1).unique())    \n",
    "    ### Vector completeness:\n",
    "    print('Data vector name: {}'.format(ser_data.name))\n",
    "    print('Data vector completeness: {:.2%}'.format(ser_data.count() / len(ser_data.index))) \n",
    "    print('ISON countries completeness: {:.2%} ({} / {})'.format(len(set_vector_countries.intersection(set_ison_countries)) / len(set_ison_countries),\n",
    "                                                                 len(set_vector_countries.intersection(set_ison_countries)),\n",
    "                                                                 len(set_ison_countries)))\n",
    "    print('Absent ISON countries: [{}]'.format(str(', '.join(sorted(list(set_ison_countries - set_vector_countries))))))\n",
    "    ### ISON Universe binding (if needed):\n",
    "    if not ('Market' in ser_data.index.names):\n",
    "        ser_data = ser_data.to_frame().join(ser_ison, how = 'left').set_index('Market', append = True).squeeze()\\\n",
    "                                      .loc[All, All, ['DM', 'EM', 'FM']].sort_index(level = ['Date', 'Country'])\n",
    "    ### Dates for heatmap x-axis labeles:\n",
    "    list_idx_dates = ser_data.index.get_level_values('Date').unique()\n",
    "    ### Dates reindexation (adding NaN values for absent observations):\n",
    "    ser_region_data = ser_data.loc[All, All, ['DM', 'EM', 'FM']].droplevel('Market').unstack('Country').reindex(list_idx_dates).stack('Country', dropna = False)      \n",
    "    ### Countries number for heatmap height defining:\n",
    "    int_fig_height = len(ser_region_data.index.get_level_values('Country').unique())    \n",
    "    ### Adding shade column for future heatmap striping:\n",
    "    list_countries = list(ser_region_data.index.get_level_values('Country').unique())\n",
    "    dict_countries = dict(zip(list_countries, map(lambda iter_num: iter_num % 2 + 2, range(len(list_countries)))))\n",
    "    df_region_shades = ser_region_data.to_frame().assign(Shade = list(map(dict_countries.get, ser_region_data.index.get_level_values('Country'))))\n",
    "    df_region_shades.columns = ['Data', 'Shade']\n",
    "    ### Heatmap drawing:\n",
    "    fig_heatmap = plt.figure(figsize = (15, int_fig_height // 5))\n",
    "    df_region_data = (df_region_shades['Data'] / df_region_shades['Data'] * df_region_shades['Shade']).unstack('Date').sort_index()\n",
    "    df_region_data.columns = df_region_data.columns.strftime('%d-%m-%Y')\n",
    "    ax_heatmap = sns.heatmap(df_region_data, cbar = False, annot = False, cmap = 'binary', xticklabels = 'auto', yticklabels = True, \n",
    "                             vmin = 0.0, vmax = 6.0)\n",
    "    ax_heatmap.set_title('ISON Universe')    \n",
    "    ### Visualizer heatmap plotting:        \n",
    "    for str_region_code, ser_region_data in ser_data.groupby('Market'):\n",
    "        ### Dates reindexation (adding NaN values for absent observations):\n",
    "        ser_region_data = ser_region_data.droplevel('Market').unstack('Country').reindex(list_idx_dates).stack('Country', dropna = False)   \n",
    "        ### Countries number for heatmap height defining:        \n",
    "        int_fig_height = len(ser_region_data.index.get_level_values('Country').unique())\n",
    "        if (int_fig_height > 5):\n",
    "            ### Adding shade column for future heatmap striping:\n",
    "            list_countries = list(ser_region_data.index.get_level_values('Country').unique())\n",
    "            dict_countries = dict(zip(list_countries, map(lambda iter_num: iter_num % 2 + 2, range(len(list_countries)))))\n",
    "            df_region_shades = ser_region_data.to_frame().assign(Shade = list(map(dict_countries.get, ser_region_data.index.get_level_values('Country'))))\n",
    "            df_region_shades.columns = ['Data', 'Shade']\n",
    "            ### Heatmap drawing:\n",
    "            fig_heatmap = plt.figure(figsize = (15, int_fig_height // 5))\n",
    "            df_region_data = (df_region_shades['Data'] / df_region_shades['Data'] * df_region_shades['Shade']).unstack('Date').sort_index()\n",
    "            df_region_data.columns = df_region_data.columns.strftime('%d-%m-%Y')\n",
    "            ax_heatmap = sns.heatmap(df_region_data, cbar = False, annot = False, cmap = 'binary', xticklabels = 'auto', yticklabels = True, \n",
    "                                     vmin = 0.0, vmax = 6.0)\n",
    "            ax_heatmap.set_title(str_region_code)\n",
    "        else:\n",
    "            print('Too few countries to show heatmap for', str_region_code, '(', int_fig_height, ')')\n",
    "    ### Plots showing:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION ISO COUNTRY CODES\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    ### Importing standard modules and date-special modules:    \n",
    "    import pandas as pd\n",
    "    ### Choosing local copy or direct link:\n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/Country_Risks/countrycode.html'\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    ### Loading data:\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    ### Dividing ISO codes:\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    ### Codes polishing:\n",
    "    df_result_codes = df_full_codes[['ISO SHORT', 'ISO LONG']]      \n",
    "    df_result_codes.index = df_result_codes.index.str.upper()\n",
    "    \n",
    "    return df_result_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING LOADING PRS DATA FROM MS EXCEL FILE\n",
    "\n",
    "def get_prs(str_path_prs, bool_convert = False, list_countries = All):\n",
    "    ### Countries to rename:\n",
    "    dict_change_country_names = {}\n",
    "    dict_change_country_names['Côte d’Ivoire'] = 'Ivory Coast'\n",
    "    dict_change_country_names['Korea, South'] = 'South Korea'\n",
    "    dict_change_country_names['UAE'] = 'United Arab Emirates'\n",
    "    ### Countries to unite data vectors:\n",
    "    dict_unite_country_data = {}\n",
    "    dict_unite_country_data['Germany, West'] = 'Germany'\n",
    "    dict_unite_country_data['Serbia-Montenegro'] = 'Serbia'    \n",
    "    ### Source loading:\n",
    "    df_prs_source = pd.read_excel(io = str_path_prs, header = 0, parse_dates = True, index_col = [0, 1], engine = 'openpyxl', \n",
    "                                  na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                               '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    ### Dates stacking:\n",
    "    ser_prs_source = df_prs_source.stack(dropna = False).reorder_levels([1, 2, 0])\n",
    "    ### Datasource naming:    \n",
    "    ser_prs_source.index.names = ['Variable', 'Date', 'Country']\n",
    "    ser_prs_source.name = 'PRS'\n",
    "    ### Type converting\n",
    "    ser_prs_source = ser_prs_source.round(2)\n",
    "    ### Non-table rows killing:\n",
    "    ser_prs_source = ser_prs_source.loc[ser_prs_source.index.get_level_values('Country').str.len() < 20]    \n",
    "    ### Sequence letter killing:\n",
    "    ser_prs_source.index.set_levels(ser_prs_source.index.levels[0].str.partition(' (').levels[0], level = 'Variable', inplace = True)\n",
    "    ### Research mode convertion:\n",
    "    if bool_convert:       \n",
    "        ### Countries renaming:\n",
    "        ser_prs_source = ser_prs_source.reset_index('Country').replace(dict_change_country_names).set_index('Country', append = True).squeeze().sort_index()\n",
    "        ### Countries data uniting:\n",
    "        for iter_name in dict_unite_country_data:\n",
    "            ser_prs_source.loc[All, All, dict_unite_country_data[iter_name]] = ser_prs_source.loc[All, All, dict_unite_country_data[iter_name]]\\\n",
    "                                                                               .combine_first(ser_prs_source.loc[All, All, iter_name])\n",
    "            ser_prs_source = ser_prs_source.drop(labels = iter_name, level = 'Country')        \n",
    "        ### Month to dates converting and indexing:\n",
    "        ser_prs_source.index.set_levels(pd.to_datetime(ser_prs_source.index.levels[1]), level = 'Date', inplace = True)\n",
    "        ### Dates resampling to business-month-ends:\n",
    "        ser_prs_source = ser_prs_source.groupby(['Variable', 'Country']).apply(lambda ser_grouped: ser_grouped.droplevel(['Variable', 'Country']).resample('BM').last())\n",
    "        ### Uppercase for countries to further interaction with ISON codes vector:\n",
    "        ser_prs_source.index.set_levels(ser_prs_source.index.levels[1].str.upper(), level = 'Country', inplace = True)\n",
    "        ### ISO country codes loading:\n",
    "        df_iso_country = get_country_codes()  \n",
    "        ### Replacing country names with country ISO codes:\n",
    "        ser_prs_source = ser_prs_source.reset_index('Country').replace(dict(zip(df_iso_country.index, df_iso_country['ISO SHORT']))).set_index('Country', append = True)\\\n",
    "                                       .squeeze()   \n",
    "        ### Forward filling:\n",
    "        ser_prs_source = ser_prs_source.groupby(['Country', 'Variable']).ffill()\n",
    "    ### Results filtering:\n",
    "    ser_prs_res = ser_prs_source.loc[All, All, list_countries].sort_index()\n",
    "    ### Results output:\n",
    "    return ser_prs_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING LOADING CONTINUUM DATA FROM MS EXCEL FILE\n",
    "\n",
    "def get_continuum(str_path_cont, bool_convert = False, list_countries = All):\n",
    "    ### Source loading:\n",
    "    df_cont_source = pd.read_excel(io = str_path_cont, header = 0, parse_dates = True, index_col = list(range(15)), engine = 'openpyxl', \n",
    "                                   na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                                '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    ### Removing blank lines:\n",
    "    df_cont_source = df_cont_source.dropna(how = 'all')\n",
    "    ### Dates stacking:\n",
    "    ser_cont_source = df_cont_source.stack(dropna = False).reorder_levels(list(range(1, 15)) + [15, 0])\n",
    "    ### Datasource naming:    \n",
    "    ser_cont_source.index.names = ser_cont_source.index.names[: -2] + ['Date', 'Country']\n",
    "    ser_cont_source.name = 'Continuum'\n",
    "    ### Non-table rows killing:\n",
    "    ser_cont_source = ser_cont_source.loc[ser_cont_source.index.get_level_values('Country').str.len() == 2]\n",
    "    ### Pillar numbers killing ('Indicator Name'):\n",
    "    ser_cont_source.index.set_levels(ser_cont_source.index.levels[4].str.partition(' (').levels[0], level = 'Indicator Name', inplace = True)\n",
    "    ### Replacing spaces for further hdf format using:\n",
    "    ser_cont_source.index.names = [iter_name.replace(' - ', '_').replace(' ', '_') for iter_name in ser_cont_source.index.names]    \n",
    "    ### Research mode convertion:\n",
    "    if bool_convert:           \n",
    "        ### Drop extra indices:\n",
    "        ser_cont_source.reset_index(['Country_Name', 'Country_RegionId', 'Country_ISO_Country_code', 'Indicator', 'Indicator_ParentName', 'Indicator_Type',\n",
    "                                     'Indicator_Description', 'Indicator_Unit', 'Indicator_Source', 'Indicator_Referenced_Data', 'Indicator_Date_Created', \n",
    "                                     'Scale', 'Units'], drop = True, inplace = True)\n",
    "        ### Key index renaming:\n",
    "        ser_cont_source.index.names = ['Indicator'] + ser_cont_source.index.names[1 : ]\n",
    "        ### Converting quarter names to date:\n",
    "        ser_cont_source.index.set_levels(pd.to_datetime(ser_cont_source.index.levels[1]), level = 'Date', inplace = True)\n",
    "        ### Dates resampling to business-month-ends:\n",
    "        ser_cont_source = ser_cont_source.groupby(['Indicator', 'Country']).apply(lambda ser_ind_country: ser_ind_country.droplevel(['Indicator', 'Country'])\\\n",
    "                                                                           .resample('QS').last().resample('BQ').last()).swaplevel('Country', 'Date')\n",
    "        ### Forward filling:\n",
    "        ser_cont_source = ser_cont_source.groupby(['Country', 'Indicator']).ffill()\n",
    "    ### Results filtering:\n",
    "    ser_cont_res = ser_cont_source.loc[All, All, list_countries].sort_index()        \n",
    "    ### Results output:\n",
    "    return ser_cont_res      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRS & CONTINUUM DATA LOADING\n",
    "\n",
    "ser_ison = ison_membership_converting(str_path_universe)\n",
    "list_ison_countries = sorted(ser_ison.index.levels[1].unique())\n",
    "\n",
    "ser_prs_pillars_only_converted = get_prs(str_path_prs_pillars_only, True, list_ison_countries)\n",
    "ser_prs_political_risk_pillar_converted = get_prs(str_path_prs_political_risk_pillar, True, list_ison_countries)\n",
    "ser_prs_full_converted = get_prs(str_path_prs_full, True, list_ison_countries)\n",
    "ser_continuum_composite_converted = get_continuum(str_path_continuum_composite, True, list_ison_countries)\n",
    "ser_continuum_gp_pillar_converted = get_continuum(str_path_continuum_gp_pillar, True, list_ison_countries)\n",
    "ser_continuum_si_pillar_converted = get_continuum(str_path_continuum_si_pillar, True, list_ison_countries)\n",
    "ser_continuum_politics_converted = get_continuum(str_path_continuum_politics, True, list_ison_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESULTS SAVING\n",
    "\n",
    "### Removing old hdf files before imported data saving:\n",
    "if (os.path.exists(str_path_prs_hdf)):\n",
    "    os.remove(str_path_prs_hdf)\n",
    "if (os.path.exists(str_path_continuum_hdf)):\n",
    "    os.remove(str_path_continuum_hdf)\n",
    "\n",
    "### Data vectors saving to hdf format:\n",
    "ser_prs_pillars_only_converted.to_hdf(str_path_prs_hdf, key = str_key_prs_pillars_only_converted, mode = 'a')\n",
    "ser_prs_political_risk_pillar_converted.to_hdf(str_path_prs_hdf, key = str_key_prs_political_risk_pillar_converted, mode = 'a')\n",
    "ser_prs_full_converted.to_hdf(str_path_prs_hdf, key = str_key_prs_full_converted, mode = 'a')\n",
    "ser_continuum_composite_converted.to_hdf(str_path_continuum_hdf, key = str_key_continuum_composite_converted, mode = 'a')\n",
    "ser_continuum_gp_pillar_converted.to_hdf(str_path_continuum_hdf, key = str_key_continuum_gp_pillar_converted, mode = 'a')\n",
    "ser_continuum_si_pillar_converted.to_hdf(str_path_continuum_hdf, key = str_key_continuum_si_pillar_converted, mode = 'a')\n",
    "ser_continuum_politics_converted.to_hdf(str_path_continuum_hdf, key = str_key_continuum_politics_converted, mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
