{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a7a59b-10ff-463f-89fc-9907166d054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INTERACTION VARIABLE COMPONENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550c7cd8-45ef-4990-8aa3-b01602516bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385efee6-9d95-4e2c-9f3f-5483cadb902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.7.4\n",
      "numpy version:  1.17.2\n",
      "pandas version:  0.25.3\n"
     ]
    }
   ],
   "source": [
    "### RUN EVERY TIME: VERSION CONTROL\n",
    "\n",
    "from platform import python_version\n",
    "print('python version: ', python_version())\n",
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab0fdf6-356c-41a1-bcd2-c1153857d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: MAIN CONSTANTS\n",
    "\n",
    "### MultiIndex level slice constant:\n",
    "All = slice(None)\n",
    "### Universe path:\n",
    "str_path_universe = 'Data_Files/Source_Files/acadian_universe.xlsx'\n",
    "### Dates:\n",
    "str_date_end = '2022-12-31'\n",
    "date_start = pd.Timestamp('1989-12-29')\n",
    "date_end = pd.Timestamp(str_date_end)\n",
    "date_ison = pd.Timestamp('1994-12-31')\n",
    "### NA for MS Excel files:\n",
    "list_na_excel_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null',\n",
    "                        '#N/A Requesting Data...', '#N/A Invalid Security', '#N/A Field Not Applicable', '---']\n",
    "### Checked EBOPS service IDs list (df_serv_to_gics['GICS Group Code']):\n",
    "list_services = ['206', '210', '214', '218', '219', '223', '227', '231', '232', '237', '240', '246', '247', '250', '251', '254', '255', '256', '257', '258', '263',\n",
    "                 '264', '269', '272', '273', '288', '289', '292', '293', '294', '310', '391', '431', '500', '888', '891', '892', '894', '950']\n",
    "### Augmented bilateral export:\n",
    "str_path_export_bilateral = 'Data_Files/Source_Files/comtrade_export_bilateral.h5'\n",
    "### Export key:\n",
    "str_key_unc_export = 'export_augmented'\n",
    "### Export Quality Index:\n",
    "str_path_imf_quality = 'Data_Files/Source_Files/imf_export_quality.h5'\n",
    "### Export key:\n",
    "str_key_imf_eq = 'export_quality'\n",
    "### Augmented bilateral import:\n",
    "str_path_import_bilateral = 'Data_Files/Source_Files/comtrade_import_bilateral.h5'\n",
    "### Import key:\n",
    "str_key_unc_import = 'import_augmented'\n",
    "### Trade Value Index:\n",
    "str_path_imf_trade = 'Data_Files/Source_Files/imf_trade_value.h5'\n",
    "### Export key:\n",
    "str_key_imf_trade = 'trade_value'\n",
    "### HS to SITC Conversion Map:\n",
    "str_path_commodity_map_xlsx = 'Data_Files/Source_Files/hs_to_sitc.xlsx'\n",
    "str_page_map = 'HS to SITC'\n",
    "### Augmented bilateral import:\n",
    "str_path_gdp = 'Data_Files/Source_Files/gdp_dataset.h5'\n",
    "### Interaction variable file:\n",
    "str_path_interact_hdf = 'Data_Files/Source_Files/comtrade_interact_exp.h5'\n",
    "str_path_interact_csv = 'Data_Files/Source_Files/comtrade_interact_exp.csv'\n",
    "str_key_interact_var = 'interact_var'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0d81c2-ed43-499c-a506-c6475599fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING WEIGHTED AVERAGE CALCULATOR\n",
    "\n",
    "def weighted_average(ser_data, ser_weight = None, int_min_count = 0):\n",
    "    ### Default output:\n",
    "    num_result = np.NaN\n",
    "    ### Checking for data presence:\n",
    "    if (ser_data.count() > int_min_count):       \n",
    "        ### Checking for weights dataset:\n",
    "        if ser_weight is None:\n",
    "            ### Calculating of simple average:\n",
    "            num_result = np.nanmean(ser_data.values)\n",
    "        else:\n",
    "            ### Weights filtering:\n",
    "            list_weight = ser_weight[ser_data.dropna().index].values\n",
    "            ### Checking for weights presence:\n",
    "            if np.nansum(list_weight):\n",
    "                ### Data filtering:\n",
    "                list_data = ser_data.dropna().values\n",
    "                ### Weighted average calculating:\n",
    "                num_result = np.nansum(list_data * list_weight) / np.nansum(list_weight)\n",
    "    ### Results output:\n",
    "    return num_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031c1797-c54c-4c44-a2c9-2cb80a951ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM MS EXCEL SOURCE (TO BE IGNORED IN PRODUCT CODE)\n",
    "\n",
    "def ison_membership_converting(str_path_universe, date_end, bool_daily = False, int_backfill_months = 0):\n",
    "    ### Defining business-month-end reindexation on country level:\n",
    "    def country_modify(ser_raw_country, date_end):\n",
    "        ser_res_country = ser_raw_country.droplevel(0).resample('MS').last().resample('BM').last()\n",
    "        range_country = pd.date_range(ser_res_country.index[0], date_end, freq = 'BM')\n",
    "        return ser_res_country.reindex(range_country).ffill()\n",
    "    ### Markets encoding table:\n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM', 0: np.NaN}     \n",
    "    ### Loading source file:\n",
    "    df_raw_universe = pd.read_excel(engine = 'openpyxl', io = str_path_universe, sheet_name = 'Switchers', header = 0, parse_dates = True, index_col = [0, 1],\n",
    "                                 na_values = list_na_excel_values, keep_default_na = False)\n",
    "    ### Converting source file:\n",
    "    df_raw_universe.index.names = ['Country', 'Date']\n",
    "    ser_raw_universe = df_raw_universe['Region']\n",
    "    ser_raw_universe.fillna(0, inplace = True)\n",
    "    ser_raw_universe.name = 'Market'\n",
    "    ### By country reindexation and translation:\n",
    "    ser_res_universe = ser_raw_universe.groupby('Country').apply(country_modify, date_end)\n",
    "    ser_res_universe.index.names = ['Country', 'Date']\n",
    "    ser_res_universe = ser_res_universe.replace(dict_markets).reorder_levels([1, 0]).sort_index() \n",
    "    ### Expanding membership for primary regions members by backfilling:\n",
    "    if int_backfill_months:\n",
    "        ### List of regions:\n",
    "        list_region = list(ser_res_universe.dropna().unique())\n",
    "        ### Initialising of collection of series with backfilled data for each region:\n",
    "        list_ison_backfill = []\n",
    "        ### Regions looping:\n",
    "        for iter_region in list_region:\n",
    "            ### Defining start of region date:\n",
    "            date_first_valid = ser_res_universe.loc[ser_res_universe == iter_region].first_valid_index()[0]\n",
    "            ### Creating dates index to backfilling:\n",
    "            idx_date_backfill = pd.date_range(end = date_first_valid, periods = int_backfill_months + 1, freq = 'BM')[: -1]\n",
    "            ### Creating primary countries index to backfilling:            \n",
    "            idx_region_backfill = ser_res_universe.loc[ser_res_universe == iter_region].loc[date_first_valid, All].index.get_level_values('Country')\n",
    "            ### Creating full index:\n",
    "            idx_ison_backfill = pd.MultiIndex.from_product([idx_date_backfill, idx_region_backfill])\n",
    "            ### Series with backfilled data:\n",
    "            list_ison_backfill.append(pd.Series(iter_region, index = idx_ison_backfill))\n",
    "        ### Combination of backfilled series and original ISON data:    \n",
    "        ser_res_universe = ser_res_universe.combine_first(pd.concat(list_ison_backfill, axis = 0)).sort_index()  \n",
    "        ser_res_universe.index.names = ['Date', 'Country']\n",
    "    ### Converting to daily frequency:\n",
    "    if bool_daily:\n",
    "        ser_res_universe = ser_res_universe.reset_index('Country').groupby('Country').resample('B').ffill()['Market'].swaplevel().sort_index()    \n",
    "    ### Results output:\n",
    "    ser_res_universe.name = 'Market'\n",
    "    return ser_res_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f6cd92-ea4b-4dc4-ae93-1a4d00fbf0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: COMMON DATA EXTRACTION STEPS\n",
    "\n",
    "### ISON membership history:\n",
    "ser_ison_membership = ison_membership_converting(str_path_universe, pd.to_datetime(str_date_end))\n",
    "ser_ison_membership.index.names = ['Date', 'Country']\n",
    "### ISON Members:\n",
    "list_ison_countries = sorted(ser_ison_membership.index.get_level_values('Country').unique())\n",
    "### ISON status for the last available date:\n",
    "ser_ison_status = ser_ison_membership.loc[ser_ison_membership.index[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00c5f0c8-5f11-457d-8308-381667fce474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BILATERAL EXPORT DATA LOADING TO PERFORM FACTOR CALCULATION\n",
    "\n",
    "gc.collect()\n",
    "list_export_chunks = []\n",
    "for num_iter_number, ser_iter_chunk in enumerate(pd.read_hdf(str_path_export_bilateral, key = str_key_unc_export, chunksize = 1000000)):\n",
    "    gc.collect()\n",
    "    print(num_iter_number, ': Extraction started')\n",
    "    ser_iter_chunk = ser_iter_chunk[ser_iter_chunk > 0.0].astype('int32')\n",
    "    df_iter_chunk = ser_iter_chunk.reset_index()\n",
    "    df_iter_chunk = df_iter_chunk[(df_iter_chunk['Reporter'] != df_iter_chunk['Partner']) & \\\n",
    "                                  ((df_iter_chunk['Type'] == 'Goods') | df_iter_chunk['Commodity_ID'].isin(list_services)) & \\\n",
    "                                  (df_iter_chunk['Reporter'] != 'World') & \\\n",
    "                                  (df_iter_chunk['Partner'] != 'World')]\\\n",
    "                               .drop('Type', axis = 1)    \n",
    "    print(num_iter_number, ': Filtering performed')    \n",
    "    ser_iter_chunk = df_iter_chunk.set_index(['Date', 'Reporter', 'Partner', 'Commodity_ID']).squeeze().sort_index()\n",
    "    del df_iter_chunk\n",
    "    gc.collect()\n",
    "    list_export_chunks.append(ser_iter_chunk)\n",
    "    print(num_iter_number, ': Chunk added to container')    \n",
    "ser_bilateral_export = pd.concat(list_export_chunks, axis = 0, sort = False).sort_index()\n",
    "ser_bilateral_export.name = 'Export'\n",
    "del list_export_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8645c-749f-4282-8b43-64f5f5be0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BILATERAL IMPORT DATA LOADING TO PERFORM FACTOR CALCULATION\n",
    "\n",
    "gc.collect()\n",
    "list_import_chunks = []\n",
    "for num_iter_number, ser_iter_chunk in enumerate(pd.read_hdf(str_path_import_bilateral, key = str_key_unc_import, chunksize = 1000000)):\n",
    "    gc.collect()\n",
    "    print(num_iter_number, ': Extraction started')\n",
    "    ser_iter_chunk = ser_iter_chunk[ser_iter_chunk > 0.0].astype('int32')\n",
    "    df_iter_chunk = ser_iter_chunk.reset_index()\n",
    "    df_iter_chunk = df_iter_chunk[(df_iter_chunk['Reporter'] != df_iter_chunk['Partner']) & \\\n",
    "                                  ((df_iter_chunk['Type'] == 'Goods') | df_iter_chunk['Commodity_ID'].isin(list_services)) & (df_iter_chunk['Reporter'] != 'World') & \\\n",
    "                                  (df_iter_chunk['Partner'] != 'World')]\\\n",
    "                               .drop('Type', axis = 1)     \n",
    "    print(num_iter_number, ': Filtering performed')    \n",
    "    ser_iter_chunk = df_iter_chunk.set_index(['Date', 'Reporter', 'Partner', 'Commodity_ID']).squeeze().sort_index()\n",
    "    del df_iter_chunk\n",
    "    gc.collect()\n",
    "    list_import_chunks.append(ser_iter_chunk)\n",
    "    print(num_iter_number, ': Chunk added to container')    \n",
    "ser_bilateral_import = pd.concat(list_import_chunks, axis = 0, sort = False).sort_index()\n",
    "ser_bilateral_import.name = 'Import'\n",
    "del list_import_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98d5cc5b-4d57-4fd8-9267-19b4a0a183fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPORTER / COMMODITY BY DATE TOTAL EXPORT & IMPORT & TRADE\n",
    "\n",
    "gc.collect()\n",
    "### Export totals:\n",
    "ser_country_comm_export = ser_bilateral_export.groupby(['Date', 'Reporter', 'Commodity_ID']).sum().dropna()\n",
    "ser_country_comm_export.name = 'Export'\n",
    "### Import totals:\n",
    "ser_country_comm_import = ser_bilateral_import.groupby(['Date', 'Reporter', 'Commodity_ID']).sum().dropna()\n",
    "ser_country_comm_import.name = 'Import'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b5b53c2-e8dc-471a-a016-b11f695cc651",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EXPORT TRADE DATA LOADING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "ser_trade_data = pd.read_hdf(path_or_buf = str_path_imf_trade, key = str_key_imf_trade).reorder_levels(['Date', 'Country', 'SITC_ID']).sort_index()\n",
    "#ser_trade_data = ser_trade_data.to_frame().join(ser_ison_status).set_index('Market', append = True).squeeze()\n",
    "ser_trade_data = ser_trade_data.drop('ag', axis = 0, level = 'SITC_ID') / 1000\n",
    "ser_trade_data.name = 'Trade_Value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3fd4eea-4ca3-4746-8db3-cbfd102e7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EXPORT QUALITY DATA LOADING\n",
    "\n",
    "gc.collect()\n",
    "ser_quality_data = pd.read_hdf(path_or_buf = str_path_imf_quality, key = str_key_imf_eq).reorder_levels(['Date', 'Country', 'SITC_ID']).sort_index()\n",
    "#ser_quality_data = ser_quality_data.to_frame().join(ser_ison_status).set_index('Market', append = True).squeeze()\n",
    "ser_quality_data = ser_quality_data.drop('ag', axis = 0, level = 'SITC_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d67fdc38-4903-4621-85d2-e9c9d888bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF DATA CONNECTION:\n",
    "\n",
    "df_quality_data = ser_quality_data.to_frame().join(ser_trade_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "515e8068-4f02-4c82-8ccf-71022c528650",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HS TO SITC CONVERSION MAP LOADING\n",
    "\n",
    "df_raw_conversion = pd.read_excel(engine = 'openpyxl', io = str_path_commodity_map_xlsx, sheet_name = str_page_map, header = 0, index_col = None,\n",
    "                                 na_values = list_na_excel_values, keep_default_na = False, dtype = str)\n",
    "df_comm_conversion = df_raw_conversion.set_index('Commodity ID')[['SITC Correspondent 1', 'SITC Correspondent 2', 'SITC Correspondent 3']]\n",
    "ser_comm_conversion = df_comm_conversion.stack().droplevel(-1)\n",
    "ser_comm_conversion.index.names = ['Commodity_ID']\n",
    "ser_comm_conversion.name = 'SITC_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aaaaffd-d619-440f-b9a8-9ee2850a4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONVERTING FROM SITC CLASSIFICATION TO HS CLASSIFICATION AND ADDING COMTRADE EXPORT FLOWS\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "def conditional_average(df_group):\n",
    "    if (len(df_group) > 1):\n",
    "        flo_result = weighted_average(df_group['Quality'], df_group['Trade_Value'])\n",
    "    else:\n",
    "        flo_result = df_group['Quality'].values[0]\n",
    "    return flo_result\n",
    "\n",
    "### Adding mapping table:\n",
    "df_quality_comtrade = df_quality_data.join(ser_comm_conversion.to_frame().set_index('SITC_ID', append = True)).reset_index('Commodity_ID')\\\n",
    "                                     .dropna(subset = ['Commodity_ID']).set_index(['Commodity_ID'], append = True)\\\n",
    "                                     .reorder_levels(['Date', 'Country', 'Commodity_ID', 'SITC_ID']).sort_index()\n",
    "### Performoing weighted average for \"n -> 1\" conversions:\n",
    "df_quality_comtrade = df_quality_comtrade.groupby(['Date', 'Country', 'Commodity_ID']).apply(conditional_average).to_frame()\n",
    "df_quality_comtrade.index.set_names('Reporter', level = 'Country', inplace = True)\n",
    "df_quality_comtrade.columns = ['Quality']\n",
    "### Adding ComTrade Export flows:\n",
    "df_quality_comtrade = df_quality_comtrade.join(ser_country_comm_export, how = 'right').dropna(subset = ['Export'])\n",
    "### Adding regional connections:\n",
    "ser_ison_status.index.name = 'Reporter'\n",
    "df_quality_comtrade = df_quality_comtrade.join(ser_ison_status).dropna(subset = ['Market']).set_index('Market', append = True)\n",
    "ser_ison_status.index.name = 'Country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0724878-f7ec-41d0-9d6a-a092e9f22877",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INTERACTION VARIABLE PREPARATION\n",
    "\n",
    "gc.collect()\n",
    "### GDP annualization:\n",
    "ser_gdp = pd.read_hdf(str_path_gdp)\n",
    "ser_gdp_ann = (ser_gdp.unstack('Country').resample('BM').bfill() / 12).rolling(12).sum().loc[date_start: date_end].stack('Country')\n",
    "ser_gdp_ann.index.names = ['Date', 'Reporter']\n",
    "### Total export annualization:\n",
    "ser_country_comm_export_add = ser_country_comm_export.groupby(['Reporter', 'Commodity_ID'], group_keys = False)\\\n",
    "                                    .apply(lambda ser_group: ser_group.append(pd.Series(ser_group[0], \n",
    "                                    index = [(ser_group.index[0][0] - pd.offsets.BYearEnd(), ser_group.index[0][1], ser_group.index[0][2])])))\\\n",
    "                                    .sort_index()\n",
    "ser_country_comm_exp_ann = ser_country_comm_export_add.groupby(['Date', 'Reporter']).sum()\n",
    "ser_country_comm_exp_ann = (ser_country_comm_exp_ann.unstack('Reporter').resample('BM').bfill() / 12).rolling(12).sum().loc[date_start: date_end].stack('Reporter')\n",
    "ser_country_comm_exp_ann.index.names = ['Date', 'Reporter']\n",
    "gc.collect()\n",
    "### Total qualified export annualization:\n",
    "list_qualified_comm = sorted(df_quality_comtrade.dropna().index.get_level_values('Commodity_ID').unique())\n",
    "ser_country_comm_export_qual = ser_country_comm_export_add.loc[:, :, list_qualified_comm]\n",
    "ser_country_comm_exp_ann_qual = ser_country_comm_export_qual.groupby(['Date', 'Reporter']).sum()\n",
    "ser_country_comm_exp_ann_qual = (ser_country_comm_exp_ann_qual.unstack('Reporter').resample('BM').bfill() / 12).rolling(12).sum()\\\n",
    "                                                              .loc[date_start: date_end].stack('Reporter')\n",
    "ser_country_comm_exp_ann_qual.index.names = ['Date', 'Reporter']\n",
    "gc.collect()\n",
    "### Total import annualization:\n",
    "ser_country_comm_import_add = ser_country_comm_import.groupby(['Reporter', 'Commodity_ID'], group_keys = False)\\\n",
    "                                    .apply(lambda ser_group: ser_group.append(pd.Series(ser_group[0], \n",
    "                                    index = [(ser_group.index[0][0] - pd.offsets.BYearEnd(), ser_group.index[0][1], ser_group.index[0][2])])))\\\n",
    "                                    .sort_index()\n",
    "ser_country_comm_imp_ann = ser_country_comm_import_add.groupby(['Date', 'Reporter']).sum()\n",
    "ser_country_comm_imp_ann = (ser_country_comm_imp_ann.unstack('Reporter').resample('BM').bfill() / 12).rolling(12).sum().loc[date_start: date_end].stack('Reporter')\n",
    "ser_country_comm_imp_ann.index.names = ['Date', 'Reporter']\n",
    "gc.collect()\n",
    "### Saving results:\n",
    "df_interaction = pd.concat([ser_gdp_ann, ser_country_comm_exp_ann, ser_country_comm_exp_ann_qual, ser_country_comm_imp_ann], axis = 1)\n",
    "df_interaction.columns = ['GDP_annualized', 'Export_annualized', 'Qualified_Export_annualized', 'Import_annualized']\n",
    "df_interaction = df_interaction.loc[(All, ser_ison_status.index), :]\n",
    "df_interaction.to_hdf(str_path_interact_hdf, str_key_interact_var)\n",
    "df_interaction.to_csv(str_path_interact_csv, sep = ';', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90ec03d4-87a1-4022-bac6-e339b2c7710d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Reporter</th>\n",
       "      <th>GDP_annualized</th>\n",
       "      <th>Export_annualized</th>\n",
       "      <th>Qualified_Export_annualized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989-12-29</td>\n",
       "      <td>AE</td>\n",
       "      <td>4.146500e+10</td>\n",
       "      <td>8.875251e+06</td>\n",
       "      <td>8.852485e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1989-12-29</td>\n",
       "      <td>AR</td>\n",
       "      <td>7.663690e+10</td>\n",
       "      <td>2.664753e+06</td>\n",
       "      <td>2.653852e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1989-12-29</td>\n",
       "      <td>AT</td>\n",
       "      <td>1.331058e+11</td>\n",
       "      <td>4.901008e+06</td>\n",
       "      <td>4.887679e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1989-12-29</td>\n",
       "      <td>AU</td>\n",
       "      <td>2.998779e+11</td>\n",
       "      <td>2.922174e+07</td>\n",
       "      <td>2.908642e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1989-12-29</td>\n",
       "      <td>BD</td>\n",
       "      <td>2.878171e+10</td>\n",
       "      <td>1.126162e+06</td>\n",
       "      <td>1.124362e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83673</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>UG</td>\n",
       "      <td>4.052979e+10</td>\n",
       "      <td>2.494386e+06</td>\n",
       "      <td>2.487020e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83674</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>US</td>\n",
       "      <td>2.331508e+13</td>\n",
       "      <td>2.141827e+09</td>\n",
       "      <td>1.701382e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83681</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>VN</td>\n",
       "      <td>3.661376e+11</td>\n",
       "      <td>3.331721e+08</td>\n",
       "      <td>3.326549e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83686</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>ZA</td>\n",
       "      <td>4.190150e+11</td>\n",
       "      <td>1.139845e+08</td>\n",
       "      <td>1.121712e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83687</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>ZM</td>\n",
       "      <td>2.214763e+10</td>\n",
       "      <td>1.094966e+07</td>\n",
       "      <td>1.094511e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30815 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Reporter  GDP_annualized  Export_annualized  \\\n",
       "1      1989-12-29       AE    4.146500e+10       8.875251e+06   \n",
       "8      1989-12-29       AR    7.663690e+10       2.664753e+06   \n",
       "9      1989-12-29       AT    1.331058e+11       4.901008e+06   \n",
       "10     1989-12-29       AU    2.998779e+11       2.922174e+07   \n",
       "13     1989-12-29       BD    2.878171e+10       1.126162e+06   \n",
       "...           ...      ...             ...                ...   \n",
       "83673  2021-12-31       UG    4.052979e+10       2.494386e+06   \n",
       "83674  2021-12-31       US    2.331508e+13       2.141827e+09   \n",
       "83681  2021-12-31       VN    3.661376e+11       3.331721e+08   \n",
       "83686  2021-12-31       ZA    4.190150e+11       1.139845e+08   \n",
       "83687  2021-12-31       ZM    2.214763e+10       1.094966e+07   \n",
       "\n",
       "       Qualified_Export_annualized  \n",
       "1                     8.852485e+06  \n",
       "8                     2.653852e+06  \n",
       "9                     4.887679e+06  \n",
       "10                    2.908642e+07  \n",
       "13                    1.124362e+06  \n",
       "...                            ...  \n",
       "83673                 2.487020e+06  \n",
       "83674                 1.701382e+09  \n",
       "83681                 3.326549e+08  \n",
       "83686                 1.121712e+08  \n",
       "83687                 1.094511e+07  \n",
       "\n",
       "[30815 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "pd.read_csv(str_path_interact_var, sep = ';').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb819ecb-da5a-46f8-b416-318f44bc1286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
