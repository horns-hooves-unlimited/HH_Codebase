{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: COMTRADE DATASETS EXTRACTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import json ### To correct JSON structure before unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.7.4\n",
      "numpy version:  1.17.2\n",
      "pandas version:  0.25.3\n"
     ]
    }
   ],
   "source": [
    "### RUN EVERY TIME: VERSION CONTROL\n",
    "\n",
    "from platform import python_version\n",
    "print('python version: ', python_version())\n",
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: MAIN CONSTANTS\n",
    "\n",
    "### MultiIndex level slice constant:\n",
    "All = slice(None)\n",
    "### Universe path:\n",
    "str_path_universe = 'Data_Files/Source_Files/acadian_universe.xlsx'\n",
    "### Dates:\n",
    "str_date_end = '2022-12-31'\n",
    "date_start = pd.Timestamp('1989-12-29')\n",
    "date_end = pd.Timestamp(str_date_end)\n",
    "date_ison = pd.Timestamp('1994-12-31')\n",
    "### NA for MS Excel files:\n",
    "list_na_excel_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null',\n",
    "                        '#N/A Requesting Data...', '#N/A Invalid Security', '#N/A Field Not Applicable', '---']\n",
    "### Checked EBOPS service IDs list (df_serv_to_gics['GICS Group Code']):\n",
    "list_services = ['206', '210', '214', '218', '219', '223', '227', '231', '232', '237', '240', '246', '247', '250', '251', '254', '255', '256', '257', '258', '263',\n",
    "                 '264', '269', '272', '273', '288', '289', '292', '293', '294', '310', '391', '431', '500', '888', '891', '892', '894', '950']\n",
    "### Augmented bilateral export:\n",
    "str_path_export_bilateral = 'Data_Files/Source_Files/comtrade_export_bilateral.h5'\n",
    "### Export key:\n",
    "str_key_unc_export = 'export_augmented'\n",
    "### Export Quality Index:\n",
    "str_path_imf_quality = 'Data_Files/Source_Files/imf_export_quality.h5'\n",
    "### Export key:\n",
    "str_key_imf_eq = 'export_quality'\n",
    "### Trade Value Index:\n",
    "str_path_imf_trade = 'Data_Files/Source_Files/imf_trade_value.h5'\n",
    "### Export key:\n",
    "str_key_imf_trade = 'trade_value'\n",
    "### HS to SITC Conversion Map:\n",
    "str_path_commodity_map_xlsx = 'Data_Files/Source_Files/hs_to_sitc.xlsx'\n",
    "str_page_map = 'HS to SITC'\n",
    "### Factor file:\n",
    "str_path_quality_exp = 'Data_Files/Source_Files/comtrade_quality_exp.h5'\n",
    "str_key_comtrade_factor = 'comtrade_factor'\n",
    "str_path_factor_xlsx = 'Data_Files/Source_Files/comtrade_factor.xlsx'\n",
    "str_path_factor_csv = 'Data_Files/Source_Files/comtrade_factor.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING WEIGHTED AVERAGE CALCULATOR\n",
    "\n",
    "def weighted_average(ser_data, ser_weight = None, int_min_count = 0):\n",
    "    ### Default output:\n",
    "    num_result = np.NaN\n",
    "    ### Checking for data presence:\n",
    "    if (ser_data.count() > int_min_count):       \n",
    "        ### Checking for weights dataset:\n",
    "        if ser_weight is None:\n",
    "            ### Calculating of simple average:\n",
    "            num_result = np.nanmean(ser_data.values)\n",
    "        else:\n",
    "            ### Weights filtering:\n",
    "            list_weight = ser_weight[ser_data.dropna().index].values\n",
    "            ### Checking for weights presence:\n",
    "            if np.nansum(list_weight):\n",
    "                ### Data filtering:\n",
    "                list_data = ser_data.dropna().values\n",
    "                ### Weighted average calculating:\n",
    "                num_result = np.nansum(list_data * list_weight) / np.nansum(list_weight)\n",
    "    ### Results output:\n",
    "    return num_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM MS EXCEL SOURCE (TO BE IGNORED IN PRODUCT CODE)\n",
    "\n",
    "def ison_membership_converting(str_path_universe, date_end, bool_daily = False, int_backfill_months = 0):\n",
    "    ### Defining business-month-end reindexation on country level:\n",
    "    def country_modify(ser_raw_country, date_end):\n",
    "        ser_res_country = ser_raw_country.droplevel(0).resample('MS').last().resample('BM').last()\n",
    "        range_country = pd.date_range(ser_res_country.index[0], date_end, freq = 'BM')\n",
    "        return ser_res_country.reindex(range_country).ffill()\n",
    "    ### Markets encoding table:\n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM', 0: np.NaN}     \n",
    "    ### Loading source file:\n",
    "    df_raw_universe = pd.read_excel(engine = 'openpyxl', io = str_path_universe, sheet_name = 'Switchers', header = 0, parse_dates = True, index_col = [0, 1],\n",
    "                                 na_values = list_na_excel_values, keep_default_na = False)\n",
    "    ### Converting source file:\n",
    "    df_raw_universe.index.names = ['Country', 'Date']\n",
    "    ser_raw_universe = df_raw_universe['Region']\n",
    "    ser_raw_universe.fillna(0, inplace = True)\n",
    "    ser_raw_universe.name = 'Market'\n",
    "    ### By country reindexation and translation:\n",
    "    ser_res_universe = ser_raw_universe.groupby('Country').apply(country_modify, date_end)\n",
    "    ser_res_universe.index.names = ['Country', 'Date']\n",
    "    ser_res_universe = ser_res_universe.replace(dict_markets).reorder_levels([1, 0]).sort_index() \n",
    "    ### Expanding membership for primary regions members by backfilling:\n",
    "    if int_backfill_months:\n",
    "        ### List of regions:\n",
    "        list_region = list(ser_res_universe.dropna().unique())\n",
    "        ### Initialising of collection of series with backfilled data for each region:\n",
    "        list_ison_backfill = []\n",
    "        ### Regions looping:\n",
    "        for iter_region in list_region:\n",
    "            ### Defining start of region date:\n",
    "            date_first_valid = ser_res_universe.loc[ser_res_universe == iter_region].first_valid_index()[0]\n",
    "            ### Creating dates index to backfilling:\n",
    "            idx_date_backfill = pd.date_range(end = date_first_valid, periods = int_backfill_months + 1, freq = 'BM')[: -1]\n",
    "            ### Creating primary countries index to backfilling:            \n",
    "            idx_region_backfill = ser_res_universe.loc[ser_res_universe == iter_region].loc[date_first_valid, All].index.get_level_values('Country')\n",
    "            ### Creating full index:\n",
    "            idx_ison_backfill = pd.MultiIndex.from_product([idx_date_backfill, idx_region_backfill])\n",
    "            ### Series with backfilled data:\n",
    "            list_ison_backfill.append(pd.Series(iter_region, index = idx_ison_backfill))\n",
    "        ### Combination of backfilled series and original ISON data:    \n",
    "        ser_res_universe = ser_res_universe.combine_first(pd.concat(list_ison_backfill, axis = 0)).sort_index()  \n",
    "        ser_res_universe.index.names = ['Date', 'Country']\n",
    "    ### Converting to daily frequency:\n",
    "    if bool_daily:\n",
    "        ser_res_universe = ser_res_universe.reset_index('Country').groupby('Country').resample('B').ffill()['Market'].swaplevel().sort_index()    \n",
    "    ### Results output:\n",
    "    ser_res_universe.name = 'Market'\n",
    "    return ser_res_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: COMMON DATA EXTRACTION STEPS\n",
    "\n",
    "### ISON membership history:\n",
    "ser_ison_membership = ison_membership_converting(str_path_universe, pd.to_datetime(str_date_end))\n",
    "ser_ison_membership.index.names = ['Date', 'Country']\n",
    "### ISON Members:\n",
    "list_ison_countries = sorted(ser_ison_membership.index.get_level_values('Country').unique())\n",
    "### ISON status for the last available date:\n",
    "ser_ison_status = ser_ison_membership.loc[ser_ison_membership.index[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EQ: GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "dict_request_headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "str_imf_base_url = 'http://dataservices.imf.org/REST/SDMX_JSON.svc/'\n",
    "str_imf_dataflow_add = 'DataFlow'\n",
    "str_imf_datastructure_add = 'DataStructure/'\n",
    "str_imf_codelist_add = 'CodeList/'\n",
    "str_imf_dataset_add = 'CompactData/'\n",
    "int_seconds_to_sleep = 3\n",
    "int_imf_country_limit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF IFS: REQUESTS SESSION INITIALIZING\n",
    "\n",
    "request_session = requests.Session()\n",
    "### For avoiding data request errors from IMF Data Service:\n",
    "request_session.headers.update(dict_request_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQ\n"
     ]
    }
   ],
   "source": [
    "### IMF EQ: DATAFLOW SEARCHING\n",
    "\n",
    "obj_imf_dataflow_list = request_session.get(str_imf_base_url + str_imf_dataflow_add).json()\n",
    "df_imf_dataflow = pd.DataFrame(obj_imf_dataflow_list['Structure']['Dataflows']['Dataflow'])\n",
    "df_imf_dataflow = df_imf_dataflow.assign(Description = df_imf_dataflow['Name'].apply(pd.Series)['#text'].values)[['@id', 'Description']]\n",
    "ser_imf_dataflow = df_imf_dataflow.set_index('@id', drop = True).squeeze()\n",
    "### Searching DataFlow code for further requests:\n",
    "str_imf_eq_id = ser_imf_dataflow[ser_imf_dataflow.str.contains('Export Quality')].index[0].replace('DS-', '')\n",
    "print(str_imf_eq_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  @conceptRef        @codelist @isFrequencyDimension\n",
      "0        FREQ          CL_FREQ                  true\n",
      "1    REF_AREA       CL_AREA_EQ                   NaN\n",
      "2     PRODUCT    CL_PRODUCT_EQ                   NaN\n",
      "3   INDICATOR  CL_INDICATOR_EQ                   NaN\n"
     ]
    }
   ],
   "source": [
    "### IMF EQ: DATASTRUCTURE SEARCHING\n",
    "\n",
    "obj_imf_eq_structure = request_session.get(str_imf_base_url + str_imf_datastructure_add + str_imf_eq_id).json()\n",
    "df_imf_eq_params = pd.DataFrame(obj_imf_eq_structure['Structure']['KeyFamilies']['KeyFamily']['Components']['Dimension'])\\\n",
    "                                [['@conceptRef', '@codelist', '@isFrequencyDimension']]\n",
    "### Receiving DataFlow parameters and code lists for each of them:\n",
    "print(df_imf_eq_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EQ: CODES DESCRIPTIONS LOADING\n",
    "\n",
    "for int_counter, str_param_code in enumerate(df_imf_eq_params['@codelist']):\n",
    "    if (int_counter == 2):\n",
    "        time.sleep(int_seconds_to_sleep)    \n",
    "        obj_imf_eq_param = request_session.get(str_imf_base_url + str_imf_codelist_add + str_param_code).json()\n",
    "        df_imf_eq_param =  pd.DataFrame(obj_imf_eq_param['Structure']['CodeLists']['CodeList']['Code'])\n",
    "        ### Receiving values for each code list:\n",
    "        df_imf_eq_param = df_imf_eq_param.assign(Text = df_imf_eq_param['Description'].apply(pd.Series)['#text'].values)[['@value', 'Text']]\n",
    "        df_imf_eq_param = df_imf_eq_param.loc[df_imf_eq_param['@value'].str.len() == 2]\n",
    "#        dict_indicator = dict(zip(df_imf_eq_param['@value'], df_imf_eq_param['Text']))\n",
    "        list_sitc_codes = sorted(df_imf_eq_param['@value'].values)\n",
    "        \n",
    "list_ison_countries = sorted(ser_ison_status.index.to_list())\n",
    "str_quality_index = 'qual'\n",
    "str_eq_freq = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EQ: QUALITY INDEX DATA RETRIEVING\n",
    "\n",
    "gc.collect()\n",
    "### List of dictionaries for future concatenation:\n",
    "list_eq_portions = [] \n",
    "### Beggining of request URL:\n",
    "str_eq_const_url = str_imf_base_url + str_imf_dataset_add + str_imf_eq_id + '/' \n",
    "str_eq_const_url\n",
    "### Looping over reporter:\n",
    "for iter_interval in range(-(-len(list_ison_countries) // int_imf_country_limit) ):\n",
    "#for iter_country in ['AU']:\n",
    "    print(str(iter_interval * int_imf_country_limit), ':', str((iter_interval + 1) * int_imf_country_limit))\n",
    "    list_iter_countries = list_ison_countries[(iter_interval * int_imf_country_limit) : ((iter_interval + 1) * int_imf_country_limit)]\n",
    "    str_eq_full_url = str_eq_const_url + '.'.join([str_eq_freq, '+'.join(list_iter_countries), '+'.join(list_sitc_codes), str_quality_index]) \\\n",
    "                                       + '?start_period=' + str(date_start.year) + '&end_period=' + str(date_end.year)\n",
    "    obj_eq_set = request_session.get(str_eq_full_url)\n",
    "    ### Data reading as JSON and adding to collection:\n",
    "    list_eq_portions.append(json.loads(obj_eq_set.text.replace('@OBS_STATUS', '@OBS_VALUE')))\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EQ: QUALITY INDEX DATA PREPARATION AND SAVING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "list_quality_data = []\n",
    "for dict_iter_response in list_eq_portions:\n",
    "    for dict_iter_portion in dict_iter_response['CompactData']['DataSet']['Series']:\n",
    "        if (len(dict_iter_portion['Obs']) > 0):\n",
    "            str_iter_country = dict_iter_portion['@REF_AREA']\n",
    "            str_iter_sitc_code = dict_iter_portion['@PRODUCT']\n",
    "            if isinstance(dict_iter_portion['Obs'], list):\n",
    "                df_iter_raw = pd.DataFrame(dict_iter_portion['Obs'])\n",
    "            else:\n",
    "                df_iter_raw = pd.DataFrame([dict_iter_portion['Obs']])\n",
    "            df_iter_raw.columns = ['Year', 'Quality']\n",
    "            df_iter_raw['Date'] = df_iter_raw['Year'].apply(pd.to_datetime) + pd.offsets.BYearEnd()\n",
    "            df_iter_raw = df_iter_raw.set_index('Date')[['Quality']].astype('float32')\n",
    "            df_iter_raw = pd.concat({str_iter_country: df_iter_raw}, names = ['Country'])\n",
    "            df_iter_raw = pd.concat({str_iter_sitc_code: df_iter_raw}, names = ['SITC_ID'])\n",
    "            list_quality_data.append(df_iter_raw)\n",
    "#        break\n",
    "#    break\n",
    "ser_quality_data = pd.concat(list_quality_data, axis = 0).squeeze().sort_index()\n",
    "ser_quality_data.to_hdf(path_or_buf = str_path_imf_quality, key = str_key_imf_eq, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EQ: CODES DESCRIPTIONS LOADING\n",
    "\n",
    "for int_counter, str_param_code in enumerate(df_imf_eq_params['@codelist']):\n",
    "    if (int_counter == 2):\n",
    "        time.sleep(int_seconds_to_sleep)    \n",
    "        obj_imf_eq_param = request_session.get(str_imf_base_url + str_imf_codelist_add + str_param_code).json()\n",
    "        df_imf_eq_param =  pd.DataFrame(obj_imf_eq_param['Structure']['CodeLists']['CodeList']['Code'])\n",
    "        ### Receiving values for each code list:\n",
    "        df_imf_eq_param = df_imf_eq_param.assign(Text = df_imf_eq_param['Description'].apply(pd.Series)['#text'].values)[['@value', 'Text']]\n",
    "        df_imf_eq_param = df_imf_eq_param.loc[df_imf_eq_param['@value'].str.len() == 2]\n",
    "        list_sitc_codes = sorted(df_imf_eq_param['@value'].values)\n",
    "        \n",
    "list_ison_countries = sorted(ser_ison_status.index.to_list())\n",
    "str_value_index = 'value'\n",
    "str_eq_freq = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EQ: TRADE VALUE DATA RETRIEVING\n",
    "\n",
    "gc.collect()\n",
    "### List of dictionaries for future concatenation:\n",
    "list_eq_portions = [] \n",
    "### Beggining of request URL:\n",
    "str_eq_const_url = str_imf_base_url + str_imf_dataset_add + str_imf_eq_id + '/' \n",
    "str_eq_const_url\n",
    "### Looping over reporter:\n",
    "for iter_interval in range(-(-len(list_ison_countries) // int_imf_country_limit) ):\n",
    "#for iter_country in ['AU']:\n",
    "    print(str(iter_interval * int_imf_country_limit), ':', str((iter_interval + 1) * int_imf_country_limit))\n",
    "    list_iter_countries = list_ison_countries[(iter_interval * int_imf_country_limit) : ((iter_interval + 1) * int_imf_country_limit)]\n",
    "    str_eq_full_url = str_eq_const_url + '.'.join([str_eq_freq, '+'.join(list_iter_countries), '+'.join(list_sitc_codes), str_value_index]) \\\n",
    "                                       + '?start_period=' + str(date_start.year) + '&end_period=' + str(date_end.year)\n",
    "    obj_eq_set = request_session.get(str_eq_full_url)\n",
    "    ### Data reading as JSON and adding to collection:\n",
    "    list_eq_portions.append(json.loads(obj_eq_set.text.replace('@OBS_STATUS', '@OBS_VALUE')))\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EQ: QUALITY INDEX DATA PREPARATION AND SAVING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "list_trade_data = []\n",
    "for dict_iter_response in list_eq_portions:\n",
    "    for dict_iter_portion in dict_iter_response['CompactData']['DataSet']['Series']:\n",
    "        if (len(dict_iter_portion['Obs']) > 0):\n",
    "            str_iter_country = dict_iter_portion['@REF_AREA']\n",
    "            str_iter_sitc_code = dict_iter_portion['@PRODUCT']\n",
    "            if isinstance(dict_iter_portion['Obs'], list):\n",
    "                df_iter_raw = pd.DataFrame(dict_iter_portion['Obs'])\n",
    "            else:\n",
    "                df_iter_raw = pd.DataFrame([dict_iter_portion['Obs']])\n",
    "            df_iter_raw.columns = ['Year', 'Quality']\n",
    "            df_iter_raw['Date'] = df_iter_raw['Year'].apply(pd.to_datetime) + pd.offsets.BYearEnd()\n",
    "            df_iter_raw = df_iter_raw.set_index('Date')[['Quality']].astype('float32')\n",
    "            df_iter_raw = pd.concat({str_iter_country: df_iter_raw}, names = ['Country'])\n",
    "            df_iter_raw = pd.concat({str_iter_sitc_code: df_iter_raw}, names = ['SITC_ID'])\n",
    "            list_trade_data.append(df_iter_raw)\n",
    "#        break\n",
    "#    break\n",
    "ser_trade_data = pd.concat(list_trade_data, axis = 0).squeeze().sort_index()\n",
    "ser_trade_data.name = 'Trade_Value'\n",
    "ser_trade_data.to_hdf(path_or_buf = str_path_imf_trade, key = str_key_imf_trade, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BILATERAL EXPORT DATA LOADING TO PERFORM FACTOR CALCULATION\n",
    "\n",
    "gc.collect()\n",
    "list_export_chunks = []\n",
    "for num_iter_number, ser_iter_chunk in enumerate(pd.read_hdf(str_path_export_bilateral, key = str_key_unc_export, chunksize = 1000000)):\n",
    "    gc.collect()\n",
    "    print(num_iter_number, ': Extraction started')\n",
    "    ser_iter_chunk = ser_iter_chunk[ser_iter_chunk > 0.0].astype('int32')\n",
    "    df_iter_chunk = ser_iter_chunk.reset_index()\n",
    "    df_iter_chunk = df_iter_chunk[(df_iter_chunk['Reporter'] != df_iter_chunk['Partner']) & \\\n",
    "                                  ((df_iter_chunk['Type'] == 'Goods') | df_iter_chunk['Commodity_ID'].isin(list_services)) & (df_iter_chunk['Reporter'] != 'World') & \\\n",
    "                                  (df_iter_chunk['Partner'] != 'World')]\\\n",
    "                               .drop('Type', axis = 1)    \n",
    "    print(num_iter_number, ': Filtering performed')    \n",
    "    ser_iter_chunk = df_iter_chunk.set_index(['Date', 'Reporter', 'Partner', 'Commodity_ID']).squeeze().sort_index()\n",
    "    del df_iter_chunk\n",
    "    gc.collect()\n",
    "    list_export_chunks.append(ser_iter_chunk)\n",
    "    print(num_iter_number, ': Chunk added to container')    \n",
    "ser_bilateral_export = pd.concat(list_export_chunks, axis = 0, sort = False).sort_index()\n",
    "ser_bilateral_export.name = 'Export'\n",
    "del list_export_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### REPORTER / COMMODITY BY DATE TOTAL EXPORT\n",
    "\n",
    "### Export totals:\n",
    "ser_country_comm_export = ser_bilateral_export.groupby(['Date', 'Reporter', 'Commodity_ID']).sum().dropna()\n",
    "ser_country_comm_export.name = 'Export'\n",
    "\n",
    "del ser_bilateral_export\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EXPORT QUALITY DATA LOADING\n",
    "\n",
    "gc.collect()\n",
    "ser_quality_data = pd.read_hdf(path_or_buf = str_path_imf_quality, key = str_key_imf_eq).reorder_levels(['Date', 'Country', 'SITC_ID']).sort_index()\n",
    "ser_quality_data = ser_quality_data.to_frame().join(ser_ison_status).set_index('Market', append = True).squeeze()\n",
    "ser_quality_data = ser_quality_data.drop('ag', axis = 0, level = 'SITC_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Market\n",
       "DM    176.0\n",
       "EM    100.0\n",
       "FM     78.0\n",
       "Name: Quality, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "str_test_date = '2014-12-31'\n",
    "str_test_country = 'US'\n",
    "str_test_id = '34'\n",
    "\n",
    "#ser_test_data = ser_quality_data.loc[str_test_date, str_test_country].droplevel('Market')\n",
    "#ser_test_data = ser_quality_data.loc[str_test_date, :, str_test_id].droplevel(['Date', 'SITC_ID'])\n",
    "ser_test_data = ser_quality_data.loc[[str_test_date]].droplevel(['Date'])\n",
    "ser_test_data.groupby(['SITC_ID', 'Market']).median().groupby('SITC_ID').rank().groupby('Market').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EXPORT QUALITY REGIONAL MEDIAN RANKS\n",
    "\n",
    "gc.collect()\n",
    "#ser_quality_ranked = ser_quality_data.groupby(['Date', 'Country']).rank(pct = True)\n",
    "#ser_quality_median = ser_quality_ranked.groupby(['Date', 'Market', 'SITC_ID']).median()\n",
    "ser_quality_median = ser_quality_data.groupby(['Date', 'Market', 'SITC_ID']).median()\n",
    "ser_quality_median = ser_quality_median.unstack(['Market', 'SITC_ID']).reindex(pd.date_range(date_start, date_end, freq = 'BY'), method = 'ffill')\\\n",
    "                                       .stack(['SITC_ID', 'Market'])\n",
    "ser_quality_median.index.names = ['Date', 'SITC_ID', 'Market']\n",
    "ser_quality_median.name = 'Quality_Median'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMF EXPORT TRADE DATA LOADING\n",
    "\n",
    "gc.collect()\n",
    "ser_ison_status.index.names = ['Country']\n",
    "ser_trade_data = pd.read_hdf(path_or_buf = str_path_imf_trade, key = str_key_imf_trade).reorder_levels(['Date', 'Country', 'SITC_ID']).sort_index()\n",
    "ser_trade_data = ser_trade_data.to_frame().join(ser_ison_status).set_index('Market', append = True).squeeze()\n",
    "ser_trade_data = ser_trade_data.drop('ag', axis = 0, level = 'SITC_ID') / 1000\n",
    "ser_trade_data = ser_trade_data.unstack(['Country', 'Market', 'SITC_ID']).reindex(pd.date_range(date_start, date_end, freq = 'BY'), method = 'ffill')\\\n",
    "                               .stack(['SITC_ID', 'Market', 'Country'])\n",
    "ser_trade_data.index.names = ['Date', 'SITC_ID', 'Market', 'Country']\n",
    "ser_trade_data.name = 'Trade_Value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HS TO SITC CONVERSION MAP LOADING\n",
    "\n",
    "df_raw_conversion = pd.read_excel(engine = 'openpyxl', io = str_path_commodity_map_xlsx, sheet_name = str_page_map, header = 0, index_col = None,\n",
    "                                 na_values = list_na_excel_values, keep_default_na = False, dtype = str)\n",
    "df_comm_conversion = df_raw_conversion.set_index('Commodity ID')[['SITC Correspondent 1', 'SITC Correspondent 2', 'SITC Correspondent 3']]\n",
    "ser_comm_conversion = df_comm_conversion.stack().droplevel(-1)\n",
    "ser_comm_conversion.index.names = ['Commodity_ID']\n",
    "ser_comm_conversion.name = 'SITC_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONVERSION OF EXPORT QUALITY DATE TO HS SYSTEM BY WEIGHTING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "df_comm_quality = ser_comm_conversion.to_frame().set_index('SITC_ID', append = True).join(ser_quality_median).droplevel('Market')\n",
    "df_comm_quality = df_comm_quality.reorder_levels(['Date', 'SITC_ID', 'Commodity_ID']).sort_index()\n",
    "ser_trade_data = ser_trade_data.droplevel('Market').reorder_levels(['Date', 'SITC_ID', 'Country']).sort_index()\n",
    "df_comm_quality = df_comm_quality.join(ser_trade_data).reorder_levels(['Date', 'Country', 'Commodity_ID', 'SITC_ID']).sort_index()\n",
    "ser_comm_quality = df_comm_quality.groupby(['Date', 'Country', 'Commodity_ID'])\\\n",
    "                                  .apply(lambda df_group: weighted_average(df_group['Quality_Median'], df_group['Trade_Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SITC_ID\n",
       "04    0.967513\n",
       "04    0.831598\n",
       "04    0.837076\n",
       "05    0.965307\n",
       "05    0.902530\n",
       "05    0.855654\n",
       "59    0.994817\n",
       "59    0.939921\n",
       "59    0.909369\n",
       "Name: Quality_Median, dtype: float32"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_test = ser_comm_conversion.to_frame().set_index('SITC_ID', append = True).join(ser_quality_median).droplevel('Market').squeeze()\n",
    "ser_test.loc[:, '11', '2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JOINING EXPORT VOLUMES TO WEIGHT QUALITY MEDIAN FOR DATE / COUNTRY PAIR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JOINING DATA\n",
    "\n",
    "ser_ison_status.index.names = ['Reporter']\n",
    "df_country_export_mapped = ser_country_comm_export.loc[:, ser_ison_status.index, :].to_frame().join(ser_comm_conversion).dropna().join(ser_ison_status)\\\n",
    "                                                   .set_index(['SITC_ID', 'Market'], append = True).join(ser_quality_median).droplevel(['SITC_ID', 'Market'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORT QUALITY FACTOR CALCULATION\n",
    "\n",
    "ser_quality_factor = df_country_export_mapped.groupby(['Date', 'Reporter'])\\\n",
    "                                             .apply(lambda df_group: weighted_average(df_group['Quality_Median'], df_group['Export'] / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MARKET CAP FACTOR RESAMPLING\n",
    "\n",
    "gc.collect()\n",
    "### Resampling to monthly data:\n",
    "def reindex_monthly(ser_group):\n",
    "    ser_result = ser_group.droplevel(['Reporter']).reindex(pd.date_range(ser_group.index[0][0], str_date_end, freq = 'BY'))\n",
    "    ser_result = ser_result.resample('BM').ffill()\n",
    "    return ser_result\n",
    "ser_factor_monthly = ser_quality_factor.groupby('Reporter').apply(reindex_monthly).swaplevel()\n",
    "ser_factor_monthly.index.names = ['Date', 'Reporter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FACTOR SAVING\n",
    "\n",
    "ser_factor_monthly.to_excel(str_path_factor_xlsx, merge_cells = False)\n",
    "ser_factor_monthly.to_csv(str_path_factor_csv, sep = ';', header = True)\n",
    "ser_factor_monthly.to_hdf(str_path_quality_exp, str_key_comtrade_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
