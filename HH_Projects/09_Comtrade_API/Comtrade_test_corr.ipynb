{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: COMTRADE DATASETS EXTRACTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.7.4\n",
      "numpy version:  1.17.2\n",
      "pandas version:  0.25.3\n"
     ]
    }
   ],
   "source": [
    "### RUN EVERY TIME: VERSION CONTROL\n",
    "\n",
    "from platform import python_version\n",
    "print('python version: ', python_version())\n",
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: MAIN CONSTANTS\n",
    "\n",
    "### MultiIndex level slice constant:\n",
    "All = slice(None)\n",
    "### Universe path:\n",
    "str_path_universe = 'Data_Files/Source_Files/acadian_universe.xlsx'\n",
    "### Dates:\n",
    "str_date_end = '2022-12-31'\n",
    "date_start = pd.Timestamp('1989-12-29')\n",
    "date_end = pd.Timestamp(str_date_end)\n",
    "date_ison = pd.Timestamp('1994-12-31')\n",
    "### NA for MS Excel files:\n",
    "list_na_excel_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null',\n",
    "                        '#N/A Requesting Data...', '#N/A Invalid Security', '#N/A Field Not Applicable', '---']\n",
    "### Checked EBOPS service IDs list (df_serv_to_gics['GICS Group Code']):\n",
    "list_services = ['206', '210', '214', '218', '219', '223', '227', '231', '232', '237', '240', '246', '247', '250', '251', '254', '255', '256', '257', '258', '263',\n",
    "                 '264', '269', '272', '273', '288', '289', '292', '293', '294', '310', '391', '431', '500', '888', '891', '892', '894', '950']\n",
    "### Augmented bilateral export:\n",
    "str_path_export_bilateral = 'Data_Files/Source_Files/comtrade_export_bilateral.h5'\n",
    "### Export key:\n",
    "str_key_unc_export = 'export_augmented'\n",
    "### Augmented bilateral import:\n",
    "str_path_import_bilateral = 'Data_Files/Source_Files/comtrade_import_bilateral.h5'\n",
    "### Import key:\n",
    "str_key_unc_import = 'import_augmented'\n",
    "### Augmented bilateral import:\n",
    "str_path_gdp = 'Data_Files/Source_Files/gdp_dataset.h5'\n",
    "### Factor file:\n",
    "str_path_simple_exp = 'Data_Files/Source_Files/comtrade_simple_exp.h5'\n",
    "str_path_pagerank_exp = 'Data_Files/Source_Files/comtrade_pagerank_exp.h5'\n",
    "str_key_comtrade_factor = 'comtrade_factor'\n",
    "str_path_factor_xlsx = 'Data_Files/Source_Files/comtrade_factor.xlsx'\n",
    "### IOnteraction variable file:\n",
    "str_path_interact_var = 'Data_Files/Source_Files/comtrade_interact_exp.h5'\n",
    "str_key_interact_var = 'interact_var'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING WEIGHTED AVERAGE CALCULATOR\n",
    "\n",
    "def weighted_average(ser_data, ser_weight = None, int_min_count = 0):\n",
    "    ### Default output:\n",
    "    num_result = np.NaN\n",
    "    ### Checking for data presence:\n",
    "    if (ser_data.count() > int_min_count):       \n",
    "        ### Checking for weights dataset:\n",
    "        if ser_weight is None:\n",
    "            ### Calculating of simple average:\n",
    "            num_result = np.nanmean(ser_data.values)\n",
    "        else:\n",
    "            ### Weights filtering:\n",
    "            list_weight = ser_weight[ser_data.dropna().index].values\n",
    "            ### Checking for weights presence:\n",
    "            if np.nansum(list_weight):\n",
    "                ### Data filtering:\n",
    "                list_data = ser_data.dropna().values\n",
    "                ### Weighted average calculating:\n",
    "                num_result = np.nansum(list_data * list_weight) / np.nansum(list_weight)\n",
    "    ### Results output:\n",
    "    return num_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING COUNTRY CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    ### In case if URL is unavailable:\n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    ### Online extraction:\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']].sort_index()    \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "    ### Results output:\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM MS EXCEL SOURCE (TO BE IGNORED IN PRODUCT CODE)\n",
    "\n",
    "def ison_membership_converting(str_path_universe, date_end, bool_daily = False, int_backfill_months = 0):\n",
    "    ### Defining business-month-end reindexation on country level:\n",
    "    def country_modify(ser_raw_country, date_end):\n",
    "        ser_res_country = ser_raw_country.droplevel(0).resample('MS').last().resample('BM').last()\n",
    "        range_country = pd.date_range(ser_res_country.index[0], date_end, freq = 'BM')\n",
    "        return ser_res_country.reindex(range_country).ffill()\n",
    "    ### Markets encoding table:\n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM', 0: np.NaN}     \n",
    "    ### Loading source file:\n",
    "    df_raw_universe = pd.read_excel(engine = 'openpyxl', io = str_path_universe, sheet_name = 'Switchers', header = 0, parse_dates = True, index_col = [0, 1],\n",
    "                                 na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    ### Converting source file:\n",
    "    df_raw_universe.index.names = ['Country', 'Date']\n",
    "    ser_raw_universe = df_raw_universe['Region']\n",
    "    ser_raw_universe.fillna(0, inplace = True)\n",
    "    ser_raw_universe.name = 'Market'\n",
    "    ### By country reindexation and translation:\n",
    "    ser_res_universe = ser_raw_universe.groupby('Country').apply(country_modify, date_end)\n",
    "    ser_res_universe.index.names = ['Country', 'Date']\n",
    "    ser_res_universe = ser_res_universe.replace(dict_markets).reorder_levels([1, 0]).sort_index() \n",
    "    ### Expanding membership for primary regions members by backfilling:\n",
    "    if int_backfill_months:\n",
    "        ### List of regions:\n",
    "        list_region = list(ser_res_universe.dropna().unique())\n",
    "        ### Initialising of collection of series with backfilled data for each region:\n",
    "        list_ison_backfill = []\n",
    "        ### Regions looping:\n",
    "        for iter_region in list_region:\n",
    "            ### Defining start of region date:\n",
    "            date_first_valid = ser_res_universe.loc[ser_res_universe == iter_region].first_valid_index()[0]\n",
    "            ### Creating dates index to backfilling:\n",
    "            idx_date_backfill = pd.date_range(end = date_first_valid, periods = int_backfill_months + 1, freq = 'BM')[: -1]\n",
    "            ### Creating primary countries index to backfilling:            \n",
    "            idx_region_backfill = ser_res_universe.loc[ser_res_universe == iter_region].loc[date_first_valid, All].index.get_level_values('Country')\n",
    "            ### Creating full index:\n",
    "            idx_ison_backfill = pd.MultiIndex.from_product([idx_date_backfill, idx_region_backfill])\n",
    "            ### Series with backfilled data:\n",
    "            list_ison_backfill.append(pd.Series(iter_region, index = idx_ison_backfill))\n",
    "        ### Combination of backfilled series and original ISON data:    \n",
    "        ser_res_universe = ser_res_universe.combine_first(pd.concat(list_ison_backfill, axis = 0)).sort_index()  \n",
    "        ser_res_universe.index.names = ['Date', 'Country']\n",
    "    ### Converting to daily frequency:\n",
    "    if bool_daily:\n",
    "        ser_res_universe = ser_res_universe.reset_index('Country').groupby('Country').resample('B').ffill()['Market'].swaplevel().sort_index()    \n",
    "    ### Results output:\n",
    "    ser_res_universe.name = 'Market'\n",
    "    return ser_res_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN EVERY TIME: COMMON DATA EXTRACTION STEPS\n",
    "\n",
    "### World Country Codes:\n",
    "df_country_codes = get_country_codes()\n",
    "### ISON membership history:\n",
    "ser_ison_membership = ison_membership_converting(str_path_universe, pd.to_datetime(str_date_end))\n",
    "ser_ison_membership.index.names = ['Date', 'Reporter']\n",
    "### ISON Members:\n",
    "list_ison_countries = sorted(ser_ison_membership.index.get_level_values('Reporter').unique())\n",
    "### ISON status for the last available date:\n",
    "ser_ison_status = ser_ison_membership.loc[ser_ison_membership.index[-1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BILATERAL EXPORT DATA LOADING TO PERFORM FACTOR CALCULATION\n",
    "\n",
    "gc.collect()\n",
    "list_export_chunks = []\n",
    "for num_iter_number, ser_iter_chunk in enumerate(pd.read_hdf(str_path_export_bilateral, key = str_key_unc_export, chunksize = 1000000)):\n",
    "    gc.collect()\n",
    "    print(num_iter_number, ': Extraction started')\n",
    "    ser_iter_chunk = ser_iter_chunk[ser_iter_chunk > 0.0].astype('int32')\n",
    "    df_iter_chunk = ser_iter_chunk.reset_index()\n",
    "    df_iter_chunk = df_iter_chunk[(df_iter_chunk['Reporter'] != df_iter_chunk['Partner']) & \\\n",
    "                                  ((df_iter_chunk['Type'] == 'Goods') | df_iter_chunk['Commodity_ID'].isin(list_services)) & (df_iter_chunk['Reporter'] != 'World') & \\\n",
    "                                  (df_iter_chunk['Partner'] != 'World')]\\\n",
    "                               .drop('Type', axis = 1)    \n",
    "    print(num_iter_number, ': Filtering performed')    \n",
    "    ser_iter_chunk = df_iter_chunk.set_index(['Date', 'Reporter', 'Partner', 'Commodity_ID']).squeeze().sort_index()\n",
    "    del df_iter_chunk\n",
    "    gc.collect()\n",
    "    list_export_chunks.append(ser_iter_chunk)\n",
    "    print(num_iter_number, ': Chunk added to container')    \n",
    "ser_bilateral_export = pd.concat(list_export_chunks, axis = 0, sort = False).sort_index()\n",
    "ser_bilateral_export.name = 'Export'\n",
    "del list_export_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BILATERAL IMPORT DATA LOADING TO PERFORM FACTOR CALCULATION\n",
    "\n",
    "gc.collect()\n",
    "list_import_chunks = []\n",
    "for num_iter_number, ser_iter_chunk in enumerate(pd.read_hdf(str_path_import_bilateral, key = str_key_unc_import, chunksize = 1000000)):\n",
    "    gc.collect()\n",
    "    print(num_iter_number, ': Extraction started')\n",
    "    ser_iter_chunk = ser_iter_chunk[ser_iter_chunk > 0.0].astype('int32')\n",
    "    df_iter_chunk = ser_iter_chunk.reset_index()\n",
    "    df_iter_chunk = df_iter_chunk[(df_iter_chunk['Reporter'] != df_iter_chunk['Partner']) & \\\n",
    "                                  ((df_iter_chunk['Type'] == 'Goods') | df_iter_chunk['Commodity_ID'].isin(list_services)) & (df_iter_chunk['Reporter'] != 'World') & \\\n",
    "                                  (df_iter_chunk['Partner'] != 'World')]\\\n",
    "                               .drop('Type', axis = 1)     \n",
    "    print(num_iter_number, ': Filtering performed')    \n",
    "    ser_iter_chunk = df_iter_chunk.set_index(['Date', 'Reporter', 'Partner', 'Commodity_ID']).squeeze().sort_index()\n",
    "    del df_iter_chunk\n",
    "    gc.collect()\n",
    "    list_import_chunks.append(ser_iter_chunk)\n",
    "    print(num_iter_number, ': Chunk added to container')    \n",
    "ser_bilateral_import = pd.concat(list_import_chunks, axis = 0, sort = False).sort_index()\n",
    "ser_bilateral_import.name = 'Import'\n",
    "del list_import_chunks\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPORTER / COMMODITY BY DATE TOTAL EXPORT & IMPORT & TRADE\n",
    "\n",
    "gc.collect()\n",
    "### Export totals:\n",
    "ser_country_comm_export = ser_bilateral_export.groupby(['Date', 'Reporter', 'Commodity_ID']).sum().dropna()\n",
    "ser_country_comm_export.name = 'Export'\n",
    "### Import totals:\n",
    "ser_country_comm_import = ser_bilateral_import.groupby(['Date', 'Reporter', 'Commodity_ID']).sum().dropna()\n",
    "ser_country_comm_import.name = 'Import'\n",
    "### Adding trade totals:\n",
    "df_country_comm_trade = pd.concat([ser_country_comm_export, ser_country_comm_import], axis = 1)\n",
    "df_country_comm_trade = df_country_comm_trade.unstack('Date').stack('Date', dropna = False)\n",
    "df_country_comm_trade = df_country_comm_trade.unstack('Reporter').stack('Reporter', dropna = False)\n",
    "df_country_comm_trade = df_country_comm_trade.unstack('Commodity_ID').stack('Commodity_ID', dropna = False).fillna(0.0)\n",
    "df_country_comm_trade['Trade'] = df_country_comm_trade['Export'] + df_country_comm_trade['Import']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOTAL COMMODITY BY DATE TRADE VOLUME & CROSS-SECTIONAL WEIGHT\n",
    "\n",
    "### Total commodity volume:\n",
    "ser_commodity_trade = df_country_comm_trade.groupby(['Date', 'Commodity_ID'])['Trade'].sum().swaplevel().sort_index()\n",
    "ser_commodity_trade.name = 'Commodity_Total'\n",
    "df_commodity_trade = ser_commodity_trade.to_frame()\n",
    "### Total commodity weight:\n",
    "df_commodity_trade['Commodity_Weight'] = df_commodity_trade['Commodity_Total'].groupby('Date').transform(lambda df_group: df_group / df_group.sum())\n",
    "### Resampling to monthly data:\n",
    "def reindex_monthly(df_group):\n",
    "    df_result = df_group.droplevel(['Commodity_ID']).reindex(pd.date_range(df_group.index[0][-1], str_date_end, freq = 'BY'))\n",
    "    df_result = df_result.resample('BM').ffill()\n",
    "    return df_result\n",
    "df_commodity_trade = df_commodity_trade.groupby('Commodity_ID').apply(reindex_monthly)\n",
    "df_commodity_trade.index.names = ['Commodity_ID', 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPORTER / COMMODITY BY DATE EXPORT WEIGHT\n",
    "\n",
    "gc.collect()\n",
    "ser_export_weight = ser_country_comm_export.groupby(['Date', 'Commodity_ID']).transform(lambda ser_group: ser_group / ser_group.sum())\n",
    "ser_export_weight.name = 'Weight_Local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPORTER / COMMODITY BY DATE PAGE RANK\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "def get_pagerank(df_group):\n",
    "    nx_graph = nx.from_pandas_edgelist(df_group, 'Reporter', 'Partner', edge_attr = 'Export', create_using = nx.DiGraph)\n",
    "    dict_pagerank = nx.pagerank(nx_graph)\n",
    "    ser_pagerank = pd.Series(dict_pagerank)\n",
    "    return ser_pagerank\n",
    "    \n",
    "ser_export_pagerank = ser_bilateral_export.reset_index().groupby(['Date', 'Commodity_ID']).apply(get_pagerank)\n",
    "ser_export_pagerank.name = 'PG_Rank_Local'\n",
    "ser_export_pagerank.index.names = ['Date', 'Commodity_ID', 'Reporter']\n",
    "ser_export_pagerank = ser_export_pagerank.reorder_levels(['Date', 'Reporter', 'Commodity_ID']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_Rank</th>\n",
       "      <th>Simple_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PG_Rank</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simple_Weight</th>\n",
       "      <td>0.088508</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PG_Rank  Simple_Weight\n",
       "PG_Rank        1.000000       0.088508\n",
       "Simple_Weight  0.088508       1.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "str_beg_date = '1999-12-31'\n",
    "str_end_date = '2000-12-29'\n",
    "str_service_id = '240'\n",
    "\n",
    "ser_test_exp = ser_bilateral_export.loc[str_end_date, :, :, str_service_id].droplevel(['Date', 'Commodity_ID'])\n",
    "#nx.from_pandas_edgelist(ser_test_exp.reset_index(), 'Reporter', 'Partner', edge_attr = 'Export', create_using = nx.DiGraph)\n",
    "ser_test_pagerank = get_pagerank(ser_test_exp.reset_index())\n",
    "ser_test_pagerank.name = 'PG_Rank'\n",
    "ser_test_simple = ser_test_exp.groupby('Reporter').sum()\n",
    "ser_test_simple = ser_test_simple / ser_test_simple.sum()\n",
    "ser_test_simple.name = 'Simple_Weight'\n",
    "\n",
    "df_test_both = pd.concat([ser_test_pagerank, ser_test_simple], axis = 1, sort = True)\n",
    "df_test_both.corr()\n",
    "#df_test_both.to_excel('Data_Files/Test_Files/weights_comparision.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reporter  Partner\n",
       "IT        CA          209362\n",
       "          JP         1067283\n",
       "Name: Export, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Reporter  Partner\n",
       "CA        IT         66570\n",
       "JP        IT         13600\n",
       "Name: Export, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Reporter  Partner\n",
       "RS        AL             9\n",
       "          AT           213\n",
       "          AU           127\n",
       "          BA           814\n",
       "          BE            70\n",
       "          CA           110\n",
       "          CY           940\n",
       "          CZ           191\n",
       "          DE         15118\n",
       "          DK            19\n",
       "          ES            10\n",
       "          FI             3\n",
       "          GB           894\n",
       "          GR            34\n",
       "          HR            77\n",
       "          HU            21\n",
       "          JP             2\n",
       "          NL            64\n",
       "          NO             9\n",
       "          RO             2\n",
       "          RU           152\n",
       "          SE            53\n",
       "          SI           165\n",
       "          SK            84\n",
       "          VA           438\n",
       "          VI          2188\n",
       "          VN             4\n",
       "Name: Export, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Reporter  Partner\n",
       "AL        RS           24\n",
       "AT        RS         1197\n",
       "AU        RS            6\n",
       "BA        RS           13\n",
       "BE        RS           81\n",
       "BG        RS          230\n",
       "BY        RS          385\n",
       "CA        RS            1\n",
       "CN        RS          141\n",
       "CU        RS            0\n",
       "CY        RS         4495\n",
       "CZ        RS            2\n",
       "DE        RS         4424\n",
       "DK        RS            5\n",
       "DO        RS            1\n",
       "EG        RS            5\n",
       "ES        RS            8\n",
       "FI        RS           17\n",
       "GB        RS         7192\n",
       "GR        RS          237\n",
       "HR        RS         1599\n",
       "HU        RS          523\n",
       "IE        RS          304\n",
       "IL        RS           18\n",
       "IN        RS            0\n",
       "JO        RS          122\n",
       "KM        RS            6\n",
       "LK        RS           13\n",
       "LU        RS           94\n",
       "MD        RS            2\n",
       "MH        RS            5\n",
       "MT        RS           22\n",
       "NL        RS           13\n",
       "NO        RS           36\n",
       "PA        RS           30\n",
       "PL        RS            2\n",
       "RO        RS           88\n",
       "RU        RS          861\n",
       "SE        RS          109\n",
       "SI        RS           43\n",
       "SK        RS            5\n",
       "TH        RS            3\n",
       "TN        RS          113\n",
       "TR        RS          173\n",
       "TV        RS            6\n",
       "UA        RS            8\n",
       "VG        RS           53\n",
       "VI        RS            0\n",
       "ZA        RS            7\n",
       "Name: Export, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "#ser_test_exp.groupby('Partner').count()\n",
    "display(ser_test_exp.loc[['IT']])\n",
    "display(ser_test_exp.loc[:, ['IT']])\n",
    "display(ser_test_exp.loc[['RS']])\n",
    "display(ser_test_exp.loc[:, ['RS']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "df_export_both = pd.concat([ser_export_weight, ser_export_pagerank], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "df_beg_both = df_export_both.loc[(str_beg_date, ser_ison_status.index, All), :].droplevel('Date')\n",
    "df_beg_both = df_beg_both.join(df_country_comm_trade.loc[str_beg_date].droplevel('Date')['Trade'])\n",
    "df_end_both = df_export_both.loc[(str_end_date, ser_ison_status.index, All), :].droplevel('Date')\n",
    "df_end_both = df_end_both.join(df_country_comm_trade.loc[str_end_date].droplevel('Date')['Trade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8080087763985896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.1993989668947142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9828768071853787"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9310211979562197"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_beg_simple = df_beg_both.groupby('Reporter', group_keys = False).apply(lambda df_group: weighted_average(df_group['Weight_Local'], df_group['Trade']))\n",
    "ser_beg_pagerank = df_beg_both.groupby('Reporter', group_keys = False).apply(lambda df_group: weighted_average(df_group['PG_Rank_Local'], df_group['Trade']))\n",
    "ser_end_simple = df_end_both.groupby('Reporter', group_keys = False).apply(lambda df_group: weighted_average(df_group['Weight_Local'], df_group['Trade']))\n",
    "ser_end_pagerank = df_end_both.groupby('Reporter', group_keys = False).apply(lambda df_group: weighted_average(df_group['PG_Rank_Local'], df_group['Trade']))\n",
    "df_simple_mean = pd.read_hdf(str_path_simple_exp, str_key_comtrade_factor)\n",
    "df_pg_rank_mean = pd.read_hdf(str_path_pagerank_exp, str_key_comtrade_factor)\n",
    "display(df_simple_mean.loc[(All, str_beg_date), 'Weight_Local'].droplevel('Date').equals(ser_beg_simple))\n",
    "display(df_pg_rank_mean.loc[(All, str_beg_date), 'PG_Rank_Local'].droplevel('Date').equals(ser_beg_pagerank))\n",
    "display(df_simple_mean.loc[(All, str_end_date), 'Weight_Local'].droplevel('Date').equals(ser_end_simple))\n",
    "display(df_pg_rank_mean.loc[(All, str_end_date), 'PG_Rank_Local'].droplevel('Date').equals(ser_end_pagerank))\n",
    "display(ser_beg_simple.corr(ser_beg_pagerank))\n",
    "display(ser_end_simple.corr(ser_end_pagerank))\n",
    "display(ser_beg_simple.corr(ser_end_simple))\n",
    "display(ser_beg_pagerank.corr(ser_end_pagerank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'206',\n",
       " '210',\n",
       " '214',\n",
       " '219',\n",
       " '223',\n",
       " '232',\n",
       " '237',\n",
       " '240',\n",
       " '246',\n",
       " '247',\n",
       " '250',\n",
       " '251',\n",
       " '255',\n",
       " '256',\n",
       " '257',\n",
       " '263',\n",
       " '264',\n",
       " '269',\n",
       " '272',\n",
       " '273',\n",
       " '288',\n",
       " '289',\n",
       " '292',\n",
       " '293',\n",
       " '294',\n",
       " '891',\n",
       " '892'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "#display(pd.concat([df_beg_both.groupby('Reporter')['Weight_Local'].count(), df_end_both.groupby('Reporter')['Weight_Local'].count()], axis = 1, sort = True))\n",
    "set(df_end_both.loc['AU'].index) - set(df_beg_both.loc['AU'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "'''\n",
    "1) Check autocorrelation\n",
    "2) Check commodities count\n",
    "3) Check reporters coverage\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
