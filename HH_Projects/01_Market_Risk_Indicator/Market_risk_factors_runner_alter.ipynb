{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing standard modules and date-special modules:\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRACTING UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "def get_market_membership_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Defining constants:\n",
    "    path_msci_data = 'Data_Files/Source_Files/sample_data_gaps.xlsx'\n",
    "    tab_monthly = 'monthly_data'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci_data, sheet_name = tab_monthly, skiprows = [0, 2], header = 0,\n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'])\n",
    "    df_universe = df_universe.loc[:, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Code']\n",
    "    df_universe.set_index(['Code', 'Date'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    \n",
    "    return ser_market_membership\n",
    "\n",
    "### EXTRACTING RETURNS DATA FROM GENERAL MS EXCEL SOURCE\n",
    "def get_universe_returns_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    from datetime import date\n",
    "    ### Constants declaring:\n",
    "    path_msci_data = 'Data_Files/Source_Files/sample_data_gaps.xlsx'\n",
    "    tab_daily = 'daily_returns'\n",
    "    date_first = date(1992, 1, 1)\n",
    "    date_last = date(2018, 12, 31)\n",
    "    index_dates = pd.date_range(date_first, date_last, freq = 'B')    \n",
    "    ### Extracting returns data:\n",
    "    df_returns = pd.read_excel(io = path_msci_data, sheet_name = tab_daily, skiprows = [0, 2], header = 0,\n",
    "                               na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                            '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'])\n",
    "    df_returns = df_returns.loc[:, ['dates', 'ctry', 'retusd', 'retloc']]\n",
    "    df_returns.columns = ['Date', 'Code', 'Ret_USD', 'Ret_LOC']\n",
    "    df_returns.set_index(['Code', 'Date'], inplace = True)\n",
    "    df_returns.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_realized_ret_USD = df_returns['Ret_USD'].copy()\n",
    "    ser_realized_ret_LOC = df_returns['Ret_LOC'].copy()\n",
    "    ### Reindexation and forward filling procedure for USD returns:\n",
    "    dict_realized_ret_USD = {}\n",
    "    dict_index_ret_USD = {}\n",
    "    ser_ret_index_USD = pd.Series(np.NaN, index = ser_realized_ret_USD.index)\n",
    "    for iter_country in ser_realized_ret_USD.index.get_level_values(0).unique():\n",
    "        ser_ret_index_USD[iter_country] = (1 + ser_realized_ret_USD[iter_country]).cumprod()\n",
    "        ser_ret_index_USD[iter_country].iloc[0] = 1\n",
    "        ser_ret_index_USD_iter = ser_ret_index_USD[iter_country].reindex(index_dates, method = 'ffill')\n",
    "        ser_ret_index_USD_iter.fillna(method = 'ffill', inplace = True)  \n",
    "        dict_index_ret_USD[iter_country] = ser_ret_index_USD_iter\n",
    "        ser_realized_ret_USD_iter = (ser_ret_index_USD_iter / ser_ret_index_USD_iter.shift(1) - 1)\n",
    "        dict_realized_ret_USD[iter_country] = ser_realized_ret_USD_iter\n",
    "    ser_realized_ret_USD = pd.concat(dict_realized_ret_USD)  \n",
    "    ser_realized_ret_USD.index.names = ['Code', 'Date']\n",
    "    ser_realized_ret_USD.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_index_ret_USD = pd.concat(dict_index_ret_USD)  \n",
    "    ser_index_ret_USD.index.names = ['Code', 'Date']\n",
    "    ser_index_ret_USD.sort_index(level = [0, 1], inplace = True)    \n",
    "    ### Reindexation and forward filling procedure for LOC returns:\n",
    "    dict_realized_ret_LOC = {}\n",
    "    dict_index_ret_LOC = {}    \n",
    "    ser_ret_index_LOC = pd.Series(np.NaN, index = ser_realized_ret_LOC.index)\n",
    "    for iter_country in ser_realized_ret_LOC.index.get_level_values(0).unique():\n",
    "        ser_ret_index_LOC[iter_country] = (1 + ser_realized_ret_LOC[iter_country]).cumprod()\n",
    "        ser_ret_index_LOC[iter_country].iloc[0] = 1   \n",
    "        ser_ret_index_LOC_iter = ser_ret_index_LOC[iter_country].reindex(index_dates, method = 'ffill')\n",
    "        ser_ret_index_LOC_iter.fillna(method = 'ffill', inplace = True)\n",
    "        dict_index_ret_LOC[iter_country] = ser_ret_index_LOC_iter        \n",
    "        ser_realized_ret_LOC_iter = (ser_ret_index_LOC_iter / ser_ret_index_LOC_iter.shift(1) - 1)   \n",
    "        dict_realized_ret_LOC[iter_country] = ser_realized_ret_LOC_iter\n",
    "    ser_realized_ret_LOC = pd.concat(dict_realized_ret_LOC)    \n",
    "    ser_realized_ret_LOC.index.names = ['Code', 'Date']\n",
    "    ser_realized_ret_LOC.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_index_ret_LOC = pd.concat(dict_index_ret_LOC)  \n",
    "    ser_index_ret_LOC.index.names = ['Code', 'Date']\n",
    "    ser_index_ret_LOC.sort_index(level = [0, 1], inplace = True)  \n",
    "    \n",
    "    return [ser_realized_ret_USD, ser_realized_ret_LOC, ser_index_ret_USD, ser_index_ret_LOC]\n",
    "\n",
    "### EXTRACTING IMPLIED VOLATILITY DATA AND VRP FACTOR DATA FROM GENERAL MS EXCEL SOURCE\n",
    "def get_universe_ivol_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    from datetime import date    \n",
    "    ### Constants declaring:\n",
    "    path_msci_data = 'Data_Files/Source_Files/sample_data_gaps.xlsx'\n",
    "    tab_ivol = 'ivol_data'\n",
    "    date_first = date(1992, 1, 1)\n",
    "    date_last = date(2018, 12, 31)\n",
    "    index_dates = pd.date_range(date_first, date_last, freq = 'B')    \n",
    "    ### Extracting ivol data:\n",
    "    df_ivol = pd.read_excel(io = path_msci_data, sheet_name = tab_ivol, skiprows = [0, 2], header = 0,\n",
    "                            na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                         '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'])\n",
    "    df_ivol = df_ivol.loc[:, ['dates', 'ctry', 'ivol3m', 'vrp3m']]\n",
    "    df_ivol.columns = ['Date', 'Code', 'IVol_3m', 'VRP_3m']\n",
    "    df_ivol.set_index(['Code', 'Date'], inplace = True)\n",
    "    df_ivol.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_ivol3m = df_ivol['IVol_3m']\n",
    "    ser_vrp3m = df_ivol['VRP_3m']    \n",
    "    ### Reindexation and forward filling procedure for implied volatlity variables:\n",
    "    dict_ivol3m = {}\n",
    "    for iter_country in ser_ivol3m.index.get_level_values(0).unique():  \n",
    "        ser_ivol_iter = ser_ivol3m[iter_country].reindex(index_dates, method = 'ffill')\n",
    "        ser_ivol_iter.fillna(method = 'ffill', inplace = True)\n",
    "        dict_ivol3m[iter_country] = ser_ivol_iter\n",
    "    ser_ivol3m = pd.concat(dict_ivol3m)    \n",
    "    ser_ivol3m.index.names = ['Code', 'Date']\n",
    "    ser_ivol3m.sort_index(level = [0, 1], inplace = True)\n",
    "    dict_vrp3m = {}\n",
    "    for iter_country in ser_vrp3m.index.get_level_values(0).unique():    \n",
    "        ser_vrp_iter = ser_vrp3m[iter_country].reindex(index_dates, method = 'ffill')\n",
    "        ser_vrp_iter.fillna(method = 'ffill', inplace = True)\n",
    "        dict_vrp3m[iter_country] = ser_vrp_iter\n",
    "    ser_vrp3m = pd.concat(dict_vrp3m)    \n",
    "    ser_vrp3m.index.names = ['Code', 'Date']\n",
    "    ser_vrp3m.sort_index(level = [0, 1], inplace = True)\n",
    "    \n",
    "    return [ser_ivol3m, ser_vrp3m]\n",
    "\n",
    "### EXTRACTING MRI INDEX FROM HDF5 SOURCE\n",
    "def get_gri_from_hdf():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    ### Constants declaring:\n",
    "    path_gri_index_hdf = 'Data_Files/Source_Files/gri_released_index.h5'\n",
    "    gri_vector_key = 'gri_vector_key'\n",
    "    gri_start_key = 'gri_start_key'  \n",
    "    gri_level_perc_key = 'gri_level_perc_key' ### ADDED FOR BETA FACTORS CALCULATION\n",
    "    gri_momentum_perc_key = 'gri_momentum_perc_key' ### ADDED FOR BETA FACTORS CALCULATION    \n",
    "    ### Extracting GRI:\n",
    "    ser_gri_released = pd.read_hdf(path_gri_index_hdf, gri_vector_key)\n",
    "    ser_gri_start_col = pd.read_hdf(path_gri_index_hdf, gri_start_key)\n",
    "    ser_gri_level_perc = pd.read_hdf(path_gri_index_hdf, gri_level_perc_key) ### ADDED FOR BETA FACTORS CALCULATION\n",
    "    ser_gri_momentum_perc = pd.read_hdf(path_gri_index_hdf, gri_momentum_perc_key) ### ADDED FOR BETA FACTORS CALCULATION\n",
    "    return [ser_gri_released, ser_gri_start_col, ser_gri_level_perc, ser_gri_momentum_perc] ### CHANGED FOR BETA FACTORS CALCULATION\n",
    "\n",
    "### EXTRACTING SOURCE DATA FROM MS EXCEL FILES AND SAVING TO HDF FILES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "### Extracting data from xlsx files\n",
    "ser_market_membership = get_market_membership_from_excel()\n",
    "[ser_realized_ret_USD, ser_realized_ret_LOC, ser_index_ret_USD, ser_index_ret_LOC] = get_universe_returns_from_excel()\n",
    "[ser_ivol3m, ser_vrp3m] = get_universe_ivol_from_excel()\n",
    "[ser_gri_released, ser_gri_start_col, ser_gri_level_perc, ser_gri_momentum_perc] = get_gri_from_hdf() ### CHANGED FOR BETA FACTORS CALCULATION\n",
    "ser_gri_released.name = 'GRI'\n",
    "ser_gri_start_col.name = 'GRI'\n",
    "### Declaring constants:\n",
    "path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "market_membership_key = 'market_membership_key'\n",
    "realized_ret_USD_key = 'realized_ret_USD_key'\n",
    "realized_ret_LOC_key = 'realized_ret_LOC_key'\n",
    "index_ret_USD_key = 'index_ret_USD_key'\n",
    "index_ret_LOC_key = 'index_ret_LOC_key'\n",
    "ivol3m_key = 'ivol3m_key'\n",
    "vrp3m_key = 'vrp3m_key'\n",
    "gri_released_key = 'gri_released_key'\n",
    "gri_start_key = 'gri_start_key'\n",
    "gri_level_perc_key = 'gri_level_perc_key' ### ADDED FOR BETA FACTORS CALCULATION\n",
    "gri_momentum_perc_key = 'gri_momentum_perc_key' ### ADDED FOR BETA FACTORS CALCULATION\n",
    "### close files that have been previously opened\n",
    "import tables\n",
    "tables.file._open_files.close_all()\n",
    "### Saving data to hdf5 fixed formatted files:\n",
    "ser_market_membership.to_hdf(path_market_risk_source_hdf, market_membership_key, mode = 'w', format = 'fixed')\n",
    "ser_realized_ret_USD.to_hdf(path_market_risk_source_hdf, realized_ret_USD_key, mode = 'a', format = 'fixed')\n",
    "ser_realized_ret_LOC.to_hdf(path_market_risk_source_hdf, realized_ret_LOC_key, mode = 'a', format = 'fixed')\n",
    "ser_index_ret_USD.to_hdf(path_market_risk_source_hdf, index_ret_USD_key, mode = 'a', format = 'fixed')\n",
    "ser_index_ret_LOC.to_hdf(path_market_risk_source_hdf, index_ret_LOC_key, mode = 'a', format = 'fixed')\n",
    "ser_ivol3m.to_hdf(path_market_risk_source_hdf, ivol3m_key, mode = 'a', format = 'fixed')\n",
    "ser_vrp3m.to_hdf(path_market_risk_source_hdf, vrp3m_key, mode = 'a', format = 'fixed')\n",
    "ser_gri_released.to_hdf(path_market_risk_source_hdf, gri_released_key, mode = 'a', format = 'fixed')\n",
    "ser_gri_start_col.to_hdf(path_market_risk_source_hdf, gri_start_key, mode = 'a', format = 'fixed')\n",
    "ser_gri_level_perc.to_hdf(path_market_risk_source_hdf, gri_level_perc_key, mode = 'a', format = 'fixed') ### ADDED FOR BETA FACTORS CALCULATION\n",
    "ser_gri_momentum_perc.to_hdf(path_market_risk_source_hdf, gri_momentum_perc_key, mode = 'a', format = 'fixed') ### ADDED FOR BETA FACTORS CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRACTING PREVIOUSLY SAVED DATA FROM HDF5 FILE\n",
    "### Declaring constants:\n",
    "path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "market_membership_key = 'market_membership_key'\n",
    "realized_ret_USD_key = 'realized_ret_USD_key'\n",
    "realized_ret_LOC_key = 'realized_ret_LOC_key'\n",
    "index_ret_USD_key = 'index_ret_USD_key'\n",
    "index_ret_LOC_key = 'index_ret_LOC_key'\n",
    "ivol3m_key = 'ivol3m_key'\n",
    "vrp3m_key = 'vrp3m_key'\n",
    "path_gri_index_hdf = 'Data_Files/Source_Files/gri_released_index.h5'\n",
    "gri_released_key = 'gri_released_key'\n",
    "gri_start_key = 'gri_start_key'\n",
    "gri_level_perc_key = 'gri_level_perc_key' ### ADDED FOR BETA FACTORS CALCULATION\n",
    "gri_momentum_perc_key = 'gri_momentum_perc_key' ### ADDED FOR BETA FACTORS CALCULATION\n",
    "### Exporting data from hdf5 fixed formatted files:\n",
    "ser_market_membership = pd.read_hdf(path_market_risk_source_hdf, market_membership_key)\n",
    "ser_realized_ret_USD = pd.read_hdf(path_market_risk_source_hdf, realized_ret_USD_key)\n",
    "ser_realized_ret_LOC = pd.read_hdf(path_market_risk_source_hdf, realized_ret_LOC_key)\n",
    "ser_index_ret_USD = pd.read_hdf(path_market_risk_source_hdf, index_ret_USD_key)\n",
    "ser_index_ret_LOC = pd.read_hdf(path_market_risk_source_hdf, index_ret_LOC_key)\n",
    "ser_ivol3m = pd.read_hdf(path_market_risk_source_hdf, ivol3m_key)\n",
    "ser_vrp3m = pd.read_hdf(path_market_risk_source_hdf, vrp3m_key)\n",
    "ser_gri_released = pd.read_hdf(path_market_risk_source_hdf, gri_released_key)\n",
    "ser_gri_start_col = pd.read_hdf(path_market_risk_source_hdf, gri_start_key)\n",
    "ser_gri_level_perc = pd.read_hdf(path_market_risk_source_hdf, gri_level_perc_key) ### ADDED FOR BETA FACTORS CALCULATION\n",
    "ser_gri_momentum_perc = pd.read_hdf(path_market_risk_source_hdf, gri_momentum_perc_key) ### ADDED FOR BETA FACTORS CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRACTING UNIVERSE DATA FOR A PARTICULAR DATE\n",
    "def get_date_membership(iter_date):\n",
    "    ### Preparing data for universe filtering:\n",
    "    if (pd.to_datetime(iter_date) == pd.to_datetime(iter_date - pd.offsets.BusinessMonthEnd(0))):\n",
    "        iter_month_end = iter_date\n",
    "    else: \n",
    "        iter_month_end = pd.to_datetime(iter_date - pd.offsets.BusinessMonthEnd(1))    \n",
    "    ### Filtering and replacing iter_date to end-of-month date:\n",
    "    ser_iter_membership = ser_market_membership.loc[:, iter_month_end]\n",
    "    ser_iter_membership = ser_iter_membership.to_frame().assign(Date = iter_month_end).set_index('Date', append = True).squeeze()\n",
    "    \n",
    "    return ser_iter_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING ASYMMETRY SERIES BUILDER\n",
    "def get_asymmetry_series(ser_market_membership, ser_returns):\n",
    "    ### Defining asymmetry calculator:\n",
    "    def get_asymmetry_value(ser_iter_returns):\n",
    "        ### Constants declaring (common for all factors):  \n",
    "        num_year_work_days = 260        \n",
    "        ### Skewness calculating:\n",
    "        asymmetry_result = np.NaN\n",
    "        if (ser_iter_returns.count() > num_year_work_days // 2):\n",
    "            ser_iter_returns = ser_iter_returns.dropna().iloc[- num_year_work_days * 2 : ] \n",
    "            ser_iter_returns = ser_iter_returns - ser_iter_returns.mean()                  \n",
    "            asymmetry_result = (ser_iter_returns[ser_iter_returns > ser_iter_returns.std()].count() - \\\n",
    "                                ser_iter_returns[ser_iter_returns < -ser_iter_returns.std()].count()) \\\n",
    "                               / ser_iter_returns.count()\n",
    "        ### Results output:\n",
    "        return asymmetry_result\n",
    "    ### Defining constants:\n",
    "    iter_date = ser_market_membership.index.get_level_values(1)[0]\n",
    "    ### Main loop performing:\n",
    "    ser_member_returns = ser_returns.loc[ser_market_membership.index.get_level_values(0),  :]   \n",
    "    ser_asymmetry = ser_member_returns.groupby('Code').apply(get_asymmetry_value)\n",
    "    ser_asymmetry = ser_asymmetry.reindex(ser_market_membership.index.get_level_values(0))\n",
    "    ser_asymmetry = ser_asymmetry.to_frame().assign(Date = iter_date).set_index('Date', append = True).squeeze()\n",
    "    ### Results output:\n",
    "    return ser_asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET ASYMMETRY TAIL FACTOR\n",
    "def get_asymmetry_tail_factor(iter_date): \n",
    "    ### Constants declaring (common for all factors):  \n",
    "    num_year_work_days = 260\n",
    "    window_years = 5       \n",
    "    ### Data preparing (common for all factors):\n",
    "    index_iter_date = pd.date_range(end = iter_date, periods = num_year_work_days * window_years, freq = 'B')\n",
    "    ser_iter_membership = get_date_membership(iter_date)\n",
    "    ser_iter_returns = ser_realized_ret_LOC.loc[:, index_iter_date]\n",
    "    ### Removing effectively missing return observations\n",
    "    ser_iter_returns.replace(0, np.nan, inplace = True)    \n",
    "    ### Factor calculation:\n",
    "    ser_iter_factor = - get_asymmetry_series(ser_iter_membership, ser_iter_returns) \n",
    "    ### Results output:\n",
    "    return ser_iter_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOOPER FOR ASYMMETRY TAIL FACTOR\n",
    "#date_range_test = pd.date_range(start = '2010-10-25', periods = 6)\n",
    "#date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()\n",
    "date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()[155 : 156]\n",
    "arr_asymmetry_tail_factor = []\n",
    "iter_counter = 0\n",
    "for iter_date in date_range_test:\n",
    "    iter_counter = iter_counter + 1\n",
    "    arr_asymmetry_tail_factor.append(get_asymmetry_tail_factor(iter_date))\n",
    "    if ((iter_counter // 10) == (iter_counter / 10)):\n",
    "        print('Progress printout', iter_counter, '/', iter_date)\n",
    "        \n",
    "ser_asymmetry_tail_factor = pd.concat(arr_asymmetry_tail_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser_asymmetry_tail_factor - AR 29-Dec-2006: -0.0\n",
      "ser_asymmetry_tail_factor - US 29-Dec-2006: 0.019230769230769232\n",
      "ser_asymmetry_tail_factor - cross-sectional mean min: -0.005933971323553761\n",
      "ser_asymmetry_tail_factor - cross-sectional mean mean: 0.00047159164615741777\n",
      "ser_asymmetry_tail_factor - cross-sectional mean max: 0.01357023341150325\n",
      "ser_asymmetry_tail_factor - cross-sectional mean stdev: 0.00354223282922243\n",
      "ser_asymmetry_tail_factor - cross-sectional mean mean: 234\n"
     ]
    }
   ],
   "source": [
    "### ASYMMETRY TAIL FACTOR TESTING:\n",
    "print('ser_asymmetry_tail_factor - AR 29-Dec-2006:', ser_asymmetry_tail_factor.loc['AR' , '2006-12-29'])\n",
    "print('ser_asymmetry_tail_factor - US 29-Dec-2006:', ser_asymmetry_tail_factor.loc['US' , '2006-12-29'])\n",
    "ser_asymmetry_tail_factor_mean = pd.Series(np.NaN, index = ser_asymmetry_tail_factor.index.get_level_values(1).unique())\n",
    "for iter_date in ser_asymmetry_tail_factor_mean.index:  \n",
    "    ser_asymmetry_tail_factor_mean[iter_date] = ser_asymmetry_tail_factor.loc[:, iter_date].mean()\n",
    "ser_asymmetry_tail_factor_mean.sort_index(inplace = True)\n",
    "print('ser_asymmetry_tail_factor - cross-sectional mean min:', ser_asymmetry_tail_factor_mean.min())\n",
    "print('ser_asymmetry_tail_factor - cross-sectional mean mean:', ser_asymmetry_tail_factor_mean.mean())\n",
    "print('ser_asymmetry_tail_factor - cross-sectional mean max:', ser_asymmetry_tail_factor_mean.max())\n",
    "print('ser_asymmetry_tail_factor - cross-sectional mean stdev:', ser_asymmetry_tail_factor_mean.std())\n",
    "print('ser_asymmetry_tail_factor - cross-sectional mean mean:', ser_asymmetry_tail_factor_mean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
