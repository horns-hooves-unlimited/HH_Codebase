{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MRI GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### STANDART MODULES INITIALISING\n",
    "\n",
    "### Importing standard modules and date-special modules:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MRI CONSTANTS AND PARAMETERS SETTING\n",
    "\n",
    "### Standart date format for notebook:\n",
    "date_format = '%Y-%m-%d'\n",
    "### MRI dates:\n",
    "date_first = date(1990, 1, 1)\n",
    "date_last = date(2018, 12, 31)\n",
    "date_start = date(1993, 12, 31)\n",
    "### Source xlsx file attributes:\n",
    "path_mri_data_xlsx = 'Data_Files/Source_Files/mri_data.xlsx'\n",
    "mri_model_name = 'Model 01'\n",
    "### HDF5 file with structured source data for selected date interval attributes:\n",
    "path_mri_data_hdf = 'Data_Files/Source_Files/mri_data.h5'\n",
    "key_mri_data_hdf = 'source_data'\n",
    "\n",
    "### Limitations for rolling windows for z-score calculating:\n",
    "asset_window_min = 252\n",
    "asset_window_max = 252 * 100\n",
    "mri_window_min = 252\n",
    "mri_window_max = 260 * 10\n",
    "### Limitations for z-score winsorizing:\n",
    "arr_winsor_boundary = [-4, 4]\n",
    "### Limitations for moving average for MRI calculation:\n",
    "mri_moving_average_window_max = 5\n",
    "### HDF5 with MRI group matrices builded from z-scored means of standartized winsorized weighted z-score matrices for each group asset:\n",
    "path_mri_standart_hdf = 'Data_Files/Source_Files/mri_group_z_matrix.h5'\n",
    "### HDF5 with MRI asset level info:\n",
    "path_mri_assets_hdf = 'Data_Files/Source_Files/mri_released_assets.h5'\n",
    "object_selected_data_hdf = 'selected_data'\n",
    "object_standartized_data_hdf = 'standartized_data'\n",
    "### HDF5 with MRI group level info:\n",
    "path_mri_groups_hdf = 'Data_Files/Source_Files/mri_released_groups.h5'\n",
    "object_diag_grouped_hdf = 'diag_grouped_data'\n",
    "object_perc_grouped_hdf = 'percentile_grouped_data'\n",
    "### HDF5 with MRI level info:\n",
    "path_mri_index_hdf = 'Data_Files/Source_Files/mri_released_index.h5'\n",
    "object_diag_mri_hdf = 'diag_MRI_data'\n",
    "object_raw_perc_mri_hdf = 'raw_perc_MRI_data'\n",
    "object_ma_perc_mri_hdf = 'ma_perc_MRI_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MRI DATA AGGREGATING FUNCTION\n",
    "def get_mri_data(source_file_path, source_model_sheet, hdf_file_path, hdf_object_key, date_index, update_hdf = True):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    \n",
    "    ### Reading Model information from Source model sheet:\n",
    "    df_model_raw = pd.read_excel(source_file_path, sheet_name = source_model_sheet, header = 1, usecols = [0, 1, 2, 3, 4, 5, 6])\n",
    "    ### Group border rows deleting:\n",
    "    df_model_raw = df_model_raw[df_model_raw['Asset Group'] != df_model_raw['Asset Code']]   \n",
    "    ### Dividing list on asset part and MRI weights part:\n",
    "    df_model_asset = df_model_raw[df_model_raw['Asset Group'] != 'MRI'] ### Asset part\n",
    "    df_model_asset.reset_index(drop = True, inplace = True)\n",
    "    df_model_mri = df_model_raw[df_model_raw['Asset Group'] == 'MRI'] ### MRI part\n",
    "    df_model_mri.reset_index(drop = True, inplace = True) \n",
    "    ### Extracting source data from initial excel file or from saved hdf\n",
    "    if (update_hdf): \n",
    "        ### Aggregating data from the source xlsx file to pd.DataFrame:\n",
    "        arr_tab_data = []\n",
    "        for iter_index, iter_row in df_model_asset.iterrows():\n",
    "            iter_tab = iter_row['Asset Tab Name']\n",
    "            iter_asset = iter_row['Asset Code']\n",
    "            ser_iter_tab = pd.read_excel(source_file_path, sheet_name = iter_tab, header = 0, index_col = 0, squeeze = True)\n",
    "            ser_iter_tab.name = iter_asset\n",
    "            arr_tab_data.append(ser_iter_tab)\n",
    "        df_source_data = pd.concat(arr_tab_data, axis = 1, join = 'outer')\n",
    "        df_source_data = df_source_data.astype(float)        \n",
    "        df_source_data.to_hdf(hdf_file_path, hdf_object_key, mode = 'w', format = 'fixed', append = False)\n",
    "    else:\n",
    "        df_source_data = pd.read_hdf(hdf_file_path, hdf_object_key)\n",
    "    ### Filtering by date_index and forward filling missing values:\n",
    "    df_source_data.fillna(method = 'ffill', inplace = True)\n",
    "    df_selected_data = df_source_data.reindex(date_index, method = 'ffill')\n",
    "    df_selected_data.index.name = 'Date'\n",
    "    return [df_model_asset, df_model_mri, df_selected_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GETTING MRI DATA FOR FUTURE CALCULATIONS\n",
    "index_mri_date = pd.date_range(date_first, date_last, freq = 'B')\n",
    "#[df_model_asset, df_model_mri, df_selected_data] = get_mri_data(path_mri_data_xlsx, mri_model_name, path_mri_data_hdf, key_mri_data_hdf, \n",
    "#                                                                 index_mri_date, update_hdf = True)\n",
    "[df_model_asset, df_model_mri, df_selected_data] = get_mri_data(path_mri_data_xlsx, mri_model_name, path_mri_data_hdf, key_mri_data_hdf, \n",
    "                                                                index_mri_date, update_hdf = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_z_score(ser_source, min_wnd, max_wnd, winsor_bottom, winsor_top):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Calculating rolling mean:\n",
    "    ser_rolling_mean = ser_source.rolling(window = max_wnd, min_periods = min_wnd, win_type = None).mean()\n",
    "    ### Calculating rolling standard deviation:\n",
    "    ser_rolling_std = ser_source.rolling(window = max_wnd, min_periods = min_wnd, win_type = None).std()\n",
    "    ### Calculating rolling z-score:\n",
    "    ser_rolling_z_score = (ser_source - ser_rolling_mean) / ser_rolling_std\n",
    "    ### Initializing resulting variables:\n",
    "    df_z_matrix = pd.DataFrame(np.NaN, index = ser_source.index, columns = ser_source.index)\n",
    "    df_z_matrix = df_z_matrix.astype(float)\n",
    "    ### Calculating z-score matrix:\n",
    "    for iter_end_index in ser_source.index:\n",
    "        ### Isolating rolling window for particular data vector element:\n",
    "        iter_start_index = iter_end_index - pd.offsets.BusinessDay(max_wnd)\n",
    "        ser_iter_source = ser_source.loc[iter_start_index : iter_end_index]\n",
    "        ### Checking for at list min_wnd elements of rolling window are not np.NaN:\n",
    "        if (ser_iter_source.count() >= min_wnd):\n",
    "            ser_iter_z_score = (ser_iter_source - ser_iter_source.mean()) / ser_iter_source.std()            \n",
    "            ### Winsorization process:\n",
    "            bool_to_winsor = True            \n",
    "            while (bool_to_winsor):       \n",
    "                ### Value based winsorization:\n",
    "                ser_iter_z_score.clip(lower = winsor_bottom, upper = winsor_top, inplace = True)\n",
    "                ### Recalculating of z scores:\n",
    "                ser_iter_z_score = (ser_iter_z_score - ser_iter_z_score.mean()) / ser_iter_z_score.std()                \n",
    "                ### Checking for boundaries:\n",
    "                if (ser_iter_z_score[(ser_iter_z_score < winsor_bottom) & (ser_iter_z_score > winsor_top)].size == 0):\n",
    "                    bool_to_winsor = False\n",
    "            ### Filling z matrix column part after the winsorizing (if needed):\n",
    "            df_z_matrix.loc[iter_start_index : iter_end_index, iter_end_index] = ser_iter_z_score.values        \n",
    "    ### Getting winsorized z meanings:     \n",
    "    ser_rolling_z_winsor = pd.Series(list(np.diag(df_z_matrix)), index = ser_source.index)\n",
    "    ### Backfilling with first not NaN column of z matrix:\n",
    "    ind_valid_index = ser_rolling_z_winsor.first_valid_index()\n",
    "    ser_rolling_z_winsor.loc[ : ind_valid_index] = df_z_matrix.loc[ : ind_valid_index, ind_valid_index]\n",
    "    \n",
    "    return [ser_rolling_z_score, ser_rolling_z_winsor, df_z_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standartized_mri_data(df_model_asset, df_selected_data, date_start, asset_window_min, asset_window_max, arr_winsor_boundary, hdf_file_path):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "\n",
    "    ### Base assets determination (resorting by earliest value):\n",
    "    df_model_asset['Asset Date'] = date_first\n",
    "    for (iter_index, asset_code) in df_model_asset['Asset Code'].iteritems():\n",
    "        df_model_asset.loc[iter_index, 'Asset Date'] = df_selected_data[asset_code].dropna().index.min() \n",
    "    df_model_asset.sort_values(['Asset Group', 'Asset Date'], inplace = True)\n",
    "    df_model_asset = df_model_asset.reset_index(drop = True)\n",
    "\n",
    "    ### Initialising loop visibility variables:          \n",
    "#    arr_group_diag_container = []\n",
    "    dict_group_diag_container = {} ### Group z-matrices diagonales container\n",
    "#    arr_group_vector_container = []\n",
    "#    arr_asset_vector_container = []\n",
    "    dict_asset_vector_container = {} ### Asset z-matrices diagonales container\n",
    "#    arr_asset_codes_global = []\n",
    "#    arr_group_codes = []\n",
    "    ### Standartizing loop on group level:\n",
    "    for asset_group_name, df_asset_group in df_model_asset.groupby('Asset Group'):\n",
    "        ### Initialising group visibility variables:\n",
    "        print('get_standartized_mri_data: group', asset_group_name, 'standartizing started')\n",
    "        bool_base_asset = True\n",
    "#        arr_asset_matrix_container = []\n",
    "        dict_asset_matrix_container = {} ### Asset matrices collection for group mean matrix calculation\n",
    "#        arr_asset_codes = []\n",
    "        ### Standartizing cycle on asset level with the group:\n",
    "        for (asset_index, asset_code) in df_asset_group['Asset Code'].iteritems():\n",
    "            ### Assignment of base asset data set:\n",
    "            if (bool_base_asset):\n",
    "                bool_base_asset = False\n",
    "                ### Performing z scoring for base asset:\n",
    "                [ser_rolling_z_score_base, ser_rolling_z_winsor_base, df_base_z_matrix] = get_rolling_z_score(df_selected_data[asset_code], \n",
    "                                                                                                              asset_window_min, asset_window_max,\n",
    "                                                                                                              arr_winsor_boundary[0], arr_winsor_boundary[1])\n",
    "                ### Calculating etalon filled quantity before date_start:\n",
    "                int_base_filled = ser_rolling_z_winsor_base[ : date_start].dropna().count()                \n",
    "                ### Defining of standartized values of base asset as diagonal of z matrix (without backfilling):\n",
    "#                arr_asset_vector_container.append(pd.Series(np.copy(np.diag(df_base_z_matrix)), index = df_base_z_matrix.index))\n",
    "                dict_asset_vector_container[asset_code] = pd.Series(list(np.diag(df_base_z_matrix)), index = df_base_z_matrix.index)\n",
    "#                ### Initialising dataset with non np.NaN wages sum for group:\n",
    "#                df_group_weights = pd.DataFrame(np.zeros(df_base_z_matrix.shape), index = df_base_z_matrix.index, columns = df_base_z_matrix.columns)\n",
    "                ### Creating a whole group dataset with multiplying asset matrix to asset weight:\n",
    "#                arr_asset_matrix_container.append(df_base_z_matrix * df_model_asset.at[asset_index, 'Factor Weights'])    \n",
    "                dict_asset_matrix_container[asset_code] = df_base_z_matrix\n",
    "#                df_group_weights = df_group_weights + df_base_z_matrix.notna() * df_model_asset.at[asset_index, 'Factor Weights']\n",
    "#                arr_asset_codes.append(asset_code)\n",
    "#                arr_asset_codes_global.append(asset_code)\n",
    "            ### Normalization of other asset's data sets:                \n",
    "            else:\n",
    "                ### Performing z scoring for asset:                \n",
    "                [ser_asset_z_score_simple, ser_asset_z_score_winsor, df_asset_z_matrix] = get_rolling_z_score(df_selected_data[asset_code], \n",
    "                                                                                                              asset_window_min, asset_window_max, \n",
    "                                                                                                              arr_winsor_boundary[0], arr_winsor_boundary[1])            \n",
    "                ### Calculating asset filled quantity:                \n",
    "                int_asset_filled = ser_asset_z_score_winsor[ : date_start].dropna().count()            \n",
    "                ### Standartizing asset if they do not have enough initial values:\n",
    "                if (int_asset_filled < int_base_filled * 2 / 3):\n",
    "#                    df_asset_start_index = ser_asset_z_score_simple.index.get_loc(ser_asset_z_score_simple.first_valid_index())\n",
    "                    index_asset_start = ser_asset_z_score_simple.first_valid_index()\n",
    "                    ### RenormaLizing asset z matrix with base z matrix data:\n",
    "#                    for end_wnd_index in range(index_asset_start, min(index_asset_start + asset_window_max, ser_asset_z_score_simple.size)):\n",
    "                    for index_asset_end in ser_asset_z_score_simple.index:\n",
    "                        if ((index_asset_end >= index_asset_start) & (index_asset_end <= (index_asset_start + pd.offsets.BusinessDay(asset_window_max)))):\n",
    "#                        ser_base_z_matrix_part = df_base_z_matrix.iloc[max(0, index_asset_start - asset_window_min + 1) : index_asset_end + 1, index_asset_end]\n",
    "                            ser_base_z_part = df_base_z_matrix.loc[index_asset_start - pd.offsets.BusinessDay(asset_window_min) : index_asset_end, index_asset_end]\n",
    "                            df_asset_z_matrix.loc[:, index_asset_end] = df_asset_z_matrix.loc[:, index_asset_end] * ser_base_z_part.std()  + ser_base_z_part.mean()\n",
    "                       \n",
    "                ### Defining of standartized values of asset as diagonale of modified z matrix (without backfilling):\n",
    "#                arr_asset_vector_container.append(pd.Series(np.copy(np.diag(df_asset_z_matrix)), index = df_asset_z_matrix.index))   \n",
    "                dict_asset_vector_container[asset_code] = pd.Series(list(np.diag(df_asset_z_matrix)), index = df_asset_z_matrix.index)\n",
    "                ### Adding asset matrix to a whole group dataset with multiplying asset matrix to asset weight:          \n",
    "#                arr_asset_matrix_container.append(df_asset_z_matrix * df_model_asset.at[asset_index, 'Factor Weights'])  \n",
    "                dict_asset_matrix_container[asset_code] = df_asset_z_matrix\n",
    "#                df_group_weights = df_group_weights + df_asset_z_matrix.notna() * df_model_asset.at[asset_index, 'Factor Weights']                    \n",
    "#                arr_asset_codes.append(asset_code)   \n",
    "#                arr_asset_codes_global.append(asset_code)  \n",
    "            print('get_standartized_mri_data: asset', asset_code, 'in group', asset_group_name, 'standartized successfully')         \n",
    "        ### Calculating z matrix for group from weighted asset matrices:\n",
    "#        df_group_mean = pd.concat(arr_asset_matrix_container, axis = 0, keys = arr_asset_codes, names = ['Asset Code', 'Date'], copy = False)   \n",
    "        df_group_mean = pd.concat(dict_asset_matrix_container, axis = 0, names = ['Asset Code', 'Date'], copy = False)\n",
    "#        print('get_standartized_mri_data: aggregated matrix for group' , asset_group_name, 'builded successfully')    \n",
    "        df_group_mean = df_group_mean.groupby('Date').mean()    \n",
    "#        df_group_mean = df_group_mean.sum(level = 1)\n",
    "#        df_group_mean[df_group_weights > 0] =  df_group_mean[df_group_weights > 0] / df_group_weights[df_group_weights > 0]\n",
    "#        df_group_mean[df_group_weights == 0] = np.NaN\n",
    "#        print('get_standartized_mri_data: mean matrix for group' , asset_group_name, 'builded successfully')         \n",
    "        df_group_mean_z = (df_group_mean - df_group_mean.mean()) / df_group_mean.std()\n",
    "        ### Adding diagonale of group weighted mean z-score matrix to MRI dataset:\n",
    "#        arr_group_diag_container.append(pd.Series(np.copy(np.diag(df_group_mean_z)), index = df_group_mean_z.index))\n",
    "        dict_group_diag_container[asset_group_name] = pd.Series(list(np.diag(df_group_mean_z)), index = df_group_mean_z.index)        \n",
    "        print('get_standartized_mri_data: z-score matrix for group' , asset_group_name, 'mean matrix builded successfully') \n",
    "        ### Saving group matrix to hdf file for further manipulations:\n",
    "#        df_group_to_save = df_group_mean_z.copy()\n",
    "#        df_group_to_save = df_group_to_save.astype(float)\n",
    "#        df_group_to_save.reset_index(inplace = True)\n",
    "#        df_group_to_save.columns = np.arange(len(df_group_to_save.columns))\n",
    "#        df_group_to_save.to_hdf(hdf_file_path, key = asset_group_name, mode = 'a', format = 'fixed')\n",
    "#        arr_group_codes.append(asset_group_name)\n",
    "#        df_group_mean_z = df_group_mean_z.astype(float)\n",
    "        df_group_mean_z.stack(dropna = False).to_hdf(hdf_file_path, key = asset_group_name, mode = 'a', format = 'fixed')\n",
    "        print('get_standartized_mri_data: z-score matrix for group' , asset_group_name, 'saved to HDF5 file', hdf_file_path, '(object key:', asset_group_name, ')')\n",
    "#        ### Creating data vector of percentiled group's z matrix columns for each group:\n",
    "#        ser_group_z_percentile = pd.Series(np.NaN, index = df_group_mean_z.index) \n",
    "#        ser_group_z_percentile.name = asset_group_name\n",
    "#        for column_index in df_group_mean_z.columns:\n",
    "#            if (column_index >= datetime.strptime(date_start, date_format)):                \n",
    "#                ser_rolling_wnd = df_group_mean_z.loc[(column_index - pd.DateOffset(years = 1) + pd.DateOffset(days = 1)) : column_index, column_index]\n",
    "#                ser_group_z_percentile[column_index] = ((ser_rolling_wnd.rank(method = 'min')[-1] - 1) / ser_rolling_wnd.notna().sum() + \n",
    "#                        ser_rolling_wnd.rank(pct = True, method = 'max')[-1]) / 2                    \n",
    "#        arr_group_vector_container.append(ser_group_z_percentile)\n",
    "    ### Collection of standartized z-scores for all assets:\n",
    "#    df_asset_standartized = pd.concat(arr_asset_vector_container, axis = 0, keys = arr_asset_codes_global, names = ['Asset Code', 'Date'], copy = False)\n",
    "    ser_asset_standartized = pd.concat(dict_asset_vector_container, axis = 0, names = ['Asset Code', 'Date'], copy = False)    \n",
    "    ser_asset_standartized = ser_asset_standartized.astype(float)\n",
    "    print('get_standartized_mri_data: asset standartized z-score collection builded successfully')\n",
    "    ### Collection of diagonales of group's z matrices for all groups:\n",
    "#    df_group_mean_z_diag = pd.concat(arr_group_diag_container, axis = 0, keys = arr_group_codes, names = ['Group Name', 'Date'], copy = False)\n",
    "    ser_group_mean_z_diag = pd.concat(dict_group_diag_container, axis = 0, names = ['Group Name', 'Date'], copy = False)    \n",
    "    print('get_standartized_mri_data: data vector collection of diagonales of mean z score matrix for all groups builded successfully') \n",
    "    ser_group_mean_z_diag = ser_group_mean_z_diag.astype(float)    \n",
    "#    ### Collection of percentiled group's z matrices for all groups:\n",
    "#    df_group_percentiled = pd.concat(arr_group_vector_container, axis = 0, keys = arr_group_codes, names = ['Group Name', 'Date'], copy = False)\n",
    "#    print('get_standartized_mri_data: percentiled data vector collection on base of mean z score matrix for all groups builded successfully')         \n",
    "    \n",
    "#    return [df_asset_standartized, df_group_mean_z_diag, df_group_percentiled]      \n",
    "    return [ser_asset_standartized, ser_group_mean_z_diag] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_standartized_mri_data: group EQ standartizing started\n",
      "get_standartized_mri_data: asset iv_us in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_eu in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_uk in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_jp in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_rvx in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_eem in group EQ standartized successfully\n",
      "get_standartized_mri_data: z-score matrix for group EQ mean matrix builded successfully\n",
      "get_standartized_mri_data: z-score matrix for group EQ saved to HDF5 file Data_Files/Source_Files/mri_group_z_matrix.h5 (object key: EQ )\n",
      "get_standartized_mri_data: group FI standartizing started\n",
      "get_standartized_mri_data: asset oas_hy in group FI standartized successfully\n",
      "get_standartized_mri_data: asset oas_em in group FI standartized successfully\n",
      "get_standartized_mri_data: z-score matrix for group FI mean matrix builded successfully\n",
      "get_standartized_mri_data: z-score matrix for group FI saved to HDF5 file Data_Files/Source_Files/mri_group_z_matrix.h5 (object key: FI )\n",
      "get_standartized_mri_data: group FX standartizing started\n",
      "get_standartized_mri_data: asset fx_jpy in group FX standartized successfully\n",
      "get_standartized_mri_data: asset fx_gbp in group FX standartized successfully\n",
      "get_standartized_mri_data: asset fx_chf in group FX standartized successfully\n",
      "get_standartized_mri_data: asset fx_eur in group FX standartized successfully\n",
      "get_standartized_mri_data: z-score matrix for group FX mean matrix builded successfully\n",
      "get_standartized_mri_data: z-score matrix for group FX saved to HDF5 file Data_Files/Source_Files/mri_group_z_matrix.h5 (object key: FX )\n",
      "get_standartized_mri_data: asset standartized z-score collection builded successfully\n",
      "get_standartized_mri_data: data vector collection of diagonales of mean z score matrix for all groups builded successfully\n"
     ]
    }
   ],
   "source": [
    "#### STANDARTISING SOURCE DATA FOR MRI CALCUCATION\n",
    "\n",
    "### Standartizing dataset:\n",
    "### Building collection of standartized winsorized z-scores for all assets:\n",
    "### Building collection of group's z matrices diagonales for all groups:\n",
    "### Saving group's z matrices:\n",
    "[ser_standartized_assets, ser_diag_mean_z_groups] = get_standartized_mri_data(df_model_asset, df_selected_data, date_start, \n",
    "                                                                              asset_window_min, asset_window_max, arr_winsor_boundary, \n",
    "                                                                              path_mri_standart_hdf)\n",
    "### Saving results for assets to HDF5 to avoid hard calculations with constant source model and datasets:\n",
    "ser_standartized_assets.to_hdf(path_mri_assets_hdf, key = object_standartized_data_hdf, mode = 'w', format = 'fixed')\n",
    "### Saving results for groups to HDF5 to avoid hard calculations with constant source model and datasets:\n",
    "ser_diag_mean_z_groups.to_hdf(path_mri_groups_hdf, key = object_diag_grouped_hdf, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving results for assets to HDF5 to avoid hard calculations with constant source model and datasets:\n",
    "ser_standartized_assets.to_hdf(path_mri_assets_hdf, key = object_standartized_data_hdf, mode = 'w', format = 'fixed')\n",
    "### Saving results for groups to HDF5 to avoid hard calculations with constant source model and datasets:\n",
    "ser_diag_mean_z_groups.to_hdf(path_mri_groups_hdf, key = object_diag_grouped_hdf, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
