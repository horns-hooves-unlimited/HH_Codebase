{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRACTING UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "def get_market_membership_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Defining constants:\n",
    "    path_msci_data = 'Data_Files/Source_Files/sample_data_gaps.xlsx'\n",
    "    tab_monthly = 'monthly_data'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci_data, sheet_name = tab_monthly, skiprows = [0, 2], header = 0,\n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'])\n",
    "    df_universe = df_universe.loc[:, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Code']\n",
    "    df_universe.set_index(['Code', 'Date'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace({50 : 'DM', 57 : 'EM', 504 : 'FM'}, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    \n",
    "    return ser_market_membership\n",
    "\n",
    "### EXTRACTING RETURNS DATA FROM GENERAL MS EXCEL SOURCE\n",
    "def get_universe_returns_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    from datetime import date\n",
    "    ### Constants declaring:\n",
    "    path_msci_data = 'Data_Files/Source_Files/sample_data_gaps.xlsx'\n",
    "    tab_daily = 'daily_returns'\n",
    "    date_first = date(1992, 1, 1)\n",
    "    date_last = date(2018, 12, 31)\n",
    "    index_dates = pd.date_range(date_first, date_last, freq = 'B')    \n",
    "    ### Extracting returns data:\n",
    "    df_returns = pd.read_excel(io = path_msci_data, sheet_name = tab_daily, skiprows = [0, 2], header = 0,\n",
    "                               na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                            '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'])\n",
    "    df_returns = df_returns.loc[:, ['dates', 'ctry', 'retusd', 'retloc']]\n",
    "    df_returns.columns = ['Date', 'Code', 'Ret_USD', 'Ret_LOC']\n",
    "    df_returns.set_index(['Code', 'Date'], inplace = True)\n",
    "    df_returns.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_realized_ret_USD = df_returns['Ret_USD'].copy()\n",
    "    ser_realized_ret_LOC = df_returns['Ret_LOC'].copy()\n",
    "    ### Appending returns on ethalon date vector:\n",
    "    date_first = date(1992, 1, 1)\n",
    "    date_last = date(2018, 12, 31)\n",
    "    index_dates = pd.date_range(date_first, date_last, freq = 'B')\n",
    "    ### Reindexation and forward filling procedure for USD returns:\n",
    "    dict_realized_ret_USD = {}\n",
    "    ser_ret_index_USD = pd.Series(np.NaN, index = ser_realized_ret_USD.index)\n",
    "    for iter_country in ser_realized_ret_USD.index.get_level_values(0).unique():\n",
    "        ser_ret_index_USD[iter_country] = (1 + ser_realized_ret_USD[iter_country]).cumprod()\n",
    "        ser_ret_index_USD[iter_country].iloc[0] = 1\n",
    "        ser_ret_index_USD_iter = ser_ret_index_USD[iter_country].reindex(index_dates, method = 'ffill')\n",
    "        ser_ret_index_USD_iter.fillna(method = 'ffill', inplace = True)    \n",
    "        ser_realized_ret_USD_iter = (ser_ret_index_USD_iter / ser_ret_index_USD_iter.shift(1) - 1)\n",
    "        dict_realized_ret_USD[iter_country] = ser_realized_ret_USD_iter\n",
    "    ser_realized_ret_USD = pd.concat(dict_realized_ret_USD)  \n",
    "    ser_realized_ret_USD.index.names = ['Code', 'Date']\n",
    "    ser_realized_ret_USD.sort_index(level = [0, 1], inplace = True)\n",
    "    ### Reindexation and forward filling procedure for LOC returns:\n",
    "    dict_realized_ret_LOC = {}\n",
    "    ser_ret_index_LOC = pd.Series(np.NaN, index = ser_realized_ret_LOC.index)\n",
    "    for iter_country in ser_realized_ret_LOC.index.get_level_values(0).unique():\n",
    "        ser_ret_index_LOC[iter_country] = (1 + ser_realized_ret_LOC[iter_country]).cumprod()\n",
    "        ser_ret_index_LOC[iter_country].iloc[0] = 1   \n",
    "        ser_ret_index_LOC_iter = ser_ret_index_LOC[iter_country].reindex(index_dates, method = 'ffill')\n",
    "        ser_ret_index_LOC_iter.fillna(method = 'ffill', inplace = True)\n",
    "        ser_realized_ret_LOC_iter = (ser_ret_index_LOC_iter / ser_ret_index_LOC_iter.shift(1) - 1)   \n",
    "        dict_realized_ret_LOC[iter_country] = ser_realized_ret_LOC_iter\n",
    "    ser_realized_ret_LOC = pd.concat(dict_realized_ret_LOC)    \n",
    "    ser_realized_ret_LOC.index.names = ['Code', 'Date']\n",
    "    ser_realized_ret_LOC.sort_index(level = [0, 1], inplace = True)\n",
    "    \n",
    "    return [ser_realized_ret_USD, ser_realized_ret_LOC]\n",
    "\n",
    "### EXTRACTING IMPLIED VOLATILITY DATA AND VRP FACTOR DATA FROM GENERAL MS EXCEL SOURCE\n",
    "def get_universe_ivol_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    from datetime import date    \n",
    "    ### Constants declaring:\n",
    "    path_msci_data = 'Data_Files/Source_Files/sample_data_gaps.xlsx'\n",
    "    tab_ivol = 'ivol_data'\n",
    "    date_first = date(1992, 1, 1)\n",
    "    date_last = date(2018, 12, 31)\n",
    "    index_dates = pd.date_range(date_first, date_last, freq = 'B')    \n",
    "    ### Extracting ivol data:\n",
    "    df_ivol = pd.read_excel(io = path_msci_data, sheet_name = tab_ivol, skiprows = [0, 2], header = 0,\n",
    "                            na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                         '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'])\n",
    "    df_ivol = df_ivol.loc[:, ['dates', 'ctry', 'ivol3m', 'vrp3m']]\n",
    "    df_ivol.columns = ['Date', 'Code', 'IVol_3m', 'VRP_3m']\n",
    "    df_ivol.set_index(['Code', 'Date'], inplace = True)\n",
    "    df_ivol.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_ivol3m = df_ivol['IVol_3m']\n",
    "    ser_vrp3m = df_ivol['VRP_3m']    \n",
    "    ### Appending returns on ethalon date vector:\n",
    "    date_first = date(1992, 1, 1)\n",
    "    date_last = date(2018, 12, 31)\n",
    "    index_dates = pd.date_range(date_first, date_last, freq = 'B')\n",
    "    dict_ivol3m = {}\n",
    "    for iter_country in ser_ivol3m.index.get_level_values(0).unique():  \n",
    "        dict_ivol3m[iter_country] = ser_ivol3m[iter_country].reindex(index_dates, method = 'ffill')\n",
    "    ser_ivol3m = pd.concat(dict_ivol3m)    \n",
    "    ser_ivol3m.index.names = ['Code', 'Date']\n",
    "    ser_ivol3m.sort_index(level = [0, 1], inplace = True)\n",
    "    dict_vrp3m = {}\n",
    "    for iter_country in ser_vrp3m.index.get_level_values(0).unique():    \n",
    "        dict_vrp3m[iter_country] = ser_vrp3m[iter_country].reindex(index_dates, method = 'ffill')    \n",
    "    ser_vrp3m = pd.concat(dict_vrp3m)    \n",
    "    ser_vrp3m.index.names = ['Code', 'Date']\n",
    "    ser_vrp3m.sort_index(level = [0, 1], inplace = True)\n",
    "    \n",
    "    return [ser_ivol3m, ser_vrp3m]\n",
    "\n",
    "### EXTRACTING MRI INDEX FROM HDF5 SOURCE\n",
    "def get_universe_gri_from_hdf():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    ### Constants declaring:\n",
    "    path_gri_index_hdf = 'Data_Files/Source_Files/mri_released_index.h5'\n",
    "    object_released_gri_hdf = 'released_MRI_data'\n",
    "    ### Extracting MRI:\n",
    "    ser_gri_released = pd.read_hdf(path_gri_index_hdf, object_released_gri_hdf)\n",
    "        \n",
    "    return ser_gri_released\n",
    "\n",
    "### SOURCE DATA EXTRACTING FROM MS EXCEL FILES AND SAVING TO HDF FILES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "### Extracting data from xlsx files\n",
    "ser_market_membership = get_market_membership_from_excel()\n",
    "[ser_realized_ret_USD, ser_realized_ret_LOC] = get_universe_returns_from_excel()\n",
    "[ser_ivol3m, ser_vrp3m] = get_universe_ivol_from_excel()\n",
    "ser_gri_released = get_universe_gri_from_hdf()\n",
    "ser_gri_released.name = 'GRI'\n",
    "### Declaring constants:\n",
    "path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "market_membership_key = 'market_membership_key'\n",
    "realized_ret_USD_key = 'realized_ret_USD_key'\n",
    "realized_ret_LOC_key = 'realized_ret_LOC_key'\n",
    "ivol3m_key = 'ivol3m_key'\n",
    "vrp3m_key = 'vrp3m_key'\n",
    "gri_released_key = 'gri_released_key'\n",
    "### Saving data to hdf5 table formatted files:\n",
    "import tables\n",
    "tables.file._open_files.close_all()\n",
    "ser_market_membership.to_hdf(path_market_risk_source_hdf, market_membership_key, mode = 'w', format = 'table')\n",
    "ser_realized_ret_USD.to_hdf(path_market_risk_source_hdf, realized_ret_USD_key, mode = 'a', format = 'table')\n",
    "ser_realized_ret_LOC.to_hdf(path_market_risk_source_hdf, realized_ret_LOC_key, mode = 'a', format = 'table')\n",
    "ser_ivol3m.to_hdf(path_market_risk_source_hdf, ivol3m_key, mode = 'a', format = 'table')\n",
    "ser_vrp3m.to_hdf(path_market_risk_source_hdf, vrp3m_key, mode = 'a', format = 'table')\n",
    "ser_gri_released.to_hdf(path_market_risk_source_hdf, gri_released_key, mode = 'a', format = 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRACTING UNIVERSE DATA FOR A PARTICULAR DATE\n",
    "def get_date_membership(iter_date):\n",
    "    ### Defining constants:    \n",
    "    path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "    market_membership_key = 'market_membership_key'  \n",
    "    ### Preparing data for universe filtering:\n",
    "    if (pd.to_datetime(iter_date) == pd.to_datetime(iter_date - pd.offsets.BusinessMonthEnd(0))):\n",
    "        iter_month_end = iter_date\n",
    "    else: \n",
    "        iter_month_end = pd.to_datetime(iter_date - pd.offsets.BusinessMonthEnd(1))    \n",
    "    ser_iter_membership = pd.read_hdf(path_market_risk_source_hdf, market_membership_key, where = 'Date = iter_month_end')\n",
    "    ser_iter_membership.rename(index = {iter_month_end : iter_date}, inplace = True)\n",
    "    \n",
    "    return ser_iter_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXPONENTIAL WEIGHTS GENERATOR\n",
    "def get_exp_weights(window_years = 5, halflife_months = 3):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import math     \n",
    "    ### Defining constants:\n",
    "    num_year_work_days = 260\n",
    "    num_year_months = 12\n",
    "    ### Array of regressioon window day numbers descending:\n",
    "    arr_weight_days = np.arange(num_year_work_days * window_years, 0, -1) - 1\n",
    "    ### Creating weights series:\n",
    "    num_period_factor = math.exp(math.log(0.5) / round((num_year_work_days / num_year_months * halflife_months)))\n",
    "    arr_weights = np.exp(math.log(num_period_factor) * arr_weight_days)\n",
    "    ser_weights = pd.Series(arr_weights)        \n",
    "    ser_weights.name = 'Weight'\n",
    "    \n",
    "    return ser_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING WEIGHTS TO SERIES BINDER\n",
    "def bind_exp_weights(ser_returns, weighting_kind = 'equal', window_years = 5, halflife_months = 3, ser_condition = pd.Series(np.NaN)):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Creating weights series:\n",
    "    if (weighting_kind == 'equal'):\n",
    "        ser_weights = pd.Series(1, index = ser_returns.index)\n",
    "    if (weighting_kind == 'expo'):       \n",
    "        ser_weights = get_exp_weights(window_years, halflife_months)[- ser_returns.size : ]\n",
    "        ser_weights.index = ser_returns.index\n",
    "    if (weighting_kind == 'expo_cond'):\n",
    "        ser_condition = abs(ser_condition - ser_condition.iloc[-1])\n",
    "        ser_condition = ser_condition.sort_values(ascending = False)\n",
    "        ser_weights = get_exp_weights(window_years, halflife_months)[- ser_returns.size : ]\n",
    "        ser_weights = pd.Series(ser_weights.values, ser_condition.index)\n",
    "        ser_weights.sort_index(inplace = True)\n",
    "        ser_weights.name = 'Weight'\n",
    "        \n",
    "    return ser_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXPONENTIAL VOLATILITY CALCULATOR\n",
    "def get_expvol_value(ser_returns, ser_weights):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Exponential volatility calculating:\n",
    "    expvol_result = np.NaN\n",
    "    ser_returns = ser_returns.dropna()\n",
    "    index_rolling = ser_returns.index.intersection(ser_weights.index)           \n",
    "    ### Exponential volatility calculating:\n",
    "    expvol_y = ser_returns[index_rolling]\n",
    "    expvol_w = ser_weights[index_rolling]             \n",
    "    expvol_w = expvol_w / expvol_w.sum()\n",
    "    expvol_result = np.sqrt(expvol_w.dot(expvol_y * expvol_y))\n",
    "        \n",
    "    return expvol_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINING EXPONENTIAL VOLATILITY SERIES BUILDER\n",
    "def get_expvol_series(ser_market_membership, ser_returns, weighting_kind = 'equal', window_years = 5, halflife_months = 3, ser_condition = pd.Series(np.NaN)):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Defining constants:\n",
    "    num_year_work_days = 260\n",
    "    ### Flattening MSCI changes by logarythm\n",
    "    ser_returns = np.log(1 + ser_returns)\n",
    "    ser_condition.fillna(method = 'ffill', inplace = True)\n",
    "    ### Main loop performing:\n",
    "    ser_expvol = pd.Series(np.NaN, index = ser_market_membership.index)\n",
    "    for iter_country in ser_market_membership.index.get_level_values(0).unique():        \n",
    "        ### Extracting returns data vector for each country/date point:\n",
    "        if (iter_country in ser_returns.index.get_level_values(0).unique()):\n",
    "            for iter_date in ser_market_membership[iter_country].index.get_level_values(0).unique():\n",
    "                ser_iter_returns = ser_returns[iter_country].loc[iter_date - pd.offsets.BusinessDay(num_year_work_days * window_years - 1) : iter_date]\n",
    "                ser_iter_returns = ser_iter_returns - ser_iter_returns.mean()\n",
    "                if (ser_iter_returns.size > 0):\n",
    "                    if (ser_condition.count() > 0):\n",
    "                        ser_iter_condition = ser_condition[ser_iter_returns.index]\n",
    "                    else:\n",
    "                        ser_iter_condition = pd.Series(np.NaN)                     \n",
    "                    ser_iter_weights = bind_exp_weights(ser_iter_returns, weighting_kind, window_years, halflife_months, ser_iter_condition) ## CHANGES: ADDED       \n",
    "                ser_iter_returns.dropna(inplace = True)     \n",
    "                if (ser_iter_returns.count() > num_year_work_days // 2):\n",
    "                    expvol_result = get_expvol_value(ser_iter_returns, ser_iter_weights) * np.sqrt(num_year_work_days)\n",
    "                    ser_expvol.loc[iter_country, iter_date] = expvol_result\n",
    "                    \n",
    "    return ser_expvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING SKEWNESS CALCULATOR\n",
    "def get_skewness_value(ser_returns):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import scipy.stats as sc    \n",
    "    ### Defining constants:\n",
    "    num_year_work_days = 260\n",
    "    ### Skewness calculating:\n",
    "    skewness_result = np.NaN\n",
    "    ser_returns = ser_returns.dropna()\n",
    "    if (ser_returns.count() > num_year_work_days // 2):\n",
    "        skewness_result = sc.skew(ser_returns, bias = False)\n",
    "        \n",
    "    return skewness_result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING SKEWNESS SERIES BUILDER\n",
    "def get_skewness_series(ser_market_membership, ser_returns, window_years = 2):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Defining constants:\n",
    "    num_year_work_days = 260\n",
    "    ### Main loop performing:\n",
    "    ser_skewness = pd.Series(np.NaN, index = ser_market_membership.index)\n",
    "    for iter_country in ser_market_membership.index.get_level_values(0).unique():        \n",
    "        ### Extracting returns data vector for each country/date point:\n",
    "        if (iter_country in ser_returns.index.get_level_values(0).unique()):\n",
    "            for iter_date in ser_market_membership[iter_country].index.get_level_values(0).unique():\n",
    "                ser_iter_returns = ser_returns[iter_country].loc[iter_date - pd.offsets.BusinessDay(num_year_work_days * window_years - 1) : iter_date].dropna()     \n",
    "                if (ser_iter_returns.count() > num_year_work_days // 2):\n",
    "                    skewness_result = get_skewness_value(ser_iter_returns)\n",
    "                    ser_skewness.loc[iter_country, iter_date] = skewness_result\n",
    "\n",
    "    return ser_skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING READY TO GO FACTOR SERIES BUILDER\n",
    "def get_market_series(ser_market_membership, ser_returns, window_years = 5):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Defining constants:\n",
    "    num_year_work_days = 260\n",
    "    ### Main loop performing:\n",
    "    ser_market = pd.Series(np.NaN, index = ser_market_membership.index)\n",
    "    for iter_country in ser_market_membership.index.get_level_values(0).unique():        \n",
    "        ### Extracting returns data vector for each country/date point:\n",
    "        if (iter_country in ser_returns.index.get_level_values(0).unique()):\n",
    "            for iter_date in ser_market_membership[iter_country].index.get_level_values(0).unique():\n",
    "                ser_iter_returns = ser_returns[iter_country].loc[iter_date - pd.offsets.BusinessDay(num_year_work_days * window_years - 1) : iter_date].dropna()     \n",
    "                if (ser_iter_returns.count() > num_year_work_days // 4):\n",
    "                    ser_market.loc[iter_country, iter_date] = ser_returns.loc[iter_country, iter_date]\n",
    "\n",
    "    return ser_market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING WEIGHTED AVERAGE CALCULATOR\n",
    "def get_average_value(ser_returns, ser_weights):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Rolling average calculating:\n",
    "    average_result = np.NaN  \n",
    "    ser_returns = ser_returns.dropna()\n",
    "    index_rolling = ser_returns.index.intersection(ser_weights.index)           \n",
    "    ### Exponential volatility calculating:\n",
    "    average_x = ser_returns[index_rolling]\n",
    "    average_w = ser_weights[index_rolling]                    \n",
    "    average_result = average_x.dot(average_w) / sum(average_w)        \n",
    "        \n",
    "    return average_result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING WEIGHTED AVERAGE SERIES BUILDER\n",
    "def get_average_series(ser_market_membership, ser_returns, weighting_kind = 'equal', window_years = 5, halflife_months = 3, ser_condition = pd.Series(np.NaN)):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Defining constants:\n",
    "    num_year_work_days = 260\n",
    "    ### Initialising delta series:\n",
    "    ser_condition.fillna(method = 'ffill', inplace = True)        \n",
    "    ### Main loop performing:\n",
    "    ser_average = pd.Series(np.NaN, index = ser_market_membership.index)\n",
    "    for iter_country in ser_market_membership.index.get_level_values(0).unique():        \n",
    "        ### Extracting returns data vector for each country/date point:\n",
    "        if (iter_country in ser_returns.index.get_level_values(0).unique()):\n",
    "            for iter_date in ser_market_membership[iter_country].index.get_level_values(0).unique():\n",
    "                ser_iter_returns = ser_returns[iter_country].loc[iter_date - pd.offsets.BusinessDay(num_year_work_days * window_years - 1) : iter_date]\n",
    "                if (ser_iter_returns.size > 0):\n",
    "                    if (ser_condition.count() > 0):\n",
    "                        ser_iter_condition = ser_condition[ser_iter_returns.index]\n",
    "                    else:\n",
    "                        ser_iter_condition = pd.Series(np.NaN)                      \n",
    "                    ser_iter_weights = bind_exp_weights(ser_iter_returns, weighting_kind, window_years, halflife_months, ser_iter_condition)                 \n",
    "                ser_iter_returns = ser_iter_returns - ser_iter_returns.shift(1)        \n",
    "                ser_iter_returns = ser_iter_returns.dropna()[ser_iter_returns != 0]\n",
    "                if (ser_iter_returns.count() > num_year_work_days // 4):\n",
    "                    average_result = get_average_value(ser_iter_returns, ser_iter_weights)\n",
    "                    ser_average.loc[iter_country, iter_date] = average_result\n",
    "    ser_average.sort_index(level = [0, 1], inplace = True)\n",
    "    \n",
    "    return ser_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET SHORT TERM EVENT RISK FACTOR\n",
    "def get_short_term_event_risk_factor(iter_date):\n",
    "    ### Importing standard modules and date-special modules (common for all factors):\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    ### Constants declaring (common for all factors):  \n",
    "    num_year_work_days = 260\n",
    "    window_years = 5\n",
    "    path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "    realized_ret_LOC_key = 'realized_ret_LOC_key'    \n",
    "    ### Data preparing (common for all factors):\n",
    "    index_iter_date = pd.date_range(end = iter_date, periods = num_year_work_days * window_years, freq = 'B')\n",
    "    ser_iter_membership = get_date_membership(iter_date)\n",
    "    ### Impossible to add country filter here:\n",
    "    ser_iter_returns = pd.read_hdf(path_market_risk_source_hdf, realized_ret_LOC_key, where = 'Date in index_iter_date')\n",
    "    ### Factor calculation:\n",
    "    ser_iter_factor = - get_expvol_series(ser_iter_membership, ser_iter_returns, 'expo', window_years, 1)\n",
    "            \n",
    "    return ser_iter_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET LOW VOLATILITY ANOMALY FACTOR\n",
    "def get_low_vol_factor(iter_date):\n",
    "    ### Importing standard modules and date-special modules (common for all factors):\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    ### Constants declaring (common for all factors):  \n",
    "    num_year_work_days = 260\n",
    "    window_years = 5  \n",
    "    path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "    realized_ret_LOC_key = 'realized_ret_LOC_key'     \n",
    "    ### Data preparing (common for all factors):\n",
    "    index_iter_date = pd.date_range(end = iter_date, periods = num_year_work_days * window_years, freq = 'B')\n",
    "    ser_iter_membership = get_date_membership(iter_date)\n",
    "    ### Impossible to add country filter here:    \n",
    "    ser_iter_returns = pd.read_hdf(path_market_risk_source_hdf, realized_ret_LOC_key, where = 'Date in index_iter_date')\n",
    "    ### Factor calculation:\n",
    "    ser_expvol24m = get_expvol_series(ser_iter_membership, ser_iter_returns, 'expo', window_years, 24)\n",
    "    ser_lowvol_base = 1 / (ser_expvol24m * ser_expvol24m)\n",
    "    ser_lowvol_base.replace([np.inf, -np.inf], np.nan, inplace = True)    \n",
    "    ser_lowvol_base = ser_lowvol_base.swaplevel()\n",
    "    ser_lowvol_base.sort_index(inplace = True)\n",
    "    ser_lowvol = pd.Series(np.NaN, index = ser_lowvol_base.index)\n",
    "    for iter_date in ser_lowvol.index.get_level_values(0).unique():  \n",
    "        ser_lowvol[iter_date] = (ser_lowvol_base[iter_date] / ser_lowvol_base[iter_date].sum())\n",
    "    ser_lowvol = ser_lowvol.swaplevel()\n",
    "    ser_iter_factor = ser_lowvol.sort_index()\n",
    "            \n",
    "    return ser_iter_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET VOLATILITY SURPRISE FACTOR\n",
    "def get_vol_surprise_factor(iter_date):\n",
    "    ### Importing standard modules and date-special modules (common for all factors):\n",
    "    import numpy as np\n",
    "    import pandas as pd     \n",
    "    ### Constants declaring (common for all factors):  \n",
    "    num_year_work_days = 260\n",
    "    window_years = 5    \n",
    "    path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "    realized_ret_LOC_key = 'realized_ret_LOC_key'\n",
    "    gri_released_key = 'gri_released_key'    \n",
    "    ### Data preparing (common for all factors):\n",
    "    index_iter_date = pd.date_range(end = iter_date, periods = num_year_work_days * window_years, freq = 'B')\n",
    "    ser_iter_membership = get_date_membership(iter_date)\n",
    "    ser_iter_returns = pd.read_hdf(path_market_risk_source_hdf, realized_ret_LOC_key, where = 'Date in index_iter_date')\n",
    "    ser_iter_condition = pd.read_hdf(path_market_risk_source_hdf, gri_released_key, where = 'index in index_iter_date')\n",
    "    ### Factor calculation:\n",
    "    ser_expvol1m = get_expvol_series(ser_iter_membership, ser_iter_returns, 'expo', window_years, 1)\n",
    "    ser_expvol1m_cond = get_expvol_series(ser_iter_membership, ser_iter_returns, 'expo_cond', window_years, 1, ser_iter_condition)\n",
    "    ser_expvol1m_surp = -np.log(ser_expvol1m / ser_expvol1m_cond)\n",
    "    ser_iter_factor = ser_expvol1m_surp \n",
    "    \n",
    "    return ser_iter_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET TAIL RISK FACTOR\n",
    "def get_tail_risk_factor(iter_date):\n",
    "    ### Importing standard modules and date-special modules (common for all factors):\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    ### Constants declaring (common for all factors):  \n",
    "    num_year_work_days = 260\n",
    "    window_years = 5    \n",
    "    path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "    realized_ret_LOC_key = 'realized_ret_LOC_key'    \n",
    "    ### Data preparing (common for all factors):\n",
    "    index_iter_date = pd.date_range(end = iter_date, periods = num_year_work_days * window_years, freq = 'B')\n",
    "    ser_iter_membership = get_date_membership(iter_date)\n",
    "    ser_iter_returns = pd.read_hdf(path_market_risk_source_hdf, realized_ret_LOC_key, where = 'Date in index_iter_date')\n",
    "    ### Factor calculation:\n",
    "    ser_iter_factor = - get_skewness_series(ser_iter_membership, ser_iter_returns, 2) \n",
    "    \n",
    "    return ser_iter_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET VRP FACTOR\n",
    "def get_vrp_factor(iter_date):\n",
    "    ### Importing standard modules and date-special modules (common for all factors):\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    ### Constants declaring (common for all factors):  \n",
    "    num_year_work_days = 260\n",
    "    window_years = 5  \n",
    "    path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "    vrp3m_key = 'vrp3m_key'   \n",
    "    ### Data preparing (common for all factors):\n",
    "    index_iter_date = pd.date_range(end = iter_date, periods = num_year_work_days * window_years, freq = 'B')\n",
    "    ser_iter_membership = get_date_membership(iter_date)\n",
    "    ser_iter_vrp = pd.read_hdf(path_market_risk_source_hdf, vrp3m_key, where = 'Date in index_iter_date')\n",
    "    ### Factor calculation:\n",
    "    ser_iter_factor = get_market_series(ser_iter_membership, ser_iter_vrp, 5) \n",
    "    \n",
    "    return ser_iter_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET IMPLIED VOLATILITY SHORT TERM MOMENTUM FACTOR\n",
    "def get_ivol_mom_1m_factor(iter_date):\n",
    "    ### Importing standard modules and date-special modules (common for all factors):\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    ### Constants declaring (common for all factors):  \n",
    "    num_year_work_days = 260\n",
    "    window_years = 5    \n",
    "    path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "    ivol3m_key = 'ivol3m_key'  \n",
    "    ### Data preparing (common for all factors):\n",
    "    index_iter_date = pd.date_range(end = iter_date, periods = num_year_work_days * window_years, freq = 'B')\n",
    "    ser_iter_membership = get_date_membership(iter_date)\n",
    "    ser_iter_ivol = pd.read_hdf(path_market_risk_source_hdf, ivol3m_key, where = 'Date in index_iter_date') \n",
    "    ### Factor calculation:\n",
    "    ser_iter_factor = get_average_series(ser_iter_membership, ser_iter_ivol, 'expo', 5, 1) \n",
    "\n",
    "    return ser_iter_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET IMPLIED VOLATILITY SHORT TERM MOMENTUM FACTOR\n",
    "def get_ivol_mom_12m_factor(iter_date):\n",
    "    ### Importing standard modules and date-special modules (common for all factors):\n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    ### Constants declaring (common for all factors):  \n",
    "    num_year_work_days = 260\n",
    "    window_years = 5   \n",
    "    path_market_risk_source_hdf = 'Data_Files/Source_Files/market_risk_source.h5'\n",
    "    ivol3m_key = 'ivol3m_key'      \n",
    "    ### Data preparing (common for all factors):\n",
    "    index_iter_date = pd.date_range(end = iter_date, periods = num_year_work_days * window_years, freq = 'B')\n",
    "    ser_iter_membership = get_date_membership(iter_date)\n",
    "    ser_iter_ivol = pd.read_hdf(path_market_risk_source_hdf, ivol3m_key, where = 'Date in index_iter_date')\n",
    "    ### Factor calculation:\n",
    "    ser_iter_factor = get_average_series(ser_iter_membership, ser_iter_ivol, 'expo', 5, 12) \n",
    "    \n",
    "    return ser_iter_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOOPER FOR SHORT TERM EVENT RISK FACTOR\n",
    "#date_range_test = pd.date_range(start = '2010-10-25', periods = 6)\n",
    "date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()\n",
    "#date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()[155 : 160]\n",
    "arr_short_term_event_risk_factor = []\n",
    "iter_counter = 0\n",
    "for iter_date in date_range_test:\n",
    "    iter_counter = iter_counter + 1\n",
    "    arr_short_term_event_risk_factor.append(get_short_term_event_risk_factor(iter_date))\n",
    "    if ((iter_counter // 10) == (iter_counter / 10)):\n",
    "        print('Progress printout',iter_counter, '/', iter_date)\n",
    "ser_short_term_event_risk_factor = pd.concat(arr_short_term_event_risk_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser_short_term_event_risk_factor - AR 29-Dec-2006: -0.20481093607134887\n",
      "ser_short_term_event_risk_factor - US 29-Dec-2006: -0.07665226549320425\n",
      "ser_short_term_event_risk_factor - cross-sectional mean min: -0.6481452307554286\n",
      "ser_short_term_event_risk_factor - cross-sectional mean mean: -0.20580347657372047\n",
      "ser_short_term_event_risk_factor - cross-sectional mean max: -0.11338560985788693\n",
      "ser_short_term_event_risk_factor - cross-sectional mean stdev: 0.07019715778814863\n",
      "ser_short_term_event_risk_factor - cross-sectional mean mean: 234\n"
     ]
    }
   ],
   "source": [
    "### SHORT TERM EVENT RISK FACTOR TESTING:\n",
    "print('ser_short_term_event_risk_factor - AR 29-Dec-2006:', ser_short_term_event_risk_factor.loc['AR' , '2006-12-29'])\n",
    "print('ser_short_term_event_risk_factor - US 29-Dec-2006:', ser_short_term_event_risk_factor.loc['US' , '2006-12-29'])\n",
    "ser_short_term_event_risk_factor_mean = pd.Series(np.NaN, index = ser_short_term_event_risk_factor.index.get_level_values(1).unique())\n",
    "for iter_date in ser_short_term_event_risk_factor_mean.index:  \n",
    "    ser_short_term_event_risk_factor_mean[iter_date] = ser_short_term_event_risk_factor.loc[:, iter_date].mean()\n",
    "ser_short_term_event_risk_factor_mean.sort_index(inplace = True)\n",
    "print('ser_short_term_event_risk_factor - cross-sectional mean min:', ser_short_term_event_risk_factor_mean.min())\n",
    "print('ser_short_term_event_risk_factor - cross-sectional mean mean:', ser_short_term_event_risk_factor_mean.mean())\n",
    "print('ser_short_term_event_risk_factor - cross-sectional mean max:', ser_short_term_event_risk_factor_mean.max())\n",
    "print('ser_short_term_event_risk_factor - cross-sectional mean stdev:', ser_short_term_event_risk_factor_mean.std())\n",
    "print('ser_short_term_event_risk_factor - cross-sectional mean mean:', ser_short_term_event_risk_factor_mean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOOPER FOR LOW VOLATILITY ANOMALY FACTOR\n",
    "#date_range_test = pd.date_range(start = '2010-10-25', periods = 6)\n",
    "date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()\n",
    "#date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()[155 : 160]\n",
    "arr_low_vol_factor = []\n",
    "iter_counter = 0\n",
    "for iter_date in date_range_test:\n",
    "    iter_counter = iter_counter + 1\n",
    "    arr_low_vol_factor.append(get_low_vol_factor(iter_date))\n",
    "    if ((iter_counter // 10) == (iter_counter / 10)):\n",
    "        print('Progress printout',iter_counter, '/', iter_date)\n",
    "        \n",
    "ser_low_vol_factor = pd.concat(arr_low_vol_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser_low_vol_factor - AR 29-Dec-2006: 0.007339857068326828\n",
      "ser_low_vol_factor - US 29-Dec-2006: 0.03595279045940818\n",
      "ser_low_vol_factor - cross-sectional mean min: 0.02040816326530611\n",
      "ser_low_vol_factor - cross-sectional mean mean: 0.02255744652417695\n",
      "ser_low_vol_factor - cross-sectional mean max: 0.04545454545454546\n",
      "ser_low_vol_factor - cross-sectional mean stdev: 0.006440980492665572\n",
      "ser_low_vol_factor - cross-sectional mean mean: 234\n"
     ]
    }
   ],
   "source": [
    "### LOW VOLATILITY ANOMALY FACTOR TESTING:\n",
    "print('ser_low_vol_factor - AR 29-Dec-2006:', ser_low_vol_factor.loc['AR' , '2006-12-29'])\n",
    "print('ser_low_vol_factor - US 29-Dec-2006:', ser_low_vol_factor.loc['US' , '2006-12-29'])\n",
    "ser_low_vol_factor_mean = pd.Series(np.NaN, index = ser_low_vol_factor.index.get_level_values(1).unique())\n",
    "for iter_date in ser_low_vol_factor_mean.index:  \n",
    "    ser_low_vol_factor_mean[iter_date] = ser_low_vol_factor.loc[:, iter_date].mean()\n",
    "ser_low_vol_factor_mean.sort_index(inplace = True)\n",
    "print('ser_low_vol_factor - cross-sectional mean min:', ser_low_vol_factor_mean.min())\n",
    "print('ser_low_vol_factor - cross-sectional mean mean:', ser_low_vol_factor_mean.mean())\n",
    "print('ser_low_vol_factor - cross-sectional mean max:', ser_low_vol_factor_mean.max())\n",
    "print('ser_low_vol_factor - cross-sectional mean stdev:', ser_low_vol_factor_mean.std())\n",
    "print('ser_low_vol_factor - cross-sectional mean mean:', ser_low_vol_factor_mean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOOPER FOR VOLATILITY SURPRISE FACTOR\n",
    "#date_range_test = pd.date_range(start = '2010-10-25', periods = 6)\n",
    "date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()\n",
    "#date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()[155 : 157]\n",
    "arr_vol_surprise_factor = []\n",
    "iter_counter = 0\n",
    "for iter_date in date_range_test:\n",
    "    iter_counter = iter_counter + 1\n",
    "    arr_vol_surprise_factor.append(get_vol_surprise_factor(iter_date))\n",
    "    if ((iter_counter // 10) == (iter_counter / 10)):\n",
    "        print('Progress printout',iter_counter, '/', iter_date)\n",
    "        \n",
    "ser_vol_surprise_factor = pd.concat(arr_vol_surprise_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser_vol_surprise_factor - AR 29-Dec-2006: -0.01821011250865118\n",
      "ser_vol_surprise_factor - US 29-Dec-2006: 0.04654380270481559\n",
      "ser_vol_surprise_factor - cross-sectional mean min: -0.4444349951854927\n",
      "ser_vol_surprise_factor - cross-sectional mean mean: 0.008079627718946126\n",
      "ser_vol_surprise_factor - cross-sectional mean max: 0.2751807419294589\n",
      "ser_vol_surprise_factor - cross-sectional mean stdev: 0.11092389390929216\n",
      "ser_vol_surprise_factor - cross-sectional mean mean: 234\n"
     ]
    }
   ],
   "source": [
    "### VOLATILITY SURPRISE FACTOR TESTING:\n",
    "print('ser_vol_surprise_factor - AR 29-Dec-2006:', ser_vol_surprise_factor.loc['AR' , '2006-12-29'])\n",
    "print('ser_vol_surprise_factor - US 29-Dec-2006:', ser_vol_surprise_factor.loc['US' , '2006-12-29'])\n",
    "ser_vol_surprise_factor_mean = pd.Series(np.NaN, index = ser_vol_surprise_factor.index.get_level_values(1).unique())\n",
    "for iter_date in ser_vol_surprise_factor_mean.index:  \n",
    "    ser_vol_surprise_factor_mean[iter_date] = ser_vol_surprise_factor.loc[:, iter_date].mean()\n",
    "ser_vol_surprise_factor_mean.sort_index(inplace = True)\n",
    "print('ser_vol_surprise_factor - cross-sectional mean min:', ser_vol_surprise_factor_mean.min())\n",
    "print('ser_vol_surprise_factor - cross-sectional mean mean:', ser_vol_surprise_factor_mean.mean())\n",
    "print('ser_vol_surprise_factor - cross-sectional mean max:', ser_vol_surprise_factor_mean.max())\n",
    "print('ser_vol_surprise_factor - cross-sectional mean stdev:', ser_vol_surprise_factor_mean.std())\n",
    "print('ser_vol_surprise_factor - cross-sectional mean mean:', ser_vol_surprise_factor_mean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOOPER FOR TAIL RISK FACTOR\n",
    "#date_range_test = pd.date_range(start = '2010-10-25', periods = 6)\n",
    "date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()\n",
    "#date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()[155 : 160]\n",
    "arr_tail_risk_factor = []\n",
    "iter_counter = 0\n",
    "for iter_date in date_range_test:\n",
    "    iter_counter = iter_counter + 1\n",
    "    arr_tail_risk_factor.append(get_tail_risk_factor(iter_date))\n",
    "    if ((iter_counter // 10) == (iter_counter / 10)):\n",
    "        print('Progress printout',iter_counter, '/', iter_date)\n",
    "        \n",
    "ser_tail_risk_factor = pd.concat(arr_tail_risk_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser_tail_risk_factor - AR 29-Dec-2006: -0.03928688949001212\n",
      "ser_tail_risk_factor - US 29-Dec-2006: -0.08036479847853283\n",
      "ser_tail_risk_factor - cross-sectional mean min: -0.3488438785320589\n",
      "ser_tail_risk_factor - cross-sectional mean mean: 0.08670576665299318\n",
      "ser_tail_risk_factor - cross-sectional mean max: 0.49624621808319275\n",
      "ser_tail_risk_factor - cross-sectional mean stdev: 0.16573629072456478\n",
      "ser_tail_risk_factor - cross-sectional mean mean: 234\n"
     ]
    }
   ],
   "source": [
    "### TAIL RISK FACTOR TESTING:\n",
    "print('ser_tail_risk_factor - AR 29-Dec-2006:', ser_tail_risk_factor.loc['AR' , '2006-12-29'])\n",
    "print('ser_tail_risk_factor - US 29-Dec-2006:', ser_tail_risk_factor.loc['US' , '2006-12-29'])\n",
    "ser_tail_risk_factor_mean = pd.Series(np.NaN, index = ser_tail_risk_factor.index.get_level_values(1).unique())\n",
    "for iter_date in ser_tail_risk_factor_mean.index:  \n",
    "    ser_tail_risk_factor_mean[iter_date] = ser_tail_risk_factor.loc[:, iter_date].mean()\n",
    "ser_tail_risk_factor_mean.sort_index(inplace = True)\n",
    "print('ser_tail_risk_factor - cross-sectional mean min:', ser_tail_risk_factor_mean.min())\n",
    "print('ser_tail_risk_factor - cross-sectional mean mean:', ser_tail_risk_factor_mean.mean())\n",
    "print('ser_tail_risk_factor - cross-sectional mean max:', ser_tail_risk_factor_mean.max())\n",
    "print('ser_tail_risk_factor - cross-sectional mean stdev:', ser_tail_risk_factor_mean.std())\n",
    "print('ser_tail_risk_factor - cross-sectional mean mean:', ser_tail_risk_factor_mean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOOPER FOR VRP FACTOR\n",
    "#date_range_test = pd.date_range(start = '2010-10-25', periods = 6)\n",
    "date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()\n",
    "#date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()[155 : 160]\n",
    "arr_vrp_factor = []\n",
    "iter_counter = 0\n",
    "for iter_date in date_range_test:\n",
    "    iter_counter = iter_counter + 1\n",
    "    arr_vrp_factor.append(get_vrp_factor(iter_date))\n",
    "    if ((iter_counter // 10) == (iter_counter / 10)):\n",
    "        print('Progress printout',iter_counter, '/', iter_date)\n",
    "        \n",
    "ser_vrp_factor = pd.concat(arr_vrp_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser_vrp_factor - AR 29-Dec-2006: 0.00163\n",
      "ser_vrp_factor - US 29-Dec-2006: -0.004396\n",
      "ser_vrp_factor - cross-sectional mean min: -0.023387673469387766\n",
      "ser_vrp_factor - cross-sectional mean mean: 0.002256157878726162\n",
      "ser_vrp_factor - cross-sectional mean max: 0.036017938775510204\n",
      "ser_vrp_factor - cross-sectional mean stdev: 0.00794579999880406\n",
      "ser_vrp_factor - cross-sectional mean mean: 237\n"
     ]
    }
   ],
   "source": [
    "### VRP FACTOR TESTING:\n",
    "print('ser_vrp_factor - AR 29-Dec-2006:', ser_vrp_factor.loc['AR' , '2006-12-29'])\n",
    "print('ser_vrp_factor - US 29-Dec-2006:', ser_vrp_factor.loc['US' , '2006-12-29'])\n",
    "ser_vrp_factor_mean = pd.Series(np.NaN, index = ser_vrp_factor.index.get_level_values(1).unique())\n",
    "for iter_date in ser_vrp_factor_mean.index:  \n",
    "    ser_vrp_factor_mean[iter_date] = ser_vrp_factor.loc[:, iter_date].mean()\n",
    "ser_vrp_factor_mean.sort_index(inplace = True)\n",
    "print('ser_vrp_factor - cross-sectional mean min:', ser_vrp_factor_mean.min())\n",
    "print('ser_vrp_factor - cross-sectional mean mean:', ser_vrp_factor_mean.mean())\n",
    "print('ser_vrp_factor - cross-sectional mean max:', ser_vrp_factor_mean.max())\n",
    "print('ser_vrp_factor - cross-sectional mean stdev:', ser_vrp_factor_mean.std())\n",
    "print('ser_vrp_factor - cross-sectional mean mean:', ser_vrp_factor_mean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOOPER FOR IVOL MOMENTUM 1M FACTOR\n",
    "#date_range_test = pd.date_range(start = '2010-10-25', periods = 6)\n",
    "date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()\n",
    "#date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()[155 : 160]\n",
    "arr_ivol_mom_1m_factor = []\n",
    "iter_counter = 0\n",
    "for iter_date in date_range_test:\n",
    "    iter_counter = iter_counter + 1\n",
    "    arr_ivol_mom_1m_factor.append(get_ivol_mom_1m_factor(iter_date))\n",
    "    if ((iter_counter // 10) == (iter_counter / 10)):\n",
    "        print('Progress printout',iter_counter, '/', iter_date)\n",
    "        \n",
    "ser_ivol_mom_1m_factor = pd.concat(arr_ivol_mom_1m_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser_ivol_mom_1m_factor - AR 29-Dec-2006: -5.728833933486413e-05\n",
      "ser_ivol_mom_1m_factor - US 29-Dec-2006: -0.0001643642124898838\n",
      "ser_ivol_mom_1m_factor - cross-sectional mean min: -0.0007719988881806511\n",
      "ser_ivol_mom_1m_factor - cross-sectional mean mean: 6.00820444231159e-05\n",
      "ser_ivol_mom_1m_factor - cross-sectional mean max: 0.0011461061607235408\n",
      "ser_ivol_mom_1m_factor - cross-sectional mean stdev: 0.0002536959457065397\n",
      "ser_ivol_mom_1m_factor - cross-sectional mean mean: 237\n"
     ]
    }
   ],
   "source": [
    "### IVOL MOMENTUM 1M FACTOR TESTING:\n",
    "print('ser_ivol_mom_1m_factor - AR 29-Dec-2006:', ser_ivol_mom_1m_factor.loc['AR' , '2006-12-29'])\n",
    "print('ser_ivol_mom_1m_factor - US 29-Dec-2006:', ser_ivol_mom_1m_factor.loc['US' , '2006-12-29'])\n",
    "ser_ivol_mom_1m_factor_mean = pd.Series(np.NaN, index = ser_ivol_mom_1m_factor.index.get_level_values(1).unique())\n",
    "for iter_date in ser_ivol_mom_1m_factor_mean.index:  \n",
    "    ser_ivol_mom_1m_factor_mean[iter_date] = ser_ivol_mom_1m_factor.loc[:, iter_date].mean()\n",
    "ser_ivol_mom_1m_factor_mean.sort_index(inplace = True)\n",
    "print('ser_ivol_mom_1m_factor - cross-sectional mean min:', ser_ivol_mom_1m_factor_mean.min())\n",
    "print('ser_ivol_mom_1m_factor - cross-sectional mean mean:', ser_ivol_mom_1m_factor_mean.mean())\n",
    "print('ser_ivol_mom_1m_factor - cross-sectional mean max:', ser_ivol_mom_1m_factor_mean.max())\n",
    "print('ser_ivol_mom_1m_factor - cross-sectional mean stdev:', ser_ivol_mom_1m_factor_mean.std())\n",
    "print('ser_ivol_mom_1m_factor - cross-sectional mean mean:', ser_ivol_mom_1m_factor_mean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress printout 10 / 1994-10-31 00:00:00\n",
      "Progress printout 20 / 1995-08-31 00:00:00\n",
      "Progress printout 30 / 1996-06-28 00:00:00\n",
      "Progress printout 40 / 1997-04-30 00:00:00\n",
      "Progress printout 50 / 1998-02-27 00:00:00\n",
      "Progress printout 60 / 1998-12-31 00:00:00\n",
      "Progress printout 70 / 1999-10-29 00:00:00\n",
      "Progress printout 80 / 2000-08-31 00:00:00\n",
      "Progress printout 90 / 2001-06-29 00:00:00\n",
      "Progress printout 100 / 2002-04-30 00:00:00\n",
      "Progress printout 110 / 2003-02-28 00:00:00\n",
      "Progress printout 120 / 2003-12-31 00:00:00\n",
      "Progress printout 130 / 2004-10-29 00:00:00\n",
      "Progress printout 140 / 2005-08-31 00:00:00\n",
      "Progress printout 150 / 2006-06-30 00:00:00\n",
      "Progress printout 160 / 2007-04-30 00:00:00\n",
      "Progress printout 170 / 2008-02-29 00:00:00\n",
      "Progress printout 180 / 2008-12-31 00:00:00\n",
      "Progress printout 190 / 2009-10-30 00:00:00\n",
      "Progress printout 200 / 2010-08-31 00:00:00\n",
      "Progress printout 210 / 2011-06-30 00:00:00\n",
      "Progress printout 220 / 2012-04-30 00:00:00\n",
      "Progress printout 230 / 2013-02-28 00:00:00\n",
      "Progress printout 240 / 2013-12-31 00:00:00\n",
      "Progress printout 250 / 2014-10-31 00:00:00\n",
      "Progress printout 260 / 2015-08-31 00:00:00\n",
      "Progress printout 270 / 2016-06-30 00:00:00\n",
      "Progress printout 280 / 2017-04-28 00:00:00\n",
      "Progress printout 290 / 2018-02-28 00:00:00\n",
      "Progress printout 300 / 2018-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "### LOOPER FOR IVOL MOMENTUM 12M FACTOR\n",
    "#date_range_test = pd.date_range(start = '2010-10-25', periods = 6)\n",
    "date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()\n",
    "#date_range_test = ser_market_membership.sort_index(level = 1).index.get_level_values(1).unique()[155 : 160]\n",
    "arr_ivol_mom_12m_factor = []\n",
    "iter_counter = 0\n",
    "for iter_date in date_range_test:\n",
    "    iter_counter = iter_counter + 1\n",
    "    arr_ivol_mom_12m_factor.append(get_ivol_mom_12m_factor(iter_date))\n",
    "    if ((iter_counter // 10) == (iter_counter / 10)):\n",
    "        print('Progress printout',iter_counter, '/', iter_date)\n",
    "        \n",
    "ser_ivol_mom_12m_factor = pd.concat(arr_ivol_mom_12m_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser_ivol_mom_12m_factor - AR 29-Dec-2006: 2.4071504646865075e-05\n",
      "ser_ivol_mom_12m_factor - US 29-Dec-2006: -1.281313465985619e-05\n",
      "ser_ivol_mom_12m_factor - cross-sectional mean min: -8.265832098596306e-05\n",
      "ser_ivol_mom_12m_factor - cross-sectional mean mean: 5.48849915627575e-06\n",
      "ser_ivol_mom_12m_factor - cross-sectional mean max: 9.861384692768506e-05\n",
      "ser_ivol_mom_12m_factor - cross-sectional mean stdev: 2.4997621734106227e-05\n",
      "ser_ivol_mom_12m_factor - cross-sectional mean mean: 237\n"
     ]
    }
   ],
   "source": [
    "### IVOL MOMENTUM 12M FACTOR TESTING:\n",
    "print('ser_ivol_mom_12m_factor - AR 29-Dec-2006:', ser_ivol_mom_12m_factor.loc['AR' , '2006-12-29'])\n",
    "print('ser_ivol_mom_12m_factor - US 29-Dec-2006:', ser_ivol_mom_12m_factor.loc['US' , '2006-12-29'])\n",
    "ser_ivol_mom_12m_factor_mean = pd.Series(np.NaN, index = ser_ivol_mom_12m_factor.index.get_level_values(1).unique())\n",
    "for iter_date in ser_ivol_mom_12m_factor_mean.index:  \n",
    "    ser_ivol_mom_12m_factor_mean[iter_date] = ser_ivol_mom_12m_factor.loc[:, iter_date].mean()\n",
    "ser_ivol_mom_12m_factor_mean.sort_index(inplace = True)\n",
    "print('ser_ivol_mom_12m_factor - cross-sectional mean min:', ser_ivol_mom_12m_factor_mean.min())\n",
    "print('ser_ivol_mom_12m_factor - cross-sectional mean mean:', ser_ivol_mom_12m_factor_mean.mean())\n",
    "print('ser_ivol_mom_12m_factor - cross-sectional mean max:', ser_ivol_mom_12m_factor_mean.max())\n",
    "print('ser_ivol_mom_12m_factor - cross-sectional mean stdev:', ser_ivol_mom_12m_factor_mean.std())\n",
    "print('ser_ivol_mom_12m_factor - cross-sectional mean mean:', ser_ivol_mom_12m_factor_mean.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
