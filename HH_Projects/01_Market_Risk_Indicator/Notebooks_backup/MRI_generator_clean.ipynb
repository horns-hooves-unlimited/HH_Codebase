{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MRI GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### STANDART MODULES INITIALISING\n",
    "\n",
    "### Importing standard modules and date-special modules:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MRI CONSTANTS AND PARAMETERS SETTING\n",
    "\n",
    "### Standart date format for notebook:\n",
    "date_format = '%Y-%m-%d'\n",
    "### MRI dates:\n",
    "date_first = date(1990, 1, 1)\n",
    "date_last = date(2018, 12, 31)\n",
    "date_start = date(1993, 12, 31)\n",
    "### Source xlsx file attributes:\n",
    "path_mri_data_xlsx = 'Data_Files/Source_Files/mri_data.xlsx'\n",
    "mri_model_name = 'Model 01'\n",
    "### HDF5 file with structured source data for selected date interval attributes:\n",
    "path_mri_data_hdf = 'Data_Files/Source_Files/mri_data.h5'\n",
    "key_mri_data_hdf = 'source_data'\n",
    "\n",
    "### Limitations for rolling windows for z-score calculating:\n",
    "asset_window_min = 252\n",
    "asset_window_max = 252 * 100\n",
    "mri_window_max = 260 * 10\n",
    "### Limitations for z-score winsorizing:\n",
    "arr_winsor_boundary = [-4, 4]\n",
    "### Limitations for moving average for MRI calculation:\n",
    "mri_moving_average_window_max = 5\n",
    "### HDF5 with MRI group matrices builded from z-scored means of standartized winsorized weighted z-score matrices for each group asset:\n",
    "path_mri_standart_hdf = 'Data_Files/Source_Files/mri_group_z_matrix.h5'\n",
    "### HDF5 with MRI asset level info:\n",
    "path_mri_assets_hdf = 'Data_Files/Source_Files/mri_released_assets.h5'\n",
    "object_selected_data_hdf = 'selected_data'\n",
    "object_standartized_data_hdf = 'standartized_data'\n",
    "### HDF5 with MRI group level info:\n",
    "path_mri_groups_hdf = 'Data_Files/Source_Files/mri_released_groups.h5'\n",
    "object_diag_grouped_hdf = 'diag_grouped_data'\n",
    "object_perc_grouped_hdf = 'percentile_grouped_data'\n",
    "### HDF5 with MRI level info:\n",
    "path_mri_index_hdf = 'Data_Files/Source_Files/mri_released_index.h5'\n",
    "object_diag_mri_hdf = 'diag_MRI_data'\n",
    "object_released_mri_hdf = 'released_MRI_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MRI DATA AGGREGATING FUNCTION\n",
    "def get_mri_data(source_file_path, source_model_sheet, hdf_file_path, hdf_object_key, date_index, update_hdf = True):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd    \n",
    "    \n",
    "    ### Reading Model information from Source model sheet:\n",
    "    df_model_raw = pd.read_excel(source_file_path, sheet_name = source_model_sheet, header = 1, usecols = [0, 1, 2, 3, 4, 5, 6])\n",
    "    ### Group border rows deleting:\n",
    "    df_model_raw = df_model_raw[df_model_raw['Asset Group'] != df_model_raw['Asset Code']]   \n",
    "    ### Dividing list on asset part and MRI weights part:\n",
    "    df_model_asset = df_model_raw[df_model_raw['Asset Group'] != 'MRI'] ### Asset part\n",
    "    df_model_asset.reset_index(drop = True, inplace = True)\n",
    "    df_model_mri = df_model_raw[df_model_raw['Asset Group'] == 'MRI'] ### MRI part\n",
    "    df_model_mri.reset_index(drop = True, inplace = True) \n",
    "    ### Extracting source data from initial excel file or from saved hdf\n",
    "    if (update_hdf): \n",
    "        ### Aggregating data from the source xlsx file to pd.DataFrame:\n",
    "        arr_tab_data = []\n",
    "        for iter_index, iter_row in df_model_asset.iterrows():\n",
    "            iter_tab = iter_row['Asset Tab Name']\n",
    "            iter_asset = iter_row['Asset Code']\n",
    "            ser_iter_tab = pd.read_excel(source_file_path, sheet_name = iter_tab, header = 0, index_col = 0, squeeze = True)\n",
    "            ser_iter_tab.name = iter_asset\n",
    "            arr_tab_data.append(ser_iter_tab)\n",
    "        df_source_data = pd.concat(arr_tab_data, axis = 1, join = 'outer')\n",
    "        df_source_data = df_source_data.astype(float)        \n",
    "        df_source_data.to_hdf(hdf_file_path, hdf_object_key, mode = 'w', format = 'fixed', append = False)\n",
    "    else:\n",
    "        df_source_data = pd.read_hdf(hdf_file_path, hdf_object_key)\n",
    "    ### Filtering by date_index and forward filling missing values:\n",
    "    df_source_data.fillna(method = 'ffill', inplace = True)\n",
    "    df_selected_data = df_source_data.reindex(date_index, method = 'ffill')\n",
    "    df_selected_data.index.name = 'Date'\n",
    "    df_selected_data = df_selected_data.astype('float64')\n",
    "    \n",
    "    return [df_model_asset, df_model_mri, df_selected_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GETTING MRI DATA FOR FUTURE CALCULATIONS\n",
    "index_mri_date = pd.date_range(date_first, date_last, freq = 'B')\n",
    "[df_model_asset, df_model_mri, df_selected_data] = get_mri_data(path_mri_data_xlsx, mri_model_name, path_mri_data_hdf, key_mri_data_hdf, \n",
    "                                                                 index_mri_date, update_hdf = True)\n",
    "#[df_model_asset, df_model_mri, df_selected_data] = get_mri_data(path_mri_data_xlsx, mri_model_name, path_mri_data_hdf, key_mri_data_hdf, \n",
    "#                                                                index_mri_date, update_hdf = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_z_score(ser_source, min_wnd, max_wnd, winsor_bottom, winsor_top):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Calculating rolling mean:\n",
    "    ser_rolling_mean = ser_source.rolling(window = max_wnd, min_periods = min_wnd, win_type = None).mean()\n",
    "    ### Calculating rolling standard deviation:\n",
    "    ser_rolling_std = ser_source.rolling(window = max_wnd, min_periods = min_wnd, win_type = None).std()\n",
    "    ### Calculating rolling z-score:\n",
    "    ser_rolling_z_score = (ser_source - ser_rolling_mean) / ser_rolling_std\n",
    "    ### Initializing resulting variables:\n",
    "    df_z_matrix = pd.DataFrame(np.NaN, index = ser_source.index, columns = ser_source.index)\n",
    "    df_z_matrix = df_z_matrix.astype('float64')\n",
    "    ### Calculating z-score matrix:\n",
    "    ind_valid_index = ser_source.first_valid_index()\n",
    "    asset_start_index = ind_valid_index + pd.offsets.BusinessDay(min_wnd - 1)  \n",
    "    for iter_end_index in ser_source.index:\n",
    "        ### Checking for at list min_wnd elements of rolling window are not np.NaN:\n",
    "        if (iter_end_index >= asset_start_index):          \n",
    "            ### Isolating rolling window for particular data vector element:\n",
    "            iter_start_index = iter_end_index - pd.offsets.BusinessDay(max_wnd)\n",
    "            ser_iter_source = ser_source.loc[iter_start_index : iter_end_index]        \n",
    "            ser_iter_z_score = (ser_iter_source - ser_iter_source.mean()) / ser_iter_source.std()            \n",
    "            ### Winsorization process:\n",
    "            bool_to_winsor = True            \n",
    "            while (bool_to_winsor): \n",
    "                ### Value based winsorization:                \n",
    "                ser_iter_z_score.clip(lower = winsor_bottom, upper = winsor_top, inplace = True)\n",
    "                ### Recalculating of z scores:\n",
    "                ser_iter_z_score = (ser_iter_z_score - ser_iter_z_score.mean()) / ser_iter_z_score.std()\n",
    "                ### Checking for boundaries:\n",
    "                if (ser_iter_z_score[(ser_iter_z_score <= (winsor_bottom - 0.01)) | (ser_iter_z_score >= (winsor_top + 0.01))].count() == 0):\n",
    "                    bool_to_winsor = False\n",
    "            ### Filling z matrix column part after the winsorizing (if needed):\n",
    "            df_z_matrix.loc[iter_start_index : iter_end_index, iter_end_index] = ser_iter_z_score.values            \n",
    "    ### Getting winsorized z meanings:     \n",
    "    ser_rolling_z_winsor = pd.Series(list(np.diag(df_z_matrix)), index = ser_source.index)\n",
    "    ### Backfilling with first not NaN column of z matrix:\n",
    "    ser_rolling_z_winsor.loc[ : asset_start_index] = df_z_matrix.loc[ : asset_start_index, asset_start_index]\n",
    "    df_z_matrix = df_z_matrix.astype('float32')\n",
    "\n",
    "    return [ser_rolling_z_score, ser_rolling_z_winsor, df_z_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-12-20 00:00:00\n",
      "1922-05-29 00:00:00\n",
      "2018-12-31 00:00:00\n",
      "raw data: 17.78\n",
      "raw data ln: 2.8780742300857587\n",
      "z-score 3905: -1.9173996588494062\n",
      "z-score min: -2.708733440781229\n",
      "z-score max: 4.007532064798355\n",
      "z-score mean: -0.1067801183124964\n",
      "z-score std: 1.1881988564929336\n",
      "z-score size: 7566\n",
      "z-score count: 3912\n",
      "z-matrix straight diag mean: -0.11462475348192766\n"
     ]
    }
   ],
   "source": [
    "### TESTING:\n",
    "asset_code = 'iv_rvx'\n",
    "[ser_rolling_z_score_base, ser_rolling_z_winsor_base, df_base_z_matrix] = get_rolling_z_score(np.log(df_selected_data[asset_code]), \n",
    "                                                                                              asset_window_min, asset_window_max,\n",
    "                                                                                              arr_winsor_boundary[0], arr_winsor_boundary[1])\n",
    "print('raw data:', df_selected_data[asset_code].iloc[3905])\n",
    "print('raw data ln:', np.log(df_selected_data[asset_code].iloc[3905]))\n",
    "print('z-score 3905:', ser_rolling_z_winsor_base.iloc[3905])\n",
    "print('z-score min:', ser_rolling_z_winsor_base[ : ].min())\n",
    "print('z-score max:', ser_rolling_z_winsor_base[ : ].max())\n",
    "print('z-score mean:', ser_rolling_z_winsor_base[ : ].mean())\n",
    "print('z-score std:', ser_rolling_z_winsor_base[ : ].std())\n",
    "print('z-score size:', ser_rolling_z_winsor_base[ : ].size)\n",
    "print('z-score count:', ser_rolling_z_winsor_base[ : ].count())\n",
    "print('z-matrix straight diag mean:', np.nanmean(np.diag(df_base_z_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standartized_mri_data(df_model_asset, df_selected_data, date_start, asset_window_min, asset_window_max, arr_winsor_boundary, hdf_file_path):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "\n",
    "    ### Base assets determination (resorting by earliest value):\n",
    "    df_model_asset['Asset Date'] = date_first\n",
    "    for (iter_index, asset_code) in df_model_asset['Asset Code'].iteritems():\n",
    "        df_model_asset.loc[iter_index, 'Asset Date'] = df_selected_data[asset_code].dropna().index.min() \n",
    "    df_model_asset.sort_values(['Asset Group', 'Asset Date'], inplace = True)\n",
    "    df_model_asset = df_model_asset.reset_index(drop = True)\n",
    "\n",
    "    ### Initialising loop visibility variables:          \n",
    "    dict_group_diag_container = {} ### Group z-matrices diagonales container\n",
    "    dict_asset_vector_container = {} ### Asset z-matrices diagonales container\n",
    "    dict_group_matrix_container = {}\n",
    "    ### Standartizing loop on group level:\n",
    "    for asset_group_name, df_asset_group in df_model_asset.groupby('Asset Group'):\n",
    "        ### Initialising group visibility variables:\n",
    "        print('get_standartized_mri_data: group', asset_group_name, 'standartizing started')\n",
    "        bool_base_asset = True\n",
    "        dict_asset_matrix_container = {} ### Asset matrices collection for group mean matrix calculation\n",
    "        ### Standartizing cycle on asset level with the group:\n",
    "        for (asset_index, asset_code) in df_asset_group['Asset Code'].iteritems():\n",
    "            ### Assignment of base asset data set:\n",
    "            if (bool_base_asset):\n",
    "                bool_base_asset = False\n",
    "                ### Performing z scoring for base asset:\n",
    "                [ser_rolling_z_score_base, ser_rolling_z_winsor_base, df_base_z_matrix] = get_rolling_z_score(np.log(df_selected_data[asset_code]), \n",
    "                                                                                                              asset_window_min, asset_window_max,\n",
    "                                                                                                              arr_winsor_boundary[0], arr_winsor_boundary[1])\n",
    "                ### Calculating ethalon filled quantity before date_start:\n",
    "                int_base_filled = ser_rolling_z_winsor_base[ : date_start].dropna().count()                \n",
    "                ### Defining of standartized values of base asset as diagonal of z matrix (without backfilling):\n",
    "                dict_asset_vector_container[asset_code] = pd.Series(list(np.diag(df_base_z_matrix)), index = df_base_z_matrix.index)\n",
    "                ### Creating a whole group dataset with multiplying asset matrix to asset weight:\n",
    "                dict_asset_matrix_container[asset_code] = df_base_z_matrix\n",
    "            ### Normalization of other asset's data sets:                \n",
    "            else:\n",
    "                ### Performing z scoring for asset:                \n",
    "                [ser_asset_z_score_simple, ser_asset_z_score_winsor, df_asset_z_matrix] = get_rolling_z_score(np.log(df_selected_data[asset_code]), \n",
    "                                                                                                              asset_window_min, asset_window_max, \n",
    "                                                                                                              arr_winsor_boundary[0], arr_winsor_boundary[1])\n",
    "                ### Calculating asset filled quantity:                \n",
    "                int_asset_filled = ser_asset_z_score_winsor[ : date_start].dropna().count()            \n",
    "                ### Standartizing asset if they do not have enough initial values:\n",
    "                if (int_asset_filled < int_base_filled * 2 / 3):\n",
    "                    index_asset_start = ser_asset_z_score_simple.first_valid_index()\n",
    "                    ### RenormaLizing asset z matrix with base z matrix data:\n",
    "                    for index_asset_end in ser_asset_z_score_simple.index:\n",
    "                        if (index_asset_end >= index_asset_start):                \n",
    "                            ser_base_z_part = df_base_z_matrix.loc[index_asset_start - pd.offsets.BusinessDay(asset_window_min - 1) : index_asset_end, index_asset_end]    \n",
    "                            df_asset_z_matrix.loc[:, index_asset_end] = df_asset_z_matrix.loc[:, index_asset_end] * ser_base_z_part.std() + ser_base_z_part.mean()\n",
    "                ### Defining of standartized values of asset as diagonale of modified z matrix (without backfilling):\n",
    "                dict_asset_vector_container[asset_code] = pd.Series(list(np.diag(df_asset_z_matrix)), index = df_asset_z_matrix.index)\n",
    "                ### Adding asset matrix to a whole group dataset with multiplying asset matrix to asset weight:          \n",
    "                df_asset_z_matrix = df_asset_z_matrix.astype('float32')\n",
    "                dict_asset_matrix_container[asset_code] = df_asset_z_matrix\n",
    "            print('get_standartized_mri_data: asset', asset_code, 'in group', asset_group_name, 'standartized successfully')         \n",
    "        ### Calculating z matrix for group from weighted asset matrices:\n",
    "        df_group_mean = pd.concat(dict_asset_matrix_container, axis = 0, names = ['Asset Code', 'Date'], copy = False)\n",
    "        df_group_mean = df_group_mean.groupby('Date').mean()    \n",
    "        df_group_mean_z = (df_group_mean - df_group_mean.mean()) / df_group_mean.std()\n",
    "        ### Adding diagonale of group weighted mean z-score matrix to MRI dataset:\n",
    "        dict_group_diag_container[asset_group_name] = pd.Series(list(np.diag(df_group_mean_z)), index = df_group_mean_z.index)        \n",
    "        print('get_standartized_mri_data: z-score matrix for group' , asset_group_name, 'mean matrix builded successfully') \n",
    "        ### Saving group matrix to hdf file for further manipulations:\n",
    "        df_group_mean_z = df_group_mean_z.astype('float32')\n",
    "        df_group_mean_z.reset_index(inplace = True)\n",
    "        df_group_mean_z.columns = np.arange(len(df_group_mean_z.columns))\n",
    "        df_group_mean_z.to_hdf(hdf_file_path, key = asset_group_name, mode = 'a', format = 'fixed')\n",
    "        print('get_standartized_mri_data: z-score matrix for group' , asset_group_name, 'saved to HDF5 file', hdf_file_path, '(object key:', asset_group_name, ')')\n",
    "    ### Collection of standartized z-scores for all assets:\n",
    "    ser_asset_standartized = pd.concat(dict_asset_vector_container, axis = 0, names = ['Asset', 'Date'], copy = False)    \n",
    "    print('get_standartized_mri_data: asset standartized z-score collection builded successfully')\n",
    "    ### Collection of diagonales of group's z matrices for all groups:\n",
    "    ser_group_mean_z_diag = pd.concat(dict_group_diag_container, axis = 0, names = ['Group', 'Date'], copy = False)    \n",
    "    print('get_standartized_mri_data: data vector collection of diagonales of mean z score matrix for all groups builded successfully')    \n",
    "    return [ser_asset_standartized, ser_group_mean_z_diag] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_standartized_mri_data: group EQ standartizing started\n",
      "get_standartized_mri_data: asset iv_us in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_eu in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_uk in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_jp in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_rvx in group EQ standartized successfully\n",
      "get_standartized_mri_data: asset iv_eem in group EQ standartized successfully\n",
      "get_standartized_mri_data: z-score matrix for group EQ mean matrix builded successfully\n",
      "get_standartized_mri_data: z-score matrix for group EQ saved to HDF5 file Data_Files/Source_Files/mri_group_z_matrix.h5 (object key: EQ )\n",
      "get_standartized_mri_data: group FI standartizing started\n",
      "get_standartized_mri_data: asset oas_hy in group FI standartized successfully\n",
      "get_standartized_mri_data: asset oas_em in group FI standartized successfully\n",
      "get_standartized_mri_data: z-score matrix for group FI mean matrix builded successfully\n",
      "get_standartized_mri_data: z-score matrix for group FI saved to HDF5 file Data_Files/Source_Files/mri_group_z_matrix.h5 (object key: FI )\n",
      "get_standartized_mri_data: group FX standartizing started\n",
      "get_standartized_mri_data: asset fx_jpy in group FX standartized successfully\n",
      "get_standartized_mri_data: asset fx_gbp in group FX standartized successfully\n",
      "get_standartized_mri_data: asset fx_chf in group FX standartized successfully\n",
      "get_standartized_mri_data: asset fx_eur in group FX standartized successfully\n",
      "get_standartized_mri_data: z-score matrix for group FX mean matrix builded successfully\n",
      "get_standartized_mri_data: z-score matrix for group FX saved to HDF5 file Data_Files/Source_Files/mri_group_z_matrix.h5 (object key: FX )\n",
      "get_standartized_mri_data: asset standartized z-score collection builded successfully\n",
      "get_standartized_mri_data: data vector collection of diagonales of mean z score matrix for all groups builded successfully\n"
     ]
    }
   ],
   "source": [
    "#### STANDARTISING SOURCE DATA FOR MRI CALCUCATION\n",
    "\n",
    "### Standartizing dataset:\n",
    "### Building collection of standartized winsorized z-scores for all assets:\n",
    "### Building collection of group's z matrices diagonales for all groups:\n",
    "### Saving group's z matrices:\n",
    "[ser_standartized_assets, ser_diag_mean_z_groups] = get_standartized_mri_data(df_model_asset, df_selected_data, date_start, \n",
    "                                                                              asset_window_min, asset_window_max, arr_winsor_boundary, \n",
    "                                                                              path_mri_standart_hdf)\n",
    "### Saving results for assets to HDF5 to avoid hard calculations with constant source model and datasets:\n",
    "import tables\n",
    "tables.file._open_files.close_all()\n",
    "ser_standartized_assets.to_hdf(path_mri_assets_hdf, key = object_standartized_data_hdf, mode = 'w', format = 'fixed')\n",
    "### Saving results for groups to HDF5 to avoid hard calculations with constant source model and datasets:\n",
    "ser_diag_mean_z_groups.to_hdf(path_mri_groups_hdf, key = object_diag_grouped_hdf, mode = 'w', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-score 3905: -1.3802614212036133\n",
      "z-score min: -2.4099533557891846\n",
      "z-score max: 4.1285858154296875\n",
      "z-score mean: -0.4078973956184543\n",
      "z-score std: 1.1452926626074527\n",
      "z-score size: 7566\n",
      "z-score count: 3661\n"
     ]
    }
   ],
   "source": [
    "### TESTING:\n",
    "asset_code = 'iv_rvx'\n",
    "print('z-score 3905:', ser_standartized_assets[asset_code].iloc[3905])\n",
    "print('z-score min:', ser_standartized_assets[asset_code][ : ].min())\n",
    "print('z-score max:', ser_standartized_assets[asset_code][ : ].max())\n",
    "print('z-score mean:', ser_standartized_assets[asset_code][ : ].mean())\n",
    "print('z-score std:', ser_standartized_assets[asset_code][ : ].std())\n",
    "print('z-score size:', ser_standartized_assets[asset_code][ : ].size)\n",
    "print('z-score count:', ser_standartized_assets[asset_code][ : ].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-score 3905: -1.596615195274353\n",
      "z-score min: -3.740589141845703\n",
      "z-score max: 4.004619121551514\n",
      "z-score mean: 0.1399801089881174\n",
      "z-score std: 1.2946608771337218\n",
      "z-score size: 7566\n",
      "z-score count: 6250\n"
     ]
    }
   ],
   "source": [
    "### TESTING:\n",
    "group_code = 'FI'\n",
    "print('z-score 3905:', ser_diag_mean_z_groups[group_code].iloc[3905])\n",
    "print('z-score min:', ser_diag_mean_z_groups[group_code][ : ].min())\n",
    "print('z-score max:', ser_diag_mean_z_groups[group_code][ : ].max())\n",
    "print('z-score mean:', ser_diag_mean_z_groups[group_code][ : ].mean())\n",
    "print('z-score std:', ser_diag_mean_z_groups[group_code][ : ].std())\n",
    "print('z-score size:', ser_diag_mean_z_groups[group_code][ : ].size)\n",
    "print('z-score count:', ser_diag_mean_z_groups[group_code][ : ].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7883340120315552"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TESTING:\n",
    "group_code = 'FI'\n",
    "df_group_z_matrix = pd.read_hdf(path_mri_standart_hdf, group_code)\n",
    "df_group_z_matrix.set_index(0, drop = True, inplace = True)\n",
    "df_group_z_matrix.iloc[:, 6999].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_mri_data(df_model_mri, hdf_z_matrix_path, date_start, mri_window_max, ma_max_wnd, arr_winsor_boundary):   \n",
    "    import numpy as np\n",
    "    import pandas as pd   \n",
    "\n",
    "    ### Initialising containers for weighted mean matrix calculation:\n",
    "    dict_group_matrix_container = {}\n",
    "    winsor_bottom = arr_winsor_boundary[0]\n",
    "    winsor_top = arr_winsor_boundary[1]    \n",
    "    ### Group aggregating cycle:    \n",
    "    for group_index, ser_group_info in df_model_mri.iterrows():\n",
    "        group_code = ser_group_info['Asset Code']\n",
    "        ### Loading group z score matrix from HDF5 file:\n",
    "        df_group_z_matrix = pd.read_hdf(hdf_z_matrix_path, group_code)\n",
    "        df_group_z_matrix.set_index(0, drop = True, inplace = True)\n",
    "        ### Adding matrix to container:\n",
    "        dict_group_matrix_container[group_index] = df_group_z_matrix\n",
    "        print('aggregate_mri_data: group', group_code, 'z matrix data extracted successfully')\n",
    "    ### Calculating mean matrix for MRI from group matrices:        \n",
    "    df_group_mean = pd.concat(dict_group_matrix_container, axis = 0, names = ['Group', 'Date'], copy = False)\n",
    "    print('aggregate_mri_data: MRI mean matrix concatenated successfully')    \n",
    "    df_group_mean = df_group_mean.groupby(['Date']).mean()   \n",
    "    df_group_mean.columns = df_group_z_matrix.index\n",
    "    print('aggregate_mri_data: MRI mean matrix averaged successfully')  \n",
    "    ### Calculating z matrix for MRI with winsorization:    \n",
    "    df_mri_z_score = pd.DataFrame(np.NaN, index = df_group_mean.index, columns = df_group_mean.columns)\n",
    "    df_mri_z_score = df_mri_z_score.astype('float32')\n",
    "    for iter_date in df_group_mean.columns:\n",
    "        if (iter_date >= pd.Timestamp(date_start)):\n",
    "            ser_iter_mri = df_group_mean.loc[iter_date - pd.offsets.BusinessDay(mri_window_max) : iter_date, iter_date]\n",
    "            ser_iter_z_score = (ser_iter_mri - ser_iter_mri.mean()) / ser_iter_mri.std()\n",
    "            ### Winsorization process:\n",
    "            bool_to_winsor = True            \n",
    "            while (bool_to_winsor):       \n",
    "                ### Value based winsorization:\n",
    "                ser_iter_z_score.clip(lower = winsor_bottom, upper = winsor_top, inplace = True)\n",
    "                ### Recalculating of z scores:\n",
    "                ser_iter_z_score = (ser_iter_z_score - ser_iter_z_score.mean()) / ser_iter_z_score.std()                \n",
    "                ### Checking for boundaries:\n",
    "                if (ser_iter_z_score[(ser_iter_z_score <= (winsor_bottom - 0.01)) | (ser_iter_z_score >= (winsor_top + 0.01))].count() == 0):                    \n",
    "                    bool_to_winsor = False    \n",
    "            df_mri_z_score.loc[iter_date - pd.offsets.BusinessDay(mri_window_max) : iter_date, iter_date] = ser_iter_z_score.values\n",
    "    ser_mri_z_diag = pd.Series(list(np.diag(df_mri_z_score)), index = df_mri_z_score.index) \n",
    "    ser_mri_z_diag.name = 'MRI-Z'\n",
    "    print('aggregate_mri_data: MRI z matrix builded successfully')             \n",
    "    ### Calculating z matrix for MRI with winsorization:       \n",
    "    df_mri_z_ma = df_mri_z_score.copy()\n",
    "    for iter_shift in np.arange(1, ma_max_wnd):\n",
    "        df_mri_z_ma = df_mri_z_ma + df_mri_z_score.shift(iter_shift)\n",
    "    df_mri_z_ma = df_mri_z_ma / ma_max_wnd\n",
    "    ser_mri_released = pd.Series(list(np.diag(df_mri_z_ma)), index = df_mri_z_ma.index)\n",
    "    ser_mri_released[ : pd.Timestamp(date_start)] = df_mri_z_ma.loc[ : pd.Timestamp(date_start), pd.Timestamp(date_start)]\n",
    "    ser_mri_released.name = 'MRI-Z-Winsor-MA5'        \n",
    "    print('aggregate_mri_data: MRI moving average resulting vector builded successfully')     \n",
    "    return [ser_mri_z_diag, ser_mri_released]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregate_mri_data: group EQ z matrix data extracted successfully\n",
      "aggregate_mri_data: group FI z matrix data extracted successfully\n",
      "aggregate_mri_data: group FX z matrix data extracted successfully\n",
      "aggregate_mri_data: MRI mean matrix concatenated successfully\n",
      "aggregate_mri_data: MRI mean matrix averaged successfully\n",
      "aggregate_mri_data: MRI z matrix builded successfully\n",
      "aggregate_mri_data: MRI moving average resulting vector builded successfully\n"
     ]
    }
   ],
   "source": [
    "### BUILDING MRI INDEX\n",
    "[ser_mri_z_diag, ser_mri_released] = aggregate_mri_data(df_model_mri, path_mri_standart_hdf, date_start, \n",
    "                                                        mri_window_max, mri_moving_average_window_max, arr_winsor_boundary)\n",
    "### Saving results for groups to HDF5 to avoid hard calculations with constant source model and datasets:\n",
    "import tables\n",
    "tables.file._open_files.close_all()\n",
    "ser_mri_z_diag.to_hdf(path_mri_index_hdf, key = object_diag_mri_hdf, mode = 'w', format = 'fixed')\n",
    "ser_mri_released.to_hdf(path_mri_index_hdf, key = object_released_mri_hdf, mode = 'a', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI 6999: Date\n",
      "2016-10-28   -0.469501\n",
      "Name: MRI-Z, dtype: float64\n",
      "MRI min: -2.9318556785583496\n",
      "MRI max: 4.007950782775879\n",
      "MRI mean: -0.027571064076795933\n",
      "MRI std: 1.208622109998802\n",
      "MRI size: 7566\n",
      "MRI count: 6522\n"
     ]
    }
   ],
   "source": [
    "### TESTING:\n",
    "print('MRI 6999:', ser_mri_z_diag.iloc[6999 : 7000])\n",
    "print('MRI min:', ser_mri_z_diag.min())\n",
    "print('MRI max:', ser_mri_z_diag.max())\n",
    "print('MRI mean:', ser_mri_z_diag.mean())\n",
    "print('MRI std:', ser_mri_z_diag.std())\n",
    "print('MRI size:', ser_mri_z_diag.size)\n",
    "print('MRI count:', ser_mri_z_diag.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI 6999: Date\n",
      "2016-10-28   -0.537115\n",
      "Name: MRI-Z-Winsor-MA5, dtype: float64\n",
      "MRI min: -2.862577438354492\n",
      "MRI max: 4.000450134277344\n",
      "MRI mean: -0.02374306619829718\n",
      "MRI std: 1.173413280964329\n",
      "MRI size: 7566\n",
      "MRI count: 7561\n"
     ]
    }
   ],
   "source": [
    "### TESTING:\n",
    "print('MRI 6999:', ser_mri_released.iloc[6999 : 7000])\n",
    "print('MRI min:', ser_mri_released.min())\n",
    "print('MRI max:', ser_mri_released.max())\n",
    "print('MRI mean:', ser_mri_released.mean())\n",
    "print('MRI std:', ser_mri_released.std())\n",
    "print('MRI size:', ser_mri_released.size)\n",
    "print('MRI count:', ser_mri_released.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING:\n",
    "ser_standartized_assets = pd.read_hdf(path_mri_assets_hdf, key = object_standartized_data_hdf)\n",
    "ser_diag_mean_z_groups = pd.read_hdf(path_mri_groups_hdf, key = object_diag_grouped_hdf)\n",
    "ser_mri_z_diag = pd.read_hdf(path_mri_index_hdf, key = object_diag_mri_hdf)\n",
    "ser_mri_released = pd.read_hdf(path_mri_index_hdf, key = object_released_mri_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1990-01-01         NaN\n",
       "1990-01-02         NaN\n",
       "1990-01-03         NaN\n",
       "1990-01-04         NaN\n",
       "1990-01-05         NaN\n",
       "1990-01-08    0.470369\n",
       "1990-01-09    0.659891\n",
       "1990-01-10    0.817269\n",
       "1990-01-11    0.848957\n",
       "1990-01-12    1.001224\n",
       "1990-01-15    1.197926\n",
       "1990-01-16    1.261960\n",
       "1990-01-17    1.317314\n",
       "1990-01-18    1.462639\n",
       "1990-01-19    1.394541\n",
       "1990-01-22    1.404716\n",
       "1990-01-23    1.421270\n",
       "1990-01-24    1.458489\n",
       "1990-01-25    1.497196\n",
       "1990-01-26    1.613590\n",
       "1990-01-29    1.606256\n",
       "1990-01-30    1.679289\n",
       "1990-01-31    1.678403\n",
       "1990-02-01    1.655841\n",
       "1990-02-02    1.597747\n",
       "1990-02-05    1.541853\n",
       "1990-02-06    1.467910\n",
       "1990-02-07    1.435599\n",
       "1990-02-08    1.401693\n",
       "1990-02-09    1.382021\n",
       "                ...   \n",
       "2018-11-20   -0.362878\n",
       "2018-11-21   -0.367763\n",
       "2018-11-22   -0.388863\n",
       "2018-11-23   -0.385297\n",
       "2018-11-26   -0.394442\n",
       "2018-11-27   -0.427599\n",
       "2018-11-28   -0.438429\n",
       "2018-11-29   -0.449689\n",
       "2018-11-30   -0.465701\n",
       "2018-12-03   -0.502604\n",
       "2018-12-04   -0.501943\n",
       "2018-12-05   -0.491896\n",
       "2018-12-06   -0.437519\n",
       "2018-12-07   -0.378716\n",
       "2018-12-10   -0.274833\n",
       "2018-12-11   -0.229174\n",
       "2018-12-12   -0.210938\n",
       "2018-12-13   -0.259189\n",
       "2018-12-14   -0.301532\n",
       "2018-12-17   -0.337660\n",
       "2018-12-18   -0.334889\n",
       "2018-12-19   -0.315678\n",
       "2018-12-20   -0.233310\n",
       "2018-12-21   -0.146436\n",
       "2018-12-24   -0.080600\n",
       "2018-12-25   -0.030605\n",
       "2018-12-26    0.021623\n",
       "2018-12-27    0.033826\n",
       "2018-12-28    0.035168\n",
       "2018-12-31    0.036490\n",
       "Name: MRI-Z-Winsor-MA5, Length: 7566, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_mri_released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
