{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRI GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['Asset Group', 'Asset Group Description', 'Asset Code', 'Asset Tab Name', 'Asset Desc', 'Processing Routine']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "### EXTRACTING GRI SOURCE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "def get_gri_data_from_excel():\n",
    "    ### Importing standard modules and date-special modules:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import date\n",
    "    ### Source xlsx file attributes:\n",
    "    path_gri_data_xlsx = 'Data_Files/Source_Files/mri_data.xlsx'\n",
    "    tab_gri_model = 'Model 01'  \n",
    "    ### Reading Model information from Source model sheet:\n",
    "    df_model_raw = pd.read_excel(path_gri_data_xlsx, sheet_name = tab_gri_model, header = 1, usecols = [0, 1, 2, 3, 4, 5, 6])\n",
    "    ### Group border rows deleting:\n",
    "    df_model_raw = df_model_raw[df_model_raw['Asset Group'] != df_model_raw['Asset Code']]   \n",
    "    ### Dividing list on asset part and MRI weights part:\n",
    "    df_model_asset = df_model_raw[df_model_raw['Asset Group'] != 'MRI'] ### Asset part\n",
    "    df_model_asset.reset_index(drop = True, inplace = True)\n",
    "    df_model_gri = df_model_raw[df_model_raw['Asset Group'] == 'MRI'] ### MRI part\n",
    "    df_model_gri.reset_index(drop = True, inplace = True) \n",
    "    ### Aggregating data from the source xlsx file to pd.DataFrame:\n",
    "    arr_tab_data = []\n",
    "    for iter_index, iter_row in df_model_asset.iterrows():\n",
    "        iter_tab = iter_row['Asset Tab Name']\n",
    "        iter_asset = iter_row['Asset Code']\n",
    "        ser_iter_tab = pd.read_excel(path_gri_data_xlsx, sheet_name = iter_tab, header = 0, index_col = 0, squeeze = True)\n",
    "        ser_iter_tab.name = iter_asset\n",
    "        arr_tab_data.append(ser_iter_tab)\n",
    "    df_source_data = pd.concat(arr_tab_data, axis = 1, join = 'outer')  \n",
    "    df_source_data.index.name = 'Date'\n",
    "    df_source_data = df_source_data.astype('float64')\n",
    "\n",
    "    return [df_model_asset, df_model_gri, df_source_data]\n",
    "    \n",
    "### EXTRACTING SOURCE DATA FROM MS EXCEL FILES AND SAVING TO HDF FILES SCRIPT\n",
    "### Importing standard modules and date-special modules:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "### Global parameters declaring:\n",
    "date_first = date(1990, 1, 1)\n",
    "date_last = date(2018, 12, 31)\n",
    "### Declaring constants:\n",
    "path_gri_data_hdf = 'Data_Files/Source_Files/gri_data.h5'\n",
    "model_asset_key = 'model_asset_key'\n",
    "model_gri_key = 'model_gri_key'\n",
    "source_data_key = 'source_data_key'\n",
    "### Data extracting:\n",
    "[df_model_asset, df_model_gri, df_source_data] = get_gri_data_from_excel()\n",
    "### closing files that have been previously opened:\n",
    "import tables\n",
    "tables.file._open_files.close_all()\n",
    "### Saving data to hdf5 table formatted files:\n",
    "df_model_asset.to_hdf(path_gri_data_hdf, model_asset_key, mode = 'w', format = 'fixed')\n",
    "df_model_gri.to_hdf(path_gri_data_hdf, model_gri_key, mode = 'a', format = 'fixed')\n",
    "df_source_data.to_hdf(path_gri_data_hdf, source_data_key, mode = 'a', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING\n",
    "### Importing standard modules and date-special modules:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "### Declaring constants:\n",
    "path_gri_data_hdf = 'Data_Files/Source_Files/gri_data.h5'\n",
    "model_asset_key = 'model_asset_key'\n",
    "model_gri_key = 'model_gri_key'\n",
    "source_data_key = 'source_data_key'\n",
    "\n",
    "df_model_asset = pd.read_hdf(path_gri_data_hdf, model_asset_key)\n",
    "df_model_gri = pd.read_hdf(path_gri_data_hdf, model_gri_key)\n",
    "df_source_data = pd.read_hdf(path_gri_data_hdf, source_data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_z_score(ser_source, min_wnd, max_wnd, winsor_bottom, winsor_top):\n",
    "    ### Importing standard modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    ### Initializing z-score vector:\n",
    "    ser_asset_z_score = pd.Series(np.NaN, index = ser_source.index)\n",
    "    ser_asset_z_score = ser_asset_z_score.astype('float64')\n",
    "    if (ser_source.count() > 0):\n",
    "        ### Initialising index conditions:\n",
    "        asset_start_index = ser_source.first_valid_index() + pd.offsets.BusinessDay(min_wnd - 1)  \n",
    "        iter_date_index = ser_source.index[-1]\n",
    "        ### Checking for at list min_wnd elements of rolling window are not np.NaN:\n",
    "        if (iter_date_index >= asset_start_index):          \n",
    "            ### Isolating rolling window for particular data vector element:\n",
    "            iter_start_index = iter_date_index - pd.offsets.BusinessDay(max_wnd)\n",
    "            ser_iter_source = ser_source.loc[iter_start_index : iter_date_index]        \n",
    "            ser_iter_z_score = (ser_iter_source - ser_iter_source.mean()) / ser_iter_source.std()            \n",
    "            ### Winsorization process:\n",
    "            bool_to_winsor = True            \n",
    "            while (bool_to_winsor): \n",
    "                ### Value based winsorization:                \n",
    "                ser_iter_z_score.clip(lower = winsor_bottom, upper = winsor_top, inplace = True)\n",
    "                ### Recalculating of z scores:\n",
    "                ser_iter_z_score = (ser_iter_z_score - ser_iter_z_score.mean()) / ser_iter_z_score.std()\n",
    "                ### Checking for boundaries:\n",
    "                if (ser_iter_z_score[(ser_iter_z_score <= (winsor_bottom - 0.01)) | (ser_iter_z_score >= (winsor_top + 0.01))].count() == 0):\n",
    "                    bool_to_winsor = False\n",
    "            ### Filling z vector part after the winsorizing (if needed):\n",
    "            ser_asset_z_score.loc[iter_start_index : iter_date_index] = ser_iter_z_score.values\n",
    "    return ser_asset_z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING\n",
    "    ### Importing standard modules and date-special modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import date    \n",
    "    ### Declaring constants:\n",
    "    date_start = date(1993, 12, 31)    \n",
    "    path_gri_data_hdf = 'Data_Files/Source_Files/gri_data.h5'\n",
    "    model_asset_key = 'model_asset_key'\n",
    "    model_gri_key = 'model_gri_key'\n",
    "    source_data_key = 'source_data_key'\n",
    "    ### Limitations for rolling windows for z-score calculating:\n",
    "    asset_window_min = 252\n",
    "    asset_window_max = 252 * 100\n",
    "    ### Limitations for z-score winsorizing:\n",
    "    arr_winsor_boundary = [-4, 4]\n",
    "    asset_code = 'iv_rvx'\n",
    "    ser_test = get_rolling_z_score(np.log(df_source_data[asset_code]), asset_window_min, asset_window_max, arr_winsor_boundary[0], arr_winsor_boundary[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gri_value(iter_date):\n",
    "    ### Importing standard modules and date-special modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import date    \n",
    "    ### Declaring constants:\n",
    "    date_first = date(1990, 1, 1)    \n",
    "    date_start = date(1993, 12, 31)    \n",
    "    path_gri_data_hdf = 'Data_Files/Source_Files/gri_data.h5'\n",
    "    model_asset_key = 'model_asset_key'\n",
    "    model_gri_key = 'model_gri_key'\n",
    "    source_data_key = 'source_data_key'\n",
    "    ### Limitations for rolling windows for z-score calculating:\n",
    "    asset_window_min = 252\n",
    "    asset_window_max = 252 * 100\n",
    "    mri_window_max = 260 * 10\n",
    "    ### Limitations for z-score winsorizing:\n",
    "    winsor_bottom = -4\n",
    "    winsor_top = 4    \n",
    "    ### Limitations for moving average for GRI calculation:\n",
    "    ma_max_wnd = 5    \n",
    "    ### Extracting model data from hdf5 file:\n",
    "    df_model_asset = pd.read_hdf(path_gri_data_hdf, model_asset_key)\n",
    "    df_model_gri = pd.read_hdf(path_gri_data_hdf, model_gri_key)\n",
    "    df_source_data = pd.read_hdf(path_gri_data_hdf, source_data_key).loc[ : iter_date]\n",
    "    df_source_data.fillna(method = 'ffill', inplace = True)\n",
    "    index_selected = pd.date_range(date_first, iter_date, freq = 'B')\n",
    "    df_selected_data = df_source_data.reindex(index_selected, method = 'ffill')    \n",
    "    ### Base assets determination (resorting by earliest value):\n",
    "    df_model_asset['Asset Date'] = date(1900, 1, 1)\n",
    "    for (iter_index, asset_code) in df_model_asset['Asset Code'].iteritems():\n",
    "        df_model_asset.loc[iter_index, 'Asset Date'] = df_selected_data[asset_code].dropna().index.min() \n",
    "    df_model_asset.sort_values(['Asset Group', 'Asset Date'], inplace = True)\n",
    "    df_model_asset = df_model_asset.reset_index(drop = True)    \n",
    "    ### Initialising loop visibility variables:          \n",
    "    dict_group_container = {} ### Group vectors collection for gri mean vector calculation   \n",
    "    ### Standartizing loop on group level:\n",
    "    for asset_group_name, df_asset_group in df_model_asset.groupby('Asset Group'):\n",
    "        ### Initialising group visibility variables:\n",
    "        bool_base_asset = True\n",
    "        dict_asset_container = {} ### Asset vectors collection for group mean matrix calculation\n",
    "        ### Standartizing cycle on asset level with the group:\n",
    "        for (asset_index, asset_code) in df_asset_group['Asset Code'].iteritems():\n",
    "            ### Assignment of base asset data set:\n",
    "            if (bool_base_asset):\n",
    "                bool_base_asset = False\n",
    "                ### Performing z scoring for base asset:\n",
    "                ser_base_source = np.log(df_selected_data[asset_code][: iter_date])\n",
    "                ser_base_z_score = get_rolling_z_score(ser_base_source, \n",
    "                                                       asset_window_min, asset_window_max,\n",
    "                                                       winsor_bottom, winsor_top)\n",
    "                ### Calculating ethalon filled quantity before date_start:\n",
    "                int_base_filled = ser_base_source[ : date_start].count()\n",
    "                ### Adding result to dictionary:\n",
    "                dict_asset_container[asset_code] = ser_base_z_score\n",
    "            ### Normalization of other asset's data sets:                \n",
    "            else:\n",
    "                ### Performing z scoring for asset:        \n",
    "                ser_asset_source = np.log(df_selected_data[asset_code][: iter_date])                \n",
    "                ser_asset_z_score = get_rolling_z_score(ser_asset_source, \n",
    "                                                        asset_window_min, asset_window_max,\n",
    "                                                        winsor_bottom, winsor_top)\n",
    "                ### Calculating asset filled quantity:                \n",
    "                int_asset_filled = ser_asset_source[ : date_start].count()          \n",
    "                ### Standartizing asset if it does not have enough initial values:\n",
    "                if (int_asset_filled < int_base_filled * 2 / 3):\n",
    "                    ### RenormaLizing asset z vector with base z vector data:\n",
    "                    if (ser_asset_z_score.first_valid_index() != None):                \n",
    "                        index_asset_start = ser_asset_z_score.first_valid_index() + pd.offsets.BusinessDay(asset_window_min - 1)\n",
    "                        ser_base_z_part = ser_base_z_score.loc[index_asset_start - pd.offsets.BusinessDay(asset_window_min - 1) : iter_date]    \n",
    "                        ser_asset_z_score = ser_asset_z_score * ser_base_z_part.std() + ser_base_z_part.mean()\n",
    "                ### Adding result to dictionary:  \n",
    "                dict_asset_container[asset_code] = ser_asset_z_score   \n",
    "        ### Calculating z vector for group:\n",
    "        ser_group_mean = pd.concat(dict_asset_container, axis = 0, names = ['Asset Code', 'Date'], copy = False)\n",
    "        ser_group_mean = ser_group_mean.groupby('Date').mean()    \n",
    "        ser_group_mean_z = (ser_group_mean - ser_group_mean.mean()) / ser_group_mean.std()  \n",
    "        dict_group_container[asset_group_name] = ser_group_mean_z\n",
    "    ### Model groups mean calculation:    \n",
    "    ser_model_mean = pd.concat(dict_group_container, axis = 0, names = ['Group', 'Date'], copy = False)\n",
    "    ser_model_mean = ser_model_mean.groupby(['Date']).mean()  \n",
    "    ### GRI z-scoring:\n",
    "    ser_gri_z_score = pd.Series(np.NaN, index = ser_model_mean.index)\n",
    "    if (iter_date >= pd.Timestamp(date_start)):\n",
    "        ser_iter_mri = ser_model_mean.loc[iter_date - pd.offsets.BusinessDay(mri_window_max) : iter_date]\n",
    "        ser_iter_z_score = (ser_iter_mri - ser_iter_mri.mean()) / ser_iter_mri.std()\n",
    "        ### Winsorization process:\n",
    "        bool_to_winsor = True            \n",
    "        while (bool_to_winsor):       \n",
    "            ### Value based winsorization:\n",
    "            ser_iter_z_score.clip(lower = winsor_bottom, upper = winsor_top, inplace = True)\n",
    "            ### Recalculating of z scores:\n",
    "            ser_iter_z_score = (ser_iter_z_score - ser_iter_z_score.mean()) / ser_iter_z_score.std()                \n",
    "            ### Checking for boundaries:\n",
    "            if (ser_iter_z_score[(ser_iter_z_score <= (winsor_bottom - 0.01)) | (ser_iter_z_score >= (winsor_top + 0.01))].count() == 0):                    \n",
    "                bool_to_winsor = False    \n",
    "        ser_gri_z_score.loc[iter_date - pd.offsets.BusinessDay(mri_window_max) : iter_date] = ser_iter_z_score.values\n",
    "    ### Calculating z matrix for MRI with winsorization:       \n",
    "    ser_gri_z_ma = ser_gri_z_score.copy()\n",
    "    for iter_shift in np.arange(1, ma_max_wnd):\n",
    "        ser_gri_z_ma = ser_gri_z_ma + ser_gri_z_score.shift(iter_shift)\n",
    "    ser_gri_z_ma = ser_gri_z_ma / ma_max_wnd\n",
    "    \n",
    "    return ser_gri_z_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress printout 1000 / 1997-10-30 00:00:00\n",
      "Progress printout 2000 / 2001-08-30 00:00:00\n",
      "Progress printout 3000 / 2005-06-30 00:00:00\n",
      "Progress printout 4000 / 2009-04-30 00:00:00\n",
      "Progress printout 5000 / 2013-02-28 00:00:00\n",
      "Progress printout 6000 / 2016-12-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "### LOOPER FOR GRI\n",
    "### Importing standard modules and date-special modules:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "### Global parameters declaring:\n",
    "date_start = date(1993, 12, 31)  \n",
    "date_last = date(2018, 12, 31)\n",
    "date_range_test = pd.date_range(date_start, date_last, freq = 'B')\n",
    "#date_test = date(2018, 1, 1)\n",
    "#date_range_test = pd.date_range(date_test, date_last, freq = 'B')\n",
    "dict_gri_vector = {}\n",
    "iter_counter = 0\n",
    "for iter_date in date_range_test:\n",
    "    iter_counter = iter_counter + 1\n",
    "    dict_gri_vector[iter_date] = get_gri_value(iter_date)\n",
    "    if ((iter_counter // 1000) == (iter_counter / 1000)):\n",
    "        print('Progress printout',iter_counter, '/', iter_date)\n",
    "ser_gri_full = pd.concat(dict_gri_vector)\n",
    "ser_gri_released = pd.Series(np.NaN, index = ser_gri_full.index.get_level_values(0).unique())\n",
    "for iter_date in ser_gri_released.index:\n",
    "    ser_gri_released[iter_date] = ser_gri_full.loc[iter_date, iter_date]\n",
    "ser_gri_released.index.name = 'Date'\n",
    "ser_gri_released.name = 'GRI_MA5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESULTS SAVING\n",
    "path_gri_index_hdf = 'Data_Files/Source_Files/gri_released_index.h5'\n",
    "gri_vector_key = 'gri_vector_key'\n",
    "gri_vintage_key = 'gri_vintage_key'\n",
    "gri_start_key = 'gri_start_key'\n",
    "ser_gri_released.to_hdf(path_gri_index_hdf, gri_vector_key, mode = 'w', format = 'fixed')\n",
    "ser_gri_full.index.names = ['Date_Point', 'Date']\n",
    "ser_gri_full.to_hdf(path_gri_index_hdf, gri_vintage_key, mode = 'a', format = 'fixed')\n",
    "ser_gri_full.loc[date_start, :].to_hdf(path_gri_index_hdf, gri_start_key, mode = 'a', format = 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRI/MRI delta sum: 0.0027388925416881884\n",
      "GRI/MRI delta min: 2.9926450206829713e-11\n",
      "GRI/MRI delta mean: 4.1994672518984796e-07\n",
      "GRI/MRI delta max: 5.781425458373235e-06\n",
      "GRI/MRI delta std: 4.133255916735697e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22e22f17208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING TESTING\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "### Global parameters declaring:\n",
    "date_first = date(1990, 1, 1)\n",
    "date_last = date(2018, 12, 31)\n",
    "date_range_test = pd.date_range(date_first, date_last, freq = 'B')\n",
    "path_mri_index_hdf = 'Data_Files/Source_Files/gri_released_index.h5'\n",
    "object_diag_mri_hdf = 'diag_MRI_data'\n",
    "object_released_mri_hdf = 'released_MRI_data'\n",
    "ser_mri_z_diag = pd.read_hdf(path_mri_index_hdf, key = object_diag_mri_hdf)\n",
    "ser_mri_released = pd.read_hdf(path_mri_index_hdf, key = object_released_mri_hdf)\n",
    "path_gri_index_hdf = 'Data_Files/Source_Files/gri_released_index.h5'\n",
    "gri_vector_key = 'gri_vector_key'\n",
    "gri_vintage_key = 'gri_vintage_key'\n",
    "ser_gri_released = pd.read_hdf(path_gri_index_hdf, gri_vector_key)\n",
    "print('GRI/MRI delta sum:', abs(ser_mri_released[date_range_test] - ser_gri_released).sum())\n",
    "print('GRI/MRI delta min:', abs(ser_mri_released[date_range_test] - ser_gri_released).min())\n",
    "print('GRI/MRI delta mean:', abs(ser_mri_released[date_range_test] - ser_gri_released).mean())\n",
    "print('GRI/MRI delta max:', abs(ser_mri_released[date_range_test] - ser_gri_released).max())\n",
    "print('GRI/MRI delta std:', abs(ser_mri_released[date_range_test] - ser_gri_released).std())\n",
    "import matplotlib\n",
    "ser_gri_released.plot(figsize = (15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
