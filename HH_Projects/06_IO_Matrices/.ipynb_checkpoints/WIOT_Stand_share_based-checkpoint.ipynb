{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f56c22-8669-4627-bf2f-536d06fc5133",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WIOT MATRICES DEMONSTRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00012dd9-876f-40b4-bd57-5073264fa364",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f1bfc5-9f80-42d5-9bb8-3e9b9fd57c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "### Date Range defining:\n",
    "str_year_start = '1994'\n",
    "### MultiIndex level slice constant:\n",
    "All = slice(None)\n",
    "### Universe path:\n",
    "str_path_universe = 'Data_Files/Source_Files/acadian_universe.xlsx'\n",
    "### Commodity to Industry shares:\n",
    "str_path_unc_ind_weights_hdf = 'Data_Files/Result_Files/unc_ind_weights.h5'\n",
    "str_path_unc_ind_weights_agg_hdf = 'Data_Files/Result_Files/unc_ind_weights_agg.h5'\n",
    "str_gics_key = 'gics_io'\n",
    "### Product / Industry mapping path:\n",
    "str_path_matrix_map = 'Data_Files/Source_Files/WIOT_mapping_detailed.xlsx'\n",
    "str_sheet_matrix = 'GICS 2018'\n",
    "### Augmented bilateral export:\n",
    "str_path_export_bilateral = 'Data_Files/Source_Files/comtrade_export_bilateral.h5'\n",
    "str_key_unc_export = 'export_augmented'\n",
    "### Date / Country / Commodity GICS Group Momentum:\n",
    "str_path_momentum = 'Data_Files/Result_Files/country_group_momentum.h5'\n",
    "str_key_momentum = 'momentum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253469f7-2ef5-4faf-a2d4-ac5da0bd9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING COUNTRY CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    ### In case if URL is unavailable:\n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    ### Online extraction:\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']].sort_index()    \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "    ### Results output:\n",
    "    return df_result\n",
    "    \n",
    "### World Country Codes:\n",
    "df_country_codes = get_country_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cdf9859-d8d9-4415-8c59-fdeee6c1b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM MS EXCEL SOURCE (TO BE IGNORED IN PRODUCT CODE)\n",
    "\n",
    "def ison_membership_converting(str_path_universe, date_end, bool_daily = False, int_backfill_months = 0):\n",
    "    ### Defining business-month-end reindexation on country level:\n",
    "    def country_modify(ser_raw_country, date_end):\n",
    "        ser_res_country = ser_raw_country.droplevel(0).resample('MS').last().resample('BM').last()\n",
    "        range_country = pd.date_range(ser_res_country.index[0], date_end, freq = 'BM')\n",
    "        return ser_res_country.reindex(range_country).ffill()\n",
    "    ### Markets encoding table:\n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM', 0: np.NaN}     \n",
    "    ### Loading source file:\n",
    "    df_raw_universe = pd.read_excel(engine = 'openpyxl', io = str_path_universe, sheet_name = 'Switchers', header = 0, parse_dates = True, index_col = [0, 1],\n",
    "                                 na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    ### Converting source file:\n",
    "    df_raw_universe.index.names = ['Country', 'Date']\n",
    "    ser_raw_universe = df_raw_universe['Region']\n",
    "    ser_raw_universe.fillna(0, inplace = True)\n",
    "    ser_raw_universe.name = 'Market'\n",
    "    ### By country reindexation and translation:\n",
    "    ser_res_universe = ser_raw_universe.groupby('Country').apply(country_modify, date_end)\n",
    "    ser_res_universe.index.names = ['Country', 'Date']\n",
    "    ser_res_universe = ser_res_universe.replace(dict_markets).reorder_levels([1, 0]).sort_index() \n",
    "    ### Expanding membership for primary regions members by backfilling:\n",
    "    if int_backfill_months:\n",
    "        ### List of regions:\n",
    "        list_region = list(ser_res_universe.dropna().unique())\n",
    "        ### Initialising of collection of series with backfilled data for each region:\n",
    "        list_ison_backfill = []\n",
    "        ### Regions looping:\n",
    "        for iter_region in list_region:\n",
    "            ### Defining start of region date:\n",
    "            date_first_valid = ser_res_universe.loc[ser_res_universe == iter_region].first_valid_index()[0]\n",
    "            ### Creating dates index to backfilling:\n",
    "            idx_date_backfill = pd.date_range(end = date_first_valid, periods = int_backfill_months + 1, freq = 'BM')[: -1]\n",
    "            ### Creating primary countries index to backfilling:            \n",
    "            idx_region_backfill = ser_res_universe.loc[ser_res_universe == iter_region].loc[date_first_valid, All].index.get_level_values('Country')\n",
    "            ### Creating full index:\n",
    "            idx_ison_backfill = pd.MultiIndex.from_product([idx_date_backfill, idx_region_backfill])\n",
    "            ### Series with backfilled data:\n",
    "            list_ison_backfill.append(pd.Series(iter_region, index = idx_ison_backfill))\n",
    "        ### Combination of backfilled series and original ISON data:    \n",
    "        ser_res_universe = ser_res_universe.combine_first(pd.concat(list_ison_backfill, axis = 0)).sort_index()  \n",
    "        ser_res_universe.index.names = ['Date', 'Country']\n",
    "    ### Converting to daily frequency:\n",
    "    if bool_daily:\n",
    "        ser_res_universe = ser_res_universe.reset_index('Country').groupby('Country').resample('B').ffill()['Market'].swaplevel().sort_index()    \n",
    "    ### Results output:\n",
    "    ser_res_universe.name = 'Market'\n",
    "    return ser_res_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f17a066-91cc-48b6-b00b-26b8080d9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DUMMY INDUSTRY RETURNS MOMENTUM GENERATION\n",
    "\n",
    "### Index of dates:\n",
    "idx_dates = pd.date_range(start = str_year_start, end = pd.to_datetime('today'), freq = 'BM')\n",
    "### List of countries:\n",
    "list_countries = df_country_codes['ISO SHORT'].to_list()# + ['WW']\n",
    "### List of GICS Industries:\n",
    "list_industries = pd.read_excel(engine = 'openpyxl', io = str_path_matrix_map, sheet_name = str_sheet_matrix, dtype = str, skiprows = 4, header = [0], \n",
    "                                usecols = [4], index_col = None).dropna().squeeze().values\n",
    "### MutiIndex creation:\n",
    "idx_momentum = pd.MultiIndex.from_product([idx_dates, list_countries, list_industries])\n",
    "### Dummy Series generation:\n",
    "ser_future_values = pd.Series(np.random.normal(0.0, 1.0, len(idx_momentum) * 2))\n",
    "ser_future_values = ser_future_values[ser_future_values.abs() <= 1.0][: len(idx_momentum)]\n",
    "ser_momentum = pd.Series(ser_future_values.values, index = idx_momentum)\n",
    "ser_momentum.index.names = ['Date', 'Importer', 'GICS_Industry_Code']\n",
    "ser_momentum.name = 'Industry_Momentum'\n",
    "ser_momentum = ser_momentum.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf177e4e-63e1-4728-9283-522658a6736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date to work with:  2023-11-30\n",
      "Date to search in annual datasets: 2021-12-31\n",
      "WIOT Weights Loaded\n",
      "Industry Returns Momentum Loaded\n",
      "Dataset with WIOT Importers Prepared to Calculate Exporter / Importer / Commodity_ID Momentum\n",
      "WIOT Importers Exporter / Importer / Commodity_ID Momentum Calculated\n",
      "Dataset with RoW Importers Prepared to Calculate Exporter / Importer / Commodity_ID Momentum\n",
      "RoW Importers Exporter / Importer / Commodity_ID Momentum Calculated\n",
      "All Importers Exporter / Importer / Commodity_ID Momentum Concatenated\n",
      "YY as Exporter Momentum Propagated on Rest of ISON Countries\n",
      "Bilateral Export Flows Loaded\n",
      "Bilateral Export Flows Joined to Exporter / Importer / Commodity_ID Momentum\n",
      "Exporter / Industry Group Momentum Calculated & Saved\n"
     ]
    }
   ],
   "source": [
    "### TRANSFORMATION TO COUNTRY / EXPORT GICS GROUP MOMENTUM\n",
    "\n",
    "def get_gics_group_mom(df_group):\n",
    "#    print(df_group.index[0])\n",
    "    df_group = df_group.droplevel(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'])\n",
    "    ser_result = (df_group['Share'] * df_group['Industry_Momentum']).sum() / df_group['Share'].sum()\n",
    "    return ser_result\n",
    "\n",
    "def get_gics_country_mom(df_group):\n",
    "#    print(df_group.index[0])\n",
    "    df_group = df_group.droplevel(['Exporter', 'Commodity_ID'])\n",
    "    ser_result = (df_group['Export'] * df_group['Commodity_Momentum']).sum() / df_group['Export'].sum()\n",
    "    return ser_result\n",
    "\n",
    "if (os.path.exists(str_path_momentum)):\n",
    "    os.remove(str_path_momentum)\n",
    "    \n",
    "### Looping over monthly Industry Returns Momentum dates:\n",
    "for iter_date in idx_dates[::-1]:\n",
    "    gc.collect()\n",
    "    print('Date to work with: ', iter_date.date())\n",
    "    ### Dates shifting to find nearest lagged BYearEnd:\n",
    "    dt_bm_begin = pd.tseries.offsets.BMonthBegin().rollback(iter_date)\n",
    "    dt_bm_lagged = pd.tseries.offsets.BMonthEnd().rollforward(dt_bm_begin - pd.DateOffset(months=12))\n",
    "    dt_by_lagged = pd.tseries.offsets.BYearEnd().rollback(dt_bm_lagged)\n",
    "    print('Date to search in annual datasets:', dt_by_lagged.date())  \n",
    "\n",
    "    ### Export Distribution Shares Extraction:\n",
    "    ser_ind_weights_bil = pd.read_hdf(path_or_buf = str_path_unc_ind_weights_hdf, key = str_gics_key, where = \"(Date in [dt_by_lagged])\")\\\n",
    "                            .droplevel('Date').astype('float16')\n",
    "    ser_ind_weights_agg = pd.read_hdf(path_or_buf = str_path_unc_ind_weights_agg_hdf, key = str_gics_key, where = \"(Date in [dt_by_lagged])\")\\\n",
    "                            .droplevel('Date').astype('float16')\n",
    "    ### WIOT Importers list extraction:\n",
    "    list_wiot_importers = ser_ind_weights_bil.index.levels[1].to_list()    \n",
    "    list_wiot_importers.remove('YY')\n",
    "    list_wiot_importers.remove('WW')    \n",
    "    print('WIOT Weights Loaded')\n",
    "    ### Industry Returns Momentum Extraction:\n",
    "    ser_ind_mom = ser_momentum[iter_date]\n",
    "    ser_ind_mom_wiot = ser_ind_mom[list_wiot_importers]\n",
    "    ser_ind_mom_row = ser_ind_mom.loc[~ser_ind_mom.index.get_level_values('Importer').isin(list_wiot_importers)] \n",
    "    print('Industry Returns Momentum Loaded')    \n",
    "    ### Adding Industry Momentum values to Export Distribution Shares:\n",
    "    df_ind_mom_wiot_wiot = ser_ind_weights_bil.to_frame().join(ser_ind_mom_wiot)\n",
    "    df_ind_mom_yy_wiot = ser_ind_weights_agg.loc[['YY'], list_wiot_importers].to_frame().join(ser_ind_mom_wiot)\n",
    "    df_ind_mom_wiot = pd.concat([df_ind_mom_wiot_wiot, df_ind_mom_yy_wiot], axis = 0)    \n",
    "    del ser_ind_weights_bil\n",
    "    del ser_ind_mom_wiot    \n",
    "    del df_ind_mom_wiot_wiot\n",
    "    del df_ind_mom_yy_wiot\n",
    "    gc.collect()            \n",
    "    df_ind_mom_wiot = df_ind_mom_wiot.reorder_levels(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code', 'GICS_Industry_Code']).sort_index()\n",
    "    df_ind_mom_wiot.index = df_ind_mom_wiot.index.set_levels(df_ind_mom_wiot.index.levels[1].astype('category'), level = 'Importer')\n",
    "    df_ind_mom_wiot.index = df_ind_mom_wiot.index.set_levels(df_ind_mom_wiot.index.levels[4].astype('category'), level = 'GICS_Industry_Code')    \n",
    "#    df_ind_mom_wiot = df_ind_mom_wiot.loc[['CN', 'MX', 'YY']]\n",
    "    print('Dataset with WIOT Importers Prepared to Calculate Exporter / Importer / Commodity_ID Momentum')    \n",
    "    ser_comm_mom_wiot = df_ind_mom_wiot.groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'], observed = True).apply(get_gics_group_mom) \n",
    "#    pandarallel.initialize(progress_bar = False)\n",
    "#    ser_comm_mom_wiot = df_ind_mom_wiot.groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'], observed = True)\\\n",
    "#                                       .parallel_apply(get_gics_group_mom)   \n",
    "    del df_ind_mom_wiot        \n",
    "    gc.collect()      \n",
    "    print('WIOT Importers Exporter / Importer / Commodity_ID Momentum Calculated')    \n",
    "    df_ind_mom_row = ser_ind_weights_agg.loc[:, 'YY'].to_frame().join(ser_ind_mom_row)\n",
    "    del ser_ind_weights_agg    \n",
    "    del ser_ind_mom_row        \n",
    "    gc.collect()        \n",
    "    df_ind_mom_row = df_ind_mom_row.reorder_levels(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code', 'GICS_Industry_Code']).sort_index()\n",
    "    df_ind_mom_row.index = df_ind_mom_row.index.set_levels(df_ind_mom_row.index.levels[1].astype('category'), level = 'Importer')\n",
    "    df_ind_mom_row.index = df_ind_mom_row.index.set_levels(df_ind_mom_row.index.levels[4].astype('category'), level = 'GICS_Industry_Code')    \n",
    "#    df_ind_mom_row = df_ind_mom_row.loc[['CN', 'MX', 'YY']]\n",
    "    print('Dataset with RoW Importers Prepared to Calculate Exporter / Importer / Commodity_ID Momentum')        \n",
    "    ser_comm_mom_row = df_ind_mom_row.groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'], observed = True).apply(get_gics_group_mom)\n",
    "#    pandarallel.initialize(progress_bar = False)\n",
    "#    ser_comm_mom_row = df_ind_mom_row.groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'], observed = True)\\\n",
    "#                                     .parallel_apply(get_gics_group_mom)\n",
    "    del df_ind_mom_row        \n",
    "    gc.collect()         \n",
    "    print('RoW Importers Exporter / Importer / Commodity_ID Momentum Calculated')  \n",
    "    ser_comm_mom = pd.concat([ser_comm_mom_wiot, ser_comm_mom_row], axis = 0).sort_index()\n",
    "    ser_comm_mom.index = ser_comm_mom.index.set_levels(ser_comm_mom.index.levels[1].astype('category'), level = 'Importer')\n",
    "    del ser_comm_mom_wiot\n",
    "    del ser_comm_mom_row\n",
    "    gc.collect()        \n",
    "    print('All Importers Exporter / Importer / Commodity_ID Momentum Concatenated')      \n",
    "    ### ISON membership:\n",
    "    list_ison_members = ison_membership_converting(str_path_universe, pd.to_datetime(dt_by_lagged))[dt_by_lagged].index.to_list()\n",
    "    ### Replacing YY as Exporter:\n",
    "    list_non_wiot_ison = sorted(list(set(list_ison_members) - set(list_wiot_importers)))\n",
    "    df_comm_mom_yy = ser_comm_mom[['YY']].unstack('Exporter')\n",
    "    df_comm_mom_yy[list_non_wiot_ison] = np.NaN\n",
    "    ser_comm_mom_yy = df_comm_mom_yy.ffill(axis = 1).drop('YY', axis = 1).stack('Exporter').astype('float16').reorder_levels([3, 0, 1, 2]).sort_index()\n",
    "    print('YY as Exporter Momentum Propagated on Rest of ISON Countries')    \n",
    "    ser_comm_mom_ison = pd.concat([ser_comm_mom, ser_comm_mom_yy], axis = 0).drop('YY', level = 'Exporter') \n",
    "    del df_comm_mom_yy\n",
    "    del ser_comm_mom\n",
    "    del ser_comm_mom_yy\n",
    "    gc.collect()\n",
    "    ser_comm_mom_ison.name = 'Commodity_Momentum'    \n",
    "    ### UN Comtrade Bilateral Export Flows Extraction:\n",
    "    ser_unc_export = pd.read_hdf(str_path_export_bilateral, key = str_key_unc_export, where = \"Date in [dt_by_lagged]\").droplevel(['Date', 'Type']).sort_index() \n",
    "    ser_unc_export.index.names = ['Exporter', 'Importer', 'Commodity_ID']\n",
    "    print('Bilateral Export Flows Loaded')  \n",
    "    df_comm_mom = ser_comm_mom_ison.to_frame().join(ser_unc_export[ser_unc_export > 0.0]).dropna()\n",
    "    del ser_comm_mom_ison\n",
    "    del ser_unc_export\n",
    "    gc.collect()\n",
    "    print('Bilateral Export Flows Joined to Exporter / Importer / Commodity_ID Momentum')      \n",
    "    ser_country_mom = df_comm_mom.groupby(['Exporter', 'Commodity_Group_Code'], observed = True).apply(get_gics_country_mom)\n",
    "    ser_country_mom.name = 'Momentum'    \n",
    "\n",
    "    pd.concat([ser_country_mom], keys = [iter_date], names = ['Date'])\\\n",
    "                                                    .to_hdf(str_path_momentum, key = str_key_momentum, mode = 'a', format = 'table', append = True)\n",
    "    print('Exporter / Industry Group Momentum Calculated & Saved')    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6134cba-36b8-49e5-a1fe-ba9d11b77818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Exporter  Commodity_Group_Code\n",
       "2023-11-30  AT        3020                    0.061567\n",
       "                      1510                   -0.030936\n",
       "                      2020                   -0.038711\n",
       "                      5020                    0.100973\n",
       "                      2530                   -0.032308\n",
       "                                                ...   \n",
       "            ZM        3030                   -0.086733\n",
       "                      2520                   -0.066546\n",
       "                      2010                   -0.078679\n",
       "                      5010                   -0.018112\n",
       "                      4520                   -0.064264\n",
       "Name: Momentum, Length: 1333, dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_test = pd.read_hdf(str_path_momentum, key = str_key_momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179a006-d563-44be-90d5-50187e0f6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f438f8f-9f16-4115-b246-01ffd95e321a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
