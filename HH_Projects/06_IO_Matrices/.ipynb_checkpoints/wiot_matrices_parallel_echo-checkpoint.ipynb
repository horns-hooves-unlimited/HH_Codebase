{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52789805-c80c-4d93-b746-57f3e2f7064b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### WIOT MATRICES CONVERTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e16ab8-be40-4f3d-b489-d977e3cfed6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from pandarallel import pandarallel\n",
    "#import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2366151b-554f-4722-bb56-f5b57cd57464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.7.4\n",
      "numpy version:  1.21.5\n",
      "pandas version:  1.3.5\n"
     ]
    }
   ],
   "source": [
    "### RUN EVERY TIME: VERSION CONTROL\n",
    "\n",
    "from platform import python_version\n",
    "print('python version: ', python_version())\n",
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa00a819-0caf-4f30-aa1a-5428518bc069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "### MultiIndex level slice constant:\n",
    "All = slice(None)\n",
    "### NA for MS Excel files:\n",
    "list_na_excel_values = ['', '---', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null',\n",
    "                        '#N/A Requesting Data...', '#N/A Invalid Security', '#N/A Field Not Applicable']\n",
    "### Product / Industry mapping path:\n",
    "str_path_matrix_map = 'Data_Files/Source_Files/WIOT_mapping_detailed.xlsx'\n",
    "str_sheet_matrix = 'Matrix to Load'\n",
    "str_sheet_unc_g_map = 'HS'\n",
    "str_sheet_unc_s_map = 'EBOPS 2010'\n",
    "str_sheet_old_way = 'Old Way Map'\n",
    "str_sheet_gics_substitution = 'GICS Substitution'\n",
    "### Path to original WIOT Tables:\n",
    "str_path_wiot_source = 'Data_Files/Source_Files/WIOT'\n",
    "### Augmented bilateral export:\n",
    "str_path_export_bilateral = 'Data_Files/Source_Files/comtrade_export_bilateral.h5'\n",
    "str_key_unc_export = 'export_augmented'\n",
    "### Downloaded and aggregated shares:\n",
    "str_path_wiot_volumes_hdf = 'Data_Files/Result_Files/wiot_volumes.h5'\n",
    "str_path_wiot_shares_hdf = 'Data_Files/Result_Files/wiot_shares.h5'\n",
    "str_path_wiot_filled_hdf = 'Data_Files/Result_Files/wiot_filled.h5'\n",
    "str_path_unc_sub_weights_full_hdf = 'Data_Files/Result_Files/unc_sub_weights_full.h5'\n",
    "str_path_unc_ind_weights_full_hdf = 'Data_Files/Result_Files/unc_ind_weights_full.h5'\n",
    "str_path_unc_nace_weights_full_hdf = 'Data_Files/Result_Files/unc_nace_weights_full.h5'\n",
    "str_path_unc_nace_weights_second_hdf = 'Data_Files/Result_Files/unc_nace_weights_second.h5'\n",
    "str_gics_key = 'gics_io'\n",
    "### Old way resulting table:\n",
    "str_path_total_shares = 'Data_Files/Test_Files/total_shares_v2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f6727b8-b5db-42a0-982c-eca55a80223b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### OLD VERSION MATRIX\n",
    "\n",
    "### Loading old version shares:\n",
    "df_old_version = pd.read_csv(str_path_total_shares, index_col = 0)\n",
    "df_old_version.index.names = ['Group_Code']\n",
    "df_old_version.index = df_old_version.index.astype('str')\n",
    "ser_ww_to_ww_old = df_old_version.stack()\n",
    "ser_ww_to_ww_old.index.names = ['Commodity_Group_Code', 'GICS_Group_Code']\n",
    "ser_ww_to_ww_old.name = 'Share_Old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9215d4e4-c244-4d08-997b-f3c40e1eae82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### GICS SUBSTITUTION MAP\n",
    "\n",
    "ser_gics_substitution = pd.read_excel(str_path_matrix_map, str_sheet_gics_substitution, dtype = 'str', index_col = None)\\\n",
    "                          .set_index('Industry Group').dropna().squeeze()\n",
    "ser_gics_substitution.index.names = ['Commodity_Group_Code']\n",
    "ser_gics_substitution.name = 'Substitute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd5929b-8476-404a-a38b-e701a1e8228f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### COMMODITIES MAPPING TO GICS INDUSTRY GROUPS\n",
    "\n",
    "### Goods:\n",
    "ser_goods_to_groups = pd.read_excel(engine = 'openpyxl', io = str_path_matrix_map, sheet_name = str_sheet_unc_g_map, dtype = str, header = [0], \n",
    "                               index_col = None).set_index('Commodity_ID')['GICS_Group'].dropna()\n",
    "ser_goods_to_groups.name = 'Commodity_Group_Code'\n",
    "### Services:\n",
    "ser_services_to_groups = pd.read_excel(engine = 'openpyxl', io = str_path_matrix_map, sheet_name = str_sheet_unc_s_map, dtype = str, header = [0], \n",
    "                               index_col = None).set_index('Commodity_ID')['GICS_Group'].dropna()\n",
    "ser_services_to_groups.name = 'Commodity_Group_Code'\n",
    "ser_services_to_groups = ser_services_to_groups[ser_services_to_groups != '---']\n",
    "### Mappers concatenation:\n",
    "ser_comm_to_groups = pd.concat([ser_goods_to_groups, ser_services_to_groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a33f2c-391f-49cf-be8e-d5d27c188135",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### UN COMTRADE TO GICS WIOT BASED MATRIX LOADING\n",
    "\n",
    "### Source table loading:\n",
    "df_unc_to_gics = pd.read_excel(engine = 'openpyxl', io = str_path_matrix_map, sheet_name = str_sheet_matrix, dtype = str, header = list(range(6)), \n",
    "                               index_col = list(range(4)))\n",
    "df_unc_to_gics.index.names = ['WIOT_Exporter_Code', 'WIOT_Description', 'Commodity_ID', 'Commodity_Description']\n",
    "df_unc_to_gics.columns.names = ['WIOT_Importer_Code', 'WIOT_Description', 'GICS_Sub_Code', 'GICS_Industry_Code', 'GICS_Group_Code', 'GICS_Sub_Name']\n",
    "### Index levels checker:\n",
    "df_unc_to_gics.index = df_unc_to_gics.index.set_levels(df_unc_to_gics.index.levels[2].astype('str'), level = 'Commodity_ID')\n",
    "### Matrix filtering:\n",
    "df_unc_to_gics = df_unc_to_gics.droplevel(['WIOT_Description', 'Commodity_Description']).droplevel(['WIOT_Description', 'GICS_Sub_Name'], axis = 1)\n",
    "df_unc_to_gics = df_unc_to_gics.drop(index = '---', level = 'Commodity_ID').drop(columns = '---', level = 'GICS_Group_Code')\n",
    "### Matrix convertation:\n",
    "df_unc_to_gics = df_unc_to_gics.replace({'x': False, 'y': True, 'z': True})\n",
    "gc.collect()\n",
    "ser_unc_to_gics = df_unc_to_gics.stack(df_unc_to_gics.columns.names).astype(bool)\n",
    "ser_unc_to_gics.name = 'Connection_Flag'\n",
    "### Adding Comtrade to GICS mapping:\n",
    "ser_unc_to_gics = ser_unc_to_gics.to_frame().join(ser_comm_to_groups, how = 'inner').set_index('Commodity_Group_Code', append = True).squeeze()\n",
    "### Index Levels categorizing:\n",
    "ser_unc_to_gics = ser_unc_to_gics.reorder_levels([0, 2, 1, 6, 3, 4, 5]).sort_index()\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[4].astype(str), level = 'GICS_Sub_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[0].astype('category'), level = 'WIOT_Exporter_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[1].astype('category'), level = 'WIOT_Importer_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[2].astype('category'), level = 'Commodity_ID')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[3].astype('category'), level = 'Commodity_Group_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[4].astype('category'), level = 'GICS_Sub_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[5].astype('category'), level = 'GICS_Industry_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[6].astype('category'), level = 'GICS_Group_Code')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "507c7522-3b78-4f92-94f7-70d5a5f3205c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### DIRECT NACE TO GICS GROUP MAP\n",
    "\n",
    "df_old_map = pd.read_excel(str_path_matrix_map, str_sheet_old_way, dtype = str)\n",
    "df_old_map['WIOT Code'] = df_old_map['WIOT Code'].str.replace('r', 'c')\n",
    "ser_old_map = df_old_map.set_index('WIOT Code').squeeze()\n",
    "ser_old_map.name = 'GICS_Group_Code'\n",
    "ser_old_map.index.name = 'WIOT_Importer_Code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585ae21f-bcdb-4a3a-a790-3d20137008cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING COUNTRY CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    ### In case if URL is unavailable:\n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    ### Online extraction:\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']].sort_index()    \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "    ### Results output:\n",
    "    return df_result\n",
    "\n",
    "### World Country Codes:\n",
    "df_country_codes = get_country_codes()\n",
    "dict_ison_mapper = df_country_codes.set_index('ISO LONG').squeeze().to_dict()\n",
    "dict_ison_mapper['ROW'] = 'YY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4dad6-3193-4969-b0db-b2c3cf7c4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WIOT DATA TABLES LOADING & CONVERTATION & SAVING\n",
    "\n",
    "### Lists of WIOT Activities:\n",
    "list_exporter_codes = ['r' + str(iter_num) for iter_num in range(1, 55)]\n",
    "list_importer_codes = ['c' + str(iter_num) for iter_num in range(1, 55)]\n",
    "#list_importer_codes.remove('c51') ### Remove of \"Public administration and defence; compulsory social security\"\n",
    "\n",
    "if (os.path.exists(str_path_wiot_volumes_hdf)):\n",
    "    os.remove(str_path_wiot_volumes_hdf)\n",
    "#for year_matrix_csv in os.listdir(str_path_wiot_source):\n",
    "for year_matrix_csv in os.listdir(str_path_wiot_source)[::-1]:    \n",
    "    gc.collect()\n",
    "    dt_year_end = (pd.to_datetime(year_matrix_csv[4 : 8]) + pd.offsets.BYearEnd())#.date()\n",
    "    str_year_num = year_matrix_csv[4 : 8]\n",
    "    print(str_year_num, ': IO Matrix of WIOT Activities Loading Started')\n",
    "    df_year_raw = pd.read_csv(str_path_wiot_source + '/' + year_matrix_csv, sep = ';', index_col = [0, 1, 2, 3], skiprows = [0, 1, 2, 3], header = [0, 1], \n",
    "                                        na_values = list_na_excel_values, keep_default_na = False)\n",
    "    ser_year_raw = df_year_raw.droplevel([0, 1]).stack([0, 1]).astype('int32')\n",
    "    ser_year_raw.name = 'Value'\n",
    "    ser_year_raw.index.names = ['Supplier_Country_Long', 'WIOT_Exporter_Code', 'User_Country_Long', 'WIOT_Importer_Code']    \n",
    "    df_year_typed = ser_year_raw.reset_index()\n",
    "    del df_year_raw\n",
    "    del ser_year_raw\n",
    "    gc.collect()\n",
    "    df_year_typed = df_year_typed[df_year_typed['Supplier_Country_Long'].isin(df_country_codes['ISO LONG'].to_list() + ['ROW']) & \n",
    "                                  df_year_typed['User_Country_Long'].isin(df_country_codes['ISO LONG'].to_list() + ['ROW']) & \n",
    "                                  df_year_typed['WIOT_Exporter_Code'].isin(list_exporter_codes) & \n",
    "                                  df_year_typed['WIOT_Importer_Code'].isin(list_importer_codes)]\n",
    "    df_year_typed['Exporter'] = df_year_typed['Supplier_Country_Long'].replace(dict_ison_mapper)\n",
    "    df_year_typed['Importer'] = df_year_typed['User_Country_Long'].replace(dict_ison_mapper)          \n",
    "    df_year_typed['Exporter'] = df_year_typed['Exporter'].astype('category')\n",
    "    df_year_typed['Importer'] = df_year_typed['Importer'].astype('category')\n",
    "    df_year_typed['WIOT_Exporter_Code'] = df_year_typed['WIOT_Exporter_Code'].astype('category')\n",
    "    df_year_typed['WIOT_Exporter_Code'] = df_year_typed['WIOT_Exporter_Code'].cat.set_categories(new_categories = list_exporter_codes, ordered = True)\n",
    "    df_year_typed['WIOT_Importer_Code'] = df_year_typed['WIOT_Importer_Code'].astype('category')    \n",
    "    df_year_typed['WIOT_Importer_Code'] = df_year_typed['WIOT_Importer_Code'].cat.set_categories(new_categories = list_importer_codes, ordered = True)    \n",
    "    ser_year_wiot = df_year_typed.set_index(['Exporter', 'Importer', 'WIOT_Exporter_Code', 'WIOT_Importer_Code'])['Value'].squeeze().sort_index()\n",
    "    ser_year_wiot = ser_year_wiot.clip(lower = 0)\n",
    "    pd.concat([ser_year_wiot], keys = [dt_year_end], names = ['Date'])\\\n",
    "                                                    .to_hdf(str_path_wiot_volumes_hdf, key = str_gics_key, mode = 'a', format = 'table', complevel = 9, append = True)\n",
    "    print(str_year_num, ': IO Matrix of WIOT Activities Saved')    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a65fe4-2d87-4615-af6f-77f0a91aafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WIOT LAST DATE MATRIX CONVERTING TO SHARES & AGGREGATED DATA ADDING\n",
    "\n",
    "gc.collect()\n",
    "ser_last_wiot = pd.read_hdf(str_path_wiot_volumes_hdf, key = str_gics_key).droplevel('Date')\n",
    "\n",
    "### Adding World as Exporter & Importer\n",
    "df_last_wiot = ser_last_wiot.reset_index()\n",
    "df_last_wiot['Exporter'] = df_last_wiot['Exporter'].cat.add_categories(['WW'])\n",
    "df_last_wiot['Importer'] = df_last_wiot['Importer'].cat.add_categories(['WW'])    \n",
    "### Inner flows filtering:\n",
    "df_inner_flows = df_last_wiot[(df_last_wiot['Exporter'] == df_last_wiot['Importer'])]      \n",
    "### Outer flows filtering:\n",
    "df_outer_flows = df_last_wiot[(df_last_wiot['Exporter'] != df_last_wiot['Importer'])]  \n",
    "### Inner values to series:\n",
    "ser_country_inner_values = df_inner_flows.set_index(['Exporter', 'Importer', 'WIOT_Exporter_Code', 'WIOT_Importer_Code']).astype('float32').squeeze()     \n",
    "### Outer values to series:    \n",
    "ser_country_to_country_values = df_outer_flows.set_index(['Exporter', 'Importer', 'WIOT_Exporter_Code', 'WIOT_Importer_Code']).astype('float32').squeeze() \n",
    "### Country to World trade:        \n",
    "ser_country_to_world_values = df_outer_flows.groupby(['Exporter', 'WIOT_Exporter_Code', 'WIOT_Importer_Code'], observed = True)['Value'].sum().squeeze().sort_index()\n",
    "### World to World trade:            \n",
    "ser_world_to_world_values = ser_country_to_world_values.groupby(['WIOT_Exporter_Code', 'WIOT_Importer_Code'], observed = True).sum().astype('float32').sort_index()\n",
    "### World to Country trade:                \n",
    "ser_world_to_country_values = df_outer_flows.groupby(['Importer', 'WIOT_Exporter_Code', 'WIOT_Importer_Code'], observed = True)['Value'].sum().squeeze().sort_index()\n",
    "### Inner shares:\n",
    "ser_country_inner_shares = ser_country_inner_values.groupby(['Exporter', 'Importer', 'WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                   .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index()     \n",
    "### Outer shares:\n",
    "ser_country_to_country_shares = ser_country_to_country_values.groupby(['Exporter', 'Importer', 'WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                             .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index()          \n",
    "ser_country_to_world_shares = ser_country_to_world_values.groupby(['Exporter', 'WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                         .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index() \n",
    "ser_country_to_world_shares = pd.concat({'WW': ser_country_to_world_shares}, names = ['Importer']).swaplevel(0, 1).sort_index()\n",
    "#ser_country_to_world_shares.drop(('WW', 'WW'), inplace = True)\n",
    "ser_world_to_country_shares = ser_world_to_country_values.groupby(['Importer', 'WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                         .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index() \n",
    "ser_world_to_country_shares = pd.concat({'WW': ser_world_to_country_shares}, names = ['Exporter'])    \n",
    "#ser_world_to_country_shares.drop(('WW', 'WW'), inplace = True)    \n",
    "ser_world_to_world_shares = ser_world_to_world_values.groupby(['WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                     .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index() \n",
    "ser_world_to_world_shares = pd.concat({'WW': pd.concat({'WW': ser_world_to_world_shares}, names = ['Importer'])}, names = ['Exporter'])    \n",
    "### Values aggregating:\n",
    "ser_last_shares = pd.concat([ser_country_inner_shares, ser_country_to_country_shares, ser_country_to_world_shares, ser_world_to_country_shares, \n",
    "                             ser_world_to_world_shares]).sort_index()\n",
    "del ser_country_to_country_shares\n",
    "gc.collect()\n",
    "#ser_last_shares.drop('9999', axis = 0, level = 'WIOT_Exporter_Code', inplace =  True)\n",
    "#ser_last_shares.drop('9999', axis = 0, level = 'WIOT_Importer_Code', inplace =  True) \n",
    "ser_last_shares.name = 'Share'\n",
    "ser_last_shares.to_hdf(str_path_wiot_shares_hdf, key = str_gics_key, mode = 'w', format = 'table', complevel = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c497ab27-ac7b-4ed8-a30a-d00c0d5fce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country_to_country': 52892, 'country_to_world': 48181, 'world_to_country': 7807, 'world_to_world': 470, 'empty': 0}\n"
     ]
    }
   ],
   "source": [
    "### FILLING GAPS IN SHARES\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "ser_last_shares = pd.read_hdf(str_path_wiot_shares_hdf, key = str_gics_key).fillna(0.0)\n",
    "\n",
    "dict_counter = {}\n",
    "dict_counter['country_to_country'] = 0\n",
    "dict_counter['country_to_world'] = 0\n",
    "dict_counter['world_to_country'] = 0\n",
    "dict_counter['world_to_world'] = 0\n",
    "dict_counter['empty'] = 0\n",
    "\n",
    "for iter_exporter in ser_last_shares.index.levels[0]:\n",
    "    for iter_importer in ser_last_shares.index.levels[1]:\n",
    "        for iter_industry in ser_last_shares.index.levels[2]:\n",
    "            ser_country_to_country = ser_last_shares.loc[iter_exporter, iter_importer, iter_industry]\n",
    "            ser_country_to_world = ser_last_shares.loc[iter_exporter, 'WW', iter_industry]\n",
    "            ser_world_to_country = ser_last_shares.loc['WW', iter_importer, iter_industry]\n",
    "            ser_world_to_world = ser_last_shares.loc['WW', 'WW', iter_industry]\n",
    "            if (ser_country_to_country.sum() == 0.0):\n",
    "                if (ser_country_to_world.sum() == 0.0):\n",
    "                    if (ser_world_to_country.sum() == 0.0):\n",
    "                        if (ser_world_to_world.sum() == 0.0):\n",
    "                            dict_counter['empty'] += 1                    \n",
    "#                            print(iter_exporter, iter_importer, iter_industry, ': no data to fill')                            \n",
    "                        else:\n",
    "                            ser_last_shares.loc[iter_exporter, iter_importer, iter_industry] = ser_world_to_world.values\n",
    "                            dict_counter['world_to_world'] += 1\n",
    "#                            print(iter_exporter, iter_importer, iter_industry, ': filled by World to World level data')                            \n",
    "                    else:\n",
    "                        ser_last_shares.loc[iter_exporter, iter_importer, iter_industry] = ser_world_to_country.values\n",
    "                        dict_counter['world_to_country'] += 1\n",
    "#                        print(iter_exporter, iter_importer, iter_industry, ': filled by World to Country level data')                        \n",
    "                else:\n",
    "                    ser_last_shares.loc[iter_exporter, iter_importer, iter_industry] = ser_country_to_world.values\n",
    "                    dict_counter['country_to_world'] += 1\n",
    "#                    print(iter_exporter, iter_importer, iter_industry, ': filled by Country to World level data')\n",
    "            else:\n",
    "                dict_counter['country_to_country'] += 1\n",
    "print(dict_counter)\n",
    "### Results saving:\n",
    "ser_last_shares.to_hdf(str_path_wiot_filled_hdf, key = str_gics_key, mode = 'w', format = 'table', complevel = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10371de5-8d43-43c5-969a-06e3e1e1f414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_to_country : 0.4837\n",
      "country_to_world : 0.4406\n",
      "world_to_country : 0.0714\n",
      "world_to_world : 0.0043\n",
      "empty : 0.0\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "\n",
    "for iter_option in dict_counter:\n",
    "    print(iter_option, ':', round(dict_counter[iter_option] / len(ser_last_shares.groupby(['Exporter', 'Importer', 'WIOT_Exporter_Code']).count()), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c8a3a8c-f33c-4026-a669-c91e1dd7a493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### DEFINING COMMODITY TO SUB INDUSTRY DISTRIBUTION CALCUCATOR\n",
    "\n",
    "def get_wiot_weights_parallel(ser_wiot_shares, ser_unc_to_gics, ser_iter_comtrade):\n",
    "    ### Extracting Groupby Keys:\n",
    "    ser_wiot_shares = ser_wiot_shares.squeeze()\n",
    "    ser_wiot_shares.name = 'Activity_Share'\n",
    "#    print(ser_wiot_shares.describe())\n",
    "    (str_iter_exporter, str_iter_importer, str_iter_code) = ser_wiot_shares.index[0][: -1]\n",
    "#    print(str_iter_exporter, str_iter_importer, str_iter_code)\n",
    "    if ((str_iter_importer == 'AT') & (str_iter_code == 'r1')):\n",
    "        print(str_iter_exporter, 'as Exporter')\n",
    "    ### Selecting Product -> Importer GICS Sub Industry Flags:\n",
    "    ser_wiot_flags = ser_unc_to_gics[str_iter_code]\n",
    "    ### Calculating of Relation Product Export Shares Inside Exporter WIOT Activity:\n",
    "    idx_comm_id = ser_wiot_flags['c2'].index.get_level_values('Commodity_ID')\n",
    "    try:\n",
    "        ser_unc_volumes = ser_iter_comtrade.loc[[str_iter_exporter], [str_iter_importer], idx_comm_id]\n",
    "    except KeyError:\n",
    "        print('No trade:', str_iter_exporter, str_iter_importer, str_iter_code)\n",
    "    else:\n",
    "        ser_unc_shares = (ser_unc_volumes / ser_unc_volumes.sum()).droplevel(['Exporter', 'Importer'])\n",
    "        ser_unc_shares.name = 'Export_Share'\n",
    "        ### Concatenating Importer WIOT Activity Shares & Product -> Importer GICS Sub Industry Flags & Product Export Shares Inside Exporter WIOT Activity:\n",
    "        df_pair_supply = ser_wiot_shares.droplevel(['Exporter', 'Importer', 'WIOT_Exporter_Code']).to_frame().join(ser_wiot_flags, how = 'left')\\\n",
    "                                                                                                            .join(ser_unc_shares, how = 'left').sort_index()\n",
    "        ### First Step Weights Distribution: Product Share, Weighted by GICS Sub Industry Share (Activity Share equal part):\n",
    "        df_pair_supply['Weight_First'] = df_pair_supply.groupby(['WIOT_Importer_Code', 'Commodity_ID'], group_keys = False, observed = True)\\\n",
    "                                        .apply(lambda df_i: df_i['Export_Share'] * df_i['Activity_Share'] * df_i['Connection_Flag'] / df_i['Connection_Flag'].sum())\n",
    "#        ### Primary Weights Normalization inside Commodity:\n",
    "#        df_pair_supply['Weight_First'] = df_pair_supply['Weight_First'].groupby('Commodity_ID', group_keys = False, observed = True)\\\n",
    "#                                                                       .apply(lambda ser_i: ser_i / ser_i.sum())   \n",
    "        ### Secondary Weights Distribution: Normalization Inside Export WIOT Activity * Import WIOT Activity Matrix:\n",
    "        df_pair_supply['Weight_Second'] = df_pair_supply['Weight_First'].groupby('WIOT_Importer_Code', group_keys = False, observed = True)\\\n",
    "                                                                        .apply(lambda ser_i: ser_i / ser_i.sum()) * df_pair_supply['Activity_Share']    \n",
    "        ### Secondary Weights Distribution: Normalization inside Commodity:\n",
    "        df_pair_supply['Weight_Second'] = df_pair_supply['Weight_Second'].groupby('Commodity_ID', group_keys = False, observed = True)\\\n",
    "                                                                         .apply(lambda ser_i: ser_i / ser_i.sum())\n",
    "        ### Results Output:\n",
    "#        return df_pair_supply['Weight_Second']        \n",
    "        ser_result = df_pair_supply.loc[df_pair_supply['Weight_Second'] > 0.0, 'Weight_Second'].astype('float16')\n",
    "#        ser_result = ser_result.groupby(['Commodity_ID', 'Commodity_Group_Code', 'GICS_Sub_Code'], group_keys = False, observed = True).sum()\n",
    "        ser_result = ser_result.groupby(['Commodity_ID', 'Commodity_Group_Code', 'WIOT_Importer_Code'], group_keys = False, observed = True).sum()        \n",
    "#        print(ser_result)\n",
    "        if (len(ser_result) > 0):\n",
    "            return ser_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc6e22fa-1c01-4746-b7e8-586edbf974ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### DISTRIBUTION CONSTANTS\n",
    "\n",
    "### Date Range defining:\n",
    "str_year_start = '1989' # '1989'\n",
    "str_year_end = '2023'\n",
    "list_dates = pd.date_range(start = str_year_start, end = str_year_end, freq = 'BY').to_list()\n",
    "#list_dates = pd.date_range(start = str_year_start, end = str_year_end, freq = '7BY').to_list()\n",
    "### WIOT Matrix Shares Loading:\n",
    "ser_last_shares = pd.read_hdf(str_path_wiot_filled_hdf, key = str_gics_key)\n",
    "list_exporters_wiot = ser_last_shares.index.levels[0].to_list()\n",
    "list_exporters_wiot.remove('YY')\n",
    "list_exporters_wiot.remove('WW')\n",
    "list_importers_wiot = ser_last_shares.index.levels[1].to_list()\n",
    "list_importers_wiot.remove('YY')\n",
    "list_importers_wiot.remove('WW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe3ec0-036d-484c-a812-a78eb3dae3ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### UN COMTRADE & WIOT AGGREGATION : ALL POSSIBLE COMBINATIONS\n",
    "\n",
    "### Deleting old data:\n",
    "if (os.path.exists(str_path_unc_nace_weights_full_hdf)):\n",
    "    os.remove(str_path_unc_nace_weights_full_hdf)\n",
    "### Looping over Comtrade History Years:    \n",
    "#for iter_date in [list_dates[-3]]:\n",
    "#for iter_date in list_dates[:-19][::-1]:\n",
    "for iter_date in list_dates[::-1]:\n",
    "    gc.collect()\n",
    "    print(iter_date.date())\n",
    "    ### UN Comtrade Bilateral Export Flows Extraction:\n",
    "    ser_iter_comtrade = pd.read_hdf(str_path_export_bilateral, key = str_key_unc_export, where = \"Date in [iter_date]\").droplevel(['Date', 'Type']).sort_index()\n",
    "    ser_iter_comtrade.index.names = ['Exporter', 'Importer', 'Commodity_ID']\n",
    "    list_exporters = ser_iter_comtrade.index.levels[0].intersection(list_exporters_wiot).to_list()\n",
    "    list_importers = ser_iter_comtrade.index.levels[1].intersection(list_importers_wiot).to_list()    \n",
    "    ### Filtering Country to Country Export Volumes:    \n",
    "    ser_iter_unc_bilateral = ser_iter_comtrade.loc[list_exporters, list_importers]\n",
    "    ### Calculation of Country to World Export Volumes:\n",
    "    ser_iter_unc_to_ww = ser_iter_comtrade.groupby(['Exporter', 'Commodity_ID']).sum()\n",
    "    ### Calculation of World to Country Export Volumes:                      \n",
    "    ser_iter_unc_from_ww = ser_iter_comtrade.groupby(['Importer', 'Commodity_ID']).sum()\n",
    "    ### Calculation of Country to Rest of the World Export Volumes:\n",
    "    ser_iter_unc_to_wiot = ser_iter_comtrade.loc[:, list_importers, :].groupby(['Exporter', 'Commodity_ID']).sum()\n",
    "    ser_iter_unc_to_yy = ser_iter_unc_to_ww - ser_iter_unc_to_wiot\n",
    "    ### Country to Totals datasets aggregation:\n",
    "    ser_iter_unc_to_add = pd.concat([ser_iter_unc_to_ww, ser_iter_unc_to_yy], keys = ['WW', 'YY'], names = ['Importer'])\n",
    "    ser_iter_unc_to_add = ser_iter_unc_to_add.reorder_levels([1, 0, 2]).sort_index()    \n",
    "    ### Calculation of Rest of the World to Country Export Volumes:   \n",
    "    ser_iter_unc_from_wiot = ser_iter_comtrade.loc[list_exporters, :, :].groupby(['Importer', 'Commodity_ID']).sum()\n",
    "    ser_iter_unc_from_yy = ser_iter_unc_from_ww - ser_iter_unc_from_wiot\n",
    "    ### Totals to Country datasets aggregation:\n",
    "    ser_iter_unc_from_add = pd.concat([ser_iter_unc_from_ww, ser_iter_unc_from_yy], keys = ['WW', 'YY'], names = ['Exporter']).sort_index()\n",
    "    ### Calculation of World to World Export Volumes:\n",
    "    ser_iter_ww_to_ww = pd.concat([ser_iter_comtrade.groupby('Commodity_ID').sum()], keys = [('WW', 'WW')], names = ['Exporter', 'Importer'])\n",
    "    ### Calculation of Rest of the World to Rest of the World Export Volumes:                      \n",
    "    ser_iter_yy_to_yy = ser_iter_comtrade.loc[~ser_iter_comtrade.index.get_level_values('Exporter').isin(list_exporters)]\n",
    "    ser_iter_yy_to_yy = ser_iter_yy_to_yy.loc[~ser_iter_yy_to_yy.index.get_level_values('Importer').isin(list_importers)]\n",
    "    ser_iter_yy_to_yy = pd.concat([ser_iter_yy_to_yy.groupby('Commodity_ID').sum()], keys = [('YY', 'YY')], names = ['Exporter', 'Importer'])  \n",
    "    ### Calculation of Rest of the World to World Export Volumes:  \n",
    "    ser_iter_yy_to_ww = ser_iter_comtrade.loc[~ser_iter_comtrade.index.get_level_values('Exporter').isin(list_exporters)]\n",
    "    ser_iter_yy_to_ww = pd.concat([ser_iter_yy_to_ww.groupby('Commodity_ID').sum()], keys = [('YY', 'WW')], names = ['Exporter', 'Importer'])\n",
    "    ### Calculation of World to Rest of the World Export Volumes:      \n",
    "    ser_iter_ww_to_yy = ser_iter_comtrade.loc[~ser_iter_comtrade.index.get_level_values('Importer').isin(list_importers)]\n",
    "    ser_iter_ww_to_yy = pd.concat([ser_iter_ww_to_yy.groupby('Commodity_ID').sum()], keys = [('WW', 'YY')], names = ['Exporter', 'Importer'])  \n",
    "    ### Aggregating all needed export flows datasets:    \n",
    "    ser_iter_unc_agg = pd.concat([ser_iter_unc_bilateral, ser_iter_unc_to_add, ser_iter_unc_from_add, \n",
    "                                  ser_iter_yy_to_yy, ser_iter_ww_to_ww, ser_iter_yy_to_ww, ser_iter_ww_to_yy])\n",
    "    list_exporters_plus = list_exporters + ['YY', 'WW']\n",
    "    list_importers_plus = list_importers + ['YY', 'WW']    \n",
    "#    ser_iter_unc_agg = ser_iter_unc_agg.loc[ser_last_shares.index.levels[0].to_list(), ser_last_shares.index.levels[1].to_list()].sort_index()\n",
    "    ser_iter_unc_agg = ser_iter_unc_agg.loc[list_exporters_plus, list_importers_plus].sort_index()\n",
    "    ### Commodity Distribution Calculation:\n",
    "#    ser_test_shares = ser_last_shares.loc[['AT', 'BE', 'YY', 'WW'], ['AT', 'BE', 'YY', 'WW']]\n",
    "#    ser_wiot_weights = ser_test_shares.to_frame().groupby(['Exporter', 'Importer', 'WIOT_Exporter_Code'], observed = True)\\\n",
    "#                            .apply(get_wiot_weights_parallel, ser_unc_to_gics.droplevel(['GICS_Industry_Code', 'GICS_Group_Code']), ser_iter_unc_agg)\\\n",
    "#                            .droplevel('WIOT_Exporter_Code').dropna().astype('float16')      \n",
    "    pandarallel.initialize(progress_bar = True, nb_workers = 12)    \n",
    "    ser_wiot_weights = ser_last_shares.to_frame().groupby(['Exporter', 'Importer', 'WIOT_Exporter_Code'], observed = True)\\\n",
    "                            .parallel_apply(get_wiot_weights_parallel, ser_unc_to_gics.droplevel(['GICS_Industry_Code', 'GICS_Group_Code']), ser_iter_unc_agg)\\\n",
    "                            .dropna().astype('float16')  \n",
    "    print(len(ser_wiot_weights))\n",
    "    ### Saving Results to File:\n",
    "    pd.concat([ser_wiot_weights], keys = [iter_date], names = ['Date'])\\\n",
    "                            .to_hdf(path_or_buf = str_path_unc_nace_weights_full_hdf, key = str_gics_key, mode = 'a', format = 'table', complevel = 9, append = True)\n",
    "#    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2eb758c-bc6a-49ce-9528-97001b1766b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING RENORMALIZING FUNCTION TO NORMALIZE WEIGHTS AFTER COLLAPSING MULTI-STRING COOMMODITY REPRESENTATION\n",
    "\n",
    "def renormalize_duplicated_commodities(ser_comm):\n",
    "    if (ser_comm.sum() != 1.0):\n",
    "        ser_comm = ser_comm / ser_comm.sum()\n",
    "    return ser_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "144ec396-eb05-4935-b0a1-7842ff7bffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING SECONDARY SHARES CALCULATOR\n",
    "\n",
    "def get_secondary_shares(df_group, ser_last_shares_internal):\n",
    "    df_to_second = df_group.join(ser_last_shares_internal).droplevel(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'])\n",
    "    ser_to_second = df_to_second.groupby('WIOT_Importer_Code', observed = True).apply(lambda df_i: (df_i['First'] * df_i['Share']).sum()).squeeze()\n",
    "    return ser_to_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3c60a99-21e1-4fa0-b102-6a14ac14301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-31\n"
     ]
    }
   ],
   "source": [
    "### SECOND ORDER SHARES CALCULATION\n",
    "\n",
    "#### Deleting old data:\n",
    "#if (os.path.exists(str_path_unc_nace_weights_second_hdf)):\n",
    "#    os.remove(str_path_unc_nace_weights_second_hdf)\n",
    "dict_second_order = {}\n",
    "### Internal trade matrices:\n",
    "ser_last_shares_internal = ser_last_shares.loc[ser_last_shares.index.get_level_values('Exporter') == ser_last_shares.index.get_level_values('Importer')]\\\n",
    "                                          .droplevel('Exporter')\n",
    "ser_last_shares_internal.name = 'Share'\n",
    "df_last_shares_internal = ser_last_shares_internal.reset_index()\n",
    "df_last_shares_internal['Importer'] = df_last_shares_internal['Importer'].astype(str)\n",
    "df_last_shares_internal['WIOT_Exporter_Code'] = df_last_shares_internal['WIOT_Exporter_Code'].astype(str)\n",
    "ser_last_shares_internal = df_last_shares_internal.set_index(['Importer', 'WIOT_Exporter_Code', 'WIOT_Importer_Code']).squeeze().sort_index()\n",
    "### Looping over Comtrade History Years: \n",
    "for iter_date in list_dates[: -2][::-1]:\n",
    "#for iter_date in list_dates[::-1]:\n",
    "    gc.collect()\n",
    "    print(iter_date.date())\n",
    "    ser_first_order = pd.read_hdf(path_or_buf = str_path_unc_nace_weights_full_hdf, key = str_gics_key, where = \"Date in [iter_date]\")\\\n",
    "                        .droplevel(['Date', 'WIOT_Exporter_Code']).sort_index()\n",
    "    ### First Order Weights Normalization:\n",
    "    ser_first_order = ser_first_order.groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code', 'WIOT_Importer_Code'], observed = True).mean()\n",
    "    ser_first_order = ser_first_order.groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'], observed = True)\\\n",
    "                                     .transform(renormalize_duplicated_commodities)    \n",
    "    ser_first_order.name = 'First'\n",
    "    ### First Order Shares as Transfer Weights:\n",
    "    df_transfer_weights = ser_first_order.reset_index()\n",
    "    df_transfer_weights['Importer'] = df_transfer_weights['Importer'].astype(str)\n",
    "    df_transfer_weights['WIOT_Exporter_Code'] = df_transfer_weights['WIOT_Importer_Code'].str.replace('c', 'r')\n",
    "    ser_transfer_weights = df_transfer_weights.set_index(['Importer', 'WIOT_Exporter_Code', 'Exporter', 'Commodity_ID', 'Commodity_Group_Code'])['First'].sort_index()\n",
    "    ### Second Order Shares calculation:\n",
    "    ser_second_order = ser_transfer_weights.to_frame().groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'], observed = True)\\\n",
    "                               .apply(get_secondary_shares, ser_last_shares_internal).stack()\n",
    "    print(len(ser_second_order))\n",
    "    ### Saving Results to File:\n",
    "#    pd.concat([ser_second_order], keys = [iter_date], names = ['Date'])\\\n",
    "#                           .to_hdf(path_or_buf = str_path_unc_nace_weights_second_hdf, key = str_gics_key, mode = 'a', format = 'table', complevel = 9, append = True)\n",
    "    dict_second_order[iter_date] = ser_second_order\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95f28495-9ded-4166-8d5e-725d6beafb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_test = ser_transfer_weights.loc[['CA', 'US', 'WW'], :, ['CA', 'US', 'WW'], ['02'], ['3020']]\\\n",
    "                               .groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'], observed = True)\\\n",
    "                               .apply(get_secondary_shares, ser_last_shares_internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb2e4766-b5b7-4518-8189-ffaa51c9f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_second_order = ser_transfer_weights.to_frame().loc[(['CA', 'US', 'WW'], All, ['CA', 'US', 'WW'], ['02'], ['3020']), :]\\\n",
    "                               .groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'], observed = True)\\\n",
    "                               .apply(get_secondary_shares, ser_last_shares_internal).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1aaa06e0-7620-42f5-9512-334c406030fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exporter  Importer  Commodity_ID  Commodity_Group_Code  WIOT_Importer_Code\n",
       "CA        US        02            3020                  c1                    0.103675\n",
       "                                                        c2                    0.001230\n",
       "                                                        c3                    0.000751\n",
       "                                                        c4                    0.001476\n",
       "                                                        c5                    0.456483\n",
       "                                                                                ...   \n",
       "WW        WW        02            3020                  c50                   0.007961\n",
       "                                                        c51                   0.018607\n",
       "                                                        c52                   0.011710\n",
       "                                                        c53                   0.028826\n",
       "                                                        c54                   0.011795\n",
       "Length: 378, dtype: float32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_second_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9371b5-4442-40b0-b489-e0a01b5bc474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593efdf4-3dc9-460b-b5ea-91ae9c8f2978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
