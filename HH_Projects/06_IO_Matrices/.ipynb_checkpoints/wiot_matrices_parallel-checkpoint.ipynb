{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52789805-c80c-4d93-b746-57f3e2f7064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WIOT MATRICES CONVERTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e16ab8-be40-4f3d-b489-d977e3cfed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "#from pandarallel import pandarallel\n",
    "import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2366151b-554f-4722-bb56-f5b57cd57464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.7.4\n",
      "numpy version:  1.21.5\n",
      "pandas version:  1.3.5\n"
     ]
    }
   ],
   "source": [
    "### RUN EVERY TIME: VERSION CONTROL\n",
    "\n",
    "from platform import python_version\n",
    "print('python version: ', python_version())\n",
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa00a819-0caf-4f30-aa1a-5428518bc069",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "### MultiIndex level slice constant:\n",
    "All = slice(None)\n",
    "### NA for MS Excel files:\n",
    "list_na_excel_values = ['', '---', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null',\n",
    "                        '#N/A Requesting Data...', '#N/A Invalid Security', '#N/A Field Not Applicable']\n",
    "### Product / Industry mapping path:\n",
    "str_path_matrix_map = 'Data_Files/Source_Files/WIOT_mapping_detailed.xlsx'\n",
    "str_sheet_matrix = 'Matrix to Load'\n",
    "str_sheet_unc_g_map = 'HS'\n",
    "str_sheet_unc_s_map = 'EBOPS 2010'\n",
    "### Path to original WIOT Tables:\n",
    "str_path_wiot_source = 'Data_Files/Source_Files/WIOT'\n",
    "### Augmented bilateral export:\n",
    "str_path_export_bilateral = 'Data_Files/Source_Files/comtrade_export_bilateral.h5'\n",
    "str_key_unc_export = 'export_augmented'\n",
    "### Downloaded and aggregated shares:\n",
    "str_path_wiot_volumes_hdf = 'Data_Files/Result_Files/wiot_volumes.h5'\n",
    "str_path_wiot_shares_hdf = 'Data_Files/Result_Files/wiot_shares.h5'\n",
    "str_path_wiot_filled_hdf = 'Data_Files/Result_Files/wiot_filled.h5'\n",
    "str_path_unc_sub_weights_hdf = 'Data_Files/Result_Files/unc_sub_weights.h5'\n",
    "str_path_unc_ind_weights_hdf = 'Data_Files/Result_Files/unc_ind_weights.h5'\n",
    "str_path_unc_sub_weights_agg_hdf = 'Data_Files/Result_Files/unc_sub_weights_agg.h5'\n",
    "str_path_unc_ind_weights_agg_hdf = 'Data_Files/Result_Files/unc_ind_weights_agg.h5'\n",
    "str_path_unc_sub_weights_full_hdf = 'Data_Files/Result_Files/unc_sub_weights_full.h5'\n",
    "str_path_unc_ind_weights_full_hdf = 'Data_Files/Result_Files/unc_ind_weights_full.h5'\n",
    "str_gics_key = 'gics_io'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd5929b-8476-404a-a38b-e701a1e8228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMODITIES MAPPING TO GICS INDUSTRY GROUPS\n",
    "\n",
    "### Goods:\n",
    "ser_goods_to_groups = pd.read_excel(engine = 'openpyxl', io = str_path_matrix_map, sheet_name = str_sheet_unc_g_map, dtype = str, header = [0], \n",
    "                               index_col = None).set_index('Commodity_ID')['GICS_Group'].dropna()\n",
    "ser_goods_to_groups.name = 'Commodity_Group_Code'\n",
    "### Services:\n",
    "ser_services_to_groups = pd.read_excel(engine = 'openpyxl', io = str_path_matrix_map, sheet_name = str_sheet_unc_s_map, dtype = str, header = [0], \n",
    "                               index_col = None).set_index('Commodity_ID')['GICS_Group'].dropna()\n",
    "ser_services_to_groups.name = 'Commodity_Group_Code'\n",
    "ser_services_to_groups = ser_services_to_groups[ser_services_to_groups != '---']\n",
    "### Mappers concatenation:\n",
    "ser_comm_to_groups = pd.concat([ser_goods_to_groups, ser_services_to_groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a33f2c-391f-49cf-be8e-d5d27c188135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### UN COMTRADE TO GICS WIOT BASED MATRIX LOADING\n",
    "\n",
    "### Source table loading:\n",
    "df_unc_to_gics = pd.read_excel(engine = 'openpyxl', io = str_path_matrix_map, sheet_name = str_sheet_matrix, dtype = str, header = list(range(6)), \n",
    "                               index_col = list(range(4)))\n",
    "df_unc_to_gics.index.names = ['WIOT_Exporter_Code', 'WIOT_Description', 'Commodity_ID', 'Commodity_Description']\n",
    "df_unc_to_gics.columns.names = ['WIOT_Importer_Code', 'WIOT_Description', 'GICS_Sub_Code', 'GICS_Industry_Code', 'GICS_Group_Code', 'GICS_Sub_Name']\n",
    "### Index levels checker:\n",
    "df_unc_to_gics.index = df_unc_to_gics.index.set_levels(df_unc_to_gics.index.levels[2].astype('str'), level = 'Commodity_ID')\n",
    "### Matrix filtering:\n",
    "df_unc_to_gics = df_unc_to_gics.droplevel(['WIOT_Description', 'Commodity_Description']).droplevel(['WIOT_Description', 'GICS_Sub_Name'], axis = 1)\n",
    "df_unc_to_gics = df_unc_to_gics.drop(index = '---', level = 'Commodity_ID').drop(columns = '---', level = 'GICS_Group_Code')\n",
    "### Matrix convertation:\n",
    "df_unc_to_gics = df_unc_to_gics.replace({'x': False, 'y': True, 'z': True})\n",
    "gc.collect()\n",
    "ser_unc_to_gics = df_unc_to_gics.stack(df_unc_to_gics.columns.names).astype(bool)\n",
    "ser_unc_to_gics.name = 'Connection_Flag'\n",
    "### Adding Comtrade to GICS mapping:\n",
    "ser_unc_to_gics = ser_unc_to_gics.to_frame().join(ser_comm_to_groups, how = 'inner').set_index('Commodity_Group_Code', append = True).squeeze()\n",
    "### Index Levels categorizing:\n",
    "ser_unc_to_gics = ser_unc_to_gics.reorder_levels([0, 2, 1, 6, 3, 4, 5]).sort_index()\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[4].astype(str), level = 'GICS_Sub_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[0].astype('category'), level = 'WIOT_Exporter_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[1].astype('category'), level = 'WIOT_Importer_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[2].astype('category'), level = 'Commodity_ID')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[3].astype('category'), level = 'Commodity_Group_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[4].astype('category'), level = 'GICS_Sub_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[5].astype('category'), level = 'GICS_Industry_Code')\n",
    "ser_unc_to_gics.index = ser_unc_to_gics.index.set_levels(ser_unc_to_gics.index.levels[6].astype('category'), level = 'GICS_Group_Code')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585ae21f-bcdb-4a3a-a790-3d20137008cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING COUNTRY CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    ### In case if URL is unavailable:\n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    ### Online extraction:\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']].sort_index()    \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "    ### Results output:\n",
    "    return df_result\n",
    "\n",
    "### World Country Codes:\n",
    "df_country_codes = get_country_codes()\n",
    "dict_ison_mapper = df_country_codes.set_index('ISO LONG').squeeze().to_dict()\n",
    "dict_ison_mapper['ROW'] = 'YY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4dad6-3193-4969-b0db-b2c3cf7c4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WIOT DATA TABLES LOADING & CONVERTATION & SAVING\n",
    "\n",
    "### Lists of WIOT Activities:\n",
    "list_exporter_codes = ['r' + str(iter_num) for iter_num in range(1, 55)]\n",
    "list_importer_codes = ['c' + str(iter_num) for iter_num in range(1, 55)]\n",
    "#list_importer_codes.remove('c51') ### Remove of \"Public administration and defence; compulsory social security\"\n",
    "\n",
    "if (os.path.exists(str_path_wiot_volumes_hdf)):\n",
    "    os.remove(str_path_wiot_volumes_hdf)\n",
    "#for year_matrix_csv in os.listdir(str_path_wiot_source):\n",
    "for year_matrix_csv in os.listdir(str_path_wiot_source)[::-1]:    \n",
    "    gc.collect()\n",
    "    dt_year_end = (pd.to_datetime(year_matrix_csv[4 : 8]) + pd.offsets.BYearEnd())#.date()\n",
    "    str_year_num = year_matrix_csv[4 : 8]\n",
    "    print(str_year_num, ': IO Matrix of WIOT Activities Loading Started')\n",
    "    df_year_raw = pd.read_csv(str_path_wiot_source + '/' + year_matrix_csv, sep = ';', index_col = [0, 1, 2, 3], skiprows = [0, 1, 2, 3], header = [0, 1], \n",
    "                                        na_values = list_na_excel_values, keep_default_na = False)\n",
    "    ser_year_raw = df_year_raw.droplevel([0, 1]).stack([0, 1]).astype('int32')\n",
    "    ser_year_raw.name = 'Value'\n",
    "    ser_year_raw.index.names = ['Supplier_Country_Long', 'WIOT_Exporter_Code', 'User_Country_Long', 'WIOT_Importer_Code']    \n",
    "    df_year_typed = ser_year_raw.reset_index()\n",
    "    del df_year_raw\n",
    "    del ser_year_raw\n",
    "    gc.collect()\n",
    "    df_year_typed = df_year_typed[df_year_typed['Supplier_Country_Long'].isin(df_country_codes['ISO LONG'].to_list() + ['ROW']) & \n",
    "                                  df_year_typed['User_Country_Long'].isin(df_country_codes['ISO LONG'].to_list() + ['ROW']) & \n",
    "                                  df_year_typed['WIOT_Exporter_Code'].isin(list_exporter_codes) & \n",
    "                                  df_year_typed['WIOT_Importer_Code'].isin(list_importer_codes)]\n",
    "    df_year_typed['Exporter'] = df_year_typed['Supplier_Country_Long'].replace(dict_ison_mapper)\n",
    "    df_year_typed['Importer'] = df_year_typed['User_Country_Long'].replace(dict_ison_mapper)          \n",
    "    df_year_typed['Exporter'] = df_year_typed['Exporter'].astype('category')\n",
    "    df_year_typed['Importer'] = df_year_typed['Importer'].astype('category')\n",
    "    df_year_typed['WIOT_Exporter_Code'] = df_year_typed['WIOT_Exporter_Code'].astype('category')\n",
    "    df_year_typed['WIOT_Exporter_Code'] = df_year_typed['WIOT_Exporter_Code'].cat.set_categories(new_categories = list_exporter_codes, ordered = True)\n",
    "    df_year_typed['WIOT_Importer_Code'] = df_year_typed['WIOT_Importer_Code'].astype('category')    \n",
    "    df_year_typed['WIOT_Importer_Code'] = df_year_typed['WIOT_Importer_Code'].cat.set_categories(new_categories = list_importer_codes, ordered = True)    \n",
    "    ser_year_wiot = df_year_typed.set_index(['Exporter', 'Importer', 'WIOT_Exporter_Code', 'WIOT_Importer_Code'])['Value'].squeeze().sort_index()\n",
    "    ser_year_wiot = ser_year_wiot.clip(lower = 0)\n",
    "    pd.concat([ser_year_wiot], keys = [dt_year_end], names = ['Date'])\\\n",
    "                                                    .to_hdf(str_path_wiot_volumes_hdf, key = str_gics_key, mode = 'a', format = 'table', complevel = 9, append = True)\n",
    "    print(str_year_num, ': IO Matrix of WIOT Activities Saved')    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a65fe4-2d87-4615-af6f-77f0a91aafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WIOT LAST DATE MATRIX CONVERTING TO SHARES & AGGREGATED DATA ADDING\n",
    "\n",
    "gc.collect()\n",
    "ser_last_wiot = pd.read_hdf(str_path_wiot_volumes_hdf, key = str_gics_key).droplevel('Date')\n",
    "\n",
    "### Adding World as Exporter & Importer\n",
    "df_last_wiot = ser_last_wiot.reset_index()\n",
    "df_last_wiot['Exporter'] = df_last_wiot['Exporter'].cat.add_categories(['WW'])\n",
    "df_last_wiot['Importer'] = df_last_wiot['Importer'].cat.add_categories(['WW'])    \n",
    "### Inner flows filtering:\n",
    "df_inner_flows = df_last_wiot[(df_last_wiot['Exporter'] == df_last_wiot['Importer'])]      \n",
    "### Outer flows filtering:\n",
    "df_outer_flows = df_last_wiot[(df_last_wiot['Exporter'] != df_last_wiot['Importer'])]  \n",
    "### Inner values to series:\n",
    "ser_country_inner_values = df_inner_flows.set_index(['Exporter', 'Importer', 'WIOT_Exporter_Code', 'WIOT_Importer_Code']).astype('float32').squeeze()     \n",
    "### Outer values to series:    \n",
    "ser_country_to_country_values = df_outer_flows.set_index(['Exporter', 'Importer', 'WIOT_Exporter_Code', 'WIOT_Importer_Code']).astype('float32').squeeze() \n",
    "### Country to World trade:        \n",
    "ser_country_to_world_values = df_outer_flows.groupby(['Exporter', 'WIOT_Exporter_Code', 'WIOT_Importer_Code'], observed = True)['Value'].sum().squeeze().sort_index()\n",
    "### World to World trade:            \n",
    "ser_world_to_world_values = ser_country_to_world_values.groupby(['WIOT_Exporter_Code', 'WIOT_Importer_Code'], observed = True).sum().astype('float32').sort_index()\n",
    "### World to Country trade:                \n",
    "ser_world_to_country_values = df_outer_flows.groupby(['Importer', 'WIOT_Exporter_Code', 'WIOT_Importer_Code'], observed = True)['Value'].sum().squeeze().sort_index()\n",
    "### Inner shares:\n",
    "ser_country_inner_shares = ser_country_inner_values.groupby(['Exporter', 'Importer', 'WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                   .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index()     \n",
    "### Outer shares:\n",
    "ser_country_to_country_shares = ser_country_to_country_values.groupby(['Exporter', 'Importer', 'WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                             .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index()          \n",
    "ser_country_to_world_shares = ser_country_to_world_values.groupby(['Exporter', 'WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                         .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index() \n",
    "ser_country_to_world_shares = pd.concat({'WW': ser_country_to_world_shares}, names = ['Importer']).swaplevel(0, 1).sort_index()\n",
    "#ser_country_to_world_shares.drop(('WW', 'WW'), inplace = True)\n",
    "ser_world_to_country_shares = ser_world_to_country_values.groupby(['Importer', 'WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                         .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index() \n",
    "ser_world_to_country_shares = pd.concat({'WW': ser_world_to_country_shares}, names = ['Exporter'])    \n",
    "#ser_world_to_country_shares.drop(('WW', 'WW'), inplace = True)    \n",
    "ser_world_to_world_shares = ser_world_to_world_values.groupby(['WIOT_Exporter_Code'], group_keys = False, observed  = True)\\\n",
    "                                                     .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index() \n",
    "ser_world_to_world_shares = pd.concat({'WW': pd.concat({'WW': ser_world_to_world_shares}, names = ['Importer'])}, names = ['Exporter'])    \n",
    "### Values aggregating:\n",
    "ser_last_shares = pd.concat([ser_country_inner_shares, ser_country_to_country_shares, ser_country_to_world_shares, ser_world_to_country_shares, \n",
    "                             ser_world_to_world_shares]).sort_index()\n",
    "del ser_country_to_country_shares\n",
    "gc.collect()\n",
    "#ser_last_shares.drop('9999', axis = 0, level = 'WIOT_Exporter_Code', inplace =  True)\n",
    "#ser_last_shares.drop('9999', axis = 0, level = 'WIOT_Importer_Code', inplace =  True) \n",
    "ser_last_shares.name = 'Share'\n",
    "ser_last_shares.to_hdf(str_path_wiot_shares_hdf, key = str_gics_key, mode = 'w', format = 'table', complevel = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c497ab27-ac7b-4ed8-a30a-d00c0d5fce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country_to_country': 52892, 'country_to_world': 48181, 'world_to_country': 7807, 'world_to_world': 470, 'empty': 0}\n"
     ]
    }
   ],
   "source": [
    "### FILLING GAPS IN SHARES\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "ser_last_shares = pd.read_hdf(str_path_wiot_shares_hdf, key = str_gics_key).fillna(0.0)\n",
    "\n",
    "dict_counter = {}\n",
    "dict_counter['country_to_country'] = 0\n",
    "dict_counter['country_to_world'] = 0\n",
    "dict_counter['world_to_country'] = 0\n",
    "dict_counter['world_to_world'] = 0\n",
    "dict_counter['empty'] = 0\n",
    "\n",
    "for iter_exporter in ser_last_shares.index.levels[0]:\n",
    "    for iter_importer in ser_last_shares.index.levels[1]:\n",
    "        for iter_industry in ser_last_shares.index.levels[2]:\n",
    "            ser_country_to_country = ser_last_shares.loc[iter_exporter, iter_importer, iter_industry]\n",
    "            ser_country_to_world = ser_last_shares.loc[iter_exporter, 'WW', iter_industry]\n",
    "            ser_world_to_country = ser_last_shares.loc['WW', iter_importer, iter_industry]\n",
    "            ser_world_to_world = ser_last_shares.loc['WW', 'WW', iter_industry]\n",
    "            if (ser_country_to_country.sum() == 0.0):\n",
    "                if (ser_country_to_world.sum() == 0.0):\n",
    "                    if (ser_world_to_country.sum() == 0.0):\n",
    "                        if (ser_world_to_world.sum() == 0.0):\n",
    "                            dict_counter['empty'] += 1                    \n",
    "#                            print(iter_exporter, iter_importer, iter_industry, ': no data to fill')                            \n",
    "                        else:\n",
    "                            ser_last_shares.loc[iter_exporter, iter_importer, iter_industry] = ser_world_to_world.values\n",
    "                            dict_counter['world_to_world'] += 1\n",
    "#                            print(iter_exporter, iter_importer, iter_industry, ': filled by World to World level data')                            \n",
    "                    else:\n",
    "                        ser_last_shares.loc[iter_exporter, iter_importer, iter_industry] = ser_world_to_country.values\n",
    "                        dict_counter['world_to_country'] += 1\n",
    "#                        print(iter_exporter, iter_importer, iter_industry, ': filled by World to Country level data')                        \n",
    "                else:\n",
    "                    ser_last_shares.loc[iter_exporter, iter_importer, iter_industry] = ser_country_to_world.values\n",
    "                    dict_counter['country_to_world'] += 1\n",
    "#                    print(iter_exporter, iter_importer, iter_industry, ': filled by Country to World level data')\n",
    "            else:\n",
    "                dict_counter['country_to_country'] += 1\n",
    "print(dict_counter)\n",
    "### Results saving:\n",
    "ser_last_shares.to_hdf(str_path_wiot_filled_hdf, key = str_gics_key, mode = 'w', format = 'table', complevel = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10371de5-8d43-43c5-969a-06e3e1e1f414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_to_country : 0.4837\n",
      "country_to_world : 0.4406\n",
      "world_to_country : 0.0714\n",
      "world_to_world : 0.0043\n",
      "empty : 0.0\n"
     ]
    }
   ],
   "source": [
    "### TEST\n",
    "\n",
    "for iter_option in dict_counter:\n",
    "    print(iter_option, ':', round(dict_counter[iter_option] / len(ser_last_shares.groupby(['Exporter', 'Importer', 'WIOT_Exporter_Code']).count()), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c8a3a8c-f33c-4026-a669-c91e1dd7a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING COMMODITY TO SUB INDUSTRY DISTRIBUTION CALCUCATOR\n",
    "\n",
    "def get_wiot_weights_parallel(ser_wiot_shares, ser_unc_to_gics, ser_iter_comtrade):\n",
    "    ### Extracting Groupby Keys:\n",
    "    ser_wiot_shares = ser_wiot_shares.squeeze()\n",
    "    ser_wiot_shares.name = 'Activity_Share'\n",
    "#    print(ser_wiot_shares.describe())\n",
    "    (str_iter_exporter, str_iter_importer, str_iter_code) = ser_wiot_shares.index[0][: -1]\n",
    "#    print(str_iter_exporter, str_iter_importer, str_iter_code)\n",
    "    if ((str_iter_importer == 'AT') & (str_iter_code == 'r1')):\n",
    "        print(str_iter_exporter, 'as Exporter')\n",
    "    ### Selecting Product -> Importer GICS Sub Industry Flags:\n",
    "    ser_wiot_flags = ser_unc_to_gics[str_iter_code]\n",
    "    ### Calculating of Relation Product Export Shares Inside Exporter WIOT Activity:\n",
    "    idx_comm_id = ser_wiot_flags['c2'].index.get_level_values('Commodity_ID')\n",
    "    try:\n",
    "        ser_unc_volumes = ser_iter_comtrade.loc[[str_iter_exporter], [str_iter_importer], idx_comm_id]\n",
    "    except KeyError:\n",
    "        print('No trade:', str_iter_exporter, str_iter_importer, str_iter_code)\n",
    "    else:\n",
    "        ser_unc_shares = (ser_unc_volumes / ser_unc_volumes.sum()).droplevel(['Exporter', 'Importer'])\n",
    "        ser_unc_shares.name = 'Export_Share'\n",
    "        ### Concatenating Importer WIOT Activity Shares & Product -> Importer GICS Sub Industry Flags & Product Export Shares Inside Exporter WIOT Activity:\n",
    "        df_pair_supply = ser_wiot_shares.droplevel(['Exporter', 'Importer', 'WIOT_Exporter_Code']).to_frame().join(ser_wiot_flags, how = 'left')\\\n",
    "                                                                                                            .join(ser_unc_shares, how = 'left').sort_index()\n",
    "        ### First Step Weights Distribution: Product Share, Weighted by GICS Sub Industry Share (Activity Share equal part):\n",
    "        df_pair_supply['Weight_First'] = df_pair_supply.groupby(['WIOT_Importer_Code', 'Commodity_ID'], observed = True, group_keys = False)\\\n",
    "                                        .apply(lambda df_i: df_i['Export_Share'] * df_i['Activity_Share'] * df_i['Connection_Flag'] / df_i['Connection_Flag'].sum())\n",
    "#        ### Primary Weights Normalization inside Commodity:\n",
    "#        df_pair_supply['Weight_First'] = df_pair_supply['Weight_First'].groupby('Commodity_ID', observed = True).transform(lambda ser_i: ser_i / ser_i.sum())   \n",
    "        ### Secondary Weights Distribution: Normalization Inside Export WIOT Activity * Import WIOT Activity Matrix:\n",
    "        df_pair_supply['Weight_Second'] = df_pair_supply['Weight_First'].groupby('WIOT_Importer_Code', observed = True).apply(lambda ser_i: ser_i / ser_i.sum())\\\n",
    "                                                                                                * df_pair_supply['Activity_Share']    \n",
    "        ### Secondary Weights Distribution: Normalization inside Commodity:\n",
    "        df_pair_supply['Weight_Second'] = df_pair_supply['Weight_Second'].groupby('Commodity_ID', observed = True).transform(lambda ser_i: ser_i / ser_i.sum())\n",
    "        ### Results Output:\n",
    "#        return df_pair_supply['Weight_Second']        \n",
    "        ser_result = df_pair_supply.loc[df_pair_supply['Weight_Second'] > 0.0, 'Weight_Second'].astype('float16')\n",
    "        ser_result = ser_result.groupby(['Commodity_ID', 'Commodity_Group_Code', 'GICS_Sub_Code'], observed = True).sum()\n",
    "        if (len(ser_result) > 0):\n",
    "            return ser_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6e22fa-1c01-4746-b7e8-586edbf974ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DISTRIBUTION CONSTANTS\n",
    "\n",
    "### Date Range defining:\n",
    "str_year_start = '1989' # '1989'\n",
    "str_year_end = '2023'\n",
    "list_dates = pd.date_range(start = str_year_start, end = str_year_end, freq = 'BY').to_list()\n",
    "#list_dates = pd.date_range(start = str_year_start, end = str_year_end, freq = '7BY').to_list()\n",
    "### WIOT Matrix Shares Loading:\n",
    "ser_last_shares = pd.read_hdf(str_path_wiot_filled_hdf, key = str_gics_key)\n",
    "list_exporters = ser_last_shares.index.levels[0].to_list()\n",
    "list_exporters.remove('YY')\n",
    "list_exporters.remove('WW')\n",
    "list_importers = ser_last_shares.index.levels[1].to_list()\n",
    "list_importers.remove('YY')\n",
    "list_importers.remove('WW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60fe3ec0-036d-484c-a812-a78eb3dae3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-30\n",
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba6f481d09c4fc68e2d6651639e2c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=27338), Label(value='0 / 27338')))â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### UN COMTRADE & WIOT AGGREGATION : ALL POSSIBLE COMBINATIONS\n",
    "\n",
    "### Deleting old data:\n",
    "if (os.path.exists(str_path_unc_sub_weights_full_hdf)):\n",
    "    os.remove(str_path_unc_sub_weights_full_hdf)\n",
    "### Looping over Comtrade History Years:    \n",
    "#for iter_date in [list_dates[-2]]:\n",
    "#for iter_date in list_dates[:-19][::-1]:\n",
    "for iter_date in list_dates[::-1]:\n",
    "    gc.collect()\n",
    "    print(iter_date.date())\n",
    "    ### UN Comtrade Bilateral Export Flows Extraction:\n",
    "    ser_iter_comtrade = pd.read_hdf(str_path_export_bilateral, key = str_key_unc_export, where = \"Date in [iter_date]\").droplevel(['Date', 'Type']).sort_index()\n",
    "    ser_iter_comtrade.index.names = ['Exporter', 'Importer', 'Commodity_ID']\n",
    "    ### Filtering Country to Country Export Volumes:\n",
    "    ser_iter_unc_bilateral = ser_iter_comtrade.loc[list_exporters, list_importers]\n",
    "    ### Calculation of Country to World Export Volumes:\n",
    "    ser_iter_unc_to_ww = ser_iter_comtrade.groupby(['Exporter', 'Commodity_ID']).sum()\n",
    "    ### Calculation of World to Country Export Volumes:                      \n",
    "    ser_iter_unc_from_ww = ser_iter_comtrade.groupby(['Importer', 'Commodity_ID']).sum()\n",
    "    ### Calculation of Country to Rest of the World Export Volumes:\n",
    "    ser_iter_unc_to_wiot = ser_iter_comtrade.loc[:, list_importers, :].groupby(['Exporter', 'Commodity_ID']).sum()\n",
    "    ser_iter_unc_to_yy = ser_iter_unc_to_ww - ser_iter_unc_to_wiot\n",
    "    ### Country to Totals datasets aggregation:\n",
    "    ser_iter_unc_to_add = pd.concat([ser_iter_unc_to_ww, ser_iter_unc_to_yy], keys = ['WW', 'YY'], names = ['Importer'])\n",
    "    ser_iter_unc_to_add = ser_iter_unc_to_add.reorder_levels([1, 0, 2]).sort_index()    \n",
    "    ### Calculation of Rest of the World to Country Export Volumes:   \n",
    "    ser_iter_unc_from_wiot = ser_iter_comtrade.loc[list_exporters, :, :].groupby(['Importer', 'Commodity_ID']).sum()\n",
    "    ser_iter_unc_from_yy = ser_iter_unc_from_ww - ser_iter_unc_from_wiot\n",
    "    ### Totals to Country datasets aggregation:\n",
    "    ser_iter_unc_from_add = pd.concat([ser_iter_unc_from_ww, ser_iter_unc_from_yy], keys = ['WW', 'YY'], names = ['Exporter']).sort_index()\n",
    "    ### Calculation of World to World Export Volumes:\n",
    "    ser_iter_ww_to_ww = pd.concat([ser_iter_comtrade.groupby('Commodity_ID').sum()], keys = [('WW', 'WW')], names = ['Exporter', 'Importer'])\n",
    "    ### Calculation of Rest of the World to Rest of the World Export Volumes:                      \n",
    "    ser_iter_yy_to_yy = ser_iter_comtrade.loc[~ser_iter_comtrade.index.get_level_values('Exporter').isin(list_exporters)]\n",
    "    ser_iter_yy_to_yy = ser_iter_yy_to_yy.loc[~ser_iter_yy_to_yy.index.get_level_values('Importer').isin(list_importers)]\n",
    "    ser_iter_yy_to_yy = pd.concat([ser_iter_yy_to_yy.groupby('Commodity_ID').sum()], keys = [('YY', 'YY')], names = ['Exporter', 'Importer'])  \n",
    "    ### Calculation of Rest of the World to World Export Volumes:  \n",
    "    ser_iter_yy_to_ww = ser_iter_comtrade.loc[~ser_iter_comtrade.index.get_level_values('Exporter').isin(list_exporters)]\n",
    "    ser_iter_yy_to_ww = pd.concat([ser_iter_yy_to_ww.groupby('Commodity_ID').sum()], keys = [('YY', 'WW')], names = ['Exporter', 'Importer'])\n",
    "    ### Calculation of World to Rest of the World Export Volumes:      \n",
    "    ser_iter_ww_to_yy = ser_iter_comtrade.loc[~ser_iter_comtrade.index.get_level_values('Importer').isin(list_importers)]\n",
    "    ser_iter_ww_to_yy = pd.concat([ser_iter_ww_to_yy.groupby('Commodity_ID').sum()], keys = [('WW', 'YY')], names = ['Exporter', 'Importer'])  \n",
    "    ### Aggregating all needed export flows datasets:    \n",
    "    ser_iter_unc_agg = pd.concat([ser_iter_unc_bilateral, ser_iter_unc_to_add, ser_iter_unc_from_add, \n",
    "                                  ser_iter_yy_to_yy, ser_iter_ww_to_ww, ser_iter_yy_to_ww, ser_iter_ww_to_yy])\n",
    "    ser_iter_unc_agg = ser_iter_unc_agg.loc[ser_last_shares.index.levels[0].to_list(), ser_last_shares.index.levels[1].to_list()].sort_index()          \n",
    "    ### Filtering aggregated shares only:\n",
    "#    ser_agg_shares = pd.concat([ser_last_shares.loc[list_exporters, list_importers],\n",
    "#                                ser_last_shares.loc[:, ['YY', 'WW']], \n",
    "#                                ser_last_shares.loc[['YY', 'WW'], list_importers]], axis = 0).sort_index()\n",
    "    ### Commodity Distribution Calculation:\n",
    "    pandarallel.initialize(progress_bar = True)\n",
    "#    ser_test_shares = ser_last_shares.loc[['AT', 'BE', 'YY', 'WW'], ['AT', 'BE', 'YY', 'WW']]\n",
    "    ser_wiot_weights = ser_last_shares.to_frame().groupby(['Exporter', 'Importer', 'WIOT_Exporter_Code'], observed = True)\\\n",
    "                            .parallel_apply(get_wiot_weights_parallel, ser_unc_to_gics.droplevel(['GICS_Industry_Code', 'GICS_Group_Code']), ser_iter_unc_agg)\\\n",
    "                            .dropna().astype('float16')  \n",
    "#    print(len(ser_wiot_weights))\n",
    "    ### Saving Results to File:\n",
    "    pd.concat([ser_wiot_weights], keys = [iter_date], names = ['Date'])\\\n",
    "                            .to_hdf(path_or_buf = str_path_unc_sub_weights_full_hdf, key = str_gics_key, mode = 'a', format = 'table', complevel = 9, append = True)\n",
    "    break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b563a8f8-cd0e-4d6a-9379-e5a99e8959a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989-12-29 00:00:00\n",
      "13269\n",
      "2022-12-30 00:00:00\n",
      "13269\n"
     ]
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "list_ww_ww = []\n",
    "for iter_date in [list_dates[0], list_dates[-1]]:\n",
    "    print(iter_date)\n",
    "    ser_test_agg = pd.read_hdf(path_or_buf = str_path_unc_sub_weights_agg_hdf, where = \"Date in [iter_date]\").sort_index()\n",
    "    print(len(ser_test_agg.loc[:, 'WW', 'WW']))\n",
    "    list_ww_ww.append(ser_test_agg.loc[:, 'WW', 'WW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb34ea79-8090-4b8f-81c3-3b4d046beee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "(list_ww_ww[1].droplevel('Date') - list_ww_ww[0].droplevel('Date')).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc855f83-2a7f-481b-b0b0-0e4591fa0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "gc.collect()\n",
    "ser_test_full = pd.read_hdf(path_or_buf = str_path_unc_sub_weights_full_hdf).sort_index()\n",
    "ser_test_full.name = 'Share'\n",
    "ser_test_agg = pd.read_hdf(path_or_buf = str_path_unc_sub_weights_agg_hdf, where = \"Date in [iter_date]\").sort_index()\n",
    "#ser_test_agg = ser_test_agg.loc[:, ['AT', 'BE', 'YY', 'WW'], ['AT', 'BE', 'YY', 'WW'], :]\n",
    "ser_test_agg.name = 'Share'\n",
    "ser_test_bil = pd.read_hdf(path_or_buf = str_path_unc_sub_weights_hdf, where = \"Date in [iter_date]\").sort_index()\n",
    "#ser_test_bil = ser_test_bil.loc[:, ['AT', 'BE', 'YY', 'WW'], ['AT', 'BE', 'YY', 'WW'], :]\n",
    "ser_test_bil.name = 'Share'\n",
    "ser_test_old = pd.concat([ser_test_bil, ser_test_agg], axis = 0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e122b12a-4ddc-4b47-978a-4b533b05ff11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_test_full.equals(ser_test_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8a8be3-0c4f-40d0-8b89-943c0c34f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-30 00:00:00 : Aggregating Export Distribution Weights by Importer Industry started\n",
      "2022-12-30 00:00:00 : Aggregating Export Distribution Weights by Importer Industry finished\n"
     ]
    }
   ],
   "source": [
    "### WIOT WEIGHTS TO GICS INDUSTRIES DISTRIBUTION\n",
    "\n",
    "### Deleting old data:\n",
    "if (os.path.exists(str_path_unc_ind_weights_full_hdf)):\n",
    "    os.remove(str_path_unc_ind_weights_full_hdf)\n",
    "### Defining renormalizing distribution to 1 for duplicated commodities (different economic activities):\n",
    "def renormalize_duplicated_commodities(ser_comm):\n",
    "    if (ser_comm.sum() != 1.0):\n",
    "        ser_comm = ser_comm / ser_comm.sum()\n",
    "    return ser_comm\n",
    "### Looping over years:\n",
    "#for iter_date in [list_dates[-2]]:\n",
    "for iter_date in list_dates[::-1]:\n",
    "    print(iter_date, ': Aggregating Export Distribution Weights by Importer Industry started')\n",
    "    gc.collect()\n",
    "    ### WIOT Weights Loading:\n",
    "    ser_wiot_weights = pd.read_hdf(path_or_buf = str_path_unc_sub_weights_full_hdf, key = str_gics_key, where = \"(Date in [iter_date])\").droplevel('Date')\n",
    "    list_levels = list(ser_wiot_weights.index.names)\n",
    "    list_levels.remove('WIOT_Exporter_Code')\n",
    "    ### Aggregating data for each commodity:\n",
    "    ser_comm_weights = ser_wiot_weights.groupby(list_levels, observed = True).mean().astype('float32')\n",
    "    del ser_wiot_weights\n",
    "    gc.collect()\n",
    "    ### Aggregating data for each commodity that represented in several ecoonomic activities:    \n",
    "    ser_norm_weights = ser_comm_weights.groupby(['Exporter', 'Importer', 'Commodity_ID', 'Commodity_Group_Code'], observed = True)\\\n",
    "                                       .transform(renormalize_duplicated_commodities)     \n",
    "    ser_norm_weights.name = 'Share'\n",
    "    ### Aggregationg from Sub Industry to Industry:\n",
    "    df_ind_weights = ser_norm_weights.reset_index('GICS_Sub_Code')\n",
    "    df_ind_weights['GICS_Industry_Code'] = df_ind_weights['GICS_Sub_Code'].str[:6]\n",
    "    ser_ind_weights = df_ind_weights.set_index('GICS_Industry_Code', append = True)['Share'].sort_index()\n",
    "    ser_ind_weights = ser_ind_weights.groupby(ser_ind_weights.index.names, observed = True).sum()   \n",
    "    ### Saving Industry weights:\n",
    "    pd.concat([ser_ind_weights], keys = [iter_date], names = ['Date'])\\\n",
    "                            .to_hdf(path_or_buf = str_path_unc_ind_weights_full_hdf, key = str_gics_key, mode = 'a', format = 'table', complevel = 9, append = True)\n",
    "    print(iter_date, ': Aggregating Export Distribution Weights by Importer Industry finished')    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8fd294f-3627-4133-a28c-0252d35587f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "gc.collect()\n",
    "ser_test_full = pd.read_hdf(path_or_buf = str_path_unc_ind_weights_full_hdf).sort_index()\n",
    "ser_test_full.name = 'Share'\n",
    "ser_test_agg = pd.read_hdf(path_or_buf = str_path_unc_ind_weights_agg_hdf, where = \"Date in [iter_date]\").sort_index()\n",
    "#ser_test_agg = ser_test_agg.loc[:, ['AT', 'BE', 'YY', 'WW'], ['AT', 'BE', 'YY', 'WW'], :]\n",
    "ser_test_agg.name = 'Share'\n",
    "ser_test_bil = pd.read_hdf(path_or_buf = str_path_unc_ind_weights_hdf, where = \"Date in [iter_date]\").sort_index()\n",
    "#ser_test_bil = ser_test_bil.loc[:, ['AT', 'BE', 'YY', 'WW'], ['AT', 'BE', 'YY', 'WW'], :]\n",
    "ser_test_bil.name = 'Share'\n",
    "ser_test_old = pd.concat([ser_test_bil, ser_test_agg], axis = 0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a16f1a-6d92-4fef-962f-669e7b21797f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_test_full.equals(ser_test_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593efdf4-3dc9-460b-b5ea-91ae9c8f2978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
