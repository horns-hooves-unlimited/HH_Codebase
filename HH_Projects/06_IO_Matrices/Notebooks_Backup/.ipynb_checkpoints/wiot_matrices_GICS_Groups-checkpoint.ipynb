{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52789805-c80c-4d93-b746-57f3e2f7064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WIOT MATRICES CONVERTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e16ab8-be40-4f3d-b489-d977e3cfed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2366151b-554f-4722-bb56-f5b57cd57464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.7.4\n",
      "numpy version:  1.17.2\n",
      "pandas version:  0.25.3\n"
     ]
    }
   ],
   "source": [
    "### RUN EVERY TIME: VERSION CONTROL\n",
    "\n",
    "from platform import python_version\n",
    "print('python version: ', python_version())\n",
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa00a819-0caf-4f30-aa1a-5428518bc069",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "### MultiIndex level slice constant:\n",
    "All = slice(None)\n",
    "### NA for MS Excel files:\n",
    "list_na_excel_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null',\n",
    "                        '#N/A Requesting Data...', '#N/A Invalid Security', '#N/A Field Not Applicable']\n",
    "### Industry mapping path:\n",
    "str_path_industry_map = 'Data_Files/Source_Files/WIOT_to_GICS_mapping.xlsx'\n",
    "str_sheet_mapping = 'WIOT Mapping'\n",
    "str_sheet_full_gics = 'GICS List old' # 'GICS List'\n",
    "### Path to original WIOT Tables:\n",
    "str_path_wiot_source = 'Data_Files/Source_Files/WIOT'\n",
    "### Downloaded and aggregated shares:\n",
    "str_path_gics_hdf = 'Data_Files/Result_Files/gics_flows_value.h5'\n",
    "str_path_flows_hdf = 'Data_Files/Result_Files/gics_flows_share.h5'\n",
    "str_path_flows_filled_hdf = 'Data_Files/Result_Files/gics_flows_filled.h5'\n",
    "str_gics_key = 'gics_io'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be936ac-1bed-4e8a-a60e-dadc88cdc8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WIOD TO GICS INDUSTRY MAPPING\n",
    "\n",
    "dict_industry_mapper = pd.read_excel(engine = 'openpyxl', io = str_path_industry_map, sheet_name = str_sheet_mapping, header = [0], index_col = 0)\\\n",
    "                         .squeeze().astype(str).to_dict()\n",
    "dict_gics_sub = pd.read_excel(engine = 'openpyxl', io = str_path_industry_map, sheet_name = str_sheet_full_gics, header = [0], index_col = None).astype(str)\\\n",
    "                  .replace({'None': None}).set_index('Industry Group').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585ae21f-bcdb-4a3a-a790-3d20137008cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING COUNTRY CODES EXTRACTOR\n",
    "\n",
    "def get_country_codes(use_local_copy = False):  \n",
    "    ### In case if URL is unavailable:\n",
    "    if (use_local_copy):\n",
    "        url_country_code = 'Data_Files/Source_Files/countrycode.html'\n",
    "    ### Online extraction:\n",
    "    else:\n",
    "        url_country_code = 'https://countrycode.org/'\n",
    "    df_full_codes = pd.read_html(url_country_code, index_col = 'COUNTRY')[0]\n",
    "    df_full_codes[['ISO SHORT', 'ISO LONG']] = df_full_codes['ISO CODES'].str.split(' / ', expand = True)\n",
    "    df_result = df_full_codes[['ISO SHORT', 'ISO LONG']].sort_index()    \n",
    "    df_result.index = df_result.index.str.upper()\n",
    "    ### Results output:\n",
    "    return df_result\n",
    "\n",
    "### World Country Codes:\n",
    "df_country_codes = get_country_codes()\n",
    "dict_ison_mapper = df_country_codes.set_index('ISO LONG').squeeze().to_dict()\n",
    "dict_ison_mapper['ROW'] = 'YY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4dad6-3193-4969-b0db-b2c3cf7c4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA TABLES LOADING & CONVERTATION\n",
    "\n",
    "dict_flows = {}\n",
    "#for year_matrix_csv in os.listdir(str_path_wiot_source):\n",
    "for year_matrix_csv in os.listdir(str_path_wiot_source)[::-1]:    \n",
    "#for year_matrix_csv in [os.listdir(str_path_wiot_source)[0]] + [os.listdir(str_path_wiot_source)[-1]]:\n",
    "    gc.collect()\n",
    "#    dt_year_end = (pd.to_datetime(year_matrix_csv[4 : 8]) + pd.offsets.BYearEnd()).date()\n",
    "    str_year_num = year_matrix_csv[4 : 8]\n",
    "    print(str_year_num)\n",
    "    df_year_raw = pd.read_csv(str_path_wiot_source + '/' + year_matrix_csv, sep = ';', index_col = [0, 1, 2, 3], skiprows = [0, 1, 2, 3], header = [0, 1], \n",
    "                                        na_values = list_na_excel_values, keep_default_na = False)\n",
    "    ser_year_raw = df_year_raw.droplevel([0, 1]).stack([0, 1]).astype('int32')\n",
    "    ser_year_raw.name = 'Value'\n",
    "    ser_year_raw.index.names = ['Supplier_Country_Long', 'Supplier_Industry_r_named', 'User_Country_Long', 'User_Industry_c_named']\n",
    "    df_year_typed = ser_year_raw.reset_index()\n",
    "    del df_year_raw\n",
    "    del ser_year_raw\n",
    "    gc.collect()\n",
    "    df_year_typed = df_year_typed[df_year_typed['Supplier_Country_Long'].isin(df_country_codes['ISO LONG'].to_list() + ['ROW']) & \n",
    "                                  df_year_typed['User_Country_Long'].isin(df_country_codes['ISO LONG'].to_list() + ['ROW'])]\n",
    "    df_year_typed['Supplier_Country'] = df_year_typed['Supplier_Country_Long'].replace(dict_ison_mapper)\n",
    "    df_year_typed['User_Country'] = df_year_typed['User_Country_Long'].replace(dict_ison_mapper)    \n",
    "    df_year_typed['User_Industry_r_named'] = df_year_typed['User_Industry_c_named'].str.replace('c', 'r')\n",
    "    df_year_typed = df_year_typed[df_year_typed['Supplier_Industry_r_named'].isin(dict_industry_mapper.keys()) & \n",
    "                                  df_year_typed['User_Industry_r_named'].isin(dict_industry_mapper.keys())]    \n",
    "    df_year_typed['User_Industry'] = df_year_typed['User_Industry_r_named'].replace(dict_industry_mapper)\n",
    "    df_year_typed['Supplier_Industry'] = df_year_typed['Supplier_Industry_r_named'].replace(dict_industry_mapper)\n",
    "    df_year_typed['Supplier_Country'] = df_year_typed['Supplier_Country'].astype('category')\n",
    "    df_year_typed['User_Country'] = df_year_typed['User_Country'].astype('category')\n",
    "    df_year_typed['User_Industry'] = df_year_typed['User_Industry'].astype('category')\n",
    "    df_year_typed['Supplier_Industry'] = df_year_typed['Supplier_Industry'].astype('category')\n",
    "    df_year_typed = df_year_typed[['Supplier_Country', 'User_Country', 'Supplier_Industry', 'User_Industry', 'Value']]\n",
    "    ser_year_gics = df_year_typed.groupby(['Supplier_Country', 'User_Country', 'Supplier_Industry', 'User_Industry']).sum().squeeze().sort_index()\n",
    "    dict_flows[str_year_num] = ser_year_gics    \n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "789045da-27e8-49c6-9c3b-00c25cb48736",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONVERTED DATA AGGREGATION & SAVING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "ser_flows = pd.concat(dict_flows, names = ['Date'])\n",
    "ser_flows.to_hdf(str_path_gics_hdf, key = str_gics_key, mode = 'w', format = 'table', complevel = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f830011e-7bf2-49d7-889f-55f12b914220",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST\n",
    "\n",
    "ser_test = pd.read_hdf(str_path_gics_hdf, key = str_gics_key, where = \"Date='2014'\").droplevel('Date')\n",
    "gc.collect()\n",
    "df_iter_flows = ser_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ead239-cf3f-4b97-9ee1-72433c50b0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n"
     ]
    }
   ],
   "source": [
    "### TOTAL VALUES & SHARES CONSTRUCTION\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "### Full values dataset loading:\n",
    "ser_flows = pd.read_hdf(str_path_gics_hdf, key = str_gics_key)\n",
    "### Containers creating:\n",
    "dict_flows_share = {}\n",
    "### Looping over years:\n",
    "for str_iter_year in ser_flows.index.levels[0][::-1]:\n",
    "    print(str_iter_year)\n",
    "    gc.collect()\n",
    "    df_iter_flows = ser_flows[str_iter_year].reset_index()\n",
    "    df_iter_flows['Supplier_Country'] = df_iter_flows['Supplier_Country'].cat.add_categories(['WW'])\n",
    "    df_iter_flows['User_Country'] = df_iter_flows['User_Country'].cat.add_categories(['WW'])    \n",
    "    ### Inner flows filtering:\n",
    "    df_inner_flows = df_iter_flows[(df_iter_flows['Supplier_Country'] == df_iter_flows['User_Country']) & \n",
    "                                  (df_iter_flows['Supplier_Industry'] != '9999') & (df_iter_flows['User_Industry'] != '9999')]      \n",
    "    ### Outer flows filtering:\n",
    "    df_outer_flows = df_iter_flows[(df_iter_flows['Supplier_Country'] != df_iter_flows['User_Country']) & \n",
    "                                  (df_iter_flows['Supplier_Industry'] != '9999') & (df_iter_flows['User_Industry'] != '9999')]  \n",
    "    ### Inner values to series:\n",
    "    ser_country_inner_values = df_inner_flows.set_index(['Supplier_Country', 'User_Country', 'Supplier_Industry', 'User_Industry']).astype('float32').squeeze()     \n",
    "    ### Outer values to series:    \n",
    "    ser_country_to_country_values = df_outer_flows.set_index(['Supplier_Country', 'User_Country', 'Supplier_Industry', 'User_Industry']).astype('float32').squeeze() \n",
    "    ### Country to World trade:        \n",
    "    ser_country_to_world_values = df_outer_flows.groupby(['Supplier_Country', 'Supplier_Industry', 'User_Industry']).sum().squeeze().sort_index()\n",
    "    ### World to World trade:            \n",
    "    ser_world_to_world_values = ser_country_to_world_values.groupby(['Supplier_Industry', 'User_Industry']).sum().astype('float32').sort_index()\n",
    "    ### World to Country trade:                \n",
    "    ser_world_to_country_values = df_outer_flows.groupby(['User_Country', 'Supplier_Industry', 'User_Industry']).sum().squeeze().sort_index()\n",
    "    ### Inner shares:\n",
    "    ser_country_inner_shares = ser_country_inner_values.groupby(['Supplier_Country', 'User_Country', 'Supplier_Industry'])\\\n",
    "                                                       .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index()     \n",
    "    ### Outer shares:\n",
    "    ser_country_to_country_shares = ser_country_to_country_values.groupby(['Supplier_Country', 'User_Country', 'Supplier_Industry'])\\\n",
    "                                                                 .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index()     \n",
    "    ser_country_to_world_shares = ser_country_to_world_values.groupby(['Supplier_Country', 'Supplier_Industry'])\\\n",
    "                                                                 .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index() \n",
    "    ser_country_to_world_shares = pd.concat({'WW': ser_country_to_world_shares}, names = ['User_Country']).swaplevel(0, 1).sort_index()\n",
    "    ser_country_to_world_shares.drop(('WW', 'WW'), inplace = True)\n",
    "    ser_world_to_country_shares = ser_world_to_country_values.groupby(['User_Country', 'Supplier_Industry'])\\\n",
    "                                                             .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index() \n",
    "    ser_world_to_country_shares = pd.concat({'WW': ser_world_to_country_shares}, names = ['Supplier_Country'])    \n",
    "    ser_world_to_country_shares.drop(('WW', 'WW'), inplace = True)    \n",
    "    ser_world_to_world_shares = ser_world_to_world_values.groupby(['Supplier_Industry'])\\\n",
    "                                    .apply(lambda ser_group: ser_group / ser_group.sum()).astype('float32').sort_index() \n",
    "    ser_world_to_world_shares = pd.concat({'WW': pd.concat({'WW': ser_world_to_world_shares}, names = ['User_Country'])}, names = ['Supplier_Country'])    \n",
    "    ### Values aggregating:\n",
    "    ser_year_shares = pd.concat([ser_country_inner_shares, ser_country_to_country_shares, ser_country_to_world_shares, ser_world_to_country_shares, \n",
    "                                 ser_world_to_world_shares]).sort_index()\n",
    "    del ser_country_to_country_shares\n",
    "    gc.collect()\n",
    "    ser_year_shares.drop('9999', axis = 0, level = 'Supplier_Industry', inplace =  True)\n",
    "    ser_year_shares.drop('9999', axis = 0, level = 'User_Industry', inplace =  True)    \n",
    "    dict_flows_share[str_iter_year] = ser_year_shares\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58699047-a508-4949-b3dd-a9fb45193591",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BILATERAL SHARES SAVING\n",
    "\n",
    "ser_all_shares = pd.concat(dict_flows_share)\n",
    "del dict_flows_share\n",
    "gc.collect()\n",
    "ser_all_shares.index.names = ['Date', 'Supplier_Country', 'User_Country', 'Supplier_Industry', 'User_Industry']\n",
    "ser_all_shares.name = 'Share'\n",
    "\n",
    "ser_all_shares.to_hdf(str_path_flows_hdf, key = str_gics_key, mode = 'w', format = 'table', complevel = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cead781-ca62-4888-9aef-9fc8262819f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INDUSTRIES REINDEXATION FUNCTION\n",
    "\n",
    "def industry_reindexation(ser_matrix):\n",
    "    ser_reindexed = ser_matrix.unstack('Supplier_Industry').reindex(dict_gics_sub.keys()).stack(dropna = False)\\\n",
    "                               .unstack('User_Industry').reindex(dict_gics_sub.keys()).stack(dropna = False).sort_index()\n",
    "    for iter_industry in dict_gics_sub:\n",
    "        if (dict_gics_sub[iter_industry] is not None):\n",
    "            ser_reindexed.loc[iter_industry] = ser_reindexed[dict_gics_sub[iter_industry]].values\n",
    "    ser_reindexed.fillna(0.0, inplace = True)\n",
    "    return ser_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be36b9a-b214-4ac8-bde4-01b961b5b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BILATERAL LEVEL INDUSTRIES REINDEXATION\n",
    "\n",
    "gc.collect()\n",
    "ser_flows_share = pd.read_hdf(str_path_flows_hdf, where = \"Date='2014'\").droplevel('Date')\n",
    "ser_flows_last = ser_flows_share.groupby(['Supplier_Country', 'User_Country'])\\\n",
    "                                .apply(lambda ser_group: industry_reindexation(ser_group.droplevel(['Supplier_Country', 'User_Country'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38eee141-d9db-456f-9fce-58abf5a347b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country_to_country': 27491, 'country_to_world': 18890, 'world_to_country': 2010, 'world_to_world': 209, 'empty': 0}\n"
     ]
    }
   ],
   "source": [
    "### FILLING EMPTY BILATERAL SHARES\n",
    "\n",
    "gc.collect()\n",
    "dict_counter = {}\n",
    "dict_counter['country_to_country'] = 0\n",
    "dict_counter['country_to_world'] = 0\n",
    "dict_counter['world_to_country'] = 0\n",
    "dict_counter['world_to_world'] = 0\n",
    "dict_counter['empty'] = 0\n",
    "\n",
    "for iter_supplier in ser_flows_last.index.levels[0]:\n",
    "    for iter_user in ser_flows_last.index.levels[1]:\n",
    "        for iter_industry in ser_flows_last.index.levels[2]:\n",
    "            ser_country_to_country = ser_flows_last.loc[iter_supplier, iter_user, iter_industry]\n",
    "            ser_country_to_world = ser_flows_last.loc[iter_supplier, 'WW', iter_industry]\n",
    "            ser_world_to_country = ser_flows_last.loc['WW', iter_user, iter_industry]\n",
    "            ser_world_to_world = ser_flows_last.loc['WW', 'WW', iter_industry]\n",
    "            if (sum(ser_country_to_country) == 0.0):\n",
    "                if (sum(ser_country_to_world) == 0.0):\n",
    "                    if (sum(ser_world_to_country) == 0.0):\n",
    "                        if (sum(ser_world_to_world) == 0.0):\n",
    "                            dict_counter['empty'] += 1                    \n",
    "#                            print(iter_supplier, iter_user, iter_industry, ': no data to fill')                            \n",
    "                        else:\n",
    "                            ser_flows_last.loc[iter_supplier, iter_user, iter_industry] = ser_world_to_world.values\n",
    "                            dict_counter['world_to_world'] += 1\n",
    "#                            print(iter_supplier, iter_user, iter_industry, ': filled by World to World level data')                            \n",
    "                    else:\n",
    "                        ser_flows_last.loc[iter_supplier, iter_user, iter_industry] = ser_world_to_country.values\n",
    "                        dict_counter['world_to_country'] += 1\n",
    "#                        print(iter_supplier, iter_user, iter_industry, ': filled by World to Country level data')                        \n",
    "                else:\n",
    "                    ser_flows_last.loc[iter_supplier, iter_user, iter_industry] = ser_country_to_world.values\n",
    "                    dict_counter['country_to_world'] += 1\n",
    "#                    print(iter_supplier, iter_user, iter_industry, ': filled by Country to World level data')\n",
    "            else:\n",
    "                dict_counter['country_to_country'] += 1\n",
    "print(dict_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc8f0ac6-b0b7-409a-b03d-82f192593a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_to_country : 0.5657\n",
      "country_to_world : 0.3887\n",
      "world_to_country : 0.0414\n",
      "world_to_world : 0.0043\n",
      "empty : 0.0\n"
     ]
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "for iter_option in dict_counter:\n",
    "    print(iter_option, ':', round(dict_counter[iter_option] / len(ser_flows_last.groupby(['Supplier_Country', 'User_Country', 'Supplier_Industry']).count()), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21d5e8df-1835-4c2d-bba2-9e80fc1440e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### REINDEXED AND FILLED FLOW SHARES SAVING\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "ser_flows_last.to_hdf(str_path_flows_filled_hdf, key = str_gics_key, mode = 'w', format = 'table', complevel = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a986c93-b7a1-4826-a3aa-a03aa7231389",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_flows_last = pd.read_hdf(str_path_flows_filled_hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9031a298-fff1-4424-929f-7e7793c41978",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_flows_last['WW', 'WW'].unstack('User_Industry').to_csv('total_shares_v2.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41babc-e0a1-4bd0-bb50-c641d64f57ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
