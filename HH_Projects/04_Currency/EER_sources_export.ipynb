{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BLOOMBERG RAW DATA CONVERTING TO DATAFRAMES AND SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "### Data source:\n",
    "str_path_bb_tr_source = 'Data_Files/Source_Files/Bloomberg_TR.xlsx'\n",
    "str_path_bb_mmr_source = 'Data_Files/Source_Files/Bloomberg_MMR.xlsx'\n",
    "str_path_bb_fx_source = 'Data_Files/Source_Files/Bloomberg_FX.xlsx'\n",
    "str_path_bb_mcap_source = 'Data_Files/Source_Files/Bloomberg_MCap.xlsx'\n",
    "str_path_bb_eer_source = 'Data_Files/Source_Files/Bloomberg_EER.xlsx'\n",
    "str_path_bb_xcra_source = 'Data_Files/Source_Files/Bloomberg_XCRA.xlsx'\n",
    "### Ret TR options:\n",
    "int_type_start = 8\n",
    "int_type_end = -6\n",
    "date_start = date(1992, 1, 1)\n",
    "date_end = date(2020, 4, 30)\n",
    "### MMR options:\n",
    "dict_mmr_replace = {'Cl': 'CI'}\n",
    "### EER options:\n",
    "dict_eer_sources = {'JPM REER B C D': 'REER 01-JPM', 'CTG REER B D': 'REER 02-CTG', 'IMF REER B M': 'REER 03-IMF', 'BIS REER B M': 'REER 04-BIS',\n",
    "                    'JPM NEER B D': 'NEER 01-JPM', 'CTG REER B D (2)': 'NEER 02-CTG', 'BIS NEER B D': 'NEER 03-BIS'}\n",
    "### XCRA options:\n",
    "int_rolling_win_max = 12\n",
    "int_rolling_win_min = int_rolling_win_max // 2\n",
    "### Results saving:\n",
    "str_path_bb_hdf = 'Data_Files/Source_Files/Bloomberg_prepared.h5'\n",
    "str_key_ret = 'bb_ret'\n",
    "str_key_mmr = 'bb_mmr'\n",
    "str_key_fx = 'bb_fx'\n",
    "str_key_mcap = 'bb_mcap'\n",
    "str_key_reer = 'bb_reer'\n",
    "str_key_neer = 'bb_neer'\n",
    "str_key_xcra = 'bb_xcra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def market_membership(convert_to_daily = False):\n",
    "    ### Importing standard modules and date-special modules:    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    ### Reindexing function declaring:\n",
    "    def reindex_month_ends(iter_group):\n",
    "        iter_range = pd.date_range(iter_group.first_valid_index(), iter_group.last_valid_index(), freq = 'BM')\n",
    "        iter_result = iter_group.reindex(iter_range)\n",
    "        return iter_result    \n",
    "    ### Declaring local constants & variables:\n",
    "    path_msci = 'Data_Files/Source_Files/sample_universe.xlsx' ### Path for membership source     \n",
    "    tab_monthly = 'universe_joined'    \n",
    "    arr_markets_needed = ['DM', 'FM', 'EM']   \n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM'}\n",
    "    no_slice = slice(None)\n",
    "    ### Extracting universe data:\n",
    "    df_universe = pd.read_excel(io = path_msci, sheet_name = tab_monthly, skiprows = [0, 2], header = 0, parse_dates = True, \n",
    "                                na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    df_universe = df_universe.loc[no_slice, ['dates', 'region', 'ctry']]\n",
    "    df_universe.columns = ['Date', 'Market', 'Country']\n",
    "    df_universe.set_index(['Date', 'Country'], inplace = True)\n",
    "    ser_universe = df_universe.squeeze()\n",
    "    ser_universe.sort_index(level = [0, 1], inplace = True)\n",
    "    ser_universe.replace(dict_markets, inplace = True)\n",
    "    ser_market_membership = ser_universe[ser_universe.isin(arr_markets_needed)]\n",
    "    ### Reindexing to show absent monthes for future daily resampling: \n",
    "    if (convert_to_daily):\n",
    "        ser_market_membership = ser_market_membership.groupby('Country').apply(lambda iter_group: reindex_month_ends(iter_group.droplevel(1)))\n",
    "        ser_market_membership.index.names = ['Country', 'Date']\n",
    "        ser_market_membership = ser_market_membership.swaplevel()\n",
    "        ser_market_membership = ser_market_membership.reset_index('Country').groupby('Country').resample('B').ffill().drop('Country', axis = 1).squeeze()\n",
    "        ser_market_membership = ser_market_membership.swaplevel().sort_index(level = ['Country', 'Date'])\n",
    "        \n",
    "    return ser_market_membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING TOTAL RETURN INDEXES LOADING\n",
    "\n",
    "def tot_ret_ind_export(str_path_bb_tr_source):\n",
    " \n",
    "    ### Loading raw excel source:\n",
    "    dict_tr_source = pd.read_excel(io = str_path_bb_tr_source, sheet_name = None, skiprows = list(range(27)), index_col = 0, header = 0, parse_dates = True, \n",
    "                                    na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                                     '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)  \n",
    "    ### Preparing datasets concatenation:\n",
    "    arr_tr_data = []\n",
    "    for str_sheet_name in dict_tr_source:\n",
    "        ### Future additional indexes:    \n",
    "        str_currency = 'LOC'\n",
    "        if ('USD' in str_sheet_name):\n",
    "            str_currency = 'USD'\n",
    "        str_ind_type = str_sheet_name[int_type_start : int_type_end]\n",
    "        ### Stacking county codes for making series:\n",
    "        ser_iter_set = dict_tr_source[str_sheet_name].stack(dropna = False)\n",
    "        ### Main index levels renaming:\n",
    "        ser_iter_set.index.names = ['Date', 'Country']\n",
    "        ### Resampling from possible calendar month ends to business month ends:\n",
    "        ser_iter_set = ser_iter_set.unstack('Country').resample('MS').last().resample('BM').last().stack('Country', dropna = False).squeeze()\n",
    "        ### Adding index levels for source description:\n",
    "        ser_iter_set = ser_iter_set.to_frame().assign(Currency = str_currency)\\\n",
    "                                              .assign(Type = str_ind_type)\\\n",
    "                                              .set_index(['Type', 'Currency'], append = True).squeeze()\n",
    "        ### Data aggregation for concatenation:\n",
    "        arr_tr_data.append(ser_iter_set)\n",
    "    ### Consolidated dataset preparing:\n",
    "    ser_tr_raw_data = pd.concat(arr_tr_data).reorder_levels([3, 2, 0, 1])    \n",
    "    ### Results output:\n",
    "    return ser_tr_raw_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING TOTAL RETURN INDEXES LOADING\n",
    "\n",
    "def tot_ret_ind_converter(str_path_bb_tr_source, date_start, date_end):\n",
    "    ### Data loading:\n",
    "    ser_tr_raw_data = tot_ret_ind_export(str_path_bb_tr_source)\n",
    "    index_raw_gaps = ser_tr_raw_data\n",
    "    ### Data reindexing and forward filling:\n",
    "    index_ret_dates = pd.date_range(date_start, date_end, freq = 'BM')\n",
    "    ser_tr_reindex = ser_tr_raw_data.reindex(index_ret_dates, level = 'Date')\n",
    "    idx_tr_empty = ser_tr_reindex.loc[ser_tr_reindex.isna()].index\n",
    "    ser_tr_reindex = ser_tr_reindex.groupby(['Currency', 'Type', 'Country']).fillna(method = 'ffill').sort_index(level = ['Currency', 'Type', 'Country', 'Date'])\n",
    "    ### Returns calculating:\n",
    "    ser_ret_reindex = ser_tr_reindex.groupby(['Currency', 'Type', 'Country']).apply(lambda iter_group: iter_group / iter_group.shift(1) - 1)\n",
    "    ### Dropping zero returns, generated by forward filling after reindexation:\n",
    "    ser_ret_reindex.loc[idx_tr_empty] = np.NaN\n",
    "    ### Dropping zero returns, generated by bloomberg request:\n",
    "    ser_ret_reindex.loc[ser_ret_reindex == 0] = np.NaN\n",
    "    ### Returns combining:\n",
    "    df_ret_reindex = ser_ret_reindex.unstack('Type')    \n",
    "    df_ret_reindex['Combined'] = df_ret_reindex.groupby(['Currency', 'Country'], group_keys = False).apply(lambda iter_group: iter_group['MSCI']\\\n",
    "                                                                                                                   .combine_first(iter_group['Old MSCI'])\n",
    "                                                                                                                   .combine_first(iter_group['Main Index']))\n",
    "    ### Results output:\n",
    "    return df_ret_reindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING MONEY MARKET RATES LOADING\n",
    "\n",
    "def mmr_export(str_path_bb_mmr_source, dict_mmr_replace):\n",
    "    ### Defining multipurpose country-level function: \n",
    "    ###   1) Resampling to BM for monthly tickers\n",
    "    ###   2) Reindexing for BD    \n",
    "    ###   3) Forward filling tickers before combining\n",
    "    ###   4) Combining tickers\n",
    "    def mmr_convertion(df_mmr_country, ser_mmr_freq, idx_mmr_date_range):\n",
    "        ### Forward fillin limit:\n",
    "        num_fill_limit = 23\n",
    "        ### Dictionary for source frequencies:\n",
    "        str_country_code = df_mmr_country.iloc[: 1].index[0][1]\n",
    "        dict_freq = dict(ser_mmr_freq.loc[str_country_code, All].droplevel('Country'))\n",
    "        ### Dictionary for transitional results:\n",
    "        dict_source = {}\n",
    "        ### Looping over sources inside country data:\n",
    "        for chr_freq in dict_freq:\n",
    "            if (dict_freq[chr_freq] == 'M'):\n",
    "                ### Resampling to Business-Month-Ends for monthly frequency (then reindexing for proper date range):\n",
    "                dict_source[chr_freq] = df_mmr_country.loc[All, chr_freq].droplevel('Country').resample('MS').last().resample('BM').last().reindex(idx_mmr_date_range)\n",
    "            elif (dict_freq[chr_freq] == 'D'):\n",
    "                ### Reindexing for proper date range for not monthly frequencies:\n",
    "                dict_source[chr_freq] = df_mmr_country.loc[All, chr_freq].droplevel('Country').reindex(idx_mmr_date_range)\n",
    "        ### Forward filling for primary source:\n",
    "        ser_mmr_country = dict_source[1].fillna(method = 'ffill', limit = num_fill_limit)   \n",
    "        ### Combining (if we have secondary source to combine with):\n",
    "        if (dict_freq[2]):\n",
    "            ### Combining sources (with preliminary forward filling for secondary source):\n",
    "            ser_mmr_country = ser_mmr_country.combine_first(dict_source[2].fillna(method = 'ffill', limit = num_fill_limit)) \n",
    "        ### Results output:\n",
    "        ser_mmr_country = ser_mmr_country.to_frame().assign(Country = str_country_code).set_index('Country', append = True).squeeze().fillna(method = 'ffill')\n",
    "        return ser_mmr_country\n",
    "    ### Loading raw excel source:\n",
    "    df_mmr_source = pd.read_excel(io = str_path_bb_mmr_source, index_col = 0, header = [0, 1], skiprows = [2], parse_dates = True, \n",
    "                                  na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                               'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)  \n",
    "    df_mmr_stacked = df_mmr_source.stack(['Code', 'Priority'], dropna = False).unstack('Priority')\n",
    "    df_mmr_stacked.index.names = ['Date', 'Country']\n",
    "    ### Loading MMR source frequencies:\n",
    "    df_mmr_freq = pd.read_excel(io = str_path_bb_mmr_source, index_col = 0, header = [0, 1], nrows = 1, parse_dates = True, \n",
    "                                  na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                               'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    ser_mmr_freq = df_mmr_freq.stack(['Code', 'Priority'], dropna = False).droplevel(0).replace(np.NaN, '')\n",
    "    ser_mmr_freq.index.names = ['Country', 'Priority']\n",
    "    ### Date range constructing:\n",
    "    date_mmr_min = df_mmr_stacked.index.get_level_values(0).unique().min()\n",
    "    date_mmr_max = df_mmr_stacked.index.get_level_values(0).unique().max()\n",
    "    idx_mmr_date_range = pd.date_range(date_mmr_min, date_mmr_max, freq = 'B')\n",
    "    ### Multi-purpose mmr raw data convertion:\n",
    "    ser_mmr_combined = df_mmr_stacked.groupby('Country', group_keys = False).apply(mmr_convertion, ser_mmr_freq, idx_mmr_date_range).squeeze()\n",
    "    ser_mmr_combined = ser_mmr_combined.reset_index('Country').replace(dict_mmr_replace).set_index('Country', append = True).squeeze()\n",
    "    ser_mmr_combined = ser_mmr_combined / 100.00\n",
    "    ser_mmr_combined.name = 'MMR'\n",
    "    ser_mmr_combined.index.names = ['Date', 'Country']\n",
    "    ### Results output:\n",
    "    return ser_mmr_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING FOREIGN EXCHANGE RATES LOADING\n",
    "\n",
    "def fx_export(str_path_bb_fx_source, str_code = 'Country'):\n",
    "    ### Defining country-level function for exchange rate division by factor:\n",
    "    def fx_convertion(ser_fx_code, ser_fx_factor, idx_fx_date_range):    \n",
    "        ### Exchange rate factor extracting:\n",
    "        str_code = ser_fx_code.iloc[: 1].index[0][1]       \n",
    "        num_factor = ser_fx_factor[str_code]\n",
    "        ### Reindexing and dividing exchange rate:\n",
    "        ser_fx_converted = ser_fx_code.droplevel('Code').reindex(idx_fx_date_range).fillna(method = 'ffill') / num_factor\n",
    "        return ser_fx_converted\n",
    "    ### Loading raw excel source:\n",
    "    df_fx_source = pd.read_excel(io = str_path_bb_fx_source, sheet_name = 'FX Data', skiprows = list(range(2, 8)), index_col = 0, header = [0, 1], parse_dates = True, \n",
    "                                    na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                                 '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    ser_fx_data = df_fx_source.stack([0, 1])\n",
    "    ### Adding USD rates:\n",
    "    ser_fx_usd = pd.Series(1, index = pd.MultiIndex.from_product([ser_fx_data.index.get_level_values(0).unique(), ['US'], ['USD']], names = ser_fx_data.index.names))\n",
    "    ser_fx_data = pd.concat([ser_fx_data, ser_fx_usd]).sort_index()\n",
    "    ### Dropping redundant index level:    \n",
    "    if (str_code == 'Country'):\n",
    "        ser_fx_data = ser_fx_data.droplevel(2)\n",
    "    else:\n",
    "        ser_fx_data = ser_fx_data.droplevel(1)\n",
    "        ser_fx_data = ser_fx_data[~ser_fx_data.index.duplicated()]\n",
    "    ser_fx_data.index.names = ['Date', 'Code']\n",
    "    ser_fx_data.name = 'FX'    \n",
    "    ### Extracting factor:\n",
    "    df_fx_factor = pd.read_excel(io = str_path_bb_fx_source, index_col = 0, header = [0, 1], nrows = 1, \n",
    "                                  na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                               'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)    \n",
    "    ser_fx_factor = df_fx_factor.stack([0, 1]).droplevel(0)\n",
    "    if (str_code == 'Country'):\n",
    "        ser_fx_factor = ser_fx_factor.droplevel(1)\n",
    "    else:\n",
    "        ser_fx_factor = ser_fx_factor.droplevel(0)\n",
    "        ser_fx_factor = ser_fx_factor[~ser_fx_factor.index.duplicated()]\n",
    "    ser_fx_factor.index.names = ['Code']\n",
    "    ser_fx_factor.name = 'Factor'\n",
    "    ### Date range constructing:\n",
    "    date_fx_min = ser_fx_data.index.get_level_values(0).unique().min()\n",
    "    date_fx_max = ser_fx_data.index.get_level_values(0).unique().max()\n",
    "    idx_fx_date_range = pd.date_range(date_fx_min, date_fx_max, freq = 'B')    \n",
    "    ### Results preparing:\n",
    "    ser_fx_ready = ser_fx_data.groupby('Code', group_keys = True).apply(fx_convertion, ser_fx_factor, idx_fx_date_range).squeeze().swaplevel()\n",
    "    ser_fx_ready.index.names = ['Date', str_code]\n",
    "    ### Results output:\n",
    "    return ser_fx_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING MARKET CAPITALIZATIONS LOADING\n",
    "\n",
    "def mcap_export(str_path_bb_mcap_source):\n",
    "    ### Loading raw excel source:\n",
    "    df_mcap_source = pd.read_excel(io = str_path_bb_mcap_source, index_col = 0, header = 0, skiprows = list(range(28)), parse_dates = True, \n",
    "                                   na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                               'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)  \n",
    "    ser_mcap_stacked = df_mcap_source.stack(dropna = False).squeeze()\n",
    "    ser_mcap_stacked = ser_mcap_stacked.astype('float32')\n",
    "    ser_mcap_stacked.index.names = ['Date', 'Country']\n",
    "    ser_mcap_stacked.name = 'Market Cap'\n",
    "    ### Loading MMR source frequencies:\n",
    "    df_mcap_currency = pd.read_excel(io = str_path_bb_mcap_source, index_col = 0, header = 0, skiprows = list(range(10)), nrows = 5, parse_dates = True, \n",
    "                                  na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                               'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    ser_mcap_currency = df_mcap_currency.iloc[4, All].squeeze()\n",
    "    ser_mcap_currency.index.names = ['Country']\n",
    "    ser_mcap_currency.name = 'Currency'\n",
    "    ### Date range constructing:\n",
    "    date_mcap_min = ser_mcap_stacked.index.get_level_values(0).unique().min()\n",
    "    date_mcap_max = ser_mcap_stacked.index.get_level_values(0).unique().max()\n",
    "    idx_mcap_date_range = pd.date_range(date_mcap_min, date_mcap_max, freq = 'B')   \n",
    "    ### Loading FX rates for currencies:\n",
    "    ser_fx_curr = fx_export(str_path_bb_fx_source, 'Currency')\n",
    "    ### Denominating to USD by Country -> Currency -> FX rate connection:\n",
    "    df_mcap_usd = ser_mcap_stacked.to_frame().join(ser_mcap_currency, how = 'left').set_index('Currency', append = True).join(ser_fx_curr, how = 'left')\n",
    "    ser_mcap_usd = df_mcap_usd['Market Cap'].mul(df_mcap_usd['FX']).droplevel('Currency')\n",
    "    ser_mcap_usd.name = 'Market Cap'\n",
    "    ### Adding ISON regions:\n",
    "    ser_ison_membership = market_membership()\n",
    "    ser_mcap_usd = ser_mcap_usd.to_frame().join(ser_ison_membership, how = 'left').set_index('Market', append = True).squeeze()\n",
    "    ### Filling values for all-empty countries (only in ISON universe):\n",
    "    list_empty_countries = ser_mcap_usd.groupby('Country').filter(lambda iter_country: iter_country.count() == 0).index.get_level_values(1).unique()\n",
    "    ser_mcap_usd.loc[All, list_empty_countries, All] = \\\n",
    "    ser_mcap_usd.groupby(['Date', 'Market']).apply(lambda iter_group: iter_group.fillna(iter_group.mean())).loc[All, list_empty_countries, All]\n",
    "    ser_mcap_usd = round(ser_mcap_usd, 2)\n",
    "    ### Forward-filling all gaps:\n",
    "    ser_mcap_usd = ser_mcap_usd.groupby(['Country']).ffill().groupby(['Country']).bfill()\n",
    "    ### Results output:\n",
    "    return ser_mcap_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION BLOOMBERG EER DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def eer_export(str_path_bb_eer_source, dict_eer_sources, bool_unique_countries = True):\n",
    "    ### Defining multipurpose country-level function: \n",
    "    ###   1) Resampling to BM for monthly tickers\n",
    "    ###   2) Reindexing for BD    \n",
    "    def eer_convertion(ser_eer_country, chr_eer_freq, idx_eer_date_range):\n",
    "        ### Country code saving:\n",
    "        str_country_code = ser_eer_country.iloc[: 1].index[0][1]\n",
    "        ### Conditional resampling and reindexing::\n",
    "        if (chr_eer_freq == 'M'):\n",
    "            ### Resampling to Business-Month-Ends for monthly frequency (then reindexing for proper date range):\n",
    "            ser_eer_converted = ser_eer_country.droplevel('Country').resample('MS').last().resample('BM').last().reindex(idx_eer_date_range)\n",
    "        else:\n",
    "            ### Reindexing for proper date range for not monthly frequencies:\n",
    "            ser_eer_converted = ser_eer_country.droplevel('Country').reindex(idx_eer_date_range)\n",
    "        ### Results output:\n",
    "        ser_eer_converted.index.names = ['Date']\n",
    "        return ser_eer_converted    \n",
    "    ### Loading raw excel source:\n",
    "    dict_eer_source = pd.read_excel(io = str_path_bb_eer_source, sheet_name = None, skiprows = list(range(4)), index_col = 0, header = 0, parse_dates = True, \n",
    "                                    na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                                 '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    ### Preparing datasets concatenation:\n",
    "    list_eer_data = []\n",
    "    for str_sheet_name in dict_eer_source:\n",
    "        ### Filtering Broad NEER or Broad CPI-Based REER:\n",
    "        if str_sheet_name in dict_eer_sources:\n",
    "            ### Future additional indexes:\n",
    "            list_iter_index = dict_eer_sources[str_sheet_name].split()\n",
    "            ### Checking for monthly frequency:\n",
    "            chr_iter_freq = 'D'\n",
    "            if (str_sheet_name.endswith('M')):\n",
    "                chr_iter_freq = 'M'\n",
    "            ### Stacking county codes for making series:\n",
    "            ser_iter_set = dict_eer_source[str_sheet_name].stack(dropna = False)\n",
    "            ### Main index levels renaming:\n",
    "            ser_iter_set.index.names = ['Date', 'Country']\n",
    "            ### Date range constructing:\n",
    "            date_eer_min = ser_iter_set.index.get_level_values(0).unique().min()\n",
    "            date_eer_max = ser_iter_set.index.get_level_values(0).unique().max()\n",
    "            idx_eer_date_range = pd.date_range(date_eer_min, date_eer_max, freq = 'B')\n",
    "            ### Multi-purpose eer raw data convertion:\n",
    "            ser_iter_eer = ser_iter_set.groupby('Country', group_keys = True).apply(eer_convertion, chr_iter_freq, idx_eer_date_range).squeeze()         \n",
    "            ### Adding index levels for source description:\n",
    "            ser_iter_eer = ser_iter_eer.to_frame().assign(Type = list_iter_index[0])\\\n",
    "                                                  .assign(Source = list_iter_index[1])\\\n",
    "                                                  .set_index(['Type', 'Source'], append = True).squeeze()\n",
    "            ### Data aggregation for concatenation:\n",
    "            list_eer_data.append(ser_iter_eer)\n",
    "    ### Consolidated dataset preparing:\n",
    "    ser_eer_data = pd.concat(list_eer_data).reorder_levels([2, 3, 0, 1])\n",
    "    if (not bool_unique_countries):\n",
    "        ### Results output:\n",
    "        return ser_eer_data\n",
    "    else:\n",
    "        ### REER filtering:\n",
    "        df_reer_data = ser_eer_data.loc['REER', All, All, All].unstack('Source').swaplevel().sort_index(axis = 1)\n",
    "        ### REER sources looping:\n",
    "        dict_reer_combined = {}\n",
    "        set_prev_countries = set()\n",
    "        for iter_source in sorted(df_reer_data.columns):\n",
    "            ### Selecting unique REER source countries\n",
    "            set_iter_countries = set(df_reer_data[iter_source].dropna().index.get_level_values(1).unique()) - set_prev_countries\n",
    "            set_prev_countries = set_prev_countries | set_iter_countries\n",
    "            ### Creating dataset from REER source:\n",
    "            dict_reer_combined[iter_source.split('-')[1]] = df_reer_data[iter_source].loc[All, set_iter_countries]\n",
    "        ### REER combined source creating:\n",
    "        df_reer_combined = pd.concat(dict_reer_combined).reset_index(0).sort_index(level = ['Date', 'Country'])\n",
    "        df_reer_combined.columns = ['Source', 'EER']\n",
    "        ser_reer = df_reer_combined['EER']\n",
    "        ### NEER filtering:\n",
    "        df_neer_data = ser_eer_data.loc['NEER', All, All, All].unstack('Source').swaplevel().sort_index(axis = 1)\n",
    "        ### NEER sources looping:\n",
    "        dict_neer_combined = {}\n",
    "        set_prev_countries = set()\n",
    "        for iter_source in sorted(df_neer_data.columns):\n",
    "            ### Selecting unique NEER source countries\n",
    "            set_iter_countries = set(df_neer_data[iter_source].dropna().index.get_level_values(1).unique()) - set_prev_countries\n",
    "            set_prev_countries = set_prev_countries | set_iter_countries\n",
    "            ### Creating dataset from NEER source:\n",
    "            dict_neer_combined[iter_source.split('-')[1]] = df_neer_data[iter_source].loc[All, set_iter_countries]\n",
    "        ### NEER combined source creating:\n",
    "        df_neer_combined = pd.concat(dict_neer_combined).reset_index(0).sort_index(level = ['Date', 'Country'])\n",
    "        df_neer_combined.columns = ['Source', 'EER']\n",
    "        ser_neer = df_neer_combined['EER'] \n",
    "        ### Results output:\n",
    "        return (ser_reer, ser_neer)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION BLOOMBERG XCRA DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def xcra_export(str_path_bb_xcra_source, bool_fill_and_ma = True):\n",
    "    ### Loading raw excel source:\n",
    "    dict_xcra_source = pd.read_excel(io = str_path_bb_xcra_source, sheet_name = None, skiprows = list(range(5)), index_col = 0, header = 0, parse_dates = True, \n",
    "                                    na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                                 '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    dict_xcra_stacked = {}\n",
    "    ### Resampling from possible calendar month ends to business month ends:\n",
    "    for iter_concept in dict_xcra_source:\n",
    "        dict_xcra_stacked[iter_concept] = dict_xcra_source[iter_concept].resample('MS').last().resample('BM').last().stack(dropna = False).squeeze()\n",
    "    ### Data consolidating:\n",
    "    df_xcra_stacked = pd.concat(dict_xcra_stacked, axis = 1)\n",
    "    df_xcra_stacked.index.names = ['Date', 'Country']    \n",
    "    ### Exit without additional data preparation:\n",
    "    if (not bool_fill_and_ma):\n",
    "        ### Results output:\n",
    "        return df_xcra_stacked\n",
    "    ### Additional data preparation:\n",
    "    else:\n",
    "        ### Imports and Exports annual MA modifying:\n",
    "        df_xcra_stacked[['Imports','Exports']] = df_xcra_stacked[['Imports','Exports']].groupby('Country', group_keys = False)\\\n",
    "                                                                                       .rolling(int_rolling_win_max, int_rolling_win_min).mean()\n",
    "        df_xcra_stacked[['Imports','Exports']] = df_xcra_stacked[['Imports','Exports']] * 12\n",
    "        ### XCRA concepts forward filling and back filling for first observation:\n",
    "        df_xcra_filled = df_xcra_stacked.groupby(['Country']).fillna(method = 'ffill').groupby(['Country']).fillna(method = 'bfill')        \n",
    "        ### Results output:\n",
    "        return df_xcra_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN SCRIPT\n",
    "\n",
    "### Data export:\n",
    "df_ret_reindex = tot_ret_ind_converter(str_path_bb_tr_source, date_start, date_end)\n",
    "ser_returns = df_ret_reindex['Combined']\n",
    "ser_mmr = mmr_export(str_path_bb_mmr_source, dict_mmr_replace)\n",
    "ser_ison_membership = market_membership()\n",
    "ser_fx_country = fx_export(str_path_bb_fx_source)\n",
    "ser_mcap = mcap_export(str_path_bb_mcap_source)\n",
    "(ser_reer, ser_neer) = eer_export(str_path_bb_eer_source, dict_eer_sources)\n",
    "df_xcra_filled = xcra_export(str_path_bb_xcra_source)\n",
    "### Data saving:\n",
    "ser_returns.to_hdf(str_path_bb_hdf, key = str_key_ret, mode = 'w')\n",
    "ser_mmr.to_hdf(str_path_bb_hdf, key = str_key_mmr, mode = 'r+')\n",
    "ser_fx_country.to_hdf(str_path_bb_hdf, key = str_key_fx, mode = 'r+')\n",
    "ser_mcap.to_hdf(str_path_bb_hdf, key = str_key_mcap, mode = 'r+')\n",
    "ser_reer.to_hdf(str_path_bb_hdf, key = str_key_reer, mode = 'r+')\n",
    "ser_neer.to_hdf(str_path_bb_hdf, key = str_key_neer, mode = 'r+')\n",
    "df_xcra_filled.to_hdf(str_path_bb_hdf, key = str_key_xcra, mode = 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_test_equal = ser_returns.unstack('Currency').groupby('Country').apply(lambda df_country: (df_country['LOC'] - df_country['USD']).abs().mean())\n",
    "\n",
    "ser_returns.unstack('Currency').loc[(All, 'EG'), All]\n",
    "\n",
    "ser_test_equal.loc[ser_test_equal < 0.01].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
