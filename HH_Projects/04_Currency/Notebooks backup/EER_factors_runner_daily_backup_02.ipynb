{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EER FACTOR DAILY GENERATOR (SHOULD BE IGNORED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODULES IMPORT (PART OF THE PRODUCT CODE)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INTERNAL PARAMETERS INITIALIZATION (SHOULD BE IGNORED)\n",
    "\n",
    "### Universe path:\n",
    "str_path_universe = 'Data_Files/Source_Files/acadian_universe.xlsx'\n",
    "### Bloomberg structured data extraction keys:\n",
    "str_path_bb_hdf = 'Data_Files/Source_Files/Bloomberg_prepared.h5'\n",
    "str_key_fx_country = 'bb_fx_country'\n",
    "str_key_fx_demeaned = 'bb_fx_demeaned'\n",
    "str_key_mcap = 'bb_mcap'\n",
    "str_key_reer = 'bb_reer'\n",
    "str_key_neer = 'bb_neer'\n",
    "str_key_reer_sourced = 'bb_reer_sourced'\n",
    "str_key_neer_sourced = 'bb_neer_sourced'\n",
    "str_key_export_monthly = 'bb_export'\n",
    "str_key_gdp = 'bb_gdp'\n",
    "str_key_cpi = 'bb_cpi'\n",
    "### General daily-mone ranges parameters:\n",
    "str_source_date_start = '1992-01-01' ### Start date for source vectors\n",
    "str_measure_date_start = '1996-08-01' ### Start date for efficacy measures\n",
    "str_ison_date_start = '1994-01-31' ### Start date for ISON Universe\n",
    "str_measure_date_end = '2020-08-31' ### End date for efficacy measures\n",
    "idx_source_date_range = pd.date_range(str_source_date_start, str_measure_date_end, freq = 'B') ### Range for source data filtering\n",
    "idx_test_date_range = pd.date_range(str_ison_date_start, str_measure_date_end, freq = 'B') ### Range for source data filtering\n",
    "idx_factor_date_range = pd.date_range(str_source_date_start, str_measure_date_end, freq = 'BM') ### Range for factor data filtering\n",
    "idx_measure_date_range = pd.date_range(str_measure_date_start, str_measure_date_end, freq = 'BM') ### Range for measures calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL PARAMETERS INITIALIZATION (PART OF THE PRODUCT CODE)\n",
    "\n",
    "### Common constants:\n",
    "All = slice(None)\n",
    "\n",
    "### Standartization parameters:\n",
    "list_truncate = [2.5, 2.0] ### Standartization boundaries\n",
    "bool_within_market = True ### Standartization option\n",
    "\n",
    "### ISON filtering options:\n",
    "list_ison = ['DM', 'EM', 'FM'] ### Regions filter to drop NaN region values\n",
    "list_filter = ['DM', 'EM', 'FM'] ### Additional regions filter\n",
    "list_countries_to_exclude = ['VE'] ### Countries not to play the game\n",
    "\n",
    "### Export annualizing options (for interaction variable calculation):\n",
    "int_rolling_exp_max = 12 ### Rolling window length, months\n",
    "int_rolling_exp_min = int_rolling_exp_max // 2 ### Minimal rolling window length, months\n",
    "### Lag shifts (for interaction variable calculation):\n",
    "int_gdp_lag = 3 ### Lag for GDP, months\n",
    "int_export_lag = 1 ### Lag for MA12 Annualized Export, months\n",
    "### General interaction variable calculation options:\n",
    "int_concept_divider = 1000 ### Divider to equalize Export and GDP scales\n",
    "int_concept_pctile_top = 0.75 ### Maximal prctile to winsorize log(1 + EXP/GDP) vector\n",
    "int_prctile_scale = 4 ### Ranking scale for interaction variable\n",
    "\n",
    "### Export adjustment parameters (for factor source tuning):\n",
    "int_season_adj_ma = 12 ### Moving average length for seasonal adjustment, months\n",
    "int_season_adj_shift = math.ceil(int_season_adj_ma / 2) ### Moving average shift for seasonal adjustment, months\n",
    "int_cpi_lag = 1 ### Lag for CPI, months\n",
    "### FX Rate parameters (for factor source tuning):\n",
    "list_extreme_fx_ret = [-0.5, 2.0] ### Boundaries to avoid denomination distortions\n",
    "### General source parameters:\n",
    "int_eer_fill_limit = 22 * 3 ### Days for forward fill sources inside country vectors\n",
    "\n",
    "### General factor calculation parameters:\n",
    "int_mom_length = 5 ### Years of momentum vector\n",
    "### Half-life period, months:\n",
    "dict_mom_hl = {} \n",
    "dict_mom_hl['LONG_TERM'] = 24\n",
    "dict_mom_hl['SHORT_TERM'] = 3\n",
    "### Minimal values number, months:\n",
    "dict_mom_min = {} \n",
    "dict_mom_min['LONG_TERM'] = dict_mom_hl['LONG_TERM']\n",
    "dict_mom_min['SHORT_TERM'] = dict_mom_hl['SHORT_TERM']\n",
    "### Factors options:\n",
    "dict_combinations = {}\n",
    "dict_combinations['LONG_TERM_EER'] = ('LONG_TERM', 'REER')\n",
    "dict_combinations['SHORT_TERM_MIXED'] = ('SHORT_TERM', 'MIXED')\n",
    "dict_combinations['LONG_TERM_EXPORT'] = ('LONG_TERM', 'EXPORT')\n",
    "### Factor averaging weights:\n",
    "dict_factors_weights = {}\n",
    "dict_factors_weights['LONG_TERM_EER'] = 1.0\n",
    "dict_factors_weights['SHORT_TERM_MIXED'] = 1.0\n",
    "dict_factors_weights['LONG_TERM_EXPORT'] = 1.0\n",
    "### Factors signs:\n",
    "dict_factors_signs = {}\n",
    "dict_factors_signs['LONG_TERM_EER'] = -1.0\n",
    "dict_factors_signs['SHORT_TERM_MIXED'] = -1.0\n",
    "dict_factors_signs['LONG_TERM_EXPORT'] = 1.0\n",
    "### Periods lengths for different frequencies:\n",
    "ser_work_periods = pd.Series(1 , index = pd.MultiIndex.from_product([['Year', 'Month'], ['Y', 'M', 'D']], names = ['Period', 'Frequency']))\n",
    "ser_work_periods['Year', 'M'] = 12\n",
    "ser_work_periods['Year', 'D'] = 260\n",
    "ser_work_periods['Month', 'Y'] = 0\n",
    "ser_work_periods['Month', 'D'] = 22\n",
    "flo_exp_weight_month = ser_work_periods['Year', 'D'] / ser_work_periods['Year', 'M'] ### Day in BMonth number for specific exponential weight calculation\n",
    "### Standalone factors weights:\n",
    "list_static_weights = [2.0, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING MATLAB STYLE PRCTILE (PART OF THE PRODUCT CODE)\n",
    "\n",
    "def prctile_matlab(ser_to_perc, p):\n",
    "    ### Sorted list preparing:\n",
    "    list_to_perc = ser_to_perc.dropna().values\n",
    "    list_sorted = np.sort(list_to_perc)\n",
    "    ### Length calculating:\n",
    "    num_len = len(list_to_perc)    \n",
    "    ### Prctile calculating:\n",
    "    num_result = np.interp(np.array(p), np.linspace(1 / (2 * num_len), (2 * num_len - 1) / (2 * num_len), num_len), list_sorted)\n",
    "    ### Results output:\n",
    "    return num_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXPONENTIAL WEIGHT (PART OF THE PRODUCT CODE)\n",
    "\n",
    "def exp_weight_single(halflife_len = 3, num_element = 0):\n",
    "    ### Weight calculating:\n",
    "    num_period_factor = math.exp(math.log(0.5) / round(halflife_len))\n",
    "    num_weight = np.exp(math.log(num_period_factor) * num_element)\n",
    "    ### Result output:\n",
    "    return num_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING GEOMETRICAL WEIGHT (PART OF THE PRODUCT CODE)\n",
    "\n",
    "def geom_weight_single(flo_ratio, flo_factor = 1, num_element = 0):\n",
    "    ### Results output:\n",
    "    return flo_factor * (flo_ratio ** num_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING WEIGHTED AVERAGE (PART OF THE PRODUCT CODE)\n",
    "\n",
    "def weighted_average(ser_data, ser_weight = False, int_min_count = 0):\n",
    "    ### Default output:\n",
    "    num_result = np.NaN\n",
    "    ### Checking for data presence:\n",
    "    if (ser_data.count() > int_min_count):       \n",
    "        ### Checking for weights dataset:\n",
    "        if isinstance(ser_weight, bool):\n",
    "            ### Calculating of simple average:\n",
    "            num_result = np.nanmean(ser_data.values)\n",
    "        else:\n",
    "            ### Weights filtering:\n",
    "            list_weight = ser_weight[ser_data.dropna().index].values\n",
    "            ### Checking for weights presence:\n",
    "            if np.nansum(list_weight):\n",
    "                ### Data filtering:\n",
    "                list_data = ser_data.dropna().values\n",
    "                ### Weighted average calculating:\n",
    "                num_result = np.nansum(list_data * list_weight) / np.nansum(list_weight)\n",
    "    ### Results output:\n",
    "    return num_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING WEIGHTED AVERAGE FOR DATAFRAME COLUMNS (PART OF THE PRODUCT CODE)\n",
    "\n",
    "def columns_average(df_series, list_weights = False):\n",
    "    ### Equal weights list creating:\n",
    "    if isinstance(list_weights, bool):\n",
    "        list_weights = [1] * len(df_series.columns)\n",
    "    ### Dataframe of weights initialising:\n",
    "    df_weights = pd.DataFrame([list_weights] * len(df_series.index), index = df_series.index, columns = df_series.columns)\n",
    "    ### Zeroing weights for NaN values:\n",
    "    for iter_col in df_weights.columns:\n",
    "        df_weights.loc[df_series[iter_col].isna(), iter_col] = 0\n",
    "    ### Weighted mean calulating:\n",
    "    df_means = (df_series * df_weights).sum(axis = 1) / df_weights.sum(axis = 1)    \n",
    "    ### Results output:\n",
    "    return df_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING MEAN MOMENTUM FUNCTION (PART OF THE PRODUCT CODE)\n",
    "\n",
    "def rolling_cond_weighted_mean(ser_country_matrix, ser_full_source, int_mean_win, int_mean_min, list_weight = False):\n",
    "    ### Defining conditional average calculator:\n",
    "    def conditional_average(ser_source, list_weight, int_min_count = 0, ser_condition = False):\n",
    "        ### Weight setting\n",
    "        ser_weight = pd.Series(list_weight[ : len(ser_source.index)], ser_source.index)\n",
    "        ### Results output:\n",
    "        return weighted_average(ser_source, ser_weight, int_min_count)    \n",
    "    ### Country saving:\n",
    "    str_country = ser_country_matrix.index[0][1]\n",
    "    ### Checking for country presence in source vector:\n",
    "    if (str_country in ser_full_source.index.get_level_values(1)):\n",
    "        ### Filtering country vector from source:\n",
    "        ser_country_source = ser_full_source.loc[All, str_country]\n",
    "        ### :\n",
    "        for iter_bm_date in ser_country_matrix.index.get_level_values(0):\n",
    "            try:\n",
    "                ### Defining monthend date number in source country vector:\n",
    "                int_idx_num = ser_country_source.index.get_loc(iter_bm_date)\n",
    "                ### Creating vectors for numerator and denominator means calculation:\n",
    "                ser_rolled_source = ser_country_source.iloc[max((int_idx_num - int_mean_win + 1), 0) : int_idx_num + 1]\n",
    "                if not isinstance(ser_full_cond, bool):\n",
    "                    ser_rolled_cond = ser_country_cond.loc[ser_rolled_source.index]\n",
    "                else:\n",
    "                    ser_rolled_cond = False\n",
    "                ### Action for MatLab compatibility:\n",
    "                ser_rolled_source.iloc[0] = np.NaN\n",
    "                ### Simple mean calculation:\n",
    "                if isinstance(list_weight, bool):\n",
    "                    ser_country_matrix.loc[iter_bm_date, str_country] = weighted_average(ser_rolled_source, False, int_mean_min)\n",
    "                else:\n",
    "                    ### Weighted mean calculation:\n",
    "                    ser_country_matrix.loc[iter_bm_date, str_country] = conditional_average(ser_rolled_source, list_weight, int_mean_min, ser_rolled_cond)\n",
    "            except KeyError:\n",
    "                pass\n",
    "    ### Resulting vector output:\n",
    "    return ser_country_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING MULTI-STEP STANDARTIZATION FOR SEPARATE SERIES (PART OF THE PRODUCT CODE)\n",
    "\n",
    "def multistep_standartize(ser_data_source, arr_truncate, ser_weight = False, reuse_outliers = False, center_result = True, full_result = False):  \n",
    "    ### Arrays of iterations properties:\n",
    "    arr_mean = []\n",
    "    arr_std = []\n",
    "    ### Adding equal weights, when weights are absent:\n",
    "    if isinstance(ser_weight, bool):\n",
    "        ser_weight = pd.Series(1, index = ser_data_source.index)\n",
    "        ser_weight.name = 'Weight'    \n",
    "    ### Workhorse and resulting data vectors initialising:\n",
    "    ser_data_iter = ser_data_source.dropna()\n",
    "    ser_weight_iter = ser_weight.copy()\n",
    "    ser_data_full = pd.Series(np.NaN, index = ser_data_iter.index)\n",
    "    ### Looping by boundaries array:\n",
    "    for num_bound_iter in arr_truncate:\n",
    "        ### Properties calculating and saving:\n",
    "        num_mean_iter = weighted_average(ser_data_iter, ser_weight_iter)\n",
    "        num_std_iter = ser_data_iter.std()\n",
    "        arr_mean.append(num_mean_iter)\n",
    "        arr_std.append(num_std_iter)\n",
    "        ser_data_iter = (ser_data_iter - num_mean_iter) / num_std_iter       \n",
    "        ### Standartizing:\n",
    "        if reuse_outliers:\n",
    "            ser_data_iter[ser_data_iter.abs() >= num_bound_iter] = np.sign(ser_data_iter) * num_bound_iter \n",
    "        else:\n",
    "            ### Saving to result and excluding from further calculations truncated values:             \n",
    "            ser_data_full.where(ser_data_iter.abs() < num_bound_iter, np.sign(ser_data_iter) * num_bound_iter, inplace = True)\n",
    "            ser_data_iter = ser_data_iter[ser_data_iter.abs() < num_bound_iter]           \n",
    "    ### Aggregating result:\n",
    "    if (reuse_outliers):\n",
    "        ser_data_full = ser_data_iter\n",
    "    else:     \n",
    "        ser_data_full[ser_data_iter.index] = ser_data_iter\n",
    "    ### Centering result:\n",
    "    if (center_result):\n",
    "        ser_result = ser_data_full - weighted_average(ser_data_full, ser_weight) \n",
    "    else:\n",
    "        ser_result = ser_data_full    \n",
    "    ### Result output:\n",
    "    ser_result.name = str(ser_data_source.name) + '_standartized'\n",
    "    if (full_result):\n",
    "        return (ser_result, arr_mean, arr_std)\n",
    "    else:\n",
    "        return ser_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING MULTI-STEP STANDARTIZATION BY MARKET FOR CROSS-SECTION (PART OF THE PRODUCT CODE)\n",
    "\n",
    "def ison_standartize(ser_to_manage, arr_truncate, ser_weight = False, reuse_outliers = False, center_result = True, full_result = False, within_market = False):\n",
    "    ### Multi-step standartizing:\n",
    "    if (within_market):\n",
    "    ### Within market standartizing:\n",
    "        ser_result = ser_to_manage.groupby(by = 'Market', group_keys = False).apply(multistep_standartize, arr_truncate, ser_weight, \n",
    "                                                                                                  reuse_outliers, center_result, full_result)\n",
    "    else:\n",
    "    ### Full universe standartizing:\n",
    "        ser_result = multistep_standartize(ser_to_manage, arr_truncate, ser_weight, reuse_outliers, center_result, full_result)\n",
    "    ### Results output:\n",
    "    return ser_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING MULTI-STEP STANDARTIZATION BY MARKET FOR FULL FACTOR STACK (PART OF THE PRODUCT CODE)\n",
    "\n",
    "def single_factor_standartize_daily(ser_factor, arr_truncate, ser_weight = False, reuse_outliers = False, center_result = True, within_market = False):\n",
    "    ### Weights preparing:\n",
    "    if isinstance(ser_weight, bool):\n",
    "        ser_weight = pd.Series(1, index = ser_factor.index)\n",
    "        ser_weight.name = 'Weight'\n",
    "    ### Multi-step standartizing:        \n",
    "    df_factor = ser_factor.to_frame().join(ser_weight, how = 'left')\n",
    "    df_factor.columns = ['Factor', 'Weight']\n",
    "    ser_result = ison_standartize(df_factor['Factor'], arr_truncate, df_factor['Weight'], reuse_outliers, center_result, False, within_market)\n",
    "    ### Results output:\n",
    "    ser_result.name = ser_factor.name\n",
    "    return ser_result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM MS EXCEL SOURCE (SHOULD BE IGNORED)\n",
    "\n",
    "def ison_membership_converting(str_path_universe, date_end, bool_daily = False, int_backfill_months = 0):\n",
    "    ### Defining business-month-end reindexation on country level:\n",
    "    def country_modify(ser_raw_country, date_end):\n",
    "        ser_res_country = ser_raw_country.droplevel(0).resample('MS').last().resample('BM').last()\n",
    "        range_country = pd.date_range(ser_res_country.index[0], date_end, freq = 'BM')\n",
    "        return ser_res_country.reindex(range_country).ffill()\n",
    "    ### Markets encoding table:\n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM', 0: np.NaN}     \n",
    "    ### Loading source file:\n",
    "    df_raw_universe = pd.read_excel(io = str_path_universe, sheet_name = 0, header = 0, parse_dates = True, index_col = [0, 1],\n",
    "                                 na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    ### Converting source file:\n",
    "    df_raw_universe.index.names = ['Country', 'Date']\n",
    "    ser_raw_universe = df_raw_universe['Region']\n",
    "    ser_raw_universe.fillna(0, inplace = True)\n",
    "    ser_raw_universe.name = 'Market'\n",
    "    ### By country reindexation and translation:\n",
    "    ser_res_universe = ser_raw_universe.groupby('Country').apply(country_modify, date_end)\n",
    "    ser_res_universe.index.names = ['Country', 'Date']\n",
    "    ser_res_universe = ser_res_universe.replace(dict_markets).reorder_levels([1, 0]).sort_index() \n",
    "    ### Expanding membership for primary regions members by backfilling:\n",
    "    if int_backfill_months:\n",
    "        ### List of regions:\n",
    "        list_region = list(ser_res_universe.dropna().unique())\n",
    "        ### Initialising of collection of series with backfilled data for each region:\n",
    "        list_ison_backfill = []\n",
    "        ### Regions looping:\n",
    "        for iter_region in list_region:\n",
    "            ### Defining start of region date:\n",
    "            date_first_valid = ser_res_universe.loc[ser_res_universe == iter_region].first_valid_index()[0]\n",
    "            ### Creating dates index to backfilling:\n",
    "            idx_date_backfill = pd.date_range(end = date_first_valid, periods = int_backfill_months + 1, freq = 'BM')[: -1]\n",
    "            ### Creating primary countries index to backfilling:            \n",
    "            idx_region_backfill = ser_res_universe.loc[ser_res_universe == iter_region].loc[date_first_valid, All].index.get_level_values('Country')\n",
    "            ### Creating full index:\n",
    "            idx_ison_backfill = pd.MultiIndex.from_product([idx_date_backfill, idx_region_backfill])\n",
    "            ### Series with backfilled data:\n",
    "            list_ison_backfill.append(pd.Series(iter_region, index = idx_ison_backfill))\n",
    "        ### Combination of backfilled series and original ISON data:    \n",
    "        ser_res_universe = ser_res_universe.combine_first(pd.concat(list_ison_backfill, axis = 0)).sort_index()  \n",
    "        ser_res_universe.index.names = ['Date', 'Country']\n",
    "    ### Converting to daily frequency:\n",
    "    if bool_daily:\n",
    "        ser_res_universe = ser_res_universe.reset_index('Country').groupby('Country').resample('B').ffill()['Market'].swaplevel().sort_index()    \n",
    "    ### Results output:\n",
    "    ser_res_universe.name = 'Market'\n",
    "    return ser_res_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA LOADING (SHOULD BE ADOPTED)\n",
    "\n",
    "ser_fx_country = pd.read_hdf(str_path_bb_hdf, key = str_key_fx_country) ### FX Rates to use in Export source denomination to domestic currency\n",
    "ser_fx_rate_demeaned = pd.read_hdf(str_path_bb_hdf, key = str_key_fx_demeaned) ### Demeaned FX Rates to use as a source in the Short-Term factor\n",
    "ser_reer = pd.read_hdf(str_path_bb_hdf, key = str_key_reer_sourced) ### Real Effective Exchange Rate to use as a source in the Short-Term factor\n",
    "ser_neer = pd.read_hdf(str_path_bb_hdf, key = str_key_neer_sourced) ### Nominal Effective Exchange Rate to use as a source in the Short-Term factor\n",
    "ser_gdp = pd.read_hdf(str_path_bb_hdf, key = str_key_gdp) ### GDP to use in Interaction variable calculation\n",
    "ser_export = pd.read_hdf(str_path_bb_hdf, key = str_key_export_monthly)\n",
    "ser_cpi = pd.read_hdf(str_path_bb_hdf, key = str_key_cpi) ### GDP to use in Interaction variable calculation\n",
    "ser_ison = ison_membership_converting(str_path_universe, datetime.strptime(str_measure_date_end, '%Y-%m-%d')) ### ISON universe, end-of-bus-month vector\n",
    "ser_ison_daily = ison_membership_converting(str_path_universe, datetime.strptime(str_measure_date_end, '%Y-%m-%d'), bool_daily = True) ### ISON universe, bus-daily vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN SCRIPT: FX RATES CORRECTING BY CLEARING OFF DENOMINATION DISTRORTIONS (SHOULD BE ADOPTED)\n",
    "\n",
    "### Deleting extreme FX Rates changes, caused by currency denomination:\n",
    "def kill_extreme_fx(ser_country_rate, list_extreme_fx_ret):\n",
    "    ### Searching for first rate:\n",
    "    idx_first_valid = ser_country_rate.first_valid_index()\n",
    "    ### Calculating FX Returns:\n",
    "    ser_country_ret = ser_country_rate.diff() / ser_country_rate.shift()\n",
    "    ### Clearing extreme returns:\n",
    "    ser_country_ret.loc[(ser_country_ret < list_extreme_fx_ret[0]) | (ser_country_ret > list_extreme_fx_ret[1])] = 0.0\n",
    "    ### Recovering FX Rates from FX Returns:\n",
    "    ser_country_res = (1 + ser_country_ret)\n",
    "    ser_country_res.loc[idx_first_valid] = ser_country_rate.loc[idx_first_valid]\n",
    "    ser_country_res = ser_country_res.cumprod()\n",
    "    ### Results output:\n",
    "    return ser_country_res\n",
    "### FX Rates clearing from distortions:\n",
    "ser_fx_rate_cleared = ser_fx_country.groupby('Country').ffill()\n",
    "ser_fx_rate_cleared = ser_fx_rate_cleared.groupby('Country').apply(kill_extreme_fx, list_extreme_fx_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN SCRIPT: EXPORT SEASONALITY ADJUSTMENT (SHOULD BE ADOPTED)\n",
    "\n",
    "### Export data filling:\n",
    "ser_export_monthly = ser_export.groupby('Country').ffill()\n",
    "### Year length moving average calculating:\n",
    "ser_ma_centered = ser_export_monthly.groupby('Country', group_keys = False).rolling(window = int_season_adj_ma, min_periods = int_season_adj_shift).mean()\n",
    "### Year length moving average shifting:\n",
    "ser_ma_centered = ser_ma_centered.groupby('Country').shift(-int_season_adj_shift)\n",
    "ser_ma_centered.name = 'MA Centered'\n",
    "### Vectors concatenation:\n",
    "df_export_adjustment = pd.concat([ser_export_monthly, ser_ma_centered], axis = 1)\n",
    "### Export / MA Ratio calculating:\n",
    "df_export_adjustment['Ratio'] = df_export_adjustment['Export'] / df_export_adjustment['MA Centered']\n",
    "### Adding month number to index:\n",
    "df_export_adjustment['Month'] = df_export_adjustment.index.get_level_values('Date').month\n",
    "df_export_adjustment.set_index(['Month'], append = True, inplace = True)\n",
    "### Month number Ratio median calculating as Scale:\n",
    "ser_ratio_median = df_export_adjustment['Ratio'].groupby(['Country', 'Month']).median()\n",
    "ser_ratio_median.name = 'Scale'\n",
    "### Scale modification:\n",
    "ser_ratio_median = ser_ratio_median / ser_ratio_median.groupby('Country').mean()\n",
    "### Adding Scale to data table:\n",
    "df_export_adjustment = df_export_adjustment.join(ser_ratio_median, on = ['Country', 'Month'], how = 'left', sort = True).reset_index('Month', drop = True)\n",
    "### Seasonally adjusted Export calculating:\n",
    "ser_export_adjusted = (df_export_adjustment['Export'] / df_export_adjustment['Scale']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN SCRIPT: FACTOR SOURCES ADOPTING (SHOULD BE ADOPTED)\n",
    "\n",
    "### Sources options preparing:\n",
    "dict_ser_eer = {}\n",
    "### Source vectors forward filling and reindexing:\n",
    "ser_reer_source = ser_reer.droplevel('Source').unstack('Country').reindex(idx_source_date_range).ffill(limit = int_eer_fill_limit).stack('Country').sort_index()\n",
    "ser_reer_source.index.names = ['Date', 'Country']\n",
    "ser_neer_source = ser_neer.droplevel('Source').unstack('Country').reindex(idx_source_date_range).ffill(limit = int_eer_fill_limit).stack('Country').sort_index()\n",
    "ser_neer_source.index.names = ['Date', 'Country']\n",
    "ser_fx_source = ser_fx_rate_demeaned.unstack('Country').reindex(idx_source_date_range).ffill(limit = int_eer_fill_limit).stack('Country').sort_index()\n",
    "ser_fx_source.index.names = ['Date', 'Country']\n",
    "ser_export_source = ser_export_adjusted.unstack('Country').reindex(idx_source_date_range).ffill(limit = int_eer_fill_limit).stack('Country').sort_index()\n",
    "ser_export_source.index.names = ['Date', 'Country']\n",
    "### REER vector creating:\n",
    "dict_ser_eer['REER'] = ser_reer_source\n",
    "### MIXED vector creating:\n",
    "### Selecting all ISON countries:\n",
    "set_ison = set(ser_ison.dropna().index.get_level_values('Country').unique())\n",
    "### Selecting all REER countries:\n",
    "set_reer_all = set(ser_reer.dropna().index.get_level_values('Country').unique())\n",
    "### Selecting all NEER countries:\n",
    "set_neer_all = set(ser_neer.dropna().index.get_level_values('Country').unique())\n",
    "### Selecting countries, where REER has monthly frequency:\n",
    "set_reer_monthly = set(ser_reer.loc[All, All, ['IMF', 'BIS']].index.get_level_values(1).unique())\n",
    "### Defining countries from REER to participate in NEER source:\n",
    "set_reer_st = set_reer_all - set_reer_monthly\n",
    "### Defining countries from NEER to participate in NEER source:\n",
    "ser_neer_st = set_reer_monthly & set_neer_all\n",
    "### Defining rest of countries to participate in NEER source from FX rates:\n",
    "set_fx_st = set_ison - (set_reer_st | ser_neer_st)\n",
    "### Converting sets to lists:\n",
    "list_reer_st = sorted(list(set_reer_st))\n",
    "list_neer_st = sorted(list(ser_neer_st))\n",
    "list_fx_st = sorted(list(set_fx_st))\n",
    "dict_ser_eer['MIXED'] = pd.concat([ser_reer_source.loc[All, list_reer_st], ser_neer_source.loc[All, list_neer_st], ser_fx_source.loc[All, list_fx_st]]).sort_index()\n",
    "### EXPORT vector creating:  \n",
    "### Selecting all ISON countries:    \n",
    "set_ison = set(ser_ison.dropna().index.get_level_values('Country').unique())\n",
    "### Monthly CPI calculating:\n",
    "ser_cpi_monthly = ser_cpi.groupby('Country').transform(lambda ser_country: (1 + ser_country / 100) ** (1 /12) - 1).groupby('Country').ffill()\n",
    "### CPI countries:\n",
    "set_cpi_export = set(ser_cpi_monthly.dropna().index.get_level_values('Country').unique())\n",
    "### FX countries:\n",
    "set_fx_export = set(ser_fx_rate_cleared.dropna().index.get_level_values('Country').unique())\n",
    "### USD Export countries:\n",
    "set_usd_export = set_ison - (set_cpi_export & set_fx_export)\n",
    "### USD Export vector:\n",
    "ser_export_usd = ser_export_source.loc[All, set_usd_export]\n",
    "### CPI cumprod monthly shifted:\n",
    "ser_cpi_cumprod = ser_cpi_monthly.groupby('Country').transform(lambda ser_country: (1 + ser_country).cumprod()).groupby('Country').shift(int_cpi_lag)\n",
    "### CPI cumprod daily:    \n",
    "ser_cpi_cumprod = ser_cpi_cumprod.unstack('Country').reindex(idx_source_date_range).ffill(limit = int_eer_fill_limit).stack('Country').sort_index()\n",
    "ser_cpi_cumprod.index.names = ['Date', 'Country']\n",
    "### Local Export vector:\n",
    "ser_export_loc = (ser_export_source / ser_fx_rate_cleared / ser_cpi_cumprod).loc[All, set_ison - set_usd_export]\n",
    "### Combined Export vector:\n",
    "ser_export_all = pd.concat([ser_export_usd, ser_export_loc]).sort_index() \n",
    "list_usd_export = sorted(set_usd_export)\n",
    "list_loc_export = sorted(set_ison - set_usd_export)   \n",
    "dict_ser_eer['EXPORT'] = ser_export_all   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN SCRIPT: INTERACTION VARIABLE PREPARING (SHOULD BE ADOPTED)\n",
    "\n",
    "### Defining the way to rank the interaction variable:\n",
    "def value_to_rank(ser_region):\n",
    "    ser_cutted = np.maximum(0, (np.minimum(prctile_matlab(ser_region, int_concept_pctile_top), ser_region)))\n",
    "    ser_cutted.loc[ser_cutted.isna()] = prctile_matlab(ser_region, 0.50)    \n",
    "    ser_result = np.maximum(0, (ser_cutted - ser_cutted.min()) / (ser_cutted.max() - ser_cutted.min()) * int_prctile_scale) + 1\n",
    "    return ser_result\n",
    "\n",
    "### Interaction variable source vectors converting:\n",
    "ser_export_ma12_annual = ser_export.groupby('Country', group_keys = False).rolling(int_rolling_exp_max, int_rolling_exp_min).mean() * int_rolling_exp_max\n",
    "ser_export_ma12_annual = ser_export_ma12_annual.groupby(['Country']).fillna(method = 'ffill').groupby(['Country']).fillna(method = 'bfill')\n",
    "### Interaction variable data shifting:\n",
    "ser_gdp_concept = ser_gdp.groupby('Country').fillna(method = 'ffill').groupby('Country').fillna(method = 'bfill').groupby('Country').shift(int_gdp_lag)\n",
    "ser_export_concept = ser_export_ma12_annual.shift(int_export_lag)\n",
    "### Interaction variable calculating:\n",
    "ser_concept_raw = ser_export_concept / ser_gdp_concept / int_concept_divider\n",
    "### Interaction variable adjusting:\n",
    "ser_concept_raw.name = 'Multiplicator'  \n",
    "### Vector ISONing:\n",
    "ser_concept_raw = ser_concept_raw.to_frame().join(ser_ison, how = 'right').set_index('Market', append = True).squeeze()   \n",
    "### Logarithmization performing:\n",
    "ser_concept_raw.loc[ser_concept_raw <= -1] = -0.99    \n",
    "ser_concept_raw = np.log(1 + ser_concept_raw)\n",
    "### Interaction variable ranking:\n",
    "ser_concept_res = ser_concept_raw.groupby(['Date', 'Market']).apply(value_to_rank).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994-03-23 00:00:00\n",
      "LONG_TERM / REER\n",
      "SHORT_TERM / MIXED\n",
      "LONG_TERM / EXPORT\n"
     ]
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "### Standalone factors collection:\n",
    "dict_iter_factor = {}\n",
    "iter_date = idx_source_date_range[580]\n",
    "#iter_date = idx_source_date_range[586]\n",
    "\n",
    "print(iter_date)\n",
    "date_iter_bm = iter_date + 1 * pd.tseries.offsets.BDay() + 0 * pd.tseries.offsets.BMonthEnd() - 1 * pd.tseries.offsets.BMonthEnd()\n",
    "ser_iter_date_concept = ser_concept_res.loc[date_iter_bm, All, All]\n",
    "ser_iter_date_concept = pd.concat({iter_date: ser_iter_date_concept.droplevel('Date')}, names = ['Date'])\n",
    "### ISON countries list\n",
    "idx_universe = ser_ison.index.get_level_values(1).unique()\n",
    "### Factors looping:\n",
    "for iter_factor in dict_combinations:\n",
    "    ### Parameters loading:\n",
    "    iter_term = dict_combinations[iter_factor][0]\n",
    "    iter_eer = dict_combinations[iter_factor][1]\n",
    "    print(f'{iter_term} / {iter_eer}')  \n",
    "    ### Momentum parameters:\n",
    "    int_mom_hl = dict_mom_hl[iter_term] * flo_exp_weight_month ### Not rounding here\n",
    "    int_mom_win = int_mom_length * ser_work_periods['Year', 'D']\n",
    "    int_mom_min = round(dict_mom_min[iter_term] * flo_exp_weight_month)\n",
    "    ### Weights array:\n",
    "    list_weight = list(map(lambda iter_num: exp_weight_single(int_mom_hl, iter_num), range(int_mom_win)))[::-1]    \n",
    "    ### Date interval for factor calculating:\n",
    "    idx_iter_date_range = pd.date_range(end = iter_date, periods = int_mom_win, freq = 'B')    \n",
    "    ### Source loading:\n",
    "    ser_iter_eer = dict_ser_eer[iter_eer].loc[idx_iter_date_range, All]    \n",
    "    ### Source performing:\n",
    "    ser_iter_delta = ser_iter_eer.groupby('Country').diff() / ser_iter_eer.groupby('Country').shift()   \n",
    "    ser_iter_delta = ser_iter_delta.replace([np.inf, -np.inf], np.NaN)    \n",
    "    ### Factor vector creating:\n",
    "    ser_iter_factor = pd.Series(index = pd.MultiIndex.from_product([[iter_date], idx_universe])).sort_index()\n",
    "    ser_iter_factor.index.set_names(['Date', 'Country'], inplace = True)    \n",
    "    ### Momentum factor calculation:\n",
    "    ser_iter_factor = ser_iter_factor.groupby('Country').transform(rolling_cond_weighted_mean, ser_iter_delta, int_mom_win, int_mom_min, list_weight)\n",
    "    ### Factor ISONing:\n",
    "    ser_iter_factor = ser_iter_factor.to_frame().join(ser_ison_daily, how = 'left').set_index('Market', append = True).squeeze()\n",
    "    ser_iter_factor.name = 'Factor' \n",
    "    ### Regions clearing:\n",
    "    ser_iter_factor = ser_iter_factor.loc[All, All, list_ison]\n",
    "    ### Countries filtering:\n",
    "    ser_iter_factor = ser_iter_factor.drop(list_countries_to_exclude, level = 'Country')     \n",
    "    ### Standalone factor standartizing:\n",
    "    ser_iter_factor_std = dict_factors_signs[iter_factor] * single_factor_standartize_daily(ser_iter_factor, list_truncate, within_market = bool_within_market)\n",
    "    ser_iter_factor_std.name = 'Factor'        \n",
    "    ### Interaction variable applying:\n",
    "    ser_iter_multiplied = ser_iter_factor_std * ser_iter_date_concept\n",
    "    ### Multiplied factor restandartizing:\n",
    "    ser_iter_multiplied_std = single_factor_standartize_daily(ser_iter_multiplied, list_truncate, within_market = bool_within_market)\n",
    "    ser_iter_multiplied_std.name = 'Factor'    \n",
    "    ### Saving result to collection:\n",
    "    dict_iter_factor[iter_factor] = ser_iter_multiplied_std\n",
    "### Concatenating factors for averaaing:\n",
    "df_weighted_factor = pd.concat(dict_iter_factor, axis = 1)\n",
    "### Factors combining:\n",
    "ser_combo_factor = columns_average(df_weighted_factor, list_static_weights)\n",
    "### Combined factor standartizing:\n",
    "ser_combo_factor_std = single_factor_standartize_daily(ser_combo_factor, list_truncate, within_market = bool_within_market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING FACTOR CREATING FUNCTION (SHOULD BE ADOPTED)\n",
    "\n",
    "def get_currency_factor(iter_date):\n",
    "    ### Standalone factors collection:\n",
    "    dict_iter_factor = {}\n",
    "    date_iter_bm = iter_date + 1 * pd.tseries.offsets.BDay() + 0 * pd.tseries.offsets.BMonthEnd() - 1 * pd.tseries.offsets.BMonthEnd()\n",
    "    ser_iter_date_concept = ser_concept_res.loc[date_iter_bm, All, All]\n",
    "    ser_iter_date_concept = pd.concat({iter_date: ser_iter_date_concept.droplevel('Date')}, names = ['Date'])\n",
    "    ### ISON countries list\n",
    "    idx_universe = ser_ison.index.get_level_values(1).unique()\n",
    "    ### Factors looping:\n",
    "    for iter_factor in dict_combinations:\n",
    "        ### Parameters loading:\n",
    "        iter_term = dict_combinations[iter_factor][0]\n",
    "        iter_eer = dict_combinations[iter_factor][1]\n",
    "        ### Momentum parameters:\n",
    "        int_mom_hl = dict_mom_hl[iter_term] * flo_exp_weight_month ### Not rounding here\n",
    "        int_mom_win = int_mom_length * ser_work_periods['Year', 'D']\n",
    "        int_mom_min = round(dict_mom_min[iter_term] * flo_exp_weight_month)\n",
    "        ### Weights array:\n",
    "        list_weight = list(map(lambda iter_num: exp_weight_single(int_mom_hl, iter_num), range(int_mom_win)))[::-1]    \n",
    "        ### Date interval for factor calculating:\n",
    "        idx_iter_date_range = pd.date_range(end = iter_date, periods = int_mom_win, freq = 'B')    \n",
    "        ### Source loading:\n",
    "        ser_iter_eer = dict_ser_eer[iter_eer].loc[idx_iter_date_range, All]    \n",
    "        ### Source performing:\n",
    "        ser_iter_delta = ser_iter_eer.groupby('Country').diff() / ser_iter_eer.groupby('Country').shift()   \n",
    "        ser_iter_delta = ser_iter_delta.replace([np.inf, -np.inf], np.NaN)    \n",
    "        ### Factor vector creating:\n",
    "        ser_iter_factor = pd.Series(index = pd.MultiIndex.from_product([[iter_date], idx_universe])).sort_index()\n",
    "        ser_iter_factor.index.set_names(['Date', 'Country'], inplace = True)    \n",
    "        ### Momentum factor calculation:\n",
    "        ser_iter_factor = ser_iter_factor.groupby('Country').transform(rolling_cond_weighted_mean, ser_iter_delta, int_mom_win, int_mom_min, list_weight)\n",
    "        ### Factor ISONing:\n",
    "        ser_iter_factor = ser_iter_factor.to_frame().join(ser_ison_daily, how = 'left').set_index('Market', append = True).squeeze()\n",
    "        ser_iter_factor.name = 'Factor' \n",
    "        ### Regions clearing:\n",
    "        ser_iter_factor = ser_iter_factor.loc[All, All, list_ison]\n",
    "        ### Countries filtering:\n",
    "        ser_iter_factor = ser_iter_factor.drop(list_countries_to_exclude, level = 'Country')     \n",
    "        ### Standalone factor standartizing:\n",
    "        ser_iter_factor_std = dict_factors_signs[iter_factor] * single_factor_standartize_daily(ser_iter_factor, list_truncate, within_market = bool_within_market)\n",
    "        ser_iter_factor_std.name = 'Factor'        \n",
    "        ### Interaction variable applying:\n",
    "        ser_iter_multiplied = ser_iter_factor_std * ser_iter_date_concept\n",
    "        ### Multiplied factor restandartizing:\n",
    "        ser_iter_multiplied_std = single_factor_standartize_daily(ser_iter_multiplied, list_truncate, within_market = bool_within_market)\n",
    "        ser_iter_multiplied_std.name = 'Factor'    \n",
    "        ### Saving result to collection:\n",
    "        dict_iter_factor[iter_factor] = ser_iter_multiplied_std\n",
    "    ### Concatenating factors for averaaing:\n",
    "    df_weighted_factor = pd.concat(dict_iter_factor, axis = 1)\n",
    "    ### Factors combining:\n",
    "    ser_combo_factor = columns_average(df_weighted_factor, list_static_weights)\n",
    "    ### Combined factor standartizing:\n",
    "    ser_combo_factor_std = single_factor_standartize_daily(ser_combo_factor, list_truncate, within_market = bool_within_market)    \n",
    "    ### Results output:\n",
    "    return ser_combo_factor_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2021-01-20 10:32:12.515120\n",
      "Finish time: 2021-01-20 10:32:36.778365\n",
      "Full interval: 0:00:24.263245\n",
      "Average interval for single date: 0:00:00.003498\n"
     ]
    }
   ],
   "source": [
    "### TESTING: PERFORMING FACTOR FOR DATE RANGE (SHOULD BE ADOPTED)\n",
    "\n",
    "#iter_date = idx_source_date_range[580]\n",
    "#iter_date = idx_source_date_range[586]\n",
    "#print(iter_date)\n",
    "\n",
    "### Local testing parameters:\n",
    "int_interval = 100\n",
    "dict_factor_by_date = {}\n",
    "date_start = datetime.utcnow()\n",
    "date_control = datetime.utcnow()\n",
    "### Test performing:\n",
    "print('Start time:', date_start)\n",
    "for iter_num, iter_date in enumerate(idx_test_date_range[580 : 587]): # enumerate(idx_test_date_range): # \n",
    "    if not (divmod(iter_num, int_interval)[1]):\n",
    "        if iter_num:\n",
    "            print('Counter marker:', iter_num, '/', len(idx_test_date_range))\n",
    "            timedelta_interval = datetime.utcnow() - date_control\n",
    "            print('Time interval since last marker:', datetime.utcnow() - date_control)            \n",
    "            print('Average interval for single date:', str(timedelta_interval / int_interval))\n",
    "        date_control = datetime.utcnow()\n",
    "    dict_factor_by_date[iter_date] = get_currency_factor(iter_date)\n",
    "date_finish = datetime.utcnow()\n",
    "print('Finish time:', date_finish)\n",
    "print('Full interval:', date_finish - date_start)\n",
    "print('Average interval for single date:', str((date_finish - date_start) / len(idx_test_date_range)))\n",
    "ser_factor_full = pd.concat(dict_factor_by_date, axis = 0).droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        Country  Market\n",
       "1996-04-22  AT       DM       -0.229720\n",
       "            AU       DM       -1.370300\n",
       "            BE       DM       -0.094994\n",
       "            CA       DM        1.788951\n",
       "            CH       DM       -0.389441\n",
       "                                 ...   \n",
       "1996-04-30  NO       DM        0.919579\n",
       "            NZ       DM       -1.916358\n",
       "            SE       DM       -1.654135\n",
       "            SG       DM       -0.644592\n",
       "            US       DM       -0.023909\n",
       "Length: 147, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "ser_factor_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors sum: 0.0\n",
      "Errors list: Series([], dtype: float64)\n",
      "Count error: 0\n"
     ]
    }
   ],
   "source": [
    "### TESTING: SAVING FACTOR TO COMPARE RESULTS (SHOULD BE IGNORED)\n",
    "\n",
    "str_path_trans_hdf = 'Data_Files/Test_Files/EER_factors_transitional.h5'\n",
    "str_key_trans_factor = 'trans_factor'\n",
    "iter_term = 'TRIPLE'\n",
    "iter_algo = 'COMBO'\n",
    "iter_concept = 'COMBO'\n",
    "iter_eer = 'COMBO'\n",
    "iter_ret = 'COMBO'\n",
    "iter_region = ['DM', 'EM', 'FM']\n",
    "str_iter_key = '__'.join([iter_term, iter_algo, iter_concept, iter_eer, iter_ret]) \n",
    "ser_combo_research = pd.read_hdf(str_path_trans_hdf, key = str_key_trans_factor + '__' + str_iter_key).loc[All, All, iter_region]\n",
    "ser_combo_test = (ser_factor_full.loc[idx_factor_date_range, All, All] - ser_combo_research).abs()\n",
    "print('Errors sum:', ser_combo_test.sum())\n",
    "print('Errors list:', ser_combo_test.loc[ser_combo_test > 0])\n",
    "print('Count error:', (ser_factor_full.loc[idx_factor_date_range, All, All].count() - ser_combo_research.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
