{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BLOOMBERG EFFECTIVE EXCHANGE RATE SOURCES COMPARING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "### Factors sources:\n",
    "str_path_bb_eer_source = 'Data_Files/Source_Files/Bloomberg_EER.xlsx'\n",
    "str_path_bb_fx_source = 'Data_Files/Source_Files/Bloomberg_FX.xlsx'\n",
    "dict_eer_sources = {'JPM REER B C D': 'REER 01-JPM', 'CTG REER B D': 'REER 02-CTG', 'IMF REER B M': 'REER 03-IMF', 'BIS REER B M': 'REER 04-BIS',\n",
    "                    'JPM NEER B D': 'NEER 01-JPM', 'CTG REER B D (2)': 'NEER 02-CTG', 'BIS NEER B D': 'NEER 03-BIS'}\n",
    "### Factors parameters:\n",
    "list_truncate = [2.5, 2.0]\n",
    "int_numer_ma_win = 21 * 3\n",
    "int_denom_ma_win = 252 * 5\n",
    "int_short_diff = 21 * 3\n",
    "### Basics for efficacy measures calculating:\n",
    "path_market_cap = 'Data_Files/Source_Files/Market_Cap.h5'\n",
    "key_market_cap = 'mcap'\n",
    "path_return = 'Data_Files/Source_Files/Returns_Integrated.h5'\n",
    "key_return = 'returns'\n",
    "### Export parameters:\n",
    "str_path_neer_export = 'Data_Files/Test_Files/Saved_NEER.xlsx'\n",
    "str_path_reer_export = 'Data_Files/Test_Files/Saved_REER.xlsx'\n",
    "str_path_fx_export = 'Data_Files/Test_Files/Saved_FX.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION BLOOMBERG EER DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def get_eer_data_excel(str_path_bb_eer_source, dict_eer_sources):\n",
    "    ### Loading raw excel source:\n",
    "    dict_eer_source = pd.read_excel(io = str_path_bb_eer_source, sheet_name = None, skiprows = list(range(4)), index_col = 0, header = 0, parse_dates = True, \n",
    "                                    na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                                 '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    ### Preparing datasets concatenation:\n",
    "    arr_eer_data = []\n",
    "    for str_sheet_name in dict_eer_source:\n",
    "        ### Filtering Broad NEER or Broad CPI-Based REER:\n",
    "        if str_sheet_name in dict_eer_sources:\n",
    "            ### Future additional indexes:\n",
    "            list_iter_index = dict_eer_sources[str_sheet_name].split()\n",
    "            ### Stacking county codes for making series:\n",
    "            ser_iter_set = dict_eer_source[str_sheet_name].stack(dropna = False)\n",
    "            ### Main index levels renaming:\n",
    "            ser_iter_set.index.names = ['Date', 'Country']\n",
    "            ### Adding index levels for source description:\n",
    "            ser_iter_set = ser_iter_set.to_frame().assign(Type = list_iter_index[0])\\\n",
    "                                                  .assign(Source = list_iter_index[1])\\\n",
    "                                                  .set_index(['Type', 'Source'], append = True).squeeze()\n",
    "            ### Data aggregation for concatenation:\n",
    "            arr_eer_data.append(ser_iter_set)\n",
    "    ### Consolidated dataset preparing:\n",
    "    ser_eer_data = pd.concat(arr_eer_data).reorder_levels([2, 3, 0, 1])\n",
    "    ### Results output:\n",
    "    return ser_eer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION BLOOMBERG EER DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def get_fx_data_excel(str_path_bb_fx_source):\n",
    "    ### Loading raw excel source:\n",
    "    df_fx_source = pd.read_excel(io = str_path_bb_fx_source, sheet_name = 'FX Data', skiprows = list(range(7)), index_col = 0, header = 0, parse_dates = True, \n",
    "                                    na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                                 '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    ### Preparing for output:\n",
    "    ser_fx_data = df_fx_source.stack(dropna = False)\n",
    "    ser_fx_data.index.names = ['Date', 'Country']\n",
    "    ser_fx_data.name = 'FX'    \n",
    "    ### Results output:\n",
    "    return ser_fx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN SCRIPT\n",
    "\n",
    "### Dataset extraction from source:\n",
    "ser_eer_data = get_eer_data_excel(str_path_bb_eer_source, dict_eer_sources)\n",
    "ser_fx_data = get_fx_data_excel(str_path_bb_fx_source)\n",
    "ser_ison_membership = get_market_membership_from_excel()\n",
    "set_ison_countries = set(ser_ison_membership.index.get_level_values(1).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full general statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">NEER</th>\n",
       "      <th colspan=\"5\" halign=\"left\">REER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>03-BIS</th>\n",
       "      <th>01-JPM</th>\n",
       "      <th>02-CTG</th>\n",
       "      <th>Total (mean)</th>\n",
       "      <th>04-BIS</th>\n",
       "      <th>01-JPM</th>\n",
       "      <th>02-CTG</th>\n",
       "      <th>03-IMF</th>\n",
       "      <th>Total (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Non-empty observations</td>\n",
       "      <td>351568</td>\n",
       "      <td>361290</td>\n",
       "      <td>290462</td>\n",
       "      <td>513578</td>\n",
       "      <td>12600</td>\n",
       "      <td>361286</td>\n",
       "      <td>290462</td>\n",
       "      <td>14142</td>\n",
       "      <td>404633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Earliest date</td>\n",
       "      <td>1996-04-11</td>\n",
       "      <td>1994-01-04</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>1994-01-31</td>\n",
       "      <td>1994-01-04</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>1990-01-31</td>\n",
       "      <td>1990-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Latest date</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>2020-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Dates between</td>\n",
       "      <td>8789</td>\n",
       "      <td>9624</td>\n",
       "      <td>11088</td>\n",
       "      <td>11088</td>\n",
       "      <td>9556</td>\n",
       "      <td>9624</td>\n",
       "      <td>11088</td>\n",
       "      <td>11047</td>\n",
       "      <td>11088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Non-empty countries number</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>77</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Average observations for country</td>\n",
       "      <td>6278</td>\n",
       "      <td>6569</td>\n",
       "      <td>5695</td>\n",
       "      <td>6670</td>\n",
       "      <td>225</td>\n",
       "      <td>6569</td>\n",
       "      <td>5695</td>\n",
       "      <td>257</td>\n",
       "      <td>5188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Non-empty dates number</td>\n",
       "      <td>6278</td>\n",
       "      <td>6606</td>\n",
       "      <td>7921</td>\n",
       "      <td>7921</td>\n",
       "      <td>225</td>\n",
       "      <td>6605</td>\n",
       "      <td>7921</td>\n",
       "      <td>260</td>\n",
       "      <td>7921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Average observations for date</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Unique countries</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        NEER                          \\\n",
       "                                      03-BIS      01-JPM      02-CTG   \n",
       "Non-empty observations                351568      361290      290462   \n",
       "Earliest date                     1996-04-11  1994-01-04  1990-01-01   \n",
       "Latest date                       2020-05-04  2020-05-11  2020-05-11   \n",
       "Dates between                           8789        9624       11088   \n",
       "Non-empty countries number                56          55          51   \n",
       "Average observations for country        6278        6569        5695   \n",
       "Non-empty dates number                  6278        6606        7921   \n",
       "Average observations for date             56          55          37   \n",
       "Unique countries                          18           8           3   \n",
       "\n",
       "                                                     REER              \\\n",
       "                                 Total (mean)      04-BIS      01-JPM   \n",
       "Non-empty observations                 513578       12600      361286   \n",
       "Earliest date                      1990-01-01  1994-01-31  1994-01-04   \n",
       "Latest date                        2020-05-11  2020-03-31  2020-05-11   \n",
       "Dates between                           11088        9556        9624   \n",
       "Non-empty countries number                 77          56          55   \n",
       "Average observations for country         6670         225        6569   \n",
       "Non-empty dates number                   7921         225        6605   \n",
       "Average observations for date              65          56          55   \n",
       "Unique countries                           77           3           4   \n",
       "\n",
       "                                                                       \n",
       "                                      02-CTG      03-IMF Total (mean)  \n",
       "Non-empty observations                290462       14142       404633  \n",
       "Earliest date                     1990-01-01  1990-01-31   1990-01-01  \n",
       "Latest date                       2020-05-11  2020-04-30   2020-05-11  \n",
       "Dates between                          11088       11047        11088  \n",
       "Non-empty countries number                51          55           78  \n",
       "Average observations for country        5695         257         5188  \n",
       "Non-empty dates number                  7921         260         7921  \n",
       "Average observations for date             37          54           51  \n",
       "Unique countries                           1           1           78  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### EER: FULL GENERAL STATISTICS CALCULATING:\n",
    "\n",
    "arr_eer_stats = []\n",
    "### Looping over types:\n",
    "for iter_type in ser_eer_data.index.get_level_values(0).unique():\n",
    "    dict_type_stats = {}\n",
    "    dict_type_countries = {}\n",
    "    ### Preliminary looping over sources inside the type for countries lists creating:\n",
    "    for iter_source in ser_eer_data.loc[iter_type, All, All, All].index.get_level_values(0).unique():\n",
    "        ser_iter_eer = ser_eer_data.loc[iter_type, iter_source, All, All].dropna()\n",
    "        dict_type_countries[iter_source] = set(ser_iter_eer.index.get_level_values(-1).unique())\n",
    "    set_type_sources = set(dict_type_countries.keys())\n",
    "    ### Looping over sources inside the type:            \n",
    "    for iter_source in ser_eer_data.loc[iter_type, All, All, All].index.get_level_values(0).unique():            \n",
    "        dict_iter_stats = {}\n",
    "        ### Data filtering by type and source:\n",
    "        ser_iter_eer = ser_eer_data.loc[iter_type, iter_source, All, All].dropna()\n",
    "        ### General stats:\n",
    "        dict_iter_stats['Non-empty observations'] = [ser_iter_eer.count()]        \n",
    "        dict_iter_stats['Earliest date'] = [sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[0].strftime('%Y-%m-%d')]\n",
    "        dict_iter_stats['Latest date'] = [sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[-1].strftime('%Y-%m-%d')]   \n",
    "        dict_iter_stats['Dates between'] = [(sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[-1] -\\\n",
    "                                            sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[0]).days]    \n",
    "        ### Country grouping:\n",
    "        ser_iter_country_count = ser_iter_eer.groupby('Country').count()\n",
    "        dict_iter_stats['Non-empty countries number'] = [ser_iter_country_count.count()]\n",
    "        dict_iter_stats['Average observations for country'] = [round(ser_iter_country_count.mean())]\n",
    "        ### Cross-section:\n",
    "        ser_iter_date_count = ser_iter_eer.groupby('Date').count()\n",
    "        dict_iter_stats['Non-empty dates number'] = [ser_iter_date_count.count()]\n",
    "        dict_iter_stats['Average observations for date'] = [round(ser_iter_date_count.mean())]        \n",
    "        ### Unique countries for particular source:\n",
    "        set_others = set()\n",
    "        for iter_other in dict_type_countries:\n",
    "            if (iter_other != iter_source):\n",
    "                set_others = set_others | dict_type_countries[iter_other]\n",
    "        list_iter_unique = sorted(dict_type_countries[iter_source] - set_others)\n",
    "        dict_iter_stats['Unique countries'] = [len(list_iter_unique)]\n",
    "        ### Converting data to oneline dataframe for future collecting:\n",
    "        dict_type_stats[iter_source] = pd.DataFrame.from_dict(dict_iter_stats, orient = 'index', columns = [iter_type])\n",
    "    ### Total stats for particular type:\n",
    "    dict_iter_stats = {}\n",
    "    ser_iter_eer = ser_eer_data.loc[iter_type, All, All, All].dropna().groupby(['Date', 'Country']).mean()\n",
    "    ### General stats:\n",
    "    dict_iter_stats['Non-empty observations'] = [ser_iter_eer.count()]        \n",
    "    dict_iter_stats['Earliest date'] = [sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[0].strftime('%Y-%m-%d')]\n",
    "    dict_iter_stats['Latest date'] = [sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[-1].strftime('%Y-%m-%d')]   \n",
    "    dict_iter_stats['Dates between'] = [(sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[-1] -\\\n",
    "                                        sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[0]).days]    \n",
    "    ### Country grouping:\n",
    "    ser_iter_country_count = ser_iter_eer.groupby('Country').count()\n",
    "    dict_iter_stats['Non-empty countries number'] = [ser_iter_country_count.count()]\n",
    "    dict_iter_stats['Average observations for country'] = [round(ser_iter_country_count.mean())]\n",
    "    ### Cross-section:\n",
    "    ser_iter_date_count = ser_iter_eer.groupby('Date').count()\n",
    "    dict_iter_stats['Non-empty dates number'] = [ser_iter_date_count.count()]\n",
    "    dict_iter_stats['Average observations for date'] = [round(ser_iter_date_count.mean())]        \n",
    "    ### Unique countries for particular source:\n",
    "    dict_iter_stats['Unique countries'] = [ser_iter_country_count.count()]\n",
    "    ### Converting data to oneline dataframe for future collecting:\n",
    "    dict_type_stats['Total (mean)'] = pd.DataFrame.from_dict(dict_iter_stats, orient = 'index', columns = [iter_type])    \n",
    "    ### Collecting stats for source:\n",
    "    arr_eer_stats.append(pd.concat(dict_type_stats, axis = 1, sort = False).swaplevel(axis = 1))    \n",
    "### Statistics aggregating:\n",
    "df_eer_stats = pd.concat(arr_eer_stats, axis = 1)\n",
    "### Statistics output:\n",
    "print('Full general statistics:')\n",
    "df_eer_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REER: 01-JPM 55 {'KR', 'MA', 'RU', 'SG', 'GH', 'GB', 'NZ', 'UA', 'US', 'RS', 'BG', 'CZ', 'PE', 'HK', 'KW', 'QA', 'CH', 'CO', 'BR', 'TN', 'PK', 'AR', 'JO', 'KE', 'DK', 'PA', 'HR', 'TR', 'MX', 'KZ', 'CN', 'HU', 'PH', 'SA', 'CA', 'ID', 'NO', 'RO', 'UG', 'NG', 'AU', 'VN', 'ZM', 'JP', 'MY', 'TW', 'EG', 'PL', 'CL', 'EC', 'IN', 'IL', 'TH', 'SE', 'ZA'}\n",
      "REER: 02-CTG 4 {'OM', 'CR', 'BH', 'AE'}\n",
      "REER: 03-IMF 16 {'FR', 'MT', 'AT', 'CI', 'LV', 'BE', 'DE', 'PT', 'IT', 'GR', 'SK', 'NL', 'CY', 'FI', 'ES', 'IE'}\n",
      "REER: 04-BIS 3 {'SI', 'EE', 'LT'}\n",
      "NEER: 01-JPM 55 {'KR', 'MA', 'RU', 'SG', 'GH', 'GB', 'NZ', 'UA', 'US', 'RS', 'BG', 'CZ', 'PE', 'HK', 'KW', 'QA', 'CH', 'CO', 'BR', 'TN', 'PK', 'AR', 'JO', 'KE', 'DK', 'PA', 'HR', 'TR', 'MX', 'KZ', 'CN', 'HU', 'PH', 'SA', 'CA', 'ID', 'NO', 'RO', 'UG', 'NG', 'AU', 'VN', 'ZM', 'JP', 'MY', 'TW', 'EG', 'PL', 'CL', 'EC', 'IN', 'IL', 'TH', 'SE', 'ZA'}\n",
      "NEER: 02-CTG 4 {'OM', 'CR', 'BH', 'AE'}\n",
      "NEER: 03-BIS 18 {'FR', 'MT', 'AT', 'LV', 'BE', 'DE', 'PT', 'IT', 'GR', 'SK', 'NL', 'CY', 'FI', 'ES', 'IE', 'SI', 'EE', 'LT'}\n"
     ]
    }
   ],
   "source": [
    "### EER: PREPARING COMBINED RAW DATA\n",
    "\n",
    "### REER filtering:\n",
    "df_reer_data = ser_eer_data.loc['REER', All, All, All].unstack('Source').sort_index(axis = 1)\n",
    "### REER sources looping:\n",
    "dict_reer_combined = {}\n",
    "set_prev_countries = set()\n",
    "for iter_source in df_reer_data.columns:\n",
    "    ### Selecting unique REER source countries\n",
    "    set_iter_countries = set(df_reer_data[iter_source].dropna().index.get_level_values(1).unique()) - set_prev_countries\n",
    "    set_prev_countries = set_prev_countries | set_iter_countries\n",
    "    print('REER:', iter_source, len(set_iter_countries), set_iter_countries)\n",
    "    ### Creating dataset from REER source:\n",
    "    dict_reer_combined[iter_source.split('-')[1]] = df_reer_data[iter_source].loc[All, set_iter_countries]\n",
    "### REER combined source creating:\n",
    "df_reer_combined = pd.concat(dict_reer_combined).reset_index(0).sort_index(level = ['Country', 'Date'])\n",
    "df_reer_combined.columns = ['Source', 'Rate']\n",
    "df_reer_combined.sort_index(level = ['Rate', 'Source'], axis = 1, inplace = True)   \n",
    "### REER dataset saving to xlsx:\n",
    "#df_reer_combined.to_excel(str_path_reer_export, merge_cells = False)\n",
    "### NEER filtering:\n",
    "df_neer_data = ser_eer_data.loc['NEER', All, All, All].unstack('Source').sort_index(axis = 1)\n",
    "### NEER sources looping:\n",
    "dict_neer_combined = {}\n",
    "set_prev_countries = set()\n",
    "for iter_source in df_neer_data.columns:\n",
    "    ### Selecting unique NEER source countries    \n",
    "    set_iter_countries = set(df_neer_data[iter_source].dropna().index.get_level_values(1).unique()) - set_prev_countries\n",
    "    set_prev_countries = set_prev_countries | set_iter_countries\n",
    "    print('NEER:', iter_source, len(set_iter_countries), set_iter_countries)    \n",
    "    ### Creating dataset from NEER source:    \n",
    "    dict_neer_combined[iter_source.split('-')[1]] = df_neer_data[iter_source].loc[All, set_iter_countries]\n",
    "### NEER combined source creating:    \n",
    "df_neer_combined = pd.concat(dict_neer_combined).reset_index(0).sort_index(level = ['Country', 'Date'])\n",
    "df_neer_combined.columns = ['Source', 'Rate']\n",
    "df_neer_combined.sort_index(level = ['Rate', 'Source'], axis = 1, inplace = True)\n",
    "### NEER ataset saving to xlsx:\n",
    "#df_neer_combined.to_excel(str_path_neer_export, merge_cells = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EER: CORRELLATION STATISTICS GENERATING:\n",
    "\n",
    "### Looping over types:\n",
    "for iter_type in ser_eer_data.index.get_level_values(0).unique():\n",
    "    ### Looping over sources inside the type:            \n",
    "    set_sources = set(ser_eer_data.loc[iter_type, All, All, All].dropna().index.get_level_values(1).unique())\n",
    "    while(set_sources):\n",
    "        iter_main_source  = set_sources.pop()\n",
    "        ### Looping over other sources to compare with looped one by country and by date:\n",
    "        for iter_other_source in set_sources:\n",
    "            df_iter_source = ser_eer_data.loc[iter_type, [iter_main_source, iter_other_source], All, All].dropna().droplevel('Type').unstack('Source')\n",
    "            ### By country bilateral correlation:\n",
    "            ser_iter_country_corr = df_iter_source.groupby('Country').corr().loc[(All, iter_main_source), iter_other_source].droplevel('Source').dropna()\n",
    "            ser_iter_country_corr.plot.bar(figsize = (15, 5), color = '#1f77b4', \n",
    "                                           title = iter_type + ' : ' + iter_main_source + ' vs ' + iter_other_source + ' timeseries correlation')\n",
    "            pd.Series(ser_iter_country_corr.mean(), index = ser_iter_country_corr.index).plot(color = 'Orange')            \n",
    "            plt.show()            \n",
    "            ### By date bilateral correlation:\n",
    "            ser_iter_x_sect_corr = df_iter_source.groupby('Date').corr().loc[(All, iter_main_source), iter_other_source].droplevel('Source').dropna()            \n",
    "            ser_iter_x_sect_corr.plot(figsize = (15, 5), color = '#1f77b4', \n",
    "                                      title = iter_type + ' : ' + iter_main_source + ' vs ' + iter_other_source + ' x-sect correlation') \n",
    "            pd.Series(ser_iter_x_sect_corr.mean(), index = ser_iter_x_sect_corr.index).plot(color = 'Orange')            \n",
    "            plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EER: LIMITED GENERAL STATISTICS CALCULATING:\n",
    "\n",
    "arr_eer_stats = []\n",
    "### Excluding NEER/CTG source & REER/BB source\n",
    "ser_eer_limited = pd.concat([ser_eer_data.loc['NEER', ['BB', 'JPM'], All, All], ser_eer_data.loc['REER', ['CTG', 'JPM'], All, All]])\n",
    "ser_eer_limited.groupby(['Type', 'Source']).count()\n",
    "### Looping over types:\n",
    "for iter_type in ser_eer_limited.index.get_level_values(0).unique():\n",
    "    dict_type_stats = {}\n",
    "    dict_type_countries = {}\n",
    "    ### Preliminary looping over sources inside the type for countries lists creating:\n",
    "    for iter_source in ser_eer_limited.loc[iter_type, All, All, All].index.get_level_values(1).unique():\n",
    "        ser_iter_eer = ser_eer_limited.loc[iter_type, iter_source, All, All].dropna()\n",
    "        dict_type_countries[iter_source] = set(ser_iter_eer.index.get_level_values(-1).unique())\n",
    "    set_type_sources = set(dict_type_countries.keys())\n",
    "    ### Looping over sources inside the type:            \n",
    "    for iter_source in ser_eer_limited.loc[iter_type, All, All, All].index.get_level_values(1).unique():            \n",
    "        dict_iter_stats = {}\n",
    "        ### Data filtering by type and source:\n",
    "        ser_iter_eer = ser_eer_limited.loc[iter_type, iter_source, All, All].dropna()\n",
    "        ### General stats:\n",
    "        dict_iter_stats['Non-empty observations'] = [ser_iter_eer.count()]        \n",
    "        dict_iter_stats['Earliest date'] = [sorted(list(ser_iter_eer.index.get_level_values(2).unique()))[0].strftime('%Y-%m-%d')]\n",
    "        dict_iter_stats['Latest date'] = [sorted(list(ser_iter_eer.index.get_level_values(2).unique()))[-1].strftime('%Y-%m-%d')]   \n",
    "        dict_iter_stats['Dates between'] = [(sorted(list(ser_iter_eer.index.get_level_values(2).unique()))[-1] -\\\n",
    "                                            sorted(list(ser_iter_eer.index.get_level_values(2).unique()))[0]).days]    \n",
    "        ### Country grouping:\n",
    "        ser_iter_country_count = ser_iter_eer.groupby('Country').count()\n",
    "        dict_iter_stats['Non-empty countries number'] = [ser_iter_country_count.count()]\n",
    "        dict_iter_stats['Average observations for country'] = [round(ser_iter_country_count.mean())]\n",
    "        ### Cross-section:\n",
    "        ser_iter_date_count = ser_iter_eer.groupby('Date').count()\n",
    "        dict_iter_stats['Non-empty dates number'] = [ser_iter_date_count.count()]\n",
    "        dict_iter_stats['Average observations for date'] = [round(ser_iter_date_count.mean())]        \n",
    "        ### Unique countries for particular source:\n",
    "        iter_others = list(filter(lambda l_source: l_source != iter_source, set_type_sources))\n",
    "        list_iter_unique = sorted(dict_type_countries[iter_source] - dict_type_countries[iter_others[0]])\n",
    "        dict_iter_stats['Unique countries'] = [len(list_iter_unique)]\n",
    "        ### Converting data to oneline dataframe for future collecting:\n",
    "        dict_type_stats[iter_source] = pd.DataFrame.from_dict(dict_iter_stats, orient = 'index', columns = [iter_type])\n",
    "    ### Total stats for particular type:\n",
    "    dict_iter_stats = {}\n",
    "    ser_iter_eer = ser_eer_limited.loc[iter_type, All, All, All].dropna().groupby(['Date', 'Country']).mean()\n",
    "    ### General stats:\n",
    "    dict_iter_stats['Non-empty observations'] = [ser_iter_eer.count()]        \n",
    "    dict_iter_stats['Earliest date'] = [sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[0].strftime('%Y-%m-%d')]\n",
    "    dict_iter_stats['Latest date'] = [sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[-1].strftime('%Y-%m-%d')]   \n",
    "    dict_iter_stats['Dates between'] = [(sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[-1] -\\\n",
    "                                        sorted(list(ser_iter_eer.index.get_level_values(0).unique()))[0]).days]    \n",
    "    ### Country grouping:\n",
    "    ser_iter_country_count = ser_iter_eer.groupby('Country').count()\n",
    "    dict_iter_stats['Non-empty countries number'] = [ser_iter_country_count.count()]\n",
    "    dict_iter_stats['Average observations for country'] = [round(ser_iter_country_count.mean())]\n",
    "    ### Cross-section:\n",
    "    ser_iter_date_count = ser_iter_eer.groupby('Date').count()\n",
    "    dict_iter_stats['Non-empty dates number'] = [ser_iter_date_count.count()]\n",
    "    dict_iter_stats['Average observations for date'] = [round(ser_iter_date_count.mean())]        \n",
    "    ### Unique countries for particular source:\n",
    "    dict_iter_stats['Unique countries'] = [ser_iter_country_count.count()]\n",
    "    ### Converting data to oneline dataframe for future collecting:\n",
    "    dict_type_stats['Total (mean)'] = pd.DataFrame.from_dict(dict_iter_stats, orient = 'index', columns = [iter_type])    \n",
    "    ### Collecting stats for source:\n",
    "    arr_eer_stats.append(pd.concat(dict_type_stats, axis = 1, sort = False).swaplevel(axis = 1))    \n",
    "### Statistics aggregating:\n",
    "df_eer_stats = pd.concat(arr_eer_stats, axis = 1)\n",
    "### Statistics output:\n",
    "print('Limited general statistics:')\n",
    "df_eer_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EER: INFORMATION ABOUT EXCLUDING SOURCES: NEER / CTG (ONE UNIQUE COUNTRY) & REER / BB (TOO LATE DATA)\n",
    "\n",
    "### NEER / Citygroup unique countries:\n",
    "set_ctg_countries = set(ser_eer_data.loc['NEER', 'CTG', All, All].dropna().index.get_level_values(3).unique())\n",
    "set_other_countries = set(ser_eer_data.loc['NEER', ['BB', 'JPM'], All, All].dropna().index.get_level_values(3).unique())\n",
    "print('NEER / CTG unique countries:\\n', sorted(set_ctg_countries.difference(set_other_countries)))\n",
    "print('NEER overall missed countries (including unique ones from CTG):\\n', sorted(set_ison_countries.difference(set_other_countries)))\n",
    "### REER / Bloomberg unique countries:\n",
    "set_bb_countries = set(ser_eer_data.loc['REER', 'BB', All, All].dropna().index.get_level_values(3).unique())\n",
    "set_other_countries = set(ser_eer_data.loc['REER', ['CTG', 'JPM'], All, All].dropna().index.get_level_values(3).unique())\n",
    "print('REER / BB unique countries:\\n', sorted(set_bb_countries.difference(set_other_countries)))\n",
    "print('REER overall missed countries (including unique ones from BB):\\n', sorted(set_ison_countries.difference(set_other_countries)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
