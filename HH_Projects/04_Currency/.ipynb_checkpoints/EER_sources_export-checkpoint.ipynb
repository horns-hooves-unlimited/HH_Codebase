{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BLOOMBERG RAW DATA CONVERTING TO DATAFRAMES AND SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INITIALIZATION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from openpyxl import load_workbook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL DATA PREPARATION\n",
    "\n",
    "### Constants:\n",
    "All = slice(None)\n",
    "### Universe path:\n",
    "str_path_universe = 'Data_Files/Source_Files/acadian_universe.xlsx'\n",
    "### Data source:\n",
    "str_path_bb_tr_d_source = 'Data_Files/Source_Files/Bloomberg_TR_daily.xlsx'\n",
    "str_path_bb_tr_m_source = 'Data_Files/Source_Files/Bloomberg_TR_monthly.xlsx'\n",
    "str_path_bb_mmr_source = 'Data_Files/Source_Files/Bloomberg_MMR.xlsx'\n",
    "str_path_bb_fx_source = 'Data_Files/Source_Files/Bloomberg_FX.xlsx'\n",
    "str_path_bb_mcap_source = 'Data_Files/Source_Files/Bloomberg_MCap.xlsx'\n",
    "str_bb_mcap_def_sheet = 'Market Cap MIXED Const'\n",
    "str_path_bb_eer_source = 'Data_Files/Source_Files/Bloomberg_EER.xlsx'\n",
    "str_path_bb_xcra_source = 'Data_Files/Source_Files/Bloomberg_XCRA.xlsx'\n",
    "### Ret TR options:\n",
    "int_type_start = 8\n",
    "int_type_end = -6\n",
    "date_start = date(1990, 1, 1)\n",
    "date_end = date(2020, 8, 31)\n",
    "date_old_msci_border = date(1998, 12, 31)\n",
    "### MMR options:\n",
    "dict_mmr_replace = {'Cl': 'CI'}\n",
    "### EER options:\n",
    "dict_eer_sources = {'JPM REER B C D': 'REER 01-JPM', 'CTG REER B D': 'REER 02-CTG', 'IMF REER B M': 'REER 03-IMF', 'BIS REER B M': 'REER 04-BIS',\n",
    "                    'JPM NEER B D': 'NEER 01-JPM', 'CTG REER B D (2)': 'NEER 02-CTG', 'BIS NEER B D': 'NEER 03-BIS'}\n",
    "### XCRA options:\n",
    "int_rolling_win_max = 12\n",
    "int_rolling_win_min = int_rolling_win_max // 2\n",
    "### Results saving:\n",
    "str_path_bb_hdf = 'Data_Files/Source_Files/Bloomberg_prepared.h5'\n",
    "str_key_ret_daily = 'bb_ret_daily'\n",
    "str_key_ret_monthly = 'bb_ret_monthly'\n",
    "str_key_mmr = 'bb_mmr'\n",
    "str_key_fx_country = 'bb_fx_country'\n",
    "str_key_fx_currency = 'bb_fx_currency'\n",
    "str_key_mcap = 'bb_mcap'\n",
    "str_key_reer = 'bb_reer'\n",
    "str_key_neer = 'bb_neer'\n",
    "str_key_xcra = 'bb_xcra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION UNIVERSE DATA FROM MS EXCEL SOURCE\n",
    "\n",
    "def ison_membership_converting(str_path_universe, date_end):\n",
    "    ### Defining business-month-end reindexation on country level:\n",
    "    def country_modify(ser_raw_country, date_end):\n",
    "        ser_res_country = ser_raw_country.droplevel(0).resample('MS').last().resample('BM').last()\n",
    "        range_country = pd.date_range(ser_res_country.index[0], date_end, freq = 'BM')\n",
    "        return ser_res_country.reindex(range_country).ffill()\n",
    "    ### Markets encoding table:\n",
    "    dict_markets = {50 : 'DM', 57 : 'EM', 504 : 'FM', 0: np.NaN}     \n",
    "    ### Loading source file:\n",
    "    df_raw_universe = pd.read_excel(io = str_path_universe, sheet_name = 0, header = 0, parse_dates = True, index_col = [0, 1],\n",
    "                                 na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                             '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null'], keep_default_na = False)\n",
    "    ### Converting source file:\n",
    "    df_raw_universe.index.names = ['Country', 'Date']\n",
    "    ser_raw_universe = df_raw_universe['Region']\n",
    "    ser_raw_universe.fillna(0, inplace = True)\n",
    "    ser_raw_universe.name = 'Market'\n",
    "    ### By country reindexation and translation:\n",
    "    ser_res_universe = ser_raw_universe.groupby('Country').apply(country_modify, date_end)\n",
    "    ser_res_universe.index.names = ['Country', 'Date']\n",
    "    ser_res_universe = ser_res_universe.replace(dict_markets).reorder_levels([1, 0]).sort_index()    \n",
    "    ### Results output:\n",
    "    return ser_res_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING DATE/COUNTRY DATA VECTOR DESCRIBER FUNCTION\n",
    "\n",
    "def date_country_vector_describer(ser_data, ser_ison):\n",
    "    ### ISON countries set:\n",
    "    set_ison_countries = set(ser_ison.index.get_level_values(1).unique())\n",
    "    ### Vector countries set:    \n",
    "    set_vector_countries = set(ser_data.dropna().index.get_level_values(1).unique())    \n",
    "    ### Vector completeness:\n",
    "    print('Data vector name: {}'.format(ser_data.name))\n",
    "    print('Data vector completeness: {:.2%}'.format(ser_data.count() / len(ser_data.index))) \n",
    "    print('ISON countries completeness: {:.2%} ({} / {})'.format(len(set_vector_countries.intersection(set_ison_countries)) / len(set_ison_countries),\n",
    "                                                                 len(set_vector_countries.intersection(set_ison_countries)),\n",
    "                                                                 len(set_ison_countries)))\n",
    "    print('Absent ISON countries: [{}]'.format(str(', '.join(sorted(list(set_ison_countries - set_vector_countries))))))\n",
    "    ### ISON Universe binding (if needed):\n",
    "    if not ('Market' in ser_data.index.names):\n",
    "        ser_data = ser_data.to_frame().join(ser_ison, how = 'left').set_index('Market', append = True).squeeze()\\\n",
    "                                      .loc[All, All, ['DM', 'EM', 'FM']].sort_index(level = ['Date', 'Country'])\n",
    "    ### Dates for heatmap x-axis labeles:\n",
    "    list_idx_dates = ser_data.index.get_level_values('Date').unique()\n",
    "    ### Dates reindexation (adding NaN values for absent observations):\n",
    "    ser_region_data = ser_data.loc[All, All, ['DM', 'EM', 'FM']].droplevel('Market').unstack('Country').reindex(list_idx_dates).stack('Country', dropna = False)      \n",
    "    ### Countries number for heatmap height defining:\n",
    "    int_fig_height = len(ser_region_data.index.get_level_values('Country').unique())    \n",
    "    ### Adding shade column for future heatmap striping:\n",
    "    list_countries = list(ser_region_data.index.get_level_values('Country').unique())\n",
    "    dict_countries = dict(zip(list_countries, map(lambda iter_num: iter_num % 2 + 2, range(len(list_countries)))))\n",
    "    df_region_shades = ser_region_data.to_frame().assign(Shade = list(map(dict_countries.get, ser_region_data.index.get_level_values('Country'))))\n",
    "    df_region_shades.columns = ['Data', 'Shade']\n",
    "    ### Heatmap drawing:\n",
    "    fig_heatmap = plt.figure(figsize = (15, int_fig_height // 5))\n",
    "    df_region_data = (df_region_shades['Data'] / df_region_shades['Data'] * df_region_shades['Shade']).unstack('Date').sort_index()\n",
    "    df_region_data.columns = df_region_data.columns.strftime('%d-%m-%Y')\n",
    "    ax_heatmap = sns.heatmap(df_region_data, cbar = False, annot = False, cmap = 'binary', xticklabels = 'auto', yticklabels = True, \n",
    "                             vmin = 0.0, vmax = 6.0)\n",
    "    ax_heatmap.set_title('ISON Universe')    \n",
    "    ### Visualizer heatmap plotting:        \n",
    "    for str_region_code, ser_region_data in ser_data.groupby('Market'):\n",
    "        ### Dates reindexation (adding NaN values for absent observations):\n",
    "        ser_region_data = ser_region_data.droplevel('Market').unstack('Country').reindex(list_idx_dates).stack('Country', dropna = False)   \n",
    "        ### Countries number for heatmap height defining:        \n",
    "        int_fig_height = len(ser_region_data.index.get_level_values('Country').unique())\n",
    "        ### Adding shade column for future heatmap striping:\n",
    "        list_countries = list(ser_region_data.index.get_level_values('Country').unique())\n",
    "        dict_countries = dict(zip(list_countries, map(lambda iter_num: iter_num % 2 + 2, range(len(list_countries)))))\n",
    "        df_region_shades = ser_region_data.to_frame().assign(Shade = list(map(dict_countries.get, ser_region_data.index.get_level_values('Country'))))\n",
    "        df_region_shades.columns = ['Data', 'Shade']\n",
    "        ### Heatmap drawing:\n",
    "        fig_heatmap = plt.figure(figsize = (15, int_fig_height // 5))\n",
    "        df_region_data = (df_region_shades['Data'] / df_region_shades['Data'] * df_region_shades['Shade']).unstack('Date').sort_index()\n",
    "        df_region_data.columns = df_region_data.columns.strftime('%d-%m-%Y')\n",
    "        ax_heatmap = sns.heatmap(df_region_data, cbar = False, annot = False, cmap = 'binary', xticklabels = 'auto', yticklabels = True, \n",
    "                                 vmin = 0.0, vmax = 6.0)\n",
    "        ax_heatmap.set_title(str_region_code)\n",
    "    ### Plots showing:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING FOREIGN EXCHANGE RATES LOADING\n",
    "\n",
    "def fx_export(str_path_bb_fx_source, str_code = 'Code'):\n",
    "    ### Defining country-level function for exchange rate division by factor:\n",
    "    def fx_convertion(ser_fx_code, ser_fx_factor, idx_fx_date_range):    \n",
    "        ### Exchange rate factor extracting:\n",
    "        str_code = ser_fx_code.iloc[: 1].index[0][1]       \n",
    "        num_factor = ser_fx_factor[str_code]\n",
    "        ### Reindexing and dividing exchange rate:\n",
    "        ser_fx_converted = ser_fx_code.droplevel('Code').reindex(idx_fx_date_range).fillna(method = 'ffill') / num_factor\n",
    "        return ser_fx_converted\n",
    "    ### Loading raw excel source:\n",
    "    df_fx_source = pd.read_excel(io = str_path_bb_fx_source, sheet_name = 'FX Data', skiprows = list(range(2, 8)), index_col = 0, header = [0, 1], parse_dates = True, \n",
    "                                    na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '#N/A Requesting Data...', \n",
    "                                                 '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    ser_fx_data = df_fx_source.stack([0, 1])\n",
    "    ### Adding USD rates:\n",
    "    ser_fx_usd = pd.Series(1, index = pd.MultiIndex.from_product([ser_fx_data.index.get_level_values(0).unique(), ['US'], ['USD']], names = ser_fx_data.index.names))\n",
    "    ser_fx_data = pd.concat([ser_fx_data, ser_fx_usd], sort = False).sort_index()\n",
    "    ### Dropping redundant index level:    \n",
    "    if (str_code == 'Country'):\n",
    "        ser_fx_data = ser_fx_data.droplevel(2)\n",
    "    else:\n",
    "        ser_fx_data = ser_fx_data.droplevel(1)\n",
    "        ser_fx_data = ser_fx_data[~ser_fx_data.index.duplicated()]\n",
    "    ser_fx_data.index.names = ['Date', 'Code']\n",
    "    ser_fx_data.name = 'FX'    \n",
    "    ### Extracting factor:\n",
    "    df_fx_factor = pd.read_excel(io = str_path_bb_fx_source, index_col = 0, header = [0, 1], nrows = 1, \n",
    "                                  na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                               'nan', 'null', '#N/A Invalid Security', '#N/A Requesting Data...'], keep_default_na = False)    \n",
    "    ser_fx_factor = df_fx_factor.stack([0, 1]).droplevel(0)\n",
    "    if (str_code == 'Country'):\n",
    "        ser_fx_factor = ser_fx_factor.droplevel(1)\n",
    "    else:\n",
    "        ser_fx_factor = ser_fx_factor.droplevel(0)\n",
    "        ser_fx_factor = ser_fx_factor[~ser_fx_factor.index.duplicated()]\n",
    "    ser_fx_factor.index.names = ['Code']\n",
    "    ser_fx_factor.name = 'Factor'\n",
    "    ### Date range constructing:\n",
    "    date_fx_min = ser_fx_data.index.get_level_values(0).unique().min()\n",
    "    date_fx_max = ser_fx_data.index.get_level_values(0).unique().max()\n",
    "    idx_fx_date_range = pd.date_range(date_fx_min, date_fx_max, freq = 'B')    \n",
    "    ### Results preparing:\n",
    "    ser_fx_ready = ser_fx_data.groupby('Code', group_keys = True).apply(fx_convertion, ser_fx_factor, idx_fx_date_range).squeeze().swaplevel()\n",
    "    ser_fx_ready.index.names = ['Date', str_code]\n",
    "    ser_fx_ready.index = ser_fx_ready.index.set_levels(ser_fx_ready.index.levels[-1].str.upper(), level = -1)\n",
    "    if (str_code == 'Country'):\n",
    "        ser_fx_ready.loc[All, 'US'] = 1\n",
    "    else:\n",
    "        ser_fx_ready.loc[All, 'USD'] = 1\n",
    "    ### Results output:\n",
    "    return ser_fx_ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING TOTAL RETURN INDEXES LOADING\n",
    "\n",
    "def tot_ret_ind_export(str_path_bb_tr_source, str_currency = 'DEF'):\n",
    "    ### Receiving workbook sheetnames: \n",
    "    list_tr_all_sheets = load_workbook(str_path_bb_tr_source, read_only = True).sheetnames\n",
    "    ### Selecting needed sheetnames:\n",
    "    list_tr_def_sheets = [str_iter_sheet for str_iter_sheet in list_tr_all_sheets if str_currency in str_iter_sheet]\n",
    "    ### Loading raw excel source:\n",
    "    dict_tr_source = pd.read_excel(io = str_path_bb_tr_source, sheet_name = list_tr_def_sheets, skiprows = list(range(15)) + list(range(16, 27)), \n",
    "                                 index_col = 0, header = [0, 1], parse_dates = True, \n",
    "                                 na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', \n",
    "                                              '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security', \n",
    "                                              '#N/A Mandatory parameter [SECURITY] cannot be empty', '#N/A Requesting Data...'], \n",
    "                                 keep_default_na = False)\n",
    "    ### Preparing datasets concatenation:\n",
    "    dict_tr_data = {}\n",
    "    for str_sheet_name in list_tr_def_sheets:\n",
    "        ### Type setting:\n",
    "        str_ind_type = str_sheet_name[int_type_start : int_type_end]\n",
    "        ### Flatenning multicolumns to easier stack:\n",
    "        dict_tr_source[str_sheet_name].columns = ['_'.join(iter_pair) for iter_pair in dict_tr_source[str_sheet_name].columns.values]\n",
    "        ser_iter_source = dict_tr_source[str_sheet_name].stack(dropna = False).squeeze()        \n",
    "        ser_iter_source.index.names = ['Date', 'Currency_Country']\n",
    "        ### Data aggregation for concatenation:\n",
    "        dict_tr_data[str_ind_type] = ser_iter_source\n",
    "    ### Consolidated dataset preparing:\n",
    "    ser_tr_raw_data = pd.concat(dict_tr_data, sort = False)\n",
    "    ser_tr_raw_data.index.names = ['Type', 'Date', 'Currency_Country']\n",
    "    df_tr_raw_data = ser_tr_raw_data.reset_index(['Type', 'Date'])\n",
    "    ### Two levels from flattened index:\n",
    "    df_tr_raw_data.index = [df_tr_raw_data.index.str[ : 3], df_tr_raw_data.index.str[-2 : ]]\n",
    "    ser_tr_indexed = df_tr_raw_data.set_index(['Type', 'Date'], append = True).squeeze()\n",
    "    ser_tr_indexed.index.names = ['Currency', 'Country', 'Type', 'Date']\n",
    "    ser_tr_indexed = ser_tr_indexed.reset_index('Currency').replace('#N/', np.NaN).dropna(how = 'all').set_index('Currency', append = True).squeeze()\\\n",
    "                                   .reorder_levels([1, 2, 3, 0])\n",
    "    ser_tr_indexed.name = 'TRI'  \n",
    "    ### Results output:\n",
    "    return ser_tr_indexed   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_ret_ind_d_converter(ser_tr_raw, ser_fx_country, date_start, date_end, daily_only = True):\n",
    "    ### Business dates indexes:\n",
    "    idx_ret_daily = pd.date_range(date_start, date_end, freq = 'B')\n",
    "    idx_old_msci_to_kill = pd.date_range(date_start, date_old_msci_border, freq = 'B')[:-1] ### To avoid fake daily returns\n",
    "    idx_ret_monthly = pd.date_range(date_start, date_end, freq = 'BM')    \n",
    "    ### TRI reindexation:\n",
    "    ser_tr_reindexed = ser_tr_raw.reindex(idx_ret_daily, level = 'Date')\n",
    "    ser_tr_reindexed = ser_tr_reindexed.groupby(['Type', 'Currency', 'Country']).fillna(method = 'ffill').sort_index(level = ['Type', 'Country', 'Currency', 'Date'])\n",
    "    ### Source returns calculation:\n",
    "    ser_ret_source = ser_tr_reindexed.groupby(['Type', 'Currency', 'Country']).apply(lambda iter_group: iter_group / iter_group.shift(1) - 1)\n",
    "    ser_ret_source.name = 'Returns Default'    \n",
    "    ### Killing repeated TRI convertion results:\n",
    "    ser_ret_source.loc[ser_ret_source == 0] = np.NaN\n",
    "    ### Killing fake daily retuns for OLd MSCI indexes:\n",
    "    ser_ret_source.loc['Old MSCI', idx_old_msci_to_kill, All, All] = np.NaN\n",
    "    ### FX index preparation:\n",
    "    ser_fx_index = ser_fx_country.reindex(idx_ret_daily, level = 'Date')\n",
    "    ser_fx_index = ser_fx_index.groupby('Country').fillna(method = 'ffill').sort_index(level = ['Country', 'Date'])\n",
    "    ser_fx_index = ser_fx_index.groupby('Country').apply(lambda iter_group: iter_group / iter_group.shift(1))\n",
    "    ser_fx_index.index.names = ['Date', 'Country']\n",
    "    ser_fx_index.name = 'FX Index'\n",
    "    ### Returns and fx data aggregation:\n",
    "    df_ret_fx_source = ser_ret_source.to_frame().join(ser_fx_index, on = ['Date', 'Country'], how = 'left')    \n",
    "    ### Currency indexes defining:\n",
    "    idx_ret_usd = df_ret_fx_source.loc[(All, All, 'USD', All), All].index\n",
    "    idx_ret_loc = df_ret_fx_source.loc[~df_ret_fx_source.index.isin(['USD'], level = 'Currency')].index\n",
    "    ### Adding future data columns:\n",
    "    df_ret_fx_source['Returns LOC'] = np.NaN\n",
    "    df_ret_fx_source['Returns USD'] = np.NaN\n",
    "    ### Copying default values to proper columns:\n",
    "    df_ret_fx_source.loc[idx_ret_usd, 'Returns USD'] = df_ret_fx_source.loc[idx_ret_usd, 'Returns Default']\n",
    "    df_ret_fx_source.loc[idx_ret_loc, 'Returns LOC'] = df_ret_fx_source.loc[idx_ret_loc, 'Returns Default']\n",
    "    ### Calculating non-default values:\n",
    "    df_ret_fx_source.loc[idx_ret_loc, 'Returns USD'] = (1 + df_ret_fx_source.loc[idx_ret_loc, 'Returns Default']) * df_ret_fx_source.loc[idx_ret_loc, 'FX Index'] - 1\n",
    "    df_ret_fx_source.loc[idx_ret_usd, 'Returns LOC'] = (1 + df_ret_fx_source.loc[idx_ret_usd, 'Returns Default']) / df_ret_fx_source.loc[idx_ret_usd, 'FX Index'] - 1\n",
    "    ### Daily returns dataset preparing:\n",
    "    df_ret_daily = df_ret_fx_source[['Returns LOC', 'Returns USD']].droplevel('Currency')   \n",
    "    ### Converting dataframe to series with new index level:\n",
    "    ser_ret_daily_loc = df_ret_daily['Returns LOC'].to_frame().assign(Currency = 'LOC').set_index('Currency', append = True).squeeze()\n",
    "    ser_ret_daily_usd = df_ret_daily['Returns USD'].to_frame().assign(Currency = 'USD').set_index('Currency', append = True).squeeze()\n",
    "    ser_ret_daily = ser_ret_daily_loc.append(ser_ret_daily_usd).sort_index()\n",
    "    ser_ret_daily.name = 'Returns'  \n",
    "    ### Daily returns collapsing by priority:\n",
    "    ser_ret_daily = ser_ret_daily.unstack('Type').groupby(['Currency', 'Country'], group_keys = False).apply(lambda iter_group: iter_group['MSCI']\\\n",
    "                                                                                                                       .combine_first(iter_group['Old MSCI'])\n",
    "                                                                                                                       .combine_first(iter_group['Main Index']))\n",
    "    ser_ret_daily = ser_ret_daily.reorder_levels(['Currency', 'Date', 'Country']).sort_index()   \n",
    "    ### Daily TRI reconstruction for monthly returns calculation:\n",
    "    ser_tri_daily = (1 + ser_ret_daily.fillna(0))\n",
    "    ### Monthly TRI calculation:\n",
    "    ser_tri_monthly = ser_tri_daily.unstack(['Currency', 'Country']).resample('MS', level = 'Date').prod().resample('BM').last().stack(['Currency', 'Country'])\n",
    "    ### Monthly returns construction:\n",
    "    ser_ret_monthly = ser_tri_monthly - 1\n",
    "    ser_ret_monthly.replace({0: np.NaN}, inplace = True)\n",
    "    ser_ret_monthly = ser_ret_monthly.reorder_levels(['Currency', 'Date', 'Country'])    \n",
    "    ser_ret_monthly.name = 'Returns'\n",
    "    ### Result output:\n",
    "    return ser_ret_daily, ser_ret_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_ret_ind_m_converter(ser_tr_raw, ser_fx_country, date_start, date_end):\n",
    "    ### Business dates indexes:\n",
    "    idx_ret_daily = pd.date_range(date_start, date_end, freq = 'B')    \n",
    "    idx_ret_monthly = pd.date_range(date_start, date_end, freq = 'BM')    \n",
    "    ### TRI reindexation:\n",
    "    ser_tr_reindexed = ser_tr_raw.groupby(['Type', 'Currency', 'Country']).resample('MS', level = 'Date').last()\\\n",
    "                                 .groupby(['Type', 'Currency', 'Country']).resample('BM', level = 'Date').last()     \n",
    "    ser_tr_reindexed = ser_tr_reindexed.reindex(idx_ret_monthly, level = 'Date')\n",
    "    ser_tr_reindexed = ser_tr_reindexed.groupby(['Type', 'Currency', 'Country']).fillna(method = 'ffill').sort_index(level = ['Type', 'Country', 'Currency', 'Date'])\n",
    "    ### Source returns calculation:\n",
    "    ser_ret_source = ser_tr_reindexed.groupby(['Type', 'Currency', 'Country']).apply(lambda iter_group: iter_group / iter_group.shift(1) - 1)\n",
    "    ser_ret_source.name = 'Returns Default'\n",
    "    ### Killing repeated TRI convertion results:\n",
    "    ser_ret_source.loc[ser_ret_source == 0] = np.NaN\n",
    "    ### FX index preparation:\n",
    "    ser_fx_index = ser_fx_country.reindex(idx_ret_daily, level = 'Date')\n",
    "    ser_fx_index = ser_fx_index.groupby('Country').fillna(method = 'ffill').sort_index(level = ['Country', 'Date'])\n",
    "    ser_fx_index = ser_fx_index.groupby('Country').resample('MS', level = 'Date').last().groupby('Country').resample('BM', level = 'Date').last()    \n",
    "    ser_fx_index = ser_fx_index.groupby('Country').apply(lambda iter_group: iter_group / iter_group.shift(1))\n",
    "    ser_fx_index.index.names = ['Country', 'Date']\n",
    "    ser_fx_index = ser_fx_index.swaplevel()\n",
    "    ser_fx_index.name = 'FX Index'\n",
    "    ### Returns and fx data aggregation:\n",
    "    df_ret_fx_source = ser_ret_source.to_frame().join(ser_fx_index, on = ['Date', 'Country'], how = 'left').reorder_levels(['Type', 'Country', 'Currency', 'Date'])  \n",
    "    ### Currency indexes defining:\n",
    "    idx_ret_usd = df_ret_fx_source.loc[(All, All, 'USD', All), All].index\n",
    "    idx_ret_loc = df_ret_fx_source.loc[~df_ret_fx_source.index.isin(['USD'], level = 'Currency')].index\n",
    "    ### Adding future data columns:\n",
    "    df_ret_fx_source['Returns LOC'] = np.NaN\n",
    "    df_ret_fx_source['Returns USD'] = np.NaN\n",
    "    ### Copying default values to proper columns:\n",
    "    df_ret_fx_source.loc[idx_ret_usd, 'Returns USD'] = df_ret_fx_source.loc[idx_ret_usd, 'Returns Default']\n",
    "    df_ret_fx_source.loc[idx_ret_loc, 'Returns LOC'] = df_ret_fx_source.loc[idx_ret_loc, 'Returns Default']\n",
    "    ### Calculating non-default values:\n",
    "    df_ret_fx_source.loc[idx_ret_loc, 'Returns USD'] = (1 + df_ret_fx_source.loc[idx_ret_loc, 'Returns Default']) * df_ret_fx_source.loc[idx_ret_loc, 'FX Index'] - 1\n",
    "    df_ret_fx_source.loc[idx_ret_usd, 'Returns LOC'] = (1 + df_ret_fx_source.loc[idx_ret_usd, 'Returns Default']) / df_ret_fx_source.loc[idx_ret_usd, 'FX Index'] - 1\n",
    "    ### Daily returns dataset preparing:\n",
    "    df_ret_monthly = df_ret_fx_source[['Returns LOC', 'Returns USD']].droplevel('Currency')   \n",
    "    ### Converting dataframe to series with new index level:\n",
    "    ser_ret_monthly_loc = df_ret_monthly['Returns LOC'].to_frame().assign(Currency = 'LOC').set_index('Currency', append = True).squeeze()\n",
    "    ser_ret_monthly_usd = df_ret_monthly['Returns USD'].to_frame().assign(Currency = 'USD').set_index('Currency', append = True).squeeze()\n",
    "    ser_ret_monthly = ser_ret_monthly_loc.append(ser_ret_monthly_usd).sort_index()\n",
    "    ser_ret_monthly.name = 'Returns'  \n",
    "    ### Daily returns collapsing by priority:\n",
    "    ser_ret_monthly = ser_ret_monthly.unstack('Type').groupby(['Currency', 'Country'], group_keys = False).apply(lambda iter_group: iter_group['MSCI']\\\n",
    "                                                                                                                       .combine_first(iter_group['Old MSCI'])\n",
    "                                                                                                                       .combine_first(iter_group['Main Index']))\n",
    "    ser_ret_monthly = ser_ret_monthly.reorder_levels(['Currency', 'Date', 'Country']).sort_index() \n",
    "    ser_ret_monthly.name = 'Returns'    \n",
    "    ### Result output:\n",
    "    return ser_ret_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING MARKET CAPITALIZATIONS LOADING\n",
    "\n",
    "def mcap_export(str_path_bb_mcap_source, str_bb_mcap_def_sheet, ser_fx_currency, ser_ison_membership):\n",
    "    ### Loading raw excel source:\n",
    "    df_mcap_source = pd.read_excel(io = str_path_bb_mcap_source, sheet_name = str_bb_mcap_def_sheet, index_col = 0, header = 0, skiprows = list(range(28)), \n",
    "                                   parse_dates = True, \n",
    "                                   na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                                'nan', 'null', '#N/A Invalid Security', '#N/A Mandatory parameter [SECURITY] cannot be empty'], keep_default_na = False)  \n",
    "    ser_mcap_stacked = df_mcap_source.stack(dropna = False).squeeze()\n",
    "    ser_mcap_stacked = ser_mcap_stacked.astype('float32')\n",
    "    ser_mcap_stacked.index.names = ['Date', 'Country']\n",
    "    ser_mcap_stacked.name = 'Market Cap Default'\n",
    "    ### Loading MMR source frequencies:\n",
    "    df_mcap_currency = pd.read_excel(io = str_path_bb_mcap_source, sheet_name = str_bb_mcap_def_sheet, index_col = 0, header = 0, skiprows = list(range(10)), nrows = 5, \n",
    "                                     parse_dates = True, \n",
    "                                     na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                                  'nan', 'null', '#N/A Invalid Security', '#N/A Mandatory parameter [SECURITY] cannot be empty', '#N/A Requesting Data...'],\n",
    "                                     keep_default_na = False)\n",
    "    ser_mcap_currency = df_mcap_currency.iloc[4, All].squeeze()\n",
    "    ser_mcap_currency.index.names = ['Country']\n",
    "    ser_mcap_currency.name = 'Currency'\n",
    "    ### Currency adding:\n",
    "    ser_mcap_curr = ser_mcap_stacked.to_frame().join(ser_mcap_currency, how = 'left').set_index('Currency', append = True).squeeze()\n",
    "    ### FX rate adding:\n",
    "    df_mcap_curr = ser_mcap_curr.to_frame().join(ser_fx_currency, on = ['Date', 'Currency'], how = 'left')\n",
    "    ### Market Cap denominating in USD:\n",
    "    df_mcap_curr['Market Cap'] = df_mcap_curr['Market Cap Default'] * df_mcap_curr['FX']\n",
    "    ### Market Cap extracting::\n",
    "    ser_mcap_usd = round(df_mcap_curr.droplevel('Currency')['Market Cap'], 2)\n",
    "    ### Resampling for correct end-of-months dates:\n",
    "    ser_mcap_usd.fillna(0, inplace = True)\n",
    "    ser_mcap_usd = ser_mcap_usd.groupby(['Country']).resample('MS', level = 'Date').last().groupby(['Country']).resample('BM', level = 'Date').last().dropna().swaplevel()\n",
    "    ser_mcap_usd.replace(0, np.NaN, inplace = True)\n",
    "    ### Adding ISON regions to fill all-empty countries\n",
    "    ser_mcap_usd = ser_mcap_usd.to_frame().join(ser_ison_membership, how = 'left').set_index('Market', append = True).squeeze()    \n",
    "    ### Filling values for all-empty countries (only in ISON universe):\n",
    "    list_empty_countries = ser_mcap_usd.groupby('Country').filter(lambda iter_country: iter_country.count() == 0).index.get_level_values(1).unique()\n",
    "    ser_mcap_ison_mean = ser_mcap_usd.groupby(['Date', 'Market']).mean()\n",
    "    ser_mcap_ison_mean.name = 'ISON Mean'\n",
    "    ser_mcap_usd.loc[All, list_empty_countries, All] = ser_mcap_usd.to_frame().join(ser_mcap_ison_mean, on = ['Date', 'Market'], how = 'left')['ISON Mean']\n",
    "    ### Forward-filling all the gaps:\n",
    "    ser_mcap_usd = ser_mcap_usd.groupby(['Country']).ffill().groupby(['Country']).bfill()\n",
    "    \n",
    "    ### Results output:\n",
    "    return ser_mcap_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING MONEY MARKET RATES LOADING\n",
    "\n",
    "def mmr_export(str_path_bb_mmr_source, dict_mmr_replace):\n",
    "    ### Defining multipurpose country-level function: \n",
    "    ###   1) Resampling to BM for monthly tickers\n",
    "    ###   2) Reindexing for BD    \n",
    "    ###   3) Forward filling tickers before combining\n",
    "    ###   4) Combining tickers\n",
    "    def mmr_convertion(df_mmr_country, ser_mmr_freq, idx_mmr_date_range):\n",
    "        ### Forward fillin limit:\n",
    "        num_fill_limit = 23\n",
    "        ### Dictionary for source frequencies:\n",
    "        str_country_code = df_mmr_country.iloc[: 1].index[0][1]\n",
    "        dict_freq = dict(ser_mmr_freq.loc[str_country_code, All].droplevel('Country'))\n",
    "        ### Dictionary for transitional results:\n",
    "        dict_source = {}\n",
    "        ### Looping over sources inside country data:\n",
    "        for chr_freq in dict_freq:\n",
    "            if (dict_freq[chr_freq] == 'M'):\n",
    "                ### Resampling to Business-Month-Ends for monthly frequency (then reindexing for proper date range):\n",
    "                dict_source[chr_freq] = df_mmr_country.loc[All, chr_freq].droplevel('Country').resample('MS').last().resample('BM').last().reindex(idx_mmr_date_range)\n",
    "            elif (dict_freq[chr_freq] == 'D'):\n",
    "                ### Reindexing for proper date range for not monthly frequencies:\n",
    "                dict_source[chr_freq] = df_mmr_country.loc[All, chr_freq].droplevel('Country').reindex(idx_mmr_date_range)\n",
    "        ### Forward filling for primary source:\n",
    "        ser_mmr_country = dict_source[1].fillna(method = 'ffill', limit = num_fill_limit)   \n",
    "        ### Combining (if we have secondary source to combine with):\n",
    "        if (dict_freq[2]):\n",
    "            ### Combining sources (with preliminary forward filling for secondary source):\n",
    "            ser_mmr_country = ser_mmr_country.combine_first(dict_source[2].fillna(method = 'ffill', limit = num_fill_limit)) \n",
    "        ### Results output:\n",
    "        ser_mmr_country = ser_mmr_country.to_frame().assign(Country = str_country_code).set_index('Country', append = True).squeeze().fillna(method = 'ffill')\n",
    "        return ser_mmr_country\n",
    "    ### Loading raw excel source:\n",
    "    df_mmr_source = pd.read_excel(io = str_path_bb_mmr_source, index_col = 0, header = [0, 1], skiprows = [2], parse_dates = True, \n",
    "                                  na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                               'nan', 'null', '#N/A Invalid Security', '#N/A Requesting Data...'], keep_default_na = False)  \n",
    "    df_mmr_stacked = df_mmr_source.stack(['Code', 'Priority'], dropna = False).unstack('Priority')\n",
    "    df_mmr_stacked.index.names = ['Date', 'Country']\n",
    "    ### Loading MMR source frequencies:\n",
    "    df_mmr_freq = pd.read_excel(io = str_path_bb_mmr_source, index_col = 0, header = [0, 1], nrows = 1, parse_dates = True, \n",
    "                                  na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a',\n",
    "                                               'nan', 'null', '#N/A Invalid Security', '#N/A Requesting Data...'], keep_default_na = False)\n",
    "    ser_mmr_freq = df_mmr_freq.stack(['Code', 'Priority'], dropna = False).droplevel(0).replace(np.NaN, '')\n",
    "    ser_mmr_freq.index.names = ['Country', 'Priority']\n",
    "    ### Date range constructing:\n",
    "    date_mmr_min = df_mmr_stacked.index.get_level_values(0).unique().min()\n",
    "    date_mmr_max = df_mmr_stacked.index.get_level_values(0).unique().max()\n",
    "    idx_mmr_date_range = pd.date_range(date_mmr_min, date_mmr_max, freq = 'B')\n",
    "    ### Multi-purpose mmr raw data convertion:\n",
    "    ser_mmr_combined = df_mmr_stacked.groupby('Country', group_keys = False).apply(mmr_convertion, ser_mmr_freq, idx_mmr_date_range).squeeze()\n",
    "    ser_mmr_combined = ser_mmr_combined.reset_index('Country').replace(dict_mmr_replace).set_index('Country', append = True).squeeze()\n",
    "    ser_mmr_combined = ser_mmr_combined / 100.00\n",
    "    ser_mmr_combined.name = 'MMR'\n",
    "    ser_mmr_combined.index.names = ['Date', 'Country']\n",
    "    ### Results output:\n",
    "    return ser_mmr_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINING EXTRACTION BLOOMBERG EER DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def eer_export(str_path_bb_eer_source, dict_eer_sources, bool_unique_countries = True, bool_need_source = False):\n",
    "    ### Defining multipurpose country-level function: \n",
    "    ###   1) Resampling to BM for monthly tickers\n",
    "    ###   2) Reindexing for BD    \n",
    "    def eer_convertion(ser_eer_country, chr_eer_freq, idx_eer_date_range):\n",
    "        ### Country code saving:\n",
    "        str_country_code = ser_eer_country.iloc[: 1].index[0][1]\n",
    "        ### Conditional resampling and reindexing::\n",
    "        if (chr_eer_freq == 'M'):\n",
    "            ### Resampling to Business-Month-Ends for monthly frequency (then reindexing for proper date range):\n",
    "            ser_eer_converted = ser_eer_country.droplevel('Country').resample('MS').last().resample('BM').last().reindex(idx_eer_date_range)\n",
    "        else:\n",
    "            ### Reindexing for proper date range for not monthly frequencies:\n",
    "            ser_eer_converted = ser_eer_country.droplevel('Country').reindex(idx_eer_date_range)\n",
    "        ### Results output:\n",
    "        ser_eer_converted.index.names = ['Date']\n",
    "        return ser_eer_converted    \n",
    "    ### Loading raw excel source:\n",
    "    dict_eer_source = pd.read_excel(io = str_path_bb_eer_source, sheet_name = None, skiprows = list(range(4)), index_col = 0, header = 0, parse_dates = True, \n",
    "                                    na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '#N/A Requesting Data...', \n",
    "                                                 '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    ### Preparing datasets concatenation:\n",
    "    list_eer_data = []\n",
    "    for str_sheet_name in dict_eer_source:\n",
    "        ### Filtering Broad NEER or Broad CPI-Based REER:\n",
    "        if str_sheet_name in dict_eer_sources:\n",
    "            ### Future additional indexes:\n",
    "            list_iter_index = dict_eer_sources[str_sheet_name].split()\n",
    "            ### Checking for monthly frequency:\n",
    "            chr_iter_freq = 'D'\n",
    "            if (str_sheet_name.endswith('M')):\n",
    "                chr_iter_freq = 'M'\n",
    "            ### Stacking county codes for making series:\n",
    "            ser_iter_set = dict_eer_source[str_sheet_name].stack(dropna = False)\n",
    "            ### Main index levels renaming:\n",
    "            ser_iter_set.index.names = ['Date', 'Country']\n",
    "            ### Date range constructing:\n",
    "            date_eer_min = ser_iter_set.index.get_level_values(0).unique().min()\n",
    "            date_eer_max = ser_iter_set.index.get_level_values(0).unique().max()\n",
    "            idx_eer_date_range = pd.date_range(date_eer_min, date_eer_max, freq = 'B')\n",
    "            ### Multi-purpose eer raw data convertion:\n",
    "            ser_iter_eer = ser_iter_set.groupby('Country', group_keys = True).apply(eer_convertion, chr_iter_freq, idx_eer_date_range).squeeze()         \n",
    "            ### Adding index levels for source description:\n",
    "            ser_iter_eer = ser_iter_eer.to_frame().assign(Type = list_iter_index[0])\\\n",
    "                                                  .assign(Source = list_iter_index[1])\\\n",
    "                                                  .set_index(['Type', 'Source'], append = True).squeeze()\n",
    "            ### Data aggregation for concatenation:\n",
    "            list_eer_data.append(ser_iter_eer)\n",
    "    ### Consolidated dataset preparing:\n",
    "    ser_eer_data = pd.concat(list_eer_data, sort = False).reorder_levels([2, 3, 1, 0])    \n",
    "    if (not bool_unique_countries):\n",
    "        ### Results output:\n",
    "        return ser_eer_data\n",
    "    else:\n",
    "        ### REER filtering:\n",
    "        df_reer_data = ser_eer_data.loc['REER', All, All, All].unstack('Source').sort_index(axis = 1)        \n",
    "        ### REER sources looping:\n",
    "        dict_reer_combined = {}\n",
    "        set_prev_countries = set()     \n",
    "        for iter_source in sorted(df_reer_data.columns):\n",
    "            ### Selecting unique REER source countries\n",
    "            set_iter_countries = set(df_reer_data[iter_source].dropna().index.get_level_values(1).unique()) - set_prev_countries\n",
    "            set_prev_countries = set_prev_countries | set_iter_countries\n",
    "            ### Creating dataset from REER source:\n",
    "            dict_reer_combined[iter_source.split('-')[1]] = df_reer_data[iter_source].loc[All, set_iter_countries]\n",
    "        ### REER combined source creating:\n",
    "        df_reer_combined = pd.concat(dict_reer_combined, sort = False).reset_index(0).sort_index(level = ['Date', 'Country'])            \n",
    "        df_reer_combined.columns = ['Source', 'EER']\n",
    "        if (not bool_need_source):            \n",
    "            ser_reer = df_reer_combined['EER']\n",
    "        else:\n",
    "            ser_reer = df_reer_combined.set_index('Source', append = True).squeeze()           \n",
    "        ### NEER filtering:\n",
    "        df_neer_data = ser_eer_data.loc['NEER', All, All, All].unstack('Source').sort_index(axis = 1)        \n",
    "        ### NEER sources looping:\n",
    "        dict_neer_combined = {}\n",
    "        set_prev_countries = set()\n",
    "        for iter_source in sorted(df_neer_data.columns):\n",
    "            ### Selecting unique NEER source countries\n",
    "            set_iter_countries = set(df_neer_data[iter_source].dropna().index.get_level_values(1).unique()) - set_prev_countries\n",
    "            set_prev_countries = set_prev_countries | set_iter_countries\n",
    "            ### Creating dataset from NEER source:\n",
    "            dict_neer_combined[iter_source.split('-')[1]] = df_neer_data[iter_source].loc[All, set_iter_countries]\n",
    "        ### NEER combined source creating:\n",
    "        df_neer_combined = pd.concat(dict_neer_combined, sort = False).reset_index(0).sort_index(level = ['Date', 'Country'])\n",
    "        df_neer_combined.columns = ['Source', 'EER']\n",
    "        if (not bool_need_source):            \n",
    "            ser_neer = df_neer_combined['EER']\n",
    "        else:\n",
    "            ser_neer = df_neer_combined.set_index('Source', append = True).squeeze()\n",
    "        ### Results output:\n",
    "        return (ser_reer, ser_neer)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINING EXTRACTION BLOOMBERG XCRA DATA FROM GENERAL MS EXCEL SOURCE\n",
    "\n",
    "def xcra_export(str_path_bb_xcra_source, bool_fill_and_ma = True):\n",
    "    ### Loading raw excel source:\n",
    "    dict_xcra_source = pd.read_excel(io = str_path_bb_xcra_source, sheet_name = None, skiprows = list(range(5)), index_col = 0, header = 0, parse_dates = True, \n",
    "                                    na_values = ['', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '#N/A Requesting Data...',\n",
    "                                                 '1.#QNAN', 'N/A', 'NULL', 'NaN', 'n/a', 'nan', 'null', '#N/A Invalid Security'], keep_default_na = False)\n",
    "    dict_xcra_stacked = {}\n",
    "    ### Resampling from possible calendar month ends to business month ends:\n",
    "    for iter_concept in dict_xcra_source:\n",
    "        dict_xcra_stacked[iter_concept] = dict_xcra_source[iter_concept].resample('MS').last().resample('BM').last().stack(dropna = False).squeeze()\n",
    "    ### Data consolidating:\n",
    "    df_xcra_stacked = pd.concat(dict_xcra_stacked, axis = 1, sort = False)\n",
    "    df_xcra_stacked.index.names = ['Date', 'Country']    \n",
    "    ### Exit without additional data preparation:\n",
    "    if (not bool_fill_and_ma):\n",
    "        ### Results output:\n",
    "        return df_xcra_stacked\n",
    "    ### Additional data preparation:\n",
    "    else:\n",
    "        ### Imports and Exports annual MA modifying:\n",
    "        df_xcra_stacked[['Imports','Exports']] = df_xcra_stacked[['Imports','Exports']].groupby('Country', group_keys = False)\\\n",
    "                                                                                       .rolling(int_rolling_win_max, int_rolling_win_min).mean()\n",
    "        df_xcra_stacked[['Imports','Exports']] = df_xcra_stacked[['Imports','Exports']] * 12\n",
    "        ### XCRA concepts forward filling and back filling for first observation:\n",
    "        df_xcra_filled = df_xcra_stacked.groupby(['Country']).fillna(method = 'ffill').groupby(['Country']).fillna(method = 'bfill')\n",
    "        ### Results output:\n",
    "        return df_xcra_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN SCRIPT\n",
    "\n",
    "### ISON universe loading:\n",
    "ser_ison = ison_membership_converting(str_path_universe, date_end)\n",
    "### FX data export:\n",
    "ser_fx_country = fx_export(str_path_bb_fx_source, str_code = 'Country')\n",
    "ser_fx_currency = fx_export(str_path_bb_fx_source, str_code = 'Currency')\n",
    "### Returns data export:\n",
    "ser_tr_d_raw = tot_ret_ind_export(str_path_bb_tr_d_source, str_currency = 'DEF')\n",
    "(ser_ret_daily, ser_ret_d_monthly) = tot_ret_ind_d_converter(ser_tr_d_raw, ser_fx_country, date_start, date_end, daily_only = False)\n",
    "ser_tr_m_raw = tot_ret_ind_export(str_path_bb_tr_m_source, str_currency = 'DEF')\n",
    "ser_ret_m_monthly = tot_ret_ind_m_converter(ser_tr_m_raw, ser_fx_country, date_start, date_end)\n",
    "### Market Caps data export:\n",
    "ser_mcap = mcap_export(str_path_bb_mcap_source, str_bb_mcap_def_sheet, ser_fx_currency, ser_ison)\n",
    "### Money market rates data export:\n",
    "ser_mmr = mmr_export(str_path_bb_mmr_source, dict_mmr_replace)\n",
    "### Effective exchange rate data export:\n",
    "(ser_reer, ser_neer) = eer_export(str_path_bb_eer_source, dict_eer_sources)\n",
    "### GDP, Export, Import, Current Account data export:\n",
    "df_xcra_filled = xcra_export(str_path_bb_xcra_source)\n",
    "### Data saving:\n",
    "ser_fx_country.to_hdf(str_path_bb_hdf, key = str_key_fx_country, mode = 'w')\n",
    "ser_fx_currency.to_hdf(str_path_bb_hdf, key = str_key_fx_currency, mode = 'r+')\n",
    "ser_ret_daily.to_hdf(str_path_bb_hdf, key = str_key_ret_daily, mode = 'r+')\n",
    "ser_ret_m_monthly.to_hdf(str_path_bb_hdf, key = str_key_ret_monthly, mode = 'r+')\n",
    "ser_mmr.to_hdf(str_path_bb_hdf, key = str_key_mmr, mode = 'r+')\n",
    "ser_mcap.to_hdf(str_path_bb_hdf, key = str_key_mcap, mode = 'r+')\n",
    "ser_reer.to_hdf(str_path_bb_hdf, key = str_key_reer, mode = 'r+')\n",
    "ser_neer.to_hdf(str_path_bb_hdf, key = str_key_neer, mode = 'r+')\n",
    "df_xcra_filled.to_hdf(str_path_bb_hdf, key = str_key_xcra, mode = 'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING: DATASETS EXPORT FOR MATLAB PERFORMING\n",
    "\n",
    "#ser_fx_country = pd.read_hdf(str_path_bb_hdf, key = str_key_fx_country)\n",
    "#ser_fx_country.to_excel('Data_Files/Test_Files/Saved_FX.xlsx', merge_cells = False)\n",
    "#ser_reer = pd.read_hdf(str_path_bb_hdf, key = str_key_reer)\n",
    "#ser_reer.to_excel('Data_Files/Test_Files/Saved_REER.xlsx', merge_cells = False)\n",
    "#ser_neer = pd.read_hdf(str_path_bb_hdf, key = str_key_neer)\n",
    "#ser_neer.to_excel('Data_Files/Test_Files/Saved_NEER.xlsx', merge_cells = False)\n",
    "#df_xcra_filled = pd.read_hdf(str_path_bb_hdf, key = str_key_xcra)\n",
    "#df_xcra_filled.to_excel('Data_Files/Test_Files/XCRA_ISON.xlsx', merge_cells = False)\n",
    "#ser_ison = ison_membership_converting(str_path_universe, date_end)\n",
    "#df_xcra_isoned = df_xcra_filled.join(ser_ison, how = 'left').set_index('Market', append = True).sort_index().loc[(All, All, ['DM', 'EM', 'FM']), All]\n",
    "#df_xcra_isoned.to_excel('Data_Files/Test_Files/XCRA_ISON_filtered.xlsx', merge_cells = False)\n",
    "#df_xcra_import = xcra_export(str_path_bb_xcra_source, False)\n",
    "#df_xcra_import.to_excel('Data_Files/Test_Files/XCRA_ISON_import.xlsx', merge_cells = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING: DATASETS EXPORT FOR MATLAB PERFORMING\n",
    "\n",
    "### GDP, Export, Import, Current Account data export:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING: COMPARISION MONTHLY RETURNS GENERATED FROM DAILY AND ORIGINAL MONTHLY RETURNS\n",
    "\n",
    "ser_ret_m_monthly.name = 'Monthly Original'\n",
    "ser_ret_d_monthly.name = 'Monthly Generated'\n",
    "df_ret_t_monthly = ser_ret_m_monthly.to_frame().join(ser_ret_d_monthly, how = 'inner')\n",
    "\n",
    "df_ret_t_monthly['Delta'] = (df_ret_t_monthly['Monthly Original'] - df_ret_t_monthly['Monthly Generated']).abs()\n",
    "df_ret_t_monthly[df_ret_t_monthly['Delta'] > 0.01].sort_index(level = ['Currency', 'Country', 'Date']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BD', 'BW', 'LB', 'LK', 'MU', 'NA']\n",
      "['BD', 'BH', 'BW', 'CI', 'CR', 'LB', 'LK', 'MU', 'NA', 'OM']\n"
     ]
    }
   ],
   "source": [
    "### TESTING: DATA COMPLETENESS: DATA LOADING\n",
    "\n",
    "### Data Loading\n",
    "ser_ison = ison_membership_converting(str_path_universe, date_end)\n",
    "ser_ret_m = pd.read_hdf(str_path_bb_hdf, key = str_key_ret_monthly)\n",
    "ser_ret_d = pd.read_hdf(str_path_bb_hdf, key = str_key_ret_daily)\n",
    "ser_mmr = pd.read_hdf(str_path_bb_hdf, key = str_key_mmr)\n",
    "ser_fx_country = pd.read_hdf(str_path_bb_hdf, key = str_key_fx_country)\n",
    "ser_mcap = pd.read_hdf(str_path_bb_hdf, key = str_key_mcap)\n",
    "ser_reer = pd.read_hdf(str_path_bb_hdf, key = str_key_reer)\n",
    "ser_neer = pd.read_hdf(str_path_bb_hdf, key = str_key_neer)\n",
    "df_xcra_filled = pd.read_hdf(str_path_bb_hdf, key = str_key_xcra)\n",
    "\n",
    "### Data control\n",
    "print(sorted(list(set(ser_ison.index.get_level_values(1).unique()) - set(ser_reer.dropna().index.get_level_values(1).unique()))))\n",
    "print(sorted(list(set(ser_ison.index.get_level_values(1).unique()) - set(ser_neer.dropna().index.get_level_values(1).unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEMP\n",
    "\n",
    "### Sourced data extracting:\n",
    "ser_eer_full = eer_export(str_path_bb_eer_source, dict_eer_sources, bool_unique_countries = False)\n",
    "ser_reer_full = ser_eer_full.loc['REER', All, All, All].droplevel(0).sort_index()\n",
    "ser_neer_full = ser_eer_full.loc['NEER', All, All, All].droplevel(0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Source</th>\n",
       "      <th>01-JPM</th>\n",
       "      <th>02-CTG</th>\n",
       "      <th>03-IMF</th>\n",
       "      <th>04-BIS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>01-JPM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884412</td>\n",
       "      <td>0.877501</td>\n",
       "      <td>0.966533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>02-CTG</td>\n",
       "      <td>0.884412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851774</td>\n",
       "      <td>0.920562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>03-IMF</td>\n",
       "      <td>0.877501</td>\n",
       "      <td>0.851774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>04-BIS</td>\n",
       "      <td>0.966533</td>\n",
       "      <td>0.920562</td>\n",
       "      <td>0.980612</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Source    01-JPM    02-CTG    03-IMF    04-BIS\n",
       "Source                                        \n",
       "01-JPM  1.000000  0.884412  0.877501  0.966533\n",
       "02-CTG  0.884412  1.000000  0.851774  0.920562\n",
       "03-IMF  0.877501  0.851774  1.000000  0.980612\n",
       "04-BIS  0.966533  0.920562  0.980612  1.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEMP\n",
    "\n",
    "\n",
    "ser_reer_full.unstack('Source').groupby('Country').corr().groupby('Source').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING: DATA COMPLETENESS: DATA VISUALIZING\n",
    "\n",
    "#date_country_vector_describer(ser_reer, ser_ison)\n",
    "#date_country_vector_describer(ser_neer, ser_ison)\n",
    "#date_country_vector_describer(ser_ret_m.loc['LOC', All, All].droplevel(0), ser_ison)\n",
    "#date_country_vector_describer(ser_ret_m.loc['USD', All, All].droplevel(0), ser_ison)\n",
    "#date_country_vector_describer(ser_ret_d.loc['LOC', All, All].droplevel(0), ser_ison)\n",
    "#date_country_vector_describer(ser_ret_d.loc['USD', All, All].droplevel(0), ser_ison)\n",
    "#date_country_vector_describer(ser_mmr, ser_ison)\n",
    "#date_country_vector_describer(ser_fx_country, ser_ison)\n",
    "date_country_vector_describer(ser_mcap.droplevel(2), ser_ison)\n",
    "#date_country_vector_describer(df_xcra_filled['Current Account'], ser_ison)\n",
    "#date_country_vector_describer(df_xcra_filled['GDP'], ser_ison)\n",
    "#date_country_vector_describer(df_xcra_filled['Imports'], ser_ison)\n",
    "#date_country_vector_describer(df_xcra_filled['Exports'], ser_ison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
